import * as z from 'zod';
import z__default, { z as z$1, ZodError } from 'zod';
import * as devalue from 'devalue';
import { createRequire } from 'node:module';
import path, { join } from 'node:path';
import { setTimeout as setTimeout$1, scheduler, setImmediate as setImmediate$1 } from 'node:timers/promises';
import process$2, { platform, hrtime, execPath, execArgv } from 'node:process';
import isPlainObject from 'is-plain-obj';
import url, { fileURLToPath } from 'node:url';
import { ChildProcess, execFile, spawnSync, spawn } from 'node:child_process';
import { StringDecoder } from 'node:string_decoder';
import require$$0$6, { debuglog, stripVTControlCharacters, inspect, promisify, callbackify, aborted } from 'node:util';
import { gray, redBright, yellowBright, bold } from 'yoctocolors';
import { c as commonjsGlobal, g as getDefaultExportFromCjs } from './_commonjsHelpers_BFTU3MAI.mjs';
import require$$0$2 from 'child_process';
import require$$0$1 from 'path';
import require$$0 from 'fs';
import os, { constants as constants$5 } from 'node:os';
import require$$8, { once as once$2, addAbortListener, EventEmitter, on, setMaxListeners } from 'node:events';
import { serialize } from 'node:v8';
import { statSync, readFileSync, appendFileSync, writeFileSync, createWriteStream, createReadStream, promises } from 'node:fs';
import tty from 'node:tty';
import require$$0$5, { Transform, getDefaultHighWaterMark, Duplex, Writable, Readable, PassThrough } from 'node:stream';
import require$$0$3, { Buffer as Buffer$1 } from 'node:buffer';
import { finished } from 'node:stream/promises';
import { z as z$2 } from 'zod/v4';
import crypto from 'node:crypto';
import require$$0$4 from 'node:assert';
import require$$4 from 'node:net';
import require$$2 from 'node:http';
import require$$7 from 'node:querystring';
import require$$0$7 from 'node:diagnostics_channel';
import require$$4$1 from 'node:tls';
import require$$1 from 'node:zlib';
import require$$5 from 'node:perf_hooks';
import require$$8$1 from 'node:util/types';
import require$$5$1 from 'node:async_hooks';
import require$$1$1 from 'node:console';
import require$$5$2 from 'string_decoder';
import require$$3 from 'node:worker_threads';
import debug from 'debug';
import ms from 'ms';

var headers$1;
var hasRequiredHeaders$1;

function requireHeaders$1 () {
	if (hasRequiredHeaders$1) return headers$1;
	hasRequiredHeaders$1 = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var headers_exports = {};
	__export(headers_exports, {
	  CITY_HEADER_NAME: () => CITY_HEADER_NAME,
	  COUNTRY_HEADER_NAME: () => COUNTRY_HEADER_NAME,
	  EMOJI_FLAG_UNICODE_STARTING_POSITION: () => EMOJI_FLAG_UNICODE_STARTING_POSITION,
	  IP_HEADER_NAME: () => IP_HEADER_NAME,
	  LATITUDE_HEADER_NAME: () => LATITUDE_HEADER_NAME,
	  LONGITUDE_HEADER_NAME: () => LONGITUDE_HEADER_NAME,
	  POSTAL_CODE_HEADER_NAME: () => POSTAL_CODE_HEADER_NAME,
	  REGION_HEADER_NAME: () => REGION_HEADER_NAME,
	  REQUEST_ID_HEADER_NAME: () => REQUEST_ID_HEADER_NAME,
	  geolocation: () => geolocation,
	  ipAddress: () => ipAddress
	});
	headers$1 = __toCommonJS(headers_exports);
	const CITY_HEADER_NAME = "x-vercel-ip-city";
	const COUNTRY_HEADER_NAME = "x-vercel-ip-country";
	const IP_HEADER_NAME = "x-real-ip";
	const LATITUDE_HEADER_NAME = "x-vercel-ip-latitude";
	const LONGITUDE_HEADER_NAME = "x-vercel-ip-longitude";
	const REGION_HEADER_NAME = "x-vercel-ip-country-region";
	const POSTAL_CODE_HEADER_NAME = "x-vercel-ip-postal-code";
	const REQUEST_ID_HEADER_NAME = "x-vercel-id";
	const EMOJI_FLAG_UNICODE_STARTING_POSITION = 127397;
	function getHeader(headers, key) {
	  return headers.get(key) ?? void 0;
	}
	function getHeaderWithDecode(request, key) {
	  const header = getHeader(request.headers, key);
	  return header ? decodeURIComponent(header) : void 0;
	}
	function getFlag(countryCode) {
	  const regex = new RegExp("^[A-Z]{2}$").test(countryCode);
	  if (!countryCode || !regex)
	    return void 0;
	  return String.fromCodePoint(
	    ...countryCode.split("").map((char) => EMOJI_FLAG_UNICODE_STARTING_POSITION + char.charCodeAt(0))
	  );
	}
	function ipAddress(input) {
	  const headers = "headers" in input ? input.headers : input;
	  return getHeader(headers, IP_HEADER_NAME);
	}
	function getRegionFromRequestId(requestId) {
	  if (!requestId) {
	    return "dev1";
	  }
	  return requestId.split(":")[0];
	}
	function geolocation(request) {
	  return {
	    // city name may be encoded to support multi-byte characters
	    city: getHeaderWithDecode(request, CITY_HEADER_NAME),
	    country: getHeader(request.headers, COUNTRY_HEADER_NAME),
	    flag: getFlag(getHeader(request.headers, COUNTRY_HEADER_NAME)),
	    countryRegion: getHeader(request.headers, REGION_HEADER_NAME),
	    region: getRegionFromRequestId(
	      getHeader(request.headers, REQUEST_ID_HEADER_NAME)
	    ),
	    latitude: getHeader(request.headers, LATITUDE_HEADER_NAME),
	    longitude: getHeader(request.headers, LONGITUDE_HEADER_NAME),
	    postalCode: getHeader(request.headers, POSTAL_CODE_HEADER_NAME)
	  };
	}
	return headers$1;
}

var getEnv_1;
var hasRequiredGetEnv;

function requireGetEnv () {
	if (hasRequiredGetEnv) return getEnv_1;
	hasRequiredGetEnv = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var get_env_exports = {};
	__export(get_env_exports, {
	  getEnv: () => getEnv
	});
	getEnv_1 = __toCommonJS(get_env_exports);
	const getEnv = (env = process.env) => ({
	  /**
	   * An indicator to show that System Environment Variables have been exposed to your project's Deployments.
	   * @example "1"
	   */
	  VERCEL: get(env, "VERCEL"),
	  /**
	   * An indicator that the code is running in a Continuous Integration environment.
	   * @example "1"
	   */
	  CI: get(env, "CI"),
	  /**
	   * The Environment that the app is deployed and running on.
	   * @example "production"
	   */
	  VERCEL_ENV: get(env, "VERCEL_ENV"),
	  /**
	   * The domain name of the generated deployment URL. The value does not include the protocol scheme https://.
	   * NOTE: This Variable cannot be used in conjunction with Standard Deployment Protection.
	   * @example "*.vercel.app"
	   */
	  VERCEL_URL: get(env, "VERCEL_URL"),
	  /**
	   * The domain name of the generated Git branch URL. The value does not include the protocol scheme https://.
	   * @example "*-git-*.vercel.app"
	   */
	  VERCEL_BRANCH_URL: get(env, "VERCEL_BRANCH_URL"),
	  /**
	   * A production domain name of the project. This is useful to reliably generate links that point to production such as OG-image URLs.
	   * The value does not include the protocol scheme https://.
	   * @example "myproject.vercel.app"
	   */
	  VERCEL_PROJECT_PRODUCTION_URL: get(env, "VERCEL_PROJECT_PRODUCTION_URL"),
	  /**
	   * The ID of the Region where the app is running.
	   *
	   * Possible values:
	   * - arn1 (Stockholm, Sweden)
	   * - bom1 (Mumbai, India)
	   * - cdg1 (Paris, France)
	   * - cle1 (Cleveland, USA)
	   * - cpt1 (Cape Town, South Africa)
	   * - dub1 (Dublin, Ireland)
	   * - fra1 (Frankfurt, Germany)
	   * - gru1 (SÃ£o Paulo, Brazil)
	   * - hkg1 (Hong Kong)
	   * - hnd1 (Tokyo, Japan)
	   * - iad1 (Washington, D.C., USA)
	   * - icn1 (Seoul, South Korea)
	   * - kix1 (Osaka, Japan)
	   * - lhr1 (London, United Kingdom)
	   * - pdx1 (Portland, USA)
	   * - sfo1 (San Francisco, USA)
	   * - sin1 (Singapore)
	   * - syd1 (Sydney, Australia)
	   * - dev1 (Development Region)
	   *
	   * @example "iad1"
	   */
	  VERCEL_REGION: get(env, "VERCEL_REGION"),
	  /**
	   * The unique identifier for the deployment, which can be used to implement Skew Protection.
	   * @example "dpl_7Gw5ZMBpQA8h9GF832KGp7nwbuh3"
	   */
	  VERCEL_DEPLOYMENT_ID: get(env, "VERCEL_DEPLOYMENT_ID"),
	  /**
	   * When Skew Protection is enabled in Project Settings, this value is set to 1.
	   * @example "1"
	   */
	  VERCEL_SKEW_PROTECTION_ENABLED: get(env, "VERCEL_SKEW_PROTECTION_ENABLED"),
	  /**
	   * The Protection Bypass for Automation value, if the secret has been generated in the project's Deployment Protection settings.
	   */
	  VERCEL_AUTOMATION_BYPASS_SECRET: get(env, "VERCEL_AUTOMATION_BYPASS_SECRET"),
	  /**
	   * The Git Provider the deployment is triggered from.
	   * @example "github"
	   */
	  VERCEL_GIT_PROVIDER: get(env, "VERCEL_GIT_PROVIDER"),
	  /**
	   * The origin repository the deployment is triggered from.
	   * @example "my-site"
	   */
	  VERCEL_GIT_REPO_SLUG: get(env, "VERCEL_GIT_REPO_SLUG"),
	  /**
	   * The account that owns the repository the deployment is triggered from.
	   * @example "acme"
	   */
	  VERCEL_GIT_REPO_OWNER: get(env, "VERCEL_GIT_REPO_OWNER"),
	  /**
	   * The ID of the repository the deployment is triggered from.
	   * @example "117716146"
	   */
	  VERCEL_GIT_REPO_ID: get(env, "VERCEL_GIT_REPO_ID"),
	  /**
	   * The git branch of the commit the deployment was triggered by.
	   * @example "improve-about-page"
	   */
	  VERCEL_GIT_COMMIT_REF: get(env, "VERCEL_GIT_COMMIT_REF"),
	  /**
	   * The git SHA of the commit the deployment was triggered by.
	   * @example "fa1eade47b73733d6312d5abfad33ce9e4068081"
	   */
	  VERCEL_GIT_COMMIT_SHA: get(env, "VERCEL_GIT_COMMIT_SHA"),
	  /**
	   * The message attached to the commit the deployment was triggered by.
	   * @example "Update about page"
	   */
	  VERCEL_GIT_COMMIT_MESSAGE: get(env, "VERCEL_GIT_COMMIT_MESSAGE"),
	  /**
	   * The username attached to the author of the commit that the project was deployed by.
	   * @example "johndoe"
	   */
	  VERCEL_GIT_COMMIT_AUTHOR_LOGIN: get(env, "VERCEL_GIT_COMMIT_AUTHOR_LOGIN"),
	  /**
	   * The name attached to the author of the commit that the project was deployed by.
	   * @example "John Doe"
	   */
	  VERCEL_GIT_COMMIT_AUTHOR_NAME: get(env, "VERCEL_GIT_COMMIT_AUTHOR_NAME"),
	  /**
	   * The git SHA of the last successful deployment for the project and branch.
	   * NOTE: This Variable is only exposed when an Ignored Build Step is provided.
	   * @example "fa1eade47b73733d6312d5abfad33ce9e4068080"
	   */
	  VERCEL_GIT_PREVIOUS_SHA: get(env, "VERCEL_GIT_PREVIOUS_SHA"),
	  /**
	   * The pull request id the deployment was triggered by. If a deployment is created on a branch before a pull request is made, this value will be an empty string.
	   * @example "23"
	   */
	  VERCEL_GIT_PULL_REQUEST_ID: get(env, "VERCEL_GIT_PULL_REQUEST_ID")
	});
	const get = (env, key) => {
	  const value = env[key];
	  return value === "" ? void 0 : value;
	};
	return getEnv_1;
}

var getContext_1$1;
var hasRequiredGetContext$1;

function requireGetContext$1 () {
	if (hasRequiredGetContext$1) return getContext_1$1;
	hasRequiredGetContext$1 = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var get_context_exports = {};
	__export(get_context_exports, {
	  SYMBOL_FOR_REQ_CONTEXT: () => SYMBOL_FOR_REQ_CONTEXT,
	  getContext: () => getContext
	});
	getContext_1$1 = __toCommonJS(get_context_exports);
	const SYMBOL_FOR_REQ_CONTEXT = Symbol.for("@vercel/request-context");
	function getContext() {
	  const fromSymbol = globalThis;
	  return fromSymbol[SYMBOL_FOR_REQ_CONTEXT]?.get?.() ?? {};
	}
	return getContext_1$1;
}

var waitUntil_1;
var hasRequiredWaitUntil;

function requireWaitUntil () {
	if (hasRequiredWaitUntil) return waitUntil_1;
	hasRequiredWaitUntil = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var wait_until_exports = {};
	__export(wait_until_exports, {
	  waitUntil: () => waitUntil
	});
	waitUntil_1 = __toCommonJS(wait_until_exports);
	var import_get_context = requireGetContext$1();
	const waitUntil = (promise) => {
	  if (promise === null || typeof promise !== "object" || typeof promise.then !== "function") {
	    throw new TypeError(
	      `waitUntil can only be called with a Promise, got ${typeof promise}`
	    );
	  }
	  return (0, import_get_context.getContext)().waitUntil?.(promise);
	};
	return waitUntil_1;
}

var middleware;
var hasRequiredMiddleware;

function requireMiddleware () {
	if (hasRequiredMiddleware) return middleware;
	hasRequiredMiddleware = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var middleware_exports = {};
	__export(middleware_exports, {
	  next: () => next,
	  rewrite: () => rewrite
	});
	middleware = __toCommonJS(middleware_exports);
	function handleMiddlewareField(init, headers) {
	  if (init?.request?.headers) {
	    if (!(init.request.headers instanceof Headers)) {
	      throw new Error("request.headers must be an instance of Headers");
	    }
	    const keys = [];
	    for (const [key, value] of init.request.headers) {
	      headers.set("x-middleware-request-" + key, value);
	      keys.push(key);
	    }
	    headers.set("x-middleware-override-headers", keys.join(","));
	  }
	}
	function rewrite(destination, init) {
	  const headers = new Headers(init?.headers ?? {});
	  headers.set("x-middleware-rewrite", String(destination));
	  handleMiddlewareField(init, headers);
	  return new Response(null, {
	    ...init,
	    headers
	  });
	}
	function next(init) {
	  const headers = new Headers(init?.headers ?? {});
	  headers.set("x-middleware-next", "1");
	  handleMiddlewareField(init, headers);
	  return new Response(null, {
	    ...init,
	    headers
	  });
	}
	return middleware;
}

var inMemoryCache;
var hasRequiredInMemoryCache;

function requireInMemoryCache () {
	if (hasRequiredInMemoryCache) return inMemoryCache;
	hasRequiredInMemoryCache = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var in_memory_cache_exports = {};
	__export(in_memory_cache_exports, {
	  InMemoryCache: () => InMemoryCache
	});
	inMemoryCache = __toCommonJS(in_memory_cache_exports);
	class InMemoryCache {
	  constructor() {
	    this.cache = {};
	  }
	  async get(key) {
	    const entry = this.cache[key];
	    if (entry) {
	      if (entry.ttl && entry.lastModified + entry.ttl * 1e3 < Date.now()) {
	        await this.delete(key);
	        return null;
	      }
	      return entry.value;
	    }
	    return null;
	  }
	  async set(key, value, options) {
	    this.cache[key] = {
	      value,
	      lastModified: Date.now(),
	      ttl: options?.ttl,
	      tags: new Set(options?.tags || [])
	    };
	  }
	  async delete(key) {
	    delete this.cache[key];
	  }
	  async expireTag(tag) {
	    const tags = Array.isArray(tag) ? tag : [tag];
	    for (const key in this.cache) {
	      if (Object.prototype.hasOwnProperty.call(this.cache, key)) {
	        const entry = this.cache[key];
	        if (tags.some((t) => entry.tags.has(t))) {
	          delete this.cache[key];
	        }
	      }
	    }
	  }
	}
	return inMemoryCache;
}

var buildClient;
var hasRequiredBuildClient;

function requireBuildClient () {
	if (hasRequiredBuildClient) return buildClient;
	hasRequiredBuildClient = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var build_client_exports = {};
	__export(build_client_exports, {
	  BuildCache: () => BuildCache
	});
	buildClient = __toCommonJS(build_client_exports);
	var import_index = requireCache$1();
	class BuildCache {
	  constructor({
	    endpoint,
	    headers,
	    onError,
	    timeout = 500
	  }) {
	    this.get = async (key) => {
	      const controller = new AbortController();
	      const timeoutId = setTimeout(() => controller.abort(), this.timeout);
	      try {
	        const res = await fetch(`${this.endpoint}${key}`, {
	          headers: this.headers,
	          method: "GET",
	          signal: controller.signal
	        });
	        if (res.status === 404) {
	          clearTimeout(timeoutId);
	          return null;
	        }
	        if (res.status === 200) {
	          const cacheState = res.headers.get(
	            import_index.HEADERS_VERCEL_CACHE_STATE
	          );
	          if (cacheState !== import_index.PkgCacheState.Fresh) {
	            res.body?.cancel?.();
	            clearTimeout(timeoutId);
	            return null;
	          }
	          const result = await res.json();
	          clearTimeout(timeoutId);
	          return result;
	        } else {
	          clearTimeout(timeoutId);
	          throw new Error(`Failed to get cache: ${res.statusText}`);
	        }
	      } catch (error) {
	        clearTimeout(timeoutId);
	        if (error.name === "AbortError") {
	          const timeoutError = new Error(
	            `Cache request timed out after ${this.timeout}ms`
	          );
	          timeoutError.stack = error.stack;
	          this.onError?.(timeoutError);
	        } else {
	          this.onError?.(error);
	        }
	        return null;
	      }
	    };
	    this.set = async (key, value, options) => {
	      const controller = new AbortController();
	      const timeoutId = setTimeout(() => controller.abort(), this.timeout);
	      try {
	        const optionalHeaders = {};
	        if (options?.ttl) {
	          optionalHeaders[import_index.HEADERS_VERCEL_REVALIDATE] = options.ttl.toString();
	        }
	        if (options?.tags && options.tags.length > 0) {
	          optionalHeaders[import_index.HEADERS_VERCEL_CACHE_TAGS] = options.tags.join(",");
	        }
	        if (options?.name) {
	          optionalHeaders[import_index.HEADERS_VERCEL_CACHE_ITEM_NAME] = options.name;
	        }
	        const res = await fetch(`${this.endpoint}${key}`, {
	          method: "POST",
	          headers: {
	            ...this.headers,
	            ...optionalHeaders
	          },
	          body: JSON.stringify(value),
	          signal: controller.signal
	        });
	        clearTimeout(timeoutId);
	        if (res.status !== 200) {
	          throw new Error(`Failed to set cache: ${res.status} ${res.statusText}`);
	        }
	      } catch (error) {
	        clearTimeout(timeoutId);
	        if (error.name === "AbortError") {
	          const timeoutError = new Error(
	            `Cache request timed out after ${this.timeout}ms`
	          );
	          timeoutError.stack = error.stack;
	          this.onError?.(timeoutError);
	        } else {
	          this.onError?.(error);
	        }
	      }
	    };
	    this.delete = async (key) => {
	      const controller = new AbortController();
	      const timeoutId = setTimeout(() => controller.abort(), this.timeout);
	      try {
	        const res = await fetch(`${this.endpoint}${key}`, {
	          method: "DELETE",
	          headers: this.headers,
	          signal: controller.signal
	        });
	        clearTimeout(timeoutId);
	        if (res.status !== 200) {
	          throw new Error(`Failed to delete cache: ${res.statusText}`);
	        }
	      } catch (error) {
	        clearTimeout(timeoutId);
	        if (error.name === "AbortError") {
	          const timeoutError = new Error(
	            `Cache request timed out after ${this.timeout}ms`
	          );
	          timeoutError.stack = error.stack;
	          this.onError?.(timeoutError);
	        } else {
	          this.onError?.(error);
	        }
	      }
	    };
	    this.expireTag = async (tag) => {
	      const controller = new AbortController();
	      const timeoutId = setTimeout(() => controller.abort(), this.timeout);
	      try {
	        if (Array.isArray(tag)) {
	          tag = tag.join(",");
	        }
	        const res = await fetch(`${this.endpoint}revalidate?tags=${tag}`, {
	          method: "POST",
	          headers: this.headers,
	          signal: controller.signal
	        });
	        clearTimeout(timeoutId);
	        if (res.status !== 200) {
	          throw new Error(`Failed to revalidate tag: ${res.statusText}`);
	        }
	      } catch (error) {
	        clearTimeout(timeoutId);
	        if (error.name === "AbortError") {
	          const timeoutError = new Error(
	            `Cache request timed out after ${this.timeout}ms`
	          );
	          timeoutError.stack = error.stack;
	          this.onError?.(timeoutError);
	        } else {
	          this.onError?.(error);
	        }
	      }
	    };
	    this.endpoint = endpoint;
	    this.headers = headers;
	    this.onError = onError;
	    this.timeout = timeout;
	  }
	}
	return buildClient;
}

var cache$1;
var hasRequiredCache$1;

function requireCache$1 () {
	if (hasRequiredCache$1) return cache$1;
	hasRequiredCache$1 = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var cache_exports = {};
	__export(cache_exports, {
	  HEADERS_VERCEL_CACHE_ITEM_NAME: () => HEADERS_VERCEL_CACHE_ITEM_NAME,
	  HEADERS_VERCEL_CACHE_STATE: () => HEADERS_VERCEL_CACHE_STATE,
	  HEADERS_VERCEL_CACHE_TAGS: () => HEADERS_VERCEL_CACHE_TAGS,
	  HEADERS_VERCEL_REVALIDATE: () => HEADERS_VERCEL_REVALIDATE,
	  PkgCacheState: () => PkgCacheState,
	  getCache: () => getCache
	});
	cache$1 = __toCommonJS(cache_exports);
	var import_get_context = requireGetContext$1();
	var import_in_memory_cache = requireInMemoryCache();
	var import_build_client = requireBuildClient();
	const defaultKeyHashFunction = (key) => {
	  let hash = 5381;
	  for (let i = 0; i < key.length; i++) {
	    hash = hash * 33 ^ key.charCodeAt(i);
	  }
	  return (hash >>> 0).toString(16);
	};
	const defaultNamespaceSeparator = "$";
	let inMemoryCacheInstance = null;
	let buildCacheInstance = null;
	const getCache = (cacheOptions) => {
	  const resolveCache = () => {
	    let cache;
	    if ((0, import_get_context.getContext)().cache) {
	      cache = (0, import_get_context.getContext)().cache;
	    } else {
	      cache = getCacheImplementation(
	        process.env.SUSPENSE_CACHE_DEBUG === "true"
	      );
	    }
	    return cache;
	  };
	  return wrapWithKeyTransformation(
	    resolveCache,
	    createKeyTransformer(cacheOptions)
	  );
	};
	function createKeyTransformer(cacheOptions) {
	  const hashFunction = cacheOptions?.keyHashFunction || defaultKeyHashFunction;
	  return (key) => {
	    if (!cacheOptions?.namespace)
	      return hashFunction(key);
	    const separator = cacheOptions.namespaceSeparator || defaultNamespaceSeparator;
	    return `${cacheOptions.namespace}${separator}${hashFunction(key)}`;
	  };
	}
	function wrapWithKeyTransformation(resolveCache, makeKey) {
	  return {
	    get: (key) => {
	      return resolveCache().get(makeKey(key));
	    },
	    set: (key, value, options) => {
	      return resolveCache().set(makeKey(key), value, options);
	    },
	    delete: (key) => {
	      return resolveCache().delete(makeKey(key));
	    },
	    expireTag: (tag) => {
	      return resolveCache().expireTag(tag);
	    }
	  };
	}
	let warnedCacheUnavailable = false;
	function getCacheImplementation(debug) {
	  if (!inMemoryCacheInstance) {
	    inMemoryCacheInstance = new import_in_memory_cache.InMemoryCache();
	  }
	  if (process.env.RUNTIME_CACHE_DISABLE_BUILD_CACHE === "true") {
	    debug && console.log("Using InMemoryCache as build cache is disabled");
	    return inMemoryCacheInstance;
	  }
	  const { RUNTIME_CACHE_ENDPOINT, RUNTIME_CACHE_HEADERS } = process.env;
	  if (debug) {
	    console.log("Runtime cache environment variables:", {
	      RUNTIME_CACHE_ENDPOINT,
	      RUNTIME_CACHE_HEADERS
	    });
	  }
	  if (!RUNTIME_CACHE_ENDPOINT || !RUNTIME_CACHE_HEADERS) {
	    if (!warnedCacheUnavailable) {
	      console.warn(
	        "Runtime Cache unavailable in this environment. Falling back to in-memory cache."
	      );
	      warnedCacheUnavailable = true;
	    }
	    return inMemoryCacheInstance;
	  }
	  if (!buildCacheInstance) {
	    let parsedHeaders = {};
	    try {
	      parsedHeaders = JSON.parse(RUNTIME_CACHE_HEADERS);
	    } catch (e) {
	      console.error("Failed to parse RUNTIME_CACHE_HEADERS:", e);
	      return inMemoryCacheInstance;
	    }
	    let timeout = 500;
	    if (process.env.RUNTIME_CACHE_TIMEOUT) {
	      const parsed = parseInt(process.env.RUNTIME_CACHE_TIMEOUT, 10);
	      if (!isNaN(parsed) && parsed > 0) {
	        timeout = parsed;
	      } else {
	        console.warn(
	          `Invalid RUNTIME_CACHE_TIMEOUT value: "${process.env.RUNTIME_CACHE_TIMEOUT}". Using default: ${timeout}ms`
	        );
	      }
	    }
	    buildCacheInstance = new import_build_client.BuildCache({
	      endpoint: RUNTIME_CACHE_ENDPOINT,
	      headers: parsedHeaders,
	      onError: (error) => console.error(error),
	      timeout
	    });
	  }
	  return buildCacheInstance;
	}
	var PkgCacheState = /* @__PURE__ */ ((PkgCacheState2) => {
	  PkgCacheState2["Fresh"] = "fresh";
	  PkgCacheState2["Stale"] = "stale";
	  PkgCacheState2["Expired"] = "expired";
	  PkgCacheState2["NotFound"] = "notFound";
	  PkgCacheState2["Error"] = "error";
	  return PkgCacheState2;
	})(PkgCacheState || {});
	const HEADERS_VERCEL_CACHE_STATE = "x-vercel-cache-state";
	const HEADERS_VERCEL_REVALIDATE = "x-vercel-revalidate";
	const HEADERS_VERCEL_CACHE_TAGS = "x-vercel-cache-tags";
	const HEADERS_VERCEL_CACHE_ITEM_NAME = "x-vercel-cache-item-name";
	return cache$1;
}

var dbConnections;
var hasRequiredDbConnections;

function requireDbConnections () {
	if (hasRequiredDbConnections) return dbConnections;
	hasRequiredDbConnections = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var db_connections_exports = {};
	__export(db_connections_exports, {
	  attachDatabasePool: () => attachDatabasePool,
	  experimental_attachDatabasePool: () => experimental_attachDatabasePool
	});
	dbConnections = __toCommonJS(db_connections_exports);
	var import_get_context = requireGetContext$1();
	const DEBUG = !!process.env.DEBUG;
	function getIdleTimeout(dbPool) {
	  if ("options" in dbPool && dbPool.options) {
	    if ("idleTimeoutMillis" in dbPool.options) {
	      return typeof dbPool.options.idleTimeoutMillis === "number" ? dbPool.options.idleTimeoutMillis : 1e4;
	    }
	    if ("maxIdleTimeMS" in dbPool.options) {
	      return typeof dbPool.options.maxIdleTimeMS === "number" ? dbPool.options.maxIdleTimeMS : 0;
	    }
	    if ("status" in dbPool) {
	      return 5e3;
	    }
	    if ("connect" in dbPool && "execute" in dbPool) {
	      return 3e4;
	    }
	  }
	  if ("config" in dbPool && dbPool.config) {
	    if ("connectionConfig" in dbPool.config && dbPool.config.connectionConfig) {
	      return dbPool.config.connectionConfig.idleTimeout || 6e4;
	    }
	    if ("idleTimeout" in dbPool.config) {
	      return typeof dbPool.config.idleTimeout === "number" ? dbPool.config.idleTimeout : 6e4;
	    }
	  }
	  if ("poolTimeout" in dbPool) {
	    return typeof dbPool.poolTimeout === "number" ? dbPool.poolTimeout : 6e4;
	  }
	  if ("idleTimeout" in dbPool) {
	    return typeof dbPool.idleTimeout === "number" ? dbPool.idleTimeout : 0;
	  }
	  return 1e4;
	}
	let idleTimeout = null;
	let idleTimeoutResolve = () => {
	};
	const bootTime = Date.now();
	const maximumDuration = 15 * 60 * 1e3 - 1e3;
	function waitUntilIdleTimeout(dbPool) {
	  if (!process.env.VERCEL_URL || // This is not set during builds where we don't need to wait for idle connections using the mechanism
	  !process.env.VERCEL_REGION) {
	    return;
	  }
	  if (idleTimeout) {
	    clearTimeout(idleTimeout);
	    idleTimeoutResolve();
	  }
	  const promise = new Promise((resolve) => {
	    idleTimeoutResolve = resolve;
	  });
	  const waitTime = Math.min(
	    getIdleTimeout(dbPool) + 100,
	    maximumDuration - (Date.now() - bootTime)
	  );
	  idleTimeout = setTimeout(() => {
	    idleTimeoutResolve?.();
	    if (DEBUG) {
	      console.log("Database pool idle timeout reached. Releasing connections.");
	    }
	  }, waitTime);
	  const requestContext = (0, import_get_context.getContext)();
	  if (requestContext?.waitUntil) {
	    requestContext.waitUntil(promise);
	  } else {
	    console.warn("Pool release event triggered outside of request scope.");
	  }
	}
	function attachDatabasePool(dbPool) {
	  if (idleTimeout) {
	    idleTimeoutResolve?.();
	    clearTimeout(idleTimeout);
	  }
	  if ("on" in dbPool && dbPool.on && "options" in dbPool && "idleTimeoutMillis" in dbPool.options) {
	    const pgPool = dbPool;
	    pgPool.on("release", () => {
	      if (DEBUG) {
	        console.log("Client released from pool");
	      }
	      waitUntilIdleTimeout(dbPool);
	    });
	    return;
	  } else if ("on" in dbPool && dbPool.on && "config" in dbPool && dbPool.config && "connectionConfig" in dbPool.config) {
	    const mysqlPool = dbPool;
	    mysqlPool.on("release", () => {
	      if (DEBUG) {
	        console.log("MySQL client released from pool");
	      }
	      waitUntilIdleTimeout(dbPool);
	    });
	    return;
	  } else if ("on" in dbPool && dbPool.on && "config" in dbPool && dbPool.config && "idleTimeout" in dbPool.config) {
	    const mysql2Pool = dbPool;
	    mysql2Pool.on("release", () => {
	      if (DEBUG) {
	        console.log("MySQL2/MariaDB client released from pool");
	      }
	      waitUntilIdleTimeout(dbPool);
	    });
	    return;
	  }
	  if ("on" in dbPool && dbPool.on && "options" in dbPool && dbPool.options && "maxIdleTimeMS" in dbPool.options) {
	    const mongoPool = dbPool;
	    mongoPool.on("connectionCheckedOut", () => {
	      if (DEBUG) {
	        console.log("MongoDB connection checked out");
	      }
	      waitUntilIdleTimeout(dbPool);
	    });
	    return;
	  }
	  if ("on" in dbPool && dbPool.on && "options" in dbPool && dbPool.options && "socket" in dbPool.options) {
	    const redisPool = dbPool;
	    redisPool.on("end", () => {
	      if (DEBUG) {
	        console.log("Redis connection ended");
	      }
	      waitUntilIdleTimeout(dbPool);
	    });
	    return;
	  }
	  throw new Error("Unsupported database pool type");
	}
	const experimental_attachDatabasePool = attachDatabasePool;
	return dbConnections;
}

var purge = {exports: {}};

var types;
var hasRequiredTypes;

function requireTypes () {
	if (hasRequiredTypes) return types;
	hasRequiredTypes = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var types_exports = {};
	types = __toCommonJS(types_exports);
	return types;
}

var hasRequiredPurge;

function requirePurge () {
	if (hasRequiredPurge) return purge.exports;
	hasRequiredPurge = 1;
	(function (module) {
		var __defProp = Object.defineProperty;
		var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
		var __getOwnPropNames = Object.getOwnPropertyNames;
		var __hasOwnProp = Object.prototype.hasOwnProperty;
		var __export = (target, all) => {
		  for (var name in all)
		    __defProp(target, name, { get: all[name], enumerable: true });
		};
		var __copyProps = (to, from, except, desc) => {
		  if (from && typeof from === "object" || typeof from === "function") {
		    for (let key of __getOwnPropNames(from))
		      if (!__hasOwnProp.call(to, key) && key !== except)
		        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
		  }
		  return to;
		};
		var __reExport = (target, mod, secondTarget) => (__copyProps(target, mod, "default"), secondTarget && __copyProps(secondTarget, mod, "default"));
		var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
		var purge_exports = {};
		__export(purge_exports, {
		  dangerouslyDeleteByTag: () => dangerouslyDeleteByTag,
		  invalidateByTag: () => invalidateByTag
		});
		module.exports = __toCommonJS(purge_exports);
		var import_get_context = requireGetContext$1();
		__reExport(purge_exports, requireTypes(), module.exports);
		const invalidateByTag = (tag) => {
		  const api = (0, import_get_context.getContext)().purge;
		  if (api) {
		    return api.invalidateByTag(tag);
		  }
		  return Promise.resolve();
		};
		const dangerouslyDeleteByTag = (tag, options) => {
		  const api = (0, import_get_context.getContext)().purge;
		  if (api) {
		    return api.dangerouslyDeleteByTag(tag, options);
		  }
		  return Promise.resolve();
		};
	} (purge));
	return purge.exports;
}

var functions;
var hasRequiredFunctions;

function requireFunctions () {
	if (hasRequiredFunctions) return functions;
	hasRequiredFunctions = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var src_exports = {};
	__export(src_exports, {
	  attachDatabasePool: () => import_db_connections.attachDatabasePool,
	  dangerouslyDeleteByTag: () => import_purge.dangerouslyDeleteByTag,
	  experimental_attachDatabasePool: () => import_db_connections.experimental_attachDatabasePool,
	  geolocation: () => import_headers.geolocation,
	  getCache: () => import_cache.getCache,
	  getEnv: () => import_get_env.getEnv,
	  invalidateByTag: () => import_purge.invalidateByTag,
	  ipAddress: () => import_headers.ipAddress,
	  next: () => import_middleware.next,
	  rewrite: () => import_middleware.rewrite,
	  waitUntil: () => import_wait_until.waitUntil
	});
	functions = __toCommonJS(src_exports);
	var import_headers = requireHeaders$1();
	var import_get_env = requireGetEnv();
	var import_wait_until = requireWaitUntil();
	var import_middleware = requireMiddleware();
	var import_cache = requireCache$1();
	var import_db_connections = requireDbConnections();
	var import_purge = requirePurge();
	return functions;
}

var functionsExports = requireFunctions();

/**
 * Polyfill for `Promise.withResolvers()`.
 *
 * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/withResolvers
 */
function withResolvers() {
    let resolve;
    let reject;
    const promise = new Promise((_resolve, _reject) => {
        resolve = _resolve;
        reject = _reject;
    });
    return { promise, resolve, reject };
}
/**
 * Creates a lazily-evaluated, memoized version of the provided function.
 *
 * The returned object exposes a `value` getter that calls `fn` only once,
 * caches its result, and returns the cached value on subsequent accesses.
 *
 * @typeParam T - The return type of the provided function.
 * @param fn - The function to be called once and whose result will be cached.
 * @returns An object with a `value` property that returns the memoized result of `fn`.
 */
function once$1(fn) {
    const result = {
        get value() {
            const value = fn();
            Object.defineProperty(result, 'value', { value });
            return value;
        },
    };
    return result;
}
/**
 * Parses a duration parameter (string, number, or Date) and returns a Date object
 * representing when the duration should elapse.
 *
 * - For strings: Parses duration strings like "1s", "5m", "1h", etc. using the `ms` library
 * - For numbers: Treats as milliseconds from now
 * - For Date objects: Returns the date directly (handles both Date instances and date-like objects from deserialization)
 *
 * @param param - The duration parameter (StringValue, Date, or number of milliseconds)
 * @returns A Date object representing when the duration should elapse
 * @throws {Error} If the parameter is invalid or cannot be parsed
 */
function parseDurationToDate(param) {
    if (typeof param === 'string') {
        const durationMs = ms(param);
        if (typeof durationMs !== 'number' || durationMs < 0) {
            throw new Error(`Invalid duration: "${param}". Expected a valid duration string like "1s", "1m", "1h", etc.`);
        }
        return new Date(Date.now() + durationMs);
    }
    else if (typeof param === 'number') {
        if (param < 0 || !Number.isFinite(param)) {
            throw new Error(`Invalid duration: ${param}. Expected a non-negative finite number of milliseconds.`);
        }
        return new Date(Date.now() + param);
    }
    else if (param instanceof Date ||
        (param &&
            typeof param === 'object' &&
            typeof param.getTime === 'function')) {
        // Handle both Date instances and date-like objects (from deserialization)
        return param instanceof Date ? param : new Date(param.getTime());
    }
    else {
        throw new Error(`Invalid duration parameter. Expected a duration string, number (milliseconds), or Date object.`);
    }
}

const BASE_URL = 'https://useworkflow.dev/err';
/**
 * @internal
 * Check if a value is an Error without relying on Node.js utilities.
 * This is needed for error classes that can be used in VM contexts where
 * Node.js imports are not available.
 */
function isError(value) {
    return (typeof value === 'object' &&
        value !== null &&
        'name' in value &&
        'message' in value);
}
/**
 * @internal
 * All the slugs of the errors used for documentation links.
 */
const ERROR_SLUGS = {
    WEBHOOK_INVALID_RESPOND_WITH_VALUE: 'webhook-invalid-respond-with-value',
    WEBHOOK_RESPONSE_NOT_SENT: 'webhook-response-not-sent',
    FETCH_IN_WORKFLOW_FUNCTION: 'fetch-in-workflow',
};
/**
 * The base class for all Workflow-related errors.
 *
 * This error is thrown by the Workflow DevKit when internal operations fail.
 * You can use this class with `instanceof` to catch any Workflow DevKit error.
 *
 * @example
 * ```ts
 * try {
 *   await getRun(runId);
 * } catch (error) {
 *   if (error instanceof WorkflowError) {
 *     console.error('Workflow DevKit error:', error.message);
 *   }
 * }
 * ```
 */
class WorkflowError extends Error {
    cause;
    constructor(message, options) {
        const msgDocs = options?.slug
            ? `${message}\n\nLearn more: ${BASE_URL}/${options.slug}`
            : message;
        super(msgDocs, { cause: options?.cause });
        this.cause = options?.cause;
        if (options?.cause instanceof Error) {
            this.stack = `${this.stack}\nCaused by: ${options.cause.stack}`;
        }
    }
    static is(value) {
        return isError(value) && value.name === 'WorkflowError';
    }
}
/**
 * Thrown when a Workflow API request fails.
 *
 * This error is thrown when HTTP requests to the Workflow backend fail,
 * typically due to network issues, invalid requests, or server errors.
 *
 * @example
 * ```ts
 * try {
 *   await startWorkflow('myWorkflow', input);
 * } catch (error) {
 *   if (error instanceof WorkflowAPIError) {
 *     console.error(`API error (${error.status}):`, error.message);
 *   }
 * }
 * ```
 */
class WorkflowAPIError extends WorkflowError {
    status;
    code;
    url;
    constructor(message, options) {
        super(message, {
            cause: options?.cause,
        });
        this.name = 'WorkflowAPIError';
        this.status = options?.status;
        this.code = options?.code;
        this.url = options?.url;
    }
    static is(value) {
        return isError(value) && value.name === 'WorkflowAPIError';
    }
}
/**
 * Thrown when a workflow run fails during execution.
 *
 * This error indicates that the workflow encountered a fatal error
 * and cannot continue. The `cause` property contains the underlying
 * error with its message, stack trace, and optional error code.
 *
 * @example
 * ```
 * const run = await getRun(runId);
 * if (run.status === 'failed') {
 *   // WorkflowRunFailedError will be thrown
 * }
 * ```
 */
class WorkflowRunFailedError extends WorkflowError {
    runId;
    constructor(runId, error) {
        // Create a proper Error instance from the StructuredError to set as cause
        // NOTE: custom error types do not get serialized/deserialized. Everything is an Error
        const causeError = new Error(error.message);
        if (error.stack) {
            causeError.stack = error.stack;
        }
        if (error.code) {
            causeError.code = error.code;
        }
        super(`Workflow run "${runId}" failed: ${error.message}`, {
            cause: causeError,
        });
        this.name = 'WorkflowRunFailedError';
        this.runId = runId;
    }
    static is(value) {
        return isError(value) && value.name === 'WorkflowRunFailedError';
    }
}
/**
 * Thrown when attempting to get results from an incomplete workflow run.
 *
 * This error occurs when you try to access the result of a workflow
 * that is still running or hasn't completed yet.
 */
class WorkflowRunNotCompletedError extends WorkflowError {
    runId;
    status;
    constructor(runId, status) {
        super(`Workflow run "${runId}" has not completed`, {});
        this.name = 'WorkflowRunNotCompletedError';
        this.runId = runId;
        this.status = status;
    }
    static is(value) {
        return isError(value) && value.name === 'WorkflowRunNotCompletedError';
    }
}
/**
 * Thrown when the Workflow runtime encounters an internal error.
 *
 * This error indicates an issue with workflow execution, such as
 * serialization failures, starting an invalid workflow function, or
 * other runtime problems.
 */
class WorkflowRuntimeError extends WorkflowError {
    constructor(message, options) {
        super(message, {
            ...options,
        });
        this.name = 'WorkflowRuntimeError';
    }
    static is(value) {
        return isError(value) && value.name === 'WorkflowRuntimeError';
    }
}
class WorkflowRunNotFoundError extends WorkflowError {
    runId;
    constructor(runId) {
        super(`Workflow run "${runId}" not found`, {});
        this.name = 'WorkflowRunNotFoundError';
        this.runId = runId;
    }
    static is(value) {
        return isError(value) && value.name === 'WorkflowRunNotFoundError';
    }
}
class WorkflowRunCancelledError extends WorkflowError {
    runId;
    constructor(runId) {
        super(`Workflow run "${runId}" cancelled`, {});
        this.name = 'WorkflowRunCancelledError';
        this.runId = runId;
    }
    static is(value) {
        return isError(value) && value.name === 'WorkflowRunCancelledError';
    }
}
/**
 * A fatal error is an error that cannot be retried.
 * It will cause the step to fail and the error will
 * be bubbled up to the workflow logic.
 */
class FatalError extends Error {
    fatal = true;
    constructor(message) {
        super(message);
        this.name = 'FatalError';
    }
    static is(value) {
        return isError(value) && value.name === 'FatalError';
    }
}
/**
 * An error that can happen during a step execution, allowing
 * for configuration of the retry behavior.
 */
class RetryableError extends Error {
    /**
     * The Date when the step should be retried.
     */
    retryAfter;
    constructor(message, options = {}) {
        super(message);
        this.name = 'RetryableError';
        if (options.retryAfter !== undefined) {
            this.retryAfter = parseDurationToDate(options.retryAfter);
        }
        else {
            // Default to 1 second (1000 milliseconds)
            this.retryAfter = new Date(Date.now() + 1000);
        }
    }
    static is(value) {
        return isError(value) && value.name === 'RetryableError';
    }
}

// Allow some arguments/options to be either a file path string or a file URL
const safeNormalizeFileUrl = (file, name) => {
	const fileString = normalizeFileUrl(normalizeDenoExecPath(file));

	if (typeof fileString !== 'string') {
		throw new TypeError(`${name} must be a string or a file URL: ${fileString}.`);
	}

	return fileString;
};

// In Deno node:process execPath is a special object, not just a string:
// https://github.com/denoland/deno/blob/f460188e583f00144000aa0d8ade08218d47c3c1/ext/node/polyfills/process.ts#L344
const normalizeDenoExecPath = file => isDenoExecPath(file)
	? file.toString()
	: file;

const isDenoExecPath = file => typeof file !== 'string'
	&& file
	&& Object.getPrototypeOf(file) === String.prototype;

// Same but also allows other values, e.g. `boolean` for the `shell` option
const normalizeFileUrl = file => file instanceof URL ? fileURLToPath(file) : file;

// The command `arguments` and `options` are both optional.
// This also does basic validation on them and on the command file.
const normalizeParameters = (rawFile, rawArguments = [], rawOptions = {}) => {
	const filePath = safeNormalizeFileUrl(rawFile, 'First argument');
	const [commandArguments, options] = isPlainObject(rawArguments)
		? [[], rawArguments]
		: [rawArguments, rawOptions];

	if (!Array.isArray(commandArguments)) {
		throw new TypeError(`Second argument must be either an array of arguments or an options object: ${commandArguments}`);
	}

	if (commandArguments.some(commandArgument => typeof commandArgument === 'object' && commandArgument !== null)) {
		throw new TypeError(`Second argument must be an array of strings: ${commandArguments}`);
	}

	const normalizedArguments = commandArguments.map(String);
	const nullByteArgument = normalizedArguments.find(normalizedArgument => normalizedArgument.includes('\0'));
	if (nullByteArgument !== undefined) {
		throw new TypeError(`Arguments cannot contain null bytes ("\\0"): ${nullByteArgument}`);
	}

	if (!isPlainObject(options)) {
		throw new TypeError(`Last argument must be an options object: ${options}`);
	}

	return [filePath, normalizedArguments, options];
};

const {toString: objectToString$1} = Object.prototype;

const isArrayBuffer = value => objectToString$1.call(value) === '[object ArrayBuffer]';

// Is either Uint8Array or Buffer
const isUint8Array = value => objectToString$1.call(value) === '[object Uint8Array]';

const bufferToUint8Array = buffer => new Uint8Array(buffer.buffer, buffer.byteOffset, buffer.byteLength);

const textEncoder$1 = new TextEncoder();
const stringToUint8Array = string => textEncoder$1.encode(string);

const textDecoder = new TextDecoder();
const uint8ArrayToString = uint8Array => textDecoder.decode(uint8Array);

const joinToString = (uint8ArraysOrStrings, encoding) => {
	const strings = uint8ArraysToStrings(uint8ArraysOrStrings, encoding);
	return strings.join('');
};

const uint8ArraysToStrings = (uint8ArraysOrStrings, encoding) => {
	if (encoding === 'utf8' && uint8ArraysOrStrings.every(uint8ArrayOrString => typeof uint8ArrayOrString === 'string')) {
		return uint8ArraysOrStrings;
	}

	const decoder = new StringDecoder(encoding);
	const strings = uint8ArraysOrStrings
		.map(uint8ArrayOrString => typeof uint8ArrayOrString === 'string'
			? stringToUint8Array(uint8ArrayOrString)
			: uint8ArrayOrString)
		.map(uint8Array => decoder.write(uint8Array));
	const finalString = decoder.end();
	return finalString === '' ? strings : [...strings, finalString];
};

const joinToUint8Array = uint8ArraysOrStrings => {
	if (uint8ArraysOrStrings.length === 1 && isUint8Array(uint8ArraysOrStrings[0])) {
		return uint8ArraysOrStrings[0];
	}

	return concatUint8Arrays(stringsToUint8Arrays(uint8ArraysOrStrings));
};

const stringsToUint8Arrays = uint8ArraysOrStrings => uint8ArraysOrStrings.map(uint8ArrayOrString => typeof uint8ArrayOrString === 'string'
	? stringToUint8Array(uint8ArrayOrString)
	: uint8ArrayOrString);

const concatUint8Arrays = uint8Arrays => {
	const result = new Uint8Array(getJoinLength(uint8Arrays));

	let index = 0;
	for (const uint8Array of uint8Arrays) {
		result.set(uint8Array, index);
		index += uint8Array.length;
	}

	return result;
};

const getJoinLength = uint8Arrays => {
	let joinLength = 0;
	for (const uint8Array of uint8Arrays) {
		joinLength += uint8Array.length;
	}

	return joinLength;
};

// Check whether the template string syntax is being used
const isTemplateString = templates => Array.isArray(templates) && Array.isArray(templates.raw);

// Convert execa`file ...commandArguments` to execa(file, commandArguments)
const parseTemplates = (templates, expressions) => {
	let tokens = [];

	for (const [index, template] of templates.entries()) {
		tokens = parseTemplate({
			templates,
			expressions,
			tokens,
			index,
			template,
		});
	}

	if (tokens.length === 0) {
		throw new TypeError('Template script must not be empty');
	}

	const [file, ...commandArguments] = tokens;
	return [file, commandArguments, {}];
};

const parseTemplate = ({templates, expressions, tokens, index, template}) => {
	if (template === undefined) {
		throw new TypeError(`Invalid backslash sequence: ${templates.raw[index]}`);
	}

	const {nextTokens, leadingWhitespaces, trailingWhitespaces} = splitByWhitespaces(template, templates.raw[index]);
	const newTokens = concatTokens(tokens, nextTokens, leadingWhitespaces);

	if (index === expressions.length) {
		return newTokens;
	}

	const expression = expressions[index];
	const expressionTokens = Array.isArray(expression)
		? expression.map(expression => parseExpression(expression))
		: [parseExpression(expression)];
	return concatTokens(newTokens, expressionTokens, trailingWhitespaces);
};

// Like `string.split(/[ \t\r\n]+/)` except newlines and tabs are:
//  - ignored when input as a backslash sequence like: `echo foo\n bar`
//  - not ignored when input directly
// The only way to distinguish those in JavaScript is to use a tagged template and compare:
//  - the first array argument, which does not escape backslash sequences
//  - its `raw` property, which escapes them
const splitByWhitespaces = (template, rawTemplate) => {
	if (rawTemplate.length === 0) {
		return {nextTokens: [], leadingWhitespaces: false, trailingWhitespaces: false};
	}

	const nextTokens = [];
	let templateStart = 0;
	const leadingWhitespaces = DELIMITERS.has(rawTemplate[0]);

	for (
		let templateIndex = 0, rawIndex = 0;
		templateIndex < template.length;
		templateIndex += 1, rawIndex += 1
	) {
		const rawCharacter = rawTemplate[rawIndex];
		if (DELIMITERS.has(rawCharacter)) {
			if (templateStart !== templateIndex) {
				nextTokens.push(template.slice(templateStart, templateIndex));
			}

			templateStart = templateIndex + 1;
		} else if (rawCharacter === '\\') {
			const nextRawCharacter = rawTemplate[rawIndex + 1];
			if (nextRawCharacter === '\n') {
				// Handles escaped newlines in templates
				templateIndex -= 1;
				rawIndex += 1;
			} else if (nextRawCharacter === 'u' && rawTemplate[rawIndex + 2] === '{') {
				rawIndex = rawTemplate.indexOf('}', rawIndex + 3);
			} else {
				rawIndex += ESCAPE_LENGTH[nextRawCharacter] ?? 1;
			}
		}
	}

	const trailingWhitespaces = templateStart === template.length;
	if (!trailingWhitespaces) {
		nextTokens.push(template.slice(templateStart));
	}

	return {nextTokens, leadingWhitespaces, trailingWhitespaces};
};

const DELIMITERS = new Set([' ', '\t', '\r', '\n']);

// Number of characters in backslash escape sequences: \0 \xXX or \uXXXX
// \cX is allowed in RegExps but not in strings
// Octal sequences are not allowed in strict mode
const ESCAPE_LENGTH = {x: 3, u: 5};

const concatTokens = (tokens, nextTokens, isSeparated) => isSeparated
	|| tokens.length === 0
	|| nextTokens.length === 0
	? [...tokens, ...nextTokens]
	: [
		...tokens.slice(0, -1),
		`${tokens.at(-1)}${nextTokens[0]}`,
		...nextTokens.slice(1),
	];

// Handle `${expression}` inside the template string syntax
const parseExpression = expression => {
	const typeOfExpression = typeof expression;

	if (typeOfExpression === 'string') {
		return expression;
	}

	if (typeOfExpression === 'number') {
		return String(expression);
	}

	if (isPlainObject(expression) && ('stdout' in expression || 'isMaxBuffer' in expression)) {
		return getSubprocessResult(expression);
	}

	if (expression instanceof ChildProcess || Object.prototype.toString.call(expression) === '[object Promise]') {
		// eslint-disable-next-line no-template-curly-in-string
		throw new TypeError('Unexpected subprocess in template expression. Please use ${await subprocess} instead of ${subprocess}.');
	}

	throw new TypeError(`Unexpected "${typeOfExpression}" in template expression`);
};

const getSubprocessResult = ({stdout}) => {
	if (typeof stdout === 'string') {
		return stdout;
	}

	if (isUint8Array(stdout)) {
		return uint8ArrayToString(stdout);
	}

	if (stdout === undefined) {
		throw new TypeError('Missing result.stdout in template expression. This is probably due to the previous subprocess\' "stdout" option.');
	}

	throw new TypeError(`Unexpected "${typeof stdout}" stdout in template expression`);
};

const isStandardStream = stream => STANDARD_STREAMS.includes(stream);
const STANDARD_STREAMS = [process$2.stdin, process$2.stdout, process$2.stderr];
const STANDARD_STREAMS_ALIASES = ['stdin', 'stdout', 'stderr'];
const getStreamName = fdNumber => STANDARD_STREAMS_ALIASES[fdNumber] ?? `stdio[${fdNumber}]`;

// Some options can have different values for `stdout`/`stderr`/`fd3`.
// This normalizes those to array of values.
// For example, `{verbose: {stdout: 'none', stderr: 'full'}}` becomes `{verbose: ['none', 'none', 'full']}`
const normalizeFdSpecificOptions = options => {
	const optionsCopy = {...options};

	for (const optionName of FD_SPECIFIC_OPTIONS) {
		optionsCopy[optionName] = normalizeFdSpecificOption(options, optionName);
	}

	return optionsCopy;
};

const normalizeFdSpecificOption = (options, optionName) => {
	const optionBaseArray = Array.from({length: getStdioLength(options) + 1});
	const optionArray = normalizeFdSpecificValue(options[optionName], optionBaseArray, optionName);
	return addDefaultValue$1(optionArray, optionName);
};

const getStdioLength = ({stdio}) => Array.isArray(stdio)
	? Math.max(stdio.length, STANDARD_STREAMS_ALIASES.length)
	: STANDARD_STREAMS_ALIASES.length;

const normalizeFdSpecificValue = (optionValue, optionArray, optionName) => isPlainObject(optionValue)
	? normalizeOptionObject(optionValue, optionArray, optionName)
	: optionArray.fill(optionValue);

const normalizeOptionObject = (optionValue, optionArray, optionName) => {
	for (const fdName of Object.keys(optionValue).sort(compareFdName)) {
		for (const fdNumber of parseFdName(fdName, optionName, optionArray)) {
			optionArray[fdNumber] = optionValue[fdName];
		}
	}

	return optionArray;
};

// Ensure priority order when setting both `stdout`/`stderr`, `fd1`/`fd2`, and `all`
const compareFdName = (fdNameA, fdNameB) => getFdNameOrder(fdNameA) < getFdNameOrder(fdNameB) ? 1 : -1;

const getFdNameOrder = fdName => {
	if (fdName === 'stdout' || fdName === 'stderr') {
		return 0;
	}

	return fdName === 'all' ? 2 : 1;
};

const parseFdName = (fdName, optionName, optionArray) => {
	if (fdName === 'ipc') {
		return [optionArray.length - 1];
	}

	const fdNumber = parseFd(fdName);
	if (fdNumber === undefined || fdNumber === 0) {
		throw new TypeError(`"${optionName}.${fdName}" is invalid.
It must be "${optionName}.stdout", "${optionName}.stderr", "${optionName}.all", "${optionName}.ipc", or "${optionName}.fd3", "${optionName}.fd4" (and so on).`);
	}

	if (fdNumber >= optionArray.length) {
		throw new TypeError(`"${optionName}.${fdName}" is invalid: that file descriptor does not exist.
Please set the "stdio" option to ensure that file descriptor exists.`);
	}

	return fdNumber === 'all' ? [1, 2] : [fdNumber];
};

// Use the same syntax for fd-specific options and the `from`/`to` options
const parseFd = fdName => {
	if (fdName === 'all') {
		return fdName;
	}

	if (STANDARD_STREAMS_ALIASES.includes(fdName)) {
		return STANDARD_STREAMS_ALIASES.indexOf(fdName);
	}

	const regexpResult = FD_REGEXP.exec(fdName);
	if (regexpResult !== null) {
		return Number(regexpResult[1]);
	}
};

const FD_REGEXP = /^fd(\d+)$/;

const addDefaultValue$1 = (optionArray, optionName) => optionArray.map(optionValue => optionValue === undefined
	? DEFAULT_OPTIONS[optionName]
	: optionValue);

// Default value for the `verbose` option
const verboseDefault = debuglog('execa').enabled ? 'full' : 'none';

const DEFAULT_OPTIONS = {
	lines: false,
	buffer: true,
	maxBuffer: 1000 * 1000 * 100,
	verbose: verboseDefault,
	stripFinalNewline: true,
};

// List of options which can have different values for `stdout`/`stderr`
const FD_SPECIFIC_OPTIONS = ['lines', 'buffer', 'maxBuffer', 'verbose', 'stripFinalNewline'];

// Retrieve fd-specific option
const getFdSpecificValue = (optionArray, fdNumber) => fdNumber === 'ipc'
	? optionArray.at(-1)
	: optionArray[fdNumber];

// The `verbose` option can have different values for `stdout`/`stderr`
const isVerbose = ({verbose}, fdNumber) => getFdVerbose(verbose, fdNumber) !== 'none';

// Whether IPC and output and logged
const isFullVerbose = ({verbose}, fdNumber) => !['none', 'short'].includes(getFdVerbose(verbose, fdNumber));

// The `verbose` option can be a function to customize logging
const getVerboseFunction = ({verbose}, fdNumber) => {
	const fdVerbose = getFdVerbose(verbose, fdNumber);
	return isVerboseFunction(fdVerbose) ? fdVerbose : undefined;
};

// When using `verbose: {stdout, stderr, fd3, ipc}`:
//  - `verbose.stdout|stderr|fd3` is used for 'output'
//  - `verbose.ipc` is only used for 'ipc'
//  - highest `verbose.*` value is used for 'command', 'error' and 'duration'
const getFdVerbose = (verbose, fdNumber) => fdNumber === undefined
	? getFdGenericVerbose(verbose)
	: getFdSpecificValue(verbose, fdNumber);

// When using `verbose: {stdout, stderr, fd3, ipc}` and logging is not specific to a file descriptor.
// We then use the highest `verbose.*` value, using the following order:
//  - function > 'full' > 'short' > 'none'
//  - if several functions are defined: stdout > stderr > fd3 > ipc
const getFdGenericVerbose = verbose => verbose.find(fdVerbose => isVerboseFunction(fdVerbose))
	?? VERBOSE_VALUES.findLast(fdVerbose => verbose.includes(fdVerbose));

// Whether the `verbose` option is customized using a function
const isVerboseFunction = fdVerbose => typeof fdVerbose === 'function';

const VERBOSE_VALUES = ['none', 'short', 'full'];

// Compute `result.command` and `result.escapedCommand`
const joinCommand = (filePath, rawArguments) => {
	const fileAndArguments = [filePath, ...rawArguments];
	const command = fileAndArguments.join(' ');
	const escapedCommand = fileAndArguments
		.map(fileAndArgument => quoteString(escapeControlCharacters(fileAndArgument)))
		.join(' ');
	return {command, escapedCommand};
};

// Remove ANSI sequences and escape control characters and newlines
const escapeLines = lines => stripVTControlCharacters(lines)
	.split('\n')
	.map(line => escapeControlCharacters(line))
	.join('\n');

const escapeControlCharacters = line => line.replaceAll(SPECIAL_CHAR_REGEXP, character => escapeControlCharacter(character));

const escapeControlCharacter = character => {
	const commonEscape = COMMON_ESCAPES[character];
	if (commonEscape !== undefined) {
		return commonEscape;
	}

	const codepoint = character.codePointAt(0);
	const codepointHex = codepoint.toString(16);
	return codepoint <= ASTRAL_START
		? `\\u${codepointHex.padStart(4, '0')}`
		: `\\U${codepointHex}`;
};

// Characters that would create issues when printed are escaped using the \u or \U notation.
// Those include control characters and newlines.
// The \u and \U notation is Bash specific, but there is no way to do this in a shell-agnostic way.
// Some shells do not even have a way to print those characters in an escaped fashion.
// Therefore, we prioritize printing those safely, instead of allowing those to be copy-pasted.
// List of Unicode character categories: https://www.fileformat.info/info/unicode/category/index.htm
const getSpecialCharRegExp = () => {
	try {
		// This throws when using Node.js without ICU support.
		// When using a RegExp literal, this would throw at parsing-time, instead of runtime.
		// eslint-disable-next-line prefer-regex-literals
		return new RegExp('\\p{Separator}|\\p{Other}', 'gu');
	} catch {
		// Similar to the above RegExp, but works even when Node.js has been built without ICU support.
		// Unlike the above RegExp, it only covers whitespaces and C0/C1 control characters.
		// It does not cover some edge cases, such as Unicode reserved characters.
		// See https://github.com/sindresorhus/execa/issues/1143
		// eslint-disable-next-line no-control-regex
		return /[\s\u0000-\u001F\u007F-\u009F\u00AD]/g;
	}
};

const SPECIAL_CHAR_REGEXP = getSpecialCharRegExp();

// Accepted by $'...' in Bash.
// Exclude \a \e \v which are accepted in Bash but not in JavaScript (except \v) and JSON.
const COMMON_ESCAPES = {
	' ': ' ',
	'\b': '\\b',
	'\f': '\\f',
	'\n': '\\n',
	'\r': '\\r',
	'\t': '\\t',
};

// Up until that codepoint, \u notation can be used instead of \U
const ASTRAL_START = 65_535;

// Some characters are shell-specific, i.e. need to be escaped when the command is copy-pasted then run.
// Escaping is shell-specific. We cannot know which shell is used: `process.platform` detection is not enough.
// For example, Windows users could be using `cmd.exe`, Powershell or Bash for Windows which all use different escaping.
// We use '...' on Unix, which is POSIX shell compliant and escape all characters but ' so this is fairly safe.
// On Windows, we assume cmd.exe is used and escape with "...", which also works with Powershell.
const quoteString = escapedArgument => {
	if (NO_ESCAPE_REGEXP.test(escapedArgument)) {
		return escapedArgument;
	}

	return platform === 'win32'
		? `"${escapedArgument.replaceAll('"', '""')}"`
		: `'${escapedArgument.replaceAll('\'', '\'\\\'\'')}'`;
};

const NO_ESCAPE_REGEXP = /^[\w./-]+$/;

function isUnicodeSupported() {
	const {env} = process$2;
	const {TERM, TERM_PROGRAM} = env;

	if (process$2.platform !== 'win32') {
		return TERM !== 'linux'; // Linux console (kernel)
	}

	return Boolean(env.WT_SESSION) // Windows Terminal
		|| Boolean(env.TERMINUS_SUBLIME) // Terminus (<0.2.27)
		|| env.ConEmuTask === '{cmd::Cmder}' // ConEmu and cmder
		|| TERM_PROGRAM === 'Terminus-Sublime'
		|| TERM_PROGRAM === 'vscode'
		|| TERM === 'xterm-256color'
		|| TERM === 'alacritty'
		|| TERM === 'rxvt-unicode'
		|| TERM === 'rxvt-unicode-256color'
		|| env.TERMINAL_EMULATOR === 'JetBrains-JediTerm';
}

const common = {
	circleQuestionMark: '(?)',
	questionMarkPrefix: '(?)',
	square: 'â',
	squareDarkShade: 'â',
	squareMediumShade: 'â',
	squareLightShade: 'â',
	squareTop: 'â',
	squareBottom: 'â',
	squareLeft: 'â',
	squareRight: 'â',
	squareCenter: 'â ',
	bullet: 'â',
	dot: 'â¤',
	ellipsis: 'â¦',
	pointerSmall: 'âº',
	triangleUp: 'â²',
	triangleUpSmall: 'â´',
	triangleDown: 'â¼',
	triangleDownSmall: 'â¾',
	triangleLeftSmall: 'â',
	triangleRightSmall: 'â¸',
	home: 'â',
	heart: 'â¥',
	musicNote: 'âª',
	musicNoteBeamed: 'â«',
	arrowUp: 'â',
	arrowDown: 'â',
	arrowLeft: 'â',
	arrowRight: 'â',
	arrowLeftRight: 'â',
	arrowUpDown: 'â',
	almostEqual: 'â',
	notEqual: 'â ',
	lessOrEqual: 'â¤',
	greaterOrEqual: 'â¥',
	identical: 'â¡',
	infinity: 'â',
	subscriptZero: 'â',
	subscriptOne: 'â',
	subscriptTwo: 'â',
	subscriptThree: 'â',
	subscriptFour: 'â',
	subscriptFive: 'â',
	subscriptSix: 'â',
	subscriptSeven: 'â',
	subscriptEight: 'â',
	subscriptNine: 'â',
	oneHalf: 'Â½',
	oneThird: 'â',
	oneQuarter: 'Â¼',
	oneFifth: 'â',
	oneSixth: 'â',
	oneEighth: 'â',
	twoThirds: 'â',
	twoFifths: 'â',
	threeQuarters: 'Â¾',
	threeFifths: 'â',
	threeEighths: 'â',
	fourFifths: 'â',
	fiveSixths: 'â',
	fiveEighths: 'â',
	sevenEighths: 'â',
	line: 'â',
	lineBold: 'â',
	lineDouble: 'â',
	lineDashed0: 'â',
	lineDashed1: 'â',
	lineDashed2: 'â',
	lineDashed3: 'â',
	lineDashed4: 'â',
	lineDashed5: 'â',
	lineDashed6: 'â´',
	lineDashed7: 'â¶',
	lineDashed8: 'â¸',
	lineDashed9: 'âº',
	lineDashed10: 'â¼',
	lineDashed11: 'â¾',
	lineDashed12: 'â',
	lineDashed13: 'â',
	lineDashed14: 'â',
	lineDashed15: 'â',
	lineVertical: 'â',
	lineVerticalBold: 'â',
	lineVerticalDouble: 'â',
	lineVerticalDashed0: 'â',
	lineVerticalDashed1: 'â',
	lineVerticalDashed2: 'â',
	lineVerticalDashed3: 'â',
	lineVerticalDashed4: 'â',
	lineVerticalDashed5: 'â',
	lineVerticalDashed6: 'âµ',
	lineVerticalDashed7: 'â·',
	lineVerticalDashed8: 'â¹',
	lineVerticalDashed9: 'â»',
	lineVerticalDashed10: 'â½',
	lineVerticalDashed11: 'â¿',
	lineDownLeft: 'â',
	lineDownLeftArc: 'â®',
	lineDownBoldLeftBold: 'â',
	lineDownBoldLeft: 'â',
	lineDownLeftBold: 'â',
	lineDownDoubleLeftDouble: 'â',
	lineDownDoubleLeft: 'â',
	lineDownLeftDouble: 'â',
	lineDownRight: 'â',
	lineDownRightArc: 'â­',
	lineDownBoldRightBold: 'â',
	lineDownBoldRight: 'â',
	lineDownRightBold: 'â',
	lineDownDoubleRightDouble: 'â',
	lineDownDoubleRight: 'â',
	lineDownRightDouble: 'â',
	lineUpLeft: 'â',
	lineUpLeftArc: 'â¯',
	lineUpBoldLeftBold: 'â',
	lineUpBoldLeft: 'â',
	lineUpLeftBold: 'â',
	lineUpDoubleLeftDouble: 'â',
	lineUpDoubleLeft: 'â',
	lineUpLeftDouble: 'â',
	lineUpRight: 'â',
	lineUpRightArc: 'â°',
	lineUpBoldRightBold: 'â',
	lineUpBoldRight: 'â',
	lineUpRightBold: 'â',
	lineUpDoubleRightDouble: 'â',
	lineUpDoubleRight: 'â',
	lineUpRightDouble: 'â',
	lineUpDownLeft: 'â¤',
	lineUpBoldDownBoldLeftBold: 'â«',
	lineUpBoldDownBoldLeft: 'â¨',
	lineUpDownLeftBold: 'â¥',
	lineUpBoldDownLeftBold: 'â©',
	lineUpDownBoldLeftBold: 'âª',
	lineUpDownBoldLeft: 'â§',
	lineUpBoldDownLeft: 'â¦',
	lineUpDoubleDownDoubleLeftDouble: 'â£',
	lineUpDoubleDownDoubleLeft: 'â¢',
	lineUpDownLeftDouble: 'â¡',
	lineUpDownRight: 'â',
	lineUpBoldDownBoldRightBold: 'â£',
	lineUpBoldDownBoldRight: 'â ',
	lineUpDownRightBold: 'â',
	lineUpBoldDownRightBold: 'â¡',
	lineUpDownBoldRightBold: 'â¢',
	lineUpDownBoldRight: 'â',
	lineUpBoldDownRight: 'â',
	lineUpDoubleDownDoubleRightDouble: 'â ',
	lineUpDoubleDownDoubleRight: 'â',
	lineUpDownRightDouble: 'â',
	lineDownLeftRight: 'â¬',
	lineDownBoldLeftBoldRightBold: 'â³',
	lineDownLeftBoldRightBold: 'â¯',
	lineDownBoldLeftRight: 'â°',
	lineDownBoldLeftBoldRight: 'â±',
	lineDownBoldLeftRightBold: 'â²',
	lineDownLeftRightBold: 'â®',
	lineDownLeftBoldRight: 'â­',
	lineDownDoubleLeftDoubleRightDouble: 'â¦',
	lineDownDoubleLeftRight: 'â¥',
	lineDownLeftDoubleRightDouble: 'â¤',
	lineUpLeftRight: 'â´',
	lineUpBoldLeftBoldRightBold: 'â»',
	lineUpLeftBoldRightBold: 'â·',
	lineUpBoldLeftRight: 'â¸',
	lineUpBoldLeftBoldRight: 'â¹',
	lineUpBoldLeftRightBold: 'âº',
	lineUpLeftRightBold: 'â¶',
	lineUpLeftBoldRight: 'âµ',
	lineUpDoubleLeftDoubleRightDouble: 'â©',
	lineUpDoubleLeftRight: 'â¨',
	lineUpLeftDoubleRightDouble: 'â§',
	lineUpDownLeftRight: 'â¼',
	lineUpBoldDownBoldLeftBoldRightBold: 'â',
	lineUpDownBoldLeftBoldRightBold: 'â',
	lineUpBoldDownLeftBoldRightBold: 'â',
	lineUpBoldDownBoldLeftRightBold: 'â',
	lineUpBoldDownBoldLeftBoldRight: 'â',
	lineUpBoldDownLeftRight: 'â',
	lineUpDownBoldLeftRight: 'â',
	lineUpDownLeftBoldRight: 'â½',
	lineUpDownLeftRightBold: 'â¾',
	lineUpBoldDownBoldLeftRight: 'â',
	lineUpDownLeftBoldRightBold: 'â¿',
	lineUpBoldDownLeftBoldRight: 'â',
	lineUpBoldDownLeftRightBold: 'â',
	lineUpDownBoldLeftBoldRight: 'â',
	lineUpDownBoldLeftRightBold: 'â',
	lineUpDoubleDownDoubleLeftDoubleRightDouble: 'â¬',
	lineUpDoubleDownDoubleLeftRight: 'â«',
	lineUpDownLeftDoubleRightDouble: 'âª',
	lineCross: 'â³',
	lineBackslash: 'â²',
	lineSlash: 'â±',
};

const specialMainSymbols = {
	tick: 'â',
	info: 'â¹',
	warning: 'â ',
	cross: 'â',
	squareSmall: 'â»',
	squareSmallFilled: 'â¼',
	circle: 'â¯',
	circleFilled: 'â',
	circleDotted: 'â',
	circleDouble: 'â',
	circleCircle: 'â',
	circleCross: 'â§',
	circlePipe: 'â¾',
	radioOn: 'â',
	radioOff: 'â¯',
	checkboxOn: 'â',
	checkboxOff: 'â',
	checkboxCircleOn: 'â§',
	checkboxCircleOff: 'â¾',
	pointer: 'â¯',
	triangleUpOutline: 'â³',
	triangleLeft: 'â',
	triangleRight: 'â¶',
	lozenge: 'â',
	lozengeOutline: 'â',
	hamburger: 'â°',
	smiley: 'ã¡',
	mustache: 'à·´',
	star: 'â',
	play: 'â¶',
	nodejs: 'â¬¢',
	oneSeventh: 'â',
	oneNinth: 'â',
	oneTenth: 'â',
};

const specialFallbackSymbols = {
	tick: 'â',
	info: 'i',
	warning: 'â¼',
	cross: 'Ã',
	squareSmall: 'â¡',
	squareSmallFilled: 'â ',
	circle: '( )',
	circleFilled: '(*)',
	circleDotted: '( )',
	circleDouble: '( )',
	circleCircle: '(â)',
	circleCross: '(Ã)',
	circlePipe: '(â)',
	radioOn: '(*)',
	radioOff: '( )',
	checkboxOn: '[Ã]',
	checkboxOff: '[ ]',
	checkboxCircleOn: '(Ã)',
	checkboxCircleOff: '( )',
	pointer: '>',
	triangleUpOutline: 'â',
	triangleLeft: 'â',
	triangleRight: 'âº',
	lozenge: 'â¦',
	lozengeOutline: 'â',
	hamburger: 'â¡',
	smiley: 'âº',
	mustache: 'âââ',
	star: 'â¶',
	play: 'âº',
	nodejs: 'â¦',
	oneSeventh: '1/7',
	oneNinth: '1/9',
	oneTenth: '1/10',
};

const mainSymbols = {...common, ...specialMainSymbols};
const fallbackSymbols = {...common, ...specialFallbackSymbols};

const shouldUseMain = isUnicodeSupported();
const figures = shouldUseMain ? mainSymbols : fallbackSymbols;

// Default when `verbose` is not a function
const defaultVerboseFunction = ({
	type,
	message,
	timestamp,
	piped,
	commandId,
	result: {failed = false} = {},
	options: {reject = true},
}) => {
	const timestampString = serializeTimestamp(timestamp);
	const icon = ICONS[type]({failed, reject, piped});
	const color = COLORS[type]({reject});
	return `${gray(`[${timestampString}]`)} ${gray(`[${commandId}]`)} ${color(icon)} ${color(message)}`;
};

// Prepending the timestamp allows debugging the slow paths of a subprocess
const serializeTimestamp = timestamp => `${padField(timestamp.getHours(), 2)}:${padField(timestamp.getMinutes(), 2)}:${padField(timestamp.getSeconds(), 2)}.${padField(timestamp.getMilliseconds(), 3)}`;

const padField = (field, padding) => String(field).padStart(padding, '0');

const getFinalIcon = ({failed, reject}) => {
	if (!failed) {
		return figures.tick;
	}

	return reject ? figures.cross : figures.warning;
};

const ICONS = {
	command: ({piped}) => piped ? '|' : '$',
	output: () => ' ',
	ipc: () => '*',
	error: getFinalIcon,
	duration: getFinalIcon,
};

const identity$1 = string => string;

const COLORS = {
	command: () => bold,
	output: () => identity$1,
	ipc: () => identity$1,
	error: ({reject}) => reject ? redBright : yellowBright,
	duration: () => gray,
};

// Apply the `verbose` function on each line
const applyVerboseOnLines = (printedLines, verboseInfo, fdNumber) => {
	const verboseFunction = getVerboseFunction(verboseInfo, fdNumber);
	return printedLines
		.map(({verboseLine, verboseObject}) => applyVerboseFunction(verboseLine, verboseObject, verboseFunction))
		.filter(printedLine => printedLine !== undefined)
		.map(printedLine => appendNewline(printedLine))
		.join('');
};

const applyVerboseFunction = (verboseLine, verboseObject, verboseFunction) => {
	if (verboseFunction === undefined) {
		return verboseLine;
	}

	const printedLine = verboseFunction(verboseLine, verboseObject);
	if (typeof printedLine === 'string') {
		return printedLine;
	}
};

const appendNewline = printedLine => printedLine.endsWith('\n')
	? printedLine
	: `${printedLine}\n`;

// This prints on stderr.
// If the subprocess prints on stdout and is using `stdout: 'inherit'`,
// there is a chance both writes will compete (introducing a race condition).
// This means their respective order is not deterministic.
// In particular, this means the verbose command lines might be after the start of the subprocess output.
// Using synchronous I/O does not solve this problem.
// However, this only seems to happen when the stdout/stderr target
// (e.g. a terminal) is being written to by many subprocesses at once, which is unlikely in real scenarios.
const verboseLog = ({type, verboseMessage, fdNumber, verboseInfo, result}) => {
	const verboseObject = getVerboseObject({type, result, verboseInfo});
	const printedLines = getPrintedLines(verboseMessage, verboseObject);
	const finalLines = applyVerboseOnLines(printedLines, verboseInfo, fdNumber);
	if (finalLines !== '') {
		console.warn(finalLines.slice(0, -1));
	}
};

const getVerboseObject = ({
	type,
	result,
	verboseInfo: {escapedCommand, commandId, rawOptions: {piped = false, ...options}},
}) => ({
	type,
	escapedCommand,
	commandId: `${commandId}`,
	timestamp: new Date(),
	piped,
	result,
	options,
});

const getPrintedLines = (verboseMessage, verboseObject) => verboseMessage
	.split('\n')
	.map(message => getPrintedLine({...verboseObject, message}));

const getPrintedLine = verboseObject => {
	const verboseLine = defaultVerboseFunction(verboseObject);
	return {verboseLine, verboseObject};
};

// Serialize any type to a line string, for logging
const serializeVerboseMessage = message => {
	const messageString = typeof message === 'string' ? message : inspect(message);
	const escapedMessage = escapeLines(messageString);
	return escapedMessage.replaceAll('\t', ' '.repeat(TAB_SIZE));
};

// Same as `util.inspect()`
const TAB_SIZE = 2;

// When `verbose` is `short|full|custom`, print each command
const logCommand = (escapedCommand, verboseInfo) => {
	if (!isVerbose(verboseInfo)) {
		return;
	}

	verboseLog({
		type: 'command',
		verboseMessage: escapedCommand,
		verboseInfo,
	});
};

// Information computed before spawning, used by the `verbose` option
const getVerboseInfo = (verbose, escapedCommand, rawOptions) => {
	validateVerbose(verbose);
	const commandId = getCommandId(verbose);
	return {
		verbose,
		escapedCommand,
		commandId,
		rawOptions,
	};
};

const getCommandId = verbose => isVerbose({verbose}) ? COMMAND_ID++ : undefined;

// Prepending the `pid` is useful when multiple commands print their output at the same time.
// However, we cannot use the real PID since this is not available with `child_process.spawnSync()`.
// Also, we cannot use the real PID if we want to print it before `child_process.spawn()` is run.
// As a pro, it is shorter than a normal PID and never re-uses the same id.
// As a con, it cannot be used to send signals.
let COMMAND_ID = 0n;

const validateVerbose = verbose => {
	for (const fdVerbose of verbose) {
		if (fdVerbose === false) {
			throw new TypeError('The "verbose: false" option was renamed to "verbose: \'none\'".');
		}

		if (fdVerbose === true) {
			throw new TypeError('The "verbose: true" option was renamed to "verbose: \'short\'".');
		}

		if (!VERBOSE_VALUES.includes(fdVerbose) && !isVerboseFunction(fdVerbose)) {
			const allowedValues = VERBOSE_VALUES.map(allowedValue => `'${allowedValue}'`).join(', ');
			throw new TypeError(`The "verbose" option must not be ${fdVerbose}. Allowed values are: ${allowedValues} or a function.`);
		}
	}
};

// Start counting time before spawning the subprocess
const getStartTime = () => hrtime.bigint();

// Compute duration after the subprocess ended.
// Printed by the `verbose` option.
const getDurationMs = startTime => Number(hrtime.bigint() - startTime) / 1e6;

// Compute `result.command`, `result.escapedCommand` and `verbose`-related information
const handleCommand = (filePath, rawArguments, rawOptions) => {
	const startTime = getStartTime();
	const {command, escapedCommand} = joinCommand(filePath, rawArguments);
	const verbose = normalizeFdSpecificOption(rawOptions, 'verbose');
	const verboseInfo = getVerboseInfo(verbose, escapedCommand, {...rawOptions});
	logCommand(escapedCommand, verboseInfo);
	return {
		command,
		escapedCommand,
		startTime,
		verboseInfo,
	};
};

var crossSpawn$1 = {exports: {}};

var windows$1;
var hasRequiredWindows;

function requireWindows () {
	if (hasRequiredWindows) return windows$1;
	hasRequiredWindows = 1;
	windows$1 = isexe;
	isexe.sync = sync;

	var fs = require$$0;

	function checkPathExt (path, options) {
	  var pathext = options.pathExt !== undefined ?
	    options.pathExt : process.env.PATHEXT;

	  if (!pathext) {
	    return true
	  }

	  pathext = pathext.split(';');
	  if (pathext.indexOf('') !== -1) {
	    return true
	  }
	  for (var i = 0; i < pathext.length; i++) {
	    var p = pathext[i].toLowerCase();
	    if (p && path.substr(-p.length).toLowerCase() === p) {
	      return true
	    }
	  }
	  return false
	}

	function checkStat (stat, path, options) {
	  if (!stat.isSymbolicLink() && !stat.isFile()) {
	    return false
	  }
	  return checkPathExt(path, options)
	}

	function isexe (path, options, cb) {
	  fs.stat(path, function (er, stat) {
	    cb(er, er ? false : checkStat(stat, path, options));
	  });
	}

	function sync (path, options) {
	  return checkStat(fs.statSync(path), path, options)
	}
	return windows$1;
}

var mode;
var hasRequiredMode;

function requireMode () {
	if (hasRequiredMode) return mode;
	hasRequiredMode = 1;
	mode = isexe;
	isexe.sync = sync;

	var fs = require$$0;

	function isexe (path, options, cb) {
	  fs.stat(path, function (er, stat) {
	    cb(er, er ? false : checkStat(stat, options));
	  });
	}

	function sync (path, options) {
	  return checkStat(fs.statSync(path), options)
	}

	function checkStat (stat, options) {
	  return stat.isFile() && checkMode(stat, options)
	}

	function checkMode (stat, options) {
	  var mod = stat.mode;
	  var uid = stat.uid;
	  var gid = stat.gid;

	  var myUid = options.uid !== undefined ?
	    options.uid : process.getuid && process.getuid();
	  var myGid = options.gid !== undefined ?
	    options.gid : process.getgid && process.getgid();

	  var u = parseInt('100', 8);
	  var g = parseInt('010', 8);
	  var o = parseInt('001', 8);
	  var ug = u | g;

	  var ret = (mod & o) ||
	    (mod & g) && gid === myGid ||
	    (mod & u) && uid === myUid ||
	    (mod & ug) && myUid === 0;

	  return ret
	}
	return mode;
}

var isexe_1;
var hasRequiredIsexe;

function requireIsexe () {
	if (hasRequiredIsexe) return isexe_1;
	hasRequiredIsexe = 1;
	var core;
	if (process.platform === 'win32' || commonjsGlobal.TESTING_WINDOWS) {
	  core = requireWindows();
	} else {
	  core = requireMode();
	}

	isexe_1 = isexe;
	isexe.sync = sync;

	function isexe (path, options, cb) {
	  if (typeof options === 'function') {
	    cb = options;
	    options = {};
	  }

	  if (!cb) {
	    if (typeof Promise !== 'function') {
	      throw new TypeError('callback not provided')
	    }

	    return new Promise(function (resolve, reject) {
	      isexe(path, options || {}, function (er, is) {
	        if (er) {
	          reject(er);
	        } else {
	          resolve(is);
	        }
	      });
	    })
	  }

	  core(path, options || {}, function (er, is) {
	    // ignore EACCES because that just means we aren't allowed to run it
	    if (er) {
	      if (er.code === 'EACCES' || options && options.ignoreErrors) {
	        er = null;
	        is = false;
	      }
	    }
	    cb(er, is);
	  });
	}

	function sync (path, options) {
	  // my kingdom for a filtered catch
	  try {
	    return core.sync(path, options || {})
	  } catch (er) {
	    if (options && options.ignoreErrors || er.code === 'EACCES') {
	      return false
	    } else {
	      throw er
	    }
	  }
	}
	return isexe_1;
}

var which_1;
var hasRequiredWhich;

function requireWhich () {
	if (hasRequiredWhich) return which_1;
	hasRequiredWhich = 1;
	const isWindows = process.platform === 'win32' ||
	    process.env.OSTYPE === 'cygwin' ||
	    process.env.OSTYPE === 'msys';

	const path = require$$0$1;
	const COLON = isWindows ? ';' : ':';
	const isexe = requireIsexe();

	const getNotFoundError = (cmd) =>
	  Object.assign(new Error(`not found: ${cmd}`), { code: 'ENOENT' });

	const getPathInfo = (cmd, opt) => {
	  const colon = opt.colon || COLON;

	  // If it has a slash, then we don't bother searching the pathenv.
	  // just check the file itself, and that's it.
	  const pathEnv = cmd.match(/\//) || isWindows && cmd.match(/\\/) ? ['']
	    : (
	      [
	        // windows always checks the cwd first
	        ...(isWindows ? [process.cwd()] : []),
	        ...(opt.path || process.env.PATH ||
	          /* istanbul ignore next: very unusual */ '').split(colon),
	      ]
	    );
	  const pathExtExe = isWindows
	    ? opt.pathExt || process.env.PATHEXT || '.EXE;.CMD;.BAT;.COM'
	    : '';
	  const pathExt = isWindows ? pathExtExe.split(colon) : [''];

	  if (isWindows) {
	    if (cmd.indexOf('.') !== -1 && pathExt[0] !== '')
	      pathExt.unshift('');
	  }

	  return {
	    pathEnv,
	    pathExt,
	    pathExtExe,
	  }
	};

	const which = (cmd, opt, cb) => {
	  if (typeof opt === 'function') {
	    cb = opt;
	    opt = {};
	  }
	  if (!opt)
	    opt = {};

	  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt);
	  const found = [];

	  const step = i => new Promise((resolve, reject) => {
	    if (i === pathEnv.length)
	      return opt.all && found.length ? resolve(found)
	        : reject(getNotFoundError(cmd))

	    const ppRaw = pathEnv[i];
	    const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw;

	    const pCmd = path.join(pathPart, cmd);
	    const p = !pathPart && /^\.[\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd
	      : pCmd;

	    resolve(subStep(p, i, 0));
	  });

	  const subStep = (p, i, ii) => new Promise((resolve, reject) => {
	    if (ii === pathExt.length)
	      return resolve(step(i + 1))
	    const ext = pathExt[ii];
	    isexe(p + ext, { pathExt: pathExtExe }, (er, is) => {
	      if (!er && is) {
	        if (opt.all)
	          found.push(p + ext);
	        else
	          return resolve(p + ext)
	      }
	      return resolve(subStep(p, i, ii + 1))
	    });
	  });

	  return cb ? step(0).then(res => cb(null, res), cb) : step(0)
	};

	const whichSync = (cmd, opt) => {
	  opt = opt || {};

	  const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt);
	  const found = [];

	  for (let i = 0; i < pathEnv.length; i ++) {
	    const ppRaw = pathEnv[i];
	    const pathPart = /^".*"$/.test(ppRaw) ? ppRaw.slice(1, -1) : ppRaw;

	    const pCmd = path.join(pathPart, cmd);
	    const p = !pathPart && /^\.[\\\/]/.test(cmd) ? cmd.slice(0, 2) + pCmd
	      : pCmd;

	    for (let j = 0; j < pathExt.length; j ++) {
	      const cur = p + pathExt[j];
	      try {
	        const is = isexe.sync(cur, { pathExt: pathExtExe });
	        if (is) {
	          if (opt.all)
	            found.push(cur);
	          else
	            return cur
	        }
	      } catch (ex) {}
	    }
	  }

	  if (opt.all && found.length)
	    return found

	  if (opt.nothrow)
	    return null

	  throw getNotFoundError(cmd)
	};

	which_1 = which;
	which.sync = whichSync;
	return which_1;
}

var pathKey$1 = {exports: {}};

var hasRequiredPathKey;

function requirePathKey () {
	if (hasRequiredPathKey) return pathKey$1.exports;
	hasRequiredPathKey = 1;

	const pathKey = (options = {}) => {
		const environment = options.env || process.env;
		const platform = options.platform || process.platform;

		if (platform !== 'win32') {
			return 'PATH';
		}

		return Object.keys(environment).reverse().find(key => key.toUpperCase() === 'PATH') || 'Path';
	};

	pathKey$1.exports = pathKey;
	// TODO: Remove this for the next major release
	pathKey$1.exports.default = pathKey;
	return pathKey$1.exports;
}

var resolveCommand_1;
var hasRequiredResolveCommand;

function requireResolveCommand () {
	if (hasRequiredResolveCommand) return resolveCommand_1;
	hasRequiredResolveCommand = 1;

	const path = require$$0$1;
	const which = requireWhich();
	const getPathKey = requirePathKey();

	function resolveCommandAttempt(parsed, withoutPathExt) {
	    const env = parsed.options.env || process.env;
	    const cwd = process.cwd();
	    const hasCustomCwd = parsed.options.cwd != null;
	    // Worker threads do not have process.chdir()
	    const shouldSwitchCwd = hasCustomCwd && process.chdir !== undefined && !process.chdir.disabled;

	    // If a custom `cwd` was specified, we need to change the process cwd
	    // because `which` will do stat calls but does not support a custom cwd
	    if (shouldSwitchCwd) {
	        try {
	            process.chdir(parsed.options.cwd);
	        } catch (err) {
	            /* Empty */
	        }
	    }

	    let resolved;

	    try {
	        resolved = which.sync(parsed.command, {
	            path: env[getPathKey({ env })],
	            pathExt: withoutPathExt ? path.delimiter : undefined,
	        });
	    } catch (e) {
	        /* Empty */
	    } finally {
	        if (shouldSwitchCwd) {
	            process.chdir(cwd);
	        }
	    }

	    // If we successfully resolved, ensure that an absolute path is returned
	    // Note that when a custom `cwd` was used, we need to resolve to an absolute path based on it
	    if (resolved) {
	        resolved = path.resolve(hasCustomCwd ? parsed.options.cwd : '', resolved);
	    }

	    return resolved;
	}

	function resolveCommand(parsed) {
	    return resolveCommandAttempt(parsed) || resolveCommandAttempt(parsed, true);
	}

	resolveCommand_1 = resolveCommand;
	return resolveCommand_1;
}

var _escape = {};

var hasRequired_escape;

function require_escape () {
	if (hasRequired_escape) return _escape;
	hasRequired_escape = 1;

	// See http://www.robvanderwoude.com/escapechars.php
	const metaCharsRegExp = /([()\][%!^"`<>&|;, *?])/g;

	function escapeCommand(arg) {
	    // Escape meta chars
	    arg = arg.replace(metaCharsRegExp, '^$1');

	    return arg;
	}

	function escapeArgument(arg, doubleEscapeMetaChars) {
	    // Convert to string
	    arg = `${arg}`;

	    // Algorithm below is based on https://qntm.org/cmd
	    // It's slightly altered to disable JS backtracking to avoid hanging on specially crafted input
	    // Please see https://github.com/moxystudio/node-cross-spawn/pull/160 for more information

	    // Sequence of backslashes followed by a double quote:
	    // double up all the backslashes and escape the double quote
	    arg = arg.replace(/(?=(\\+?)?)\1"/g, '$1$1\\"');

	    // Sequence of backslashes followed by the end of the string
	    // (which will become a double quote later):
	    // double up all the backslashes
	    arg = arg.replace(/(?=(\\+?)?)\1$/, '$1$1');

	    // All other backslashes occur literally

	    // Quote the whole thing:
	    arg = `"${arg}"`;

	    // Escape meta chars
	    arg = arg.replace(metaCharsRegExp, '^$1');

	    // Double escape meta chars if necessary
	    if (doubleEscapeMetaChars) {
	        arg = arg.replace(metaCharsRegExp, '^$1');
	    }

	    return arg;
	}

	_escape.command = escapeCommand;
	_escape.argument = escapeArgument;
	return _escape;
}

var shebangRegex;
var hasRequiredShebangRegex;

function requireShebangRegex () {
	if (hasRequiredShebangRegex) return shebangRegex;
	hasRequiredShebangRegex = 1;
	shebangRegex = /^#!(.*)/;
	return shebangRegex;
}

var shebangCommand;
var hasRequiredShebangCommand;

function requireShebangCommand () {
	if (hasRequiredShebangCommand) return shebangCommand;
	hasRequiredShebangCommand = 1;
	const shebangRegex = requireShebangRegex();

	shebangCommand = (string = '') => {
		const match = string.match(shebangRegex);

		if (!match) {
			return null;
		}

		const [path, argument] = match[0].replace(/#! ?/, '').split(' ');
		const binary = path.split('/').pop();

		if (binary === 'env') {
			return argument;
		}

		return argument ? `${binary} ${argument}` : binary;
	};
	return shebangCommand;
}

var readShebang_1;
var hasRequiredReadShebang;

function requireReadShebang () {
	if (hasRequiredReadShebang) return readShebang_1;
	hasRequiredReadShebang = 1;

	const fs = require$$0;
	const shebangCommand = requireShebangCommand();

	function readShebang(command) {
	    // Read the first 150 bytes from the file
	    const size = 150;
	    const buffer = Buffer.alloc(size);

	    let fd;

	    try {
	        fd = fs.openSync(command, 'r');
	        fs.readSync(fd, buffer, 0, size, 0);
	        fs.closeSync(fd);
	    } catch (e) { /* Empty */ }

	    // Attempt to extract shebang (null is returned if not a shebang)
	    return shebangCommand(buffer.toString());
	}

	readShebang_1 = readShebang;
	return readShebang_1;
}

var parse_1;
var hasRequiredParse$1;

function requireParse$1 () {
	if (hasRequiredParse$1) return parse_1;
	hasRequiredParse$1 = 1;

	const path = require$$0$1;
	const resolveCommand = requireResolveCommand();
	const escape = require_escape();
	const readShebang = requireReadShebang();

	const isWin = process.platform === 'win32';
	const isExecutableRegExp = /\.(?:com|exe)$/i;
	const isCmdShimRegExp = /node_modules[\\/].bin[\\/][^\\/]+\.cmd$/i;

	function detectShebang(parsed) {
	    parsed.file = resolveCommand(parsed);

	    const shebang = parsed.file && readShebang(parsed.file);

	    if (shebang) {
	        parsed.args.unshift(parsed.file);
	        parsed.command = shebang;

	        return resolveCommand(parsed);
	    }

	    return parsed.file;
	}

	function parseNonShell(parsed) {
	    if (!isWin) {
	        return parsed;
	    }

	    // Detect & add support for shebangs
	    const commandFile = detectShebang(parsed);

	    // We don't need a shell if the command filename is an executable
	    const needsShell = !isExecutableRegExp.test(commandFile);

	    // If a shell is required, use cmd.exe and take care of escaping everything correctly
	    // Note that `forceShell` is an hidden option used only in tests
	    if (parsed.options.forceShell || needsShell) {
	        // Need to double escape meta chars if the command is a cmd-shim located in `node_modules/.bin/`
	        // The cmd-shim simply calls execute the package bin file with NodeJS, proxying any argument
	        // Because the escape of metachars with ^ gets interpreted when the cmd.exe is first called,
	        // we need to double escape them
	        const needsDoubleEscapeMetaChars = isCmdShimRegExp.test(commandFile);

	        // Normalize posix paths into OS compatible paths (e.g.: foo/bar -> foo\bar)
	        // This is necessary otherwise it will always fail with ENOENT in those cases
	        parsed.command = path.normalize(parsed.command);

	        // Escape command & arguments
	        parsed.command = escape.command(parsed.command);
	        parsed.args = parsed.args.map((arg) => escape.argument(arg, needsDoubleEscapeMetaChars));

	        const shellCommand = [parsed.command].concat(parsed.args).join(' ');

	        parsed.args = ['/d', '/s', '/c', `"${shellCommand}"`];
	        parsed.command = process.env.comspec || 'cmd.exe';
	        parsed.options.windowsVerbatimArguments = true; // Tell node's spawn that the arguments are already escaped
	    }

	    return parsed;
	}

	function parse(command, args, options) {
	    // Normalize arguments, similar to nodejs
	    if (args && !Array.isArray(args)) {
	        options = args;
	        args = null;
	    }

	    args = args ? args.slice(0) : []; // Clone array to avoid changing the original
	    options = Object.assign({}, options); // Clone object to avoid changing the original

	    // Build our parsed object
	    const parsed = {
	        command,
	        args,
	        options,
	        file: undefined,
	        original: {
	            command,
	            args,
	        },
	    };

	    // Delegate further parsing to shell or non-shell
	    return options.shell ? parsed : parseNonShell(parsed);
	}

	parse_1 = parse;
	return parse_1;
}

var enoent;
var hasRequiredEnoent;

function requireEnoent () {
	if (hasRequiredEnoent) return enoent;
	hasRequiredEnoent = 1;

	const isWin = process.platform === 'win32';

	function notFoundError(original, syscall) {
	    return Object.assign(new Error(`${syscall} ${original.command} ENOENT`), {
	        code: 'ENOENT',
	        errno: 'ENOENT',
	        syscall: `${syscall} ${original.command}`,
	        path: original.command,
	        spawnargs: original.args,
	    });
	}

	function hookChildProcess(cp, parsed) {
	    if (!isWin) {
	        return;
	    }

	    const originalEmit = cp.emit;

	    cp.emit = function (name, arg1) {
	        // If emitting "exit" event and exit code is 1, we need to check if
	        // the command exists and emit an "error" instead
	        // See https://github.com/IndigoUnited/node-cross-spawn/issues/16
	        if (name === 'exit') {
	            const err = verifyENOENT(arg1, parsed);

	            if (err) {
	                return originalEmit.call(cp, 'error', err);
	            }
	        }

	        return originalEmit.apply(cp, arguments); // eslint-disable-line prefer-rest-params
	    };
	}

	function verifyENOENT(status, parsed) {
	    if (isWin && status === 1 && !parsed.file) {
	        return notFoundError(parsed.original, 'spawn');
	    }

	    return null;
	}

	function verifyENOENTSync(status, parsed) {
	    if (isWin && status === 1 && !parsed.file) {
	        return notFoundError(parsed.original, 'spawnSync');
	    }

	    return null;
	}

	enoent = {
	    hookChildProcess,
	    verifyENOENT,
	    verifyENOENTSync,
	    notFoundError,
	};
	return enoent;
}

var hasRequiredCrossSpawn;

function requireCrossSpawn () {
	if (hasRequiredCrossSpawn) return crossSpawn$1.exports;
	hasRequiredCrossSpawn = 1;

	const cp = require$$0$2;
	const parse = requireParse$1();
	const enoent = requireEnoent();

	function spawn(command, args, options) {
	    // Parse the arguments
	    const parsed = parse(command, args, options);

	    // Spawn the child process
	    const spawned = cp.spawn(parsed.command, parsed.args, parsed.options);

	    // Hook into child process "exit" event to emit an error if the command
	    // does not exists, see: https://github.com/IndigoUnited/node-cross-spawn/issues/16
	    enoent.hookChildProcess(spawned, parsed);

	    return spawned;
	}

	function spawnSync(command, args, options) {
	    // Parse the arguments
	    const parsed = parse(command, args, options);

	    // Spawn the child process
	    const result = cp.spawnSync(parsed.command, parsed.args, parsed.options);

	    // Analyze if the command does not exist, see: https://github.com/IndigoUnited/node-cross-spawn/issues/16
	    result.error = result.error || enoent.verifyENOENTSync(result.status, parsed);

	    return result;
	}

	crossSpawn$1.exports = spawn;
	crossSpawn$1.exports.spawn = spawn;
	crossSpawn$1.exports.sync = spawnSync;

	crossSpawn$1.exports._parse = parse;
	crossSpawn$1.exports._enoent = enoent;
	return crossSpawn$1.exports;
}

var crossSpawnExports = requireCrossSpawn();
const crossSpawn = /*@__PURE__*/getDefaultExportFromCjs(crossSpawnExports);

function pathKey(options = {}) {
	const {
		env = process.env,
		platform = process.platform
	} = options;

	if (platform !== 'win32') {
		return 'PATH';
	}

	return Object.keys(env).reverse().find(key => key.toUpperCase() === 'PATH') || 'Path';
}

promisify(execFile);

function toPath(urlOrPath) {
	return urlOrPath instanceof URL ? fileURLToPath(urlOrPath) : urlOrPath;
}

function traversePathUp(startPath) {
	return {
		* [Symbol.iterator]() {
			let currentPath = path.resolve(toPath(startPath));
			let previousPath;

			while (previousPath !== currentPath) {
				yield currentPath;
				previousPath = currentPath;
				currentPath = path.resolve(currentPath, '..');
			}
		},
	};
}

const npmRunPath = ({
	cwd = process$2.cwd(),
	path: pathOption = process$2.env[pathKey()],
	preferLocal = true,
	execPath = process$2.execPath,
	addExecPath = true,
} = {}) => {
	const cwdPath = path.resolve(toPath(cwd));
	const result = [];
	const pathParts = pathOption.split(path.delimiter);

	if (preferLocal) {
		applyPreferLocal(result, pathParts, cwdPath);
	}

	if (addExecPath) {
		applyExecPath(result, pathParts, execPath, cwdPath);
	}

	return pathOption === '' || pathOption === path.delimiter
		? `${result.join(path.delimiter)}${pathOption}`
		: [...result, pathOption].join(path.delimiter);
};

const applyPreferLocal = (result, pathParts, cwdPath) => {
	for (const directory of traversePathUp(cwdPath)) {
		const pathPart = path.join(directory, 'node_modules/.bin');
		if (!pathParts.includes(pathPart)) {
			result.push(pathPart);
		}
	}
};

// Ensure the running `node` binary is used
const applyExecPath = (result, pathParts, execPath, cwdPath) => {
	const pathPart = path.resolve(cwdPath, toPath(execPath), '..');
	if (!pathParts.includes(pathPart)) {
		result.push(pathPart);
	}
};

const npmRunPathEnv = ({env = process$2.env, ...options} = {}) => {
	env = {...env};

	const pathName = pathKey({env});
	options.path = env[pathName];
	env[pathName] = npmRunPath(options);

	return env;
};

// When the subprocess fails, this is the error instance being returned.
// If another error instance is being thrown, it is kept as `error.cause`.
const getFinalError = (originalError, message, isSync) => {
	const ErrorClass = isSync ? ExecaSyncError : ExecaError;
	const options = originalError instanceof DiscardedError ? {} : {cause: originalError};
	return new ErrorClass(message, options);
};

// Indicates that the error is used only to interrupt control flow, but not in the return value
class DiscardedError extends Error {}

// Proper way to set `error.name`: it should be inherited and non-enumerable
const setErrorName = (ErrorClass, value) => {
	Object.defineProperty(ErrorClass.prototype, 'name', {
		value,
		writable: true,
		enumerable: false,
		configurable: true,
	});
	Object.defineProperty(ErrorClass.prototype, execaErrorSymbol, {
		value: true,
		writable: false,
		enumerable: false,
		configurable: false,
	});
};

// Unlike `instanceof`, this works across realms
const isExecaError = error => isErrorInstance(error) && execaErrorSymbol in error;

const execaErrorSymbol = Symbol('isExecaError');

const isErrorInstance = value => Object.prototype.toString.call(value) === '[object Error]';

// We use two different Error classes for async/sync methods since they have slightly different shape and types
class ExecaError extends Error {}
setErrorName(ExecaError, ExecaError.name);

class ExecaSyncError extends Error {}
setErrorName(ExecaSyncError, ExecaSyncError.name);

const getRealtimeSignals=()=>{
const length=SIGRTMAX-SIGRTMIN+1;
return Array.from({length},getRealtimeSignal)
};

const getRealtimeSignal=(value,index)=>({
name:`SIGRT${index+1}`,
number:SIGRTMIN+index,
action:"terminate",
description:"Application-specific signal (realtime)",
standard:"posix"
});

const SIGRTMIN=34;
const SIGRTMAX=64;

const SIGNALS=[
{
name:"SIGHUP",
number:1,
action:"terminate",
description:"Terminal closed",
standard:"posix"
},
{
name:"SIGINT",
number:2,
action:"terminate",
description:"User interruption with CTRL-C",
standard:"ansi"
},
{
name:"SIGQUIT",
number:3,
action:"core",
description:"User interruption with CTRL-\\",
standard:"posix"
},
{
name:"SIGILL",
number:4,
action:"core",
description:"Invalid machine instruction",
standard:"ansi"
},
{
name:"SIGTRAP",
number:5,
action:"core",
description:"Debugger breakpoint",
standard:"posix"
},
{
name:"SIGABRT",
number:6,
action:"core",
description:"Aborted",
standard:"ansi"
},
{
name:"SIGIOT",
number:6,
action:"core",
description:"Aborted",
standard:"bsd"
},
{
name:"SIGBUS",
number:7,
action:"core",
description:
"Bus error due to misaligned, non-existing address or paging error",
standard:"bsd"
},
{
name:"SIGEMT",
number:7,
action:"terminate",
description:"Command should be emulated but is not implemented",
standard:"other"
},
{
name:"SIGFPE",
number:8,
action:"core",
description:"Floating point arithmetic error",
standard:"ansi"
},
{
name:"SIGKILL",
number:9,
action:"terminate",
description:"Forced termination",
standard:"posix",
forced:true
},
{
name:"SIGUSR1",
number:10,
action:"terminate",
description:"Application-specific signal",
standard:"posix"
},
{
name:"SIGSEGV",
number:11,
action:"core",
description:"Segmentation fault",
standard:"ansi"
},
{
name:"SIGUSR2",
number:12,
action:"terminate",
description:"Application-specific signal",
standard:"posix"
},
{
name:"SIGPIPE",
number:13,
action:"terminate",
description:"Broken pipe or socket",
standard:"posix"
},
{
name:"SIGALRM",
number:14,
action:"terminate",
description:"Timeout or timer",
standard:"posix"
},
{
name:"SIGTERM",
number:15,
action:"terminate",
description:"Termination",
standard:"ansi"
},
{
name:"SIGSTKFLT",
number:16,
action:"terminate",
description:"Stack is empty or overflowed",
standard:"other"
},
{
name:"SIGCHLD",
number:17,
action:"ignore",
description:"Child process terminated, paused or unpaused",
standard:"posix"
},
{
name:"SIGCLD",
number:17,
action:"ignore",
description:"Child process terminated, paused or unpaused",
standard:"other"
},
{
name:"SIGCONT",
number:18,
action:"unpause",
description:"Unpaused",
standard:"posix",
forced:true
},
{
name:"SIGSTOP",
number:19,
action:"pause",
description:"Paused",
standard:"posix",
forced:true
},
{
name:"SIGTSTP",
number:20,
action:"pause",
description:"Paused using CTRL-Z or \"suspend\"",
standard:"posix"
},
{
name:"SIGTTIN",
number:21,
action:"pause",
description:"Background process cannot read terminal input",
standard:"posix"
},
{
name:"SIGBREAK",
number:21,
action:"terminate",
description:"User interruption with CTRL-BREAK",
standard:"other"
},
{
name:"SIGTTOU",
number:22,
action:"pause",
description:"Background process cannot write to terminal output",
standard:"posix"
},
{
name:"SIGURG",
number:23,
action:"ignore",
description:"Socket received out-of-band data",
standard:"bsd"
},
{
name:"SIGXCPU",
number:24,
action:"core",
description:"Process timed out",
standard:"bsd"
},
{
name:"SIGXFSZ",
number:25,
action:"core",
description:"File too big",
standard:"bsd"
},
{
name:"SIGVTALRM",
number:26,
action:"terminate",
description:"Timeout or timer",
standard:"bsd"
},
{
name:"SIGPROF",
number:27,
action:"terminate",
description:"Timeout or timer",
standard:"bsd"
},
{
name:"SIGWINCH",
number:28,
action:"ignore",
description:"Terminal window size changed",
standard:"bsd"
},
{
name:"SIGIO",
number:29,
action:"terminate",
description:"I/O is available",
standard:"other"
},
{
name:"SIGPOLL",
number:29,
action:"terminate",
description:"Watched event",
standard:"other"
},
{
name:"SIGINFO",
number:29,
action:"ignore",
description:"Request for process information",
standard:"other"
},
{
name:"SIGPWR",
number:30,
action:"terminate",
description:"Device running out of power",
standard:"systemv"
},
{
name:"SIGSYS",
number:31,
action:"core",
description:"Invalid system call",
standard:"other"
},
{
name:"SIGUNUSED",
number:31,
action:"terminate",
description:"Invalid system call",
standard:"other"
}];

const getSignals=()=>{
const realtimeSignals=getRealtimeSignals();
const signals=[...SIGNALS,...realtimeSignals].map(normalizeSignal$1);
return signals
};







const normalizeSignal$1=({
name,
number:defaultNumber,
description,
action,
forced=false,
standard
})=>{
const{
signals:{[name]:constantSignal}
}=constants$5;
const supported=constantSignal!==undefined;
const number=supported?constantSignal:defaultNumber;
return {name,number,description,supported,action,forced,standard}
};

const getSignalsByName=()=>{
const signals=getSignals();
return Object.fromEntries(signals.map(getSignalByName))
};

const getSignalByName=({
name,
number,
description,
supported,
action,
forced,
standard
})=>[name,{name,number,description,supported,action,forced,standard}];

const signalsByName=getSignalsByName();




const getSignalsByNumber=()=>{
const signals=getSignals();
const length=SIGRTMAX+1;
const signalsA=Array.from({length},(value,number)=>
getSignalByNumber(number,signals)
);
return Object.assign({},...signalsA)
};

const getSignalByNumber=(number,signals)=>{
const signal=findSignalByNumber(number,signals);

if(signal===undefined){
return {}
}

const{name,description,supported,action,forced,standard}=signal;
return {
[number]:{
name,
number,
description,
supported,
action,
forced,
standard
}
}
};



const findSignalByNumber=(number,signals)=>{
const signal=signals.find(({name})=>constants$5.signals[name]===number);

if(signal!==undefined){
return signal
}

return signals.find((signalA)=>signalA.number===number)
};

getSignalsByNumber();

// Normalize signals for comparison purpose.
// Also validate the signal exists.
const normalizeKillSignal = killSignal => {
	const optionName = 'option `killSignal`';
	if (killSignal === 0) {
		throw new TypeError(`Invalid ${optionName}: 0 cannot be used.`);
	}

	return normalizeSignal(killSignal, optionName);
};

const normalizeSignalArgument = signal => signal === 0
	? signal
	: normalizeSignal(signal, '`subprocess.kill()`\'s argument');

const normalizeSignal = (signalNameOrInteger, optionName) => {
	if (Number.isInteger(signalNameOrInteger)) {
		return normalizeSignalInteger(signalNameOrInteger, optionName);
	}

	if (typeof signalNameOrInteger === 'string') {
		return normalizeSignalName(signalNameOrInteger, optionName);
	}

	throw new TypeError(`Invalid ${optionName} ${String(signalNameOrInteger)}: it must be a string or an integer.\n${getAvailableSignals()}`);
};

const normalizeSignalInteger = (signalInteger, optionName) => {
	if (signalsIntegerToName.has(signalInteger)) {
		return signalsIntegerToName.get(signalInteger);
	}

	throw new TypeError(`Invalid ${optionName} ${signalInteger}: this signal integer does not exist.\n${getAvailableSignals()}`);
};

const getSignalsIntegerToName = () => new Map(Object.entries(constants$5.signals)
	.reverse()
	.map(([signalName, signalInteger]) => [signalInteger, signalName]));

const signalsIntegerToName = getSignalsIntegerToName();

const normalizeSignalName = (signalName, optionName) => {
	if (signalName in constants$5.signals) {
		return signalName;
	}

	if (signalName.toUpperCase() in constants$5.signals) {
		throw new TypeError(`Invalid ${optionName} '${signalName}': please rename it to '${signalName.toUpperCase()}'.`);
	}

	throw new TypeError(`Invalid ${optionName} '${signalName}': this signal name does not exist.\n${getAvailableSignals()}`);
};

const getAvailableSignals = () => `Available signal names: ${getAvailableSignalNames()}.
Available signal numbers: ${getAvailableSignalIntegers()}.`;

const getAvailableSignalNames = () => Object.keys(constants$5.signals)
	.sort()
	.map(signalName => `'${signalName}'`)
	.join(', ');

const getAvailableSignalIntegers = () => [...new Set(Object.values(constants$5.signals)
	.sort((signalInteger, signalIntegerTwo) => signalInteger - signalIntegerTwo))]
	.join(', ');

// Human-friendly description of a signal
const getSignalDescription = signal => signalsByName[signal].description;

// Normalize the `forceKillAfterDelay` option
const normalizeForceKillAfterDelay = forceKillAfterDelay => {
	if (forceKillAfterDelay === false) {
		return forceKillAfterDelay;
	}

	if (forceKillAfterDelay === true) {
		return DEFAULT_FORCE_KILL_TIMEOUT;
	}

	if (!Number.isFinite(forceKillAfterDelay) || forceKillAfterDelay < 0) {
		throw new TypeError(`Expected the \`forceKillAfterDelay\` option to be a non-negative integer, got \`${forceKillAfterDelay}\` (${typeof forceKillAfterDelay})`);
	}

	return forceKillAfterDelay;
};

const DEFAULT_FORCE_KILL_TIMEOUT = 1000 * 5;

// Monkey-patches `subprocess.kill()` to add `forceKillAfterDelay` behavior and `.kill(error)`
const subprocessKill = (
	{kill, options: {forceKillAfterDelay, killSignal}, onInternalError, context, controller},
	signalOrError,
	errorArgument,
) => {
	const {signal, error} = parseKillArguments(signalOrError, errorArgument, killSignal);
	emitKillError(error, onInternalError);
	const killResult = kill(signal);
	setKillTimeout({
		kill,
		signal,
		forceKillAfterDelay,
		killSignal,
		killResult,
		context,
		controller,
	});
	return killResult;
};

const parseKillArguments = (signalOrError, errorArgument, killSignal) => {
	const [signal = killSignal, error] = isErrorInstance(signalOrError)
		? [undefined, signalOrError]
		: [signalOrError, errorArgument];

	if (typeof signal !== 'string' && !Number.isInteger(signal)) {
		throw new TypeError(`The first argument must be an error instance or a signal name string/integer: ${String(signal)}`);
	}

	if (error !== undefined && !isErrorInstance(error)) {
		throw new TypeError(`The second argument is optional. If specified, it must be an error instance: ${error}`);
	}

	return {signal: normalizeSignalArgument(signal), error};
};

// Fails right away when calling `subprocess.kill(error)`.
// Does not wait for actual signal termination.
// Uses a deferred promise instead of the `error` event on the subprocess, as this is less intrusive.
const emitKillError = (error, onInternalError) => {
	if (error !== undefined) {
		onInternalError.reject(error);
	}
};

const setKillTimeout = async ({kill, signal, forceKillAfterDelay, killSignal, killResult, context, controller}) => {
	if (signal === killSignal && killResult) {
		killOnTimeout({
			kill,
			forceKillAfterDelay,
			context,
			controllerSignal: controller.signal,
		});
	}
};

// Forcefully terminate a subprocess after a timeout
const killOnTimeout = async ({kill, forceKillAfterDelay, context, controllerSignal}) => {
	if (forceKillAfterDelay === false) {
		return;
	}

	try {
		await setTimeout$1(forceKillAfterDelay, undefined, {signal: controllerSignal});
		if (kill('SIGKILL')) {
			context.isForcefullyTerminated ??= true;
		}
	} catch {}
};

// Combines `util.aborted()` and `events.addAbortListener()`: promise-based and cleaned up with a stop signal
const onAbortedSignal = async (mainSignal, stopSignal) => {
	if (!mainSignal.aborted) {
		await once$2(mainSignal, 'abort', {signal: stopSignal});
	}
};

// Validate the `cancelSignal` option
const validateCancelSignal = ({cancelSignal}) => {
	if (cancelSignal !== undefined && Object.prototype.toString.call(cancelSignal) !== '[object AbortSignal]') {
		throw new Error(`The \`cancelSignal\` option must be an AbortSignal: ${String(cancelSignal)}`);
	}
};

// Terminate the subprocess when aborting the `cancelSignal` option and `gracefulSignal` is `false`
const throwOnCancel = ({subprocess, cancelSignal, gracefulCancel, context, controller}) => cancelSignal === undefined || gracefulCancel
	? []
	: [terminateOnCancel(subprocess, cancelSignal, context, controller)];

const terminateOnCancel = async (subprocess, cancelSignal, context, {signal}) => {
	await onAbortedSignal(cancelSignal, signal);
	context.terminationReason ??= 'cancel';
	subprocess.kill();
	throw cancelSignal.reason;
};

// Validate the IPC channel is connected before receiving/sending messages
const validateIpcMethod = ({methodName, isSubprocess, ipc, isConnected}) => {
	validateIpcOption(methodName, isSubprocess, ipc);
	validateConnection(methodName, isSubprocess, isConnected);
};

// Better error message when forgetting to set `ipc: true` and using the IPC methods
const validateIpcOption = (methodName, isSubprocess, ipc) => {
	if (!ipc) {
		throw new Error(`${getMethodName(methodName, isSubprocess)} can only be used if the \`ipc\` option is \`true\`.`);
	}
};

// Better error message when one process does not send/receive messages once the other process has disconnected.
// This also makes it clear that any buffered messages are lost once either process has disconnected.
// Also when aborting `cancelSignal` after disconnecting the IPC.
const validateConnection = (methodName, isSubprocess, isConnected) => {
	if (!isConnected) {
		throw new Error(`${getMethodName(methodName, isSubprocess)} cannot be used: the ${getOtherProcessName(isSubprocess)} has already exited or disconnected.`);
	}
};

// When `getOneMessage()` could not complete due to an early disconnection
const throwOnEarlyDisconnect = isSubprocess => {
	throw new Error(`${getMethodName('getOneMessage', isSubprocess)} could not complete: the ${getOtherProcessName(isSubprocess)} exited or disconnected.`);
};

// When both processes use `sendMessage()` with `strict` at the same time
const throwOnStrictDeadlockError = isSubprocess => {
	throw new Error(`${getMethodName('sendMessage', isSubprocess)} failed: the ${getOtherProcessName(isSubprocess)} is sending a message too, instead of listening to incoming messages.
This can be fixed by both sending a message and listening to incoming messages at the same time:

const [receivedMessage] = await Promise.all([
	${getMethodName('getOneMessage', isSubprocess)},
	${getMethodName('sendMessage', isSubprocess, 'message, {strict: true}')},
]);`);
};

// When the other process used `strict` but the current process had I/O error calling `sendMessage()` for the response
const getStrictResponseError = (error, isSubprocess) => new Error(`${getMethodName('sendMessage', isSubprocess)} failed when sending an acknowledgment response to the ${getOtherProcessName(isSubprocess)}.`, {cause: error});

// When using `strict` but the other process was not listening for messages
const throwOnMissingStrict = isSubprocess => {
	throw new Error(`${getMethodName('sendMessage', isSubprocess)} failed: the ${getOtherProcessName(isSubprocess)} is not listening to incoming messages.`);
};

// When using `strict` but the other process disconnected before receiving the message
const throwOnStrictDisconnect = isSubprocess => {
	throw new Error(`${getMethodName('sendMessage', isSubprocess)} failed: the ${getOtherProcessName(isSubprocess)} exited without listening to incoming messages.`);
};

// When the current process disconnects while the subprocess is listening to `cancelSignal`
const getAbortDisconnectError = () => new Error(`\`cancelSignal\` aborted: the ${getOtherProcessName(true)} disconnected.`);

// When the subprocess uses `cancelSignal` but not the current process
const throwOnMissingParent = () => {
	throw new Error('`getCancelSignal()` cannot be used without setting the `cancelSignal` subprocess option.');
};

// EPIPE can happen when sending a message to a subprocess that is closing but has not disconnected yet
const handleEpipeError = ({error, methodName, isSubprocess}) => {
	if (error.code === 'EPIPE') {
		throw new Error(`${getMethodName(methodName, isSubprocess)} cannot be used: the ${getOtherProcessName(isSubprocess)} is disconnecting.`, {cause: error});
	}
};

// Better error message when sending messages which cannot be serialized.
// Works with both `serialization: 'advanced'` and `serialization: 'json'`.
const handleSerializationError = ({error, methodName, isSubprocess, message}) => {
	if (isSerializationError(error)) {
		throw new Error(`${getMethodName(methodName, isSubprocess)}'s argument type is invalid: the message cannot be serialized: ${String(message)}.`, {cause: error});
	}
};

const isSerializationError = ({code, message}) => SERIALIZATION_ERROR_CODES.has(code)
	|| SERIALIZATION_ERROR_MESSAGES.some(serializationErrorMessage => message.includes(serializationErrorMessage));

// `error.code` set by Node.js when it failed to serialize the message
const SERIALIZATION_ERROR_CODES = new Set([
	// Message is `undefined`
	'ERR_MISSING_ARGS',
	// Message is a function, a bigint, a symbol
	'ERR_INVALID_ARG_TYPE',
]);

// `error.message` set by Node.js when it failed to serialize the message
const SERIALIZATION_ERROR_MESSAGES = [
	// Message is a promise or a proxy, with `serialization: 'advanced'`
	'could not be cloned',
	// Message has cycles, with `serialization: 'json'`
	'circular structure',
	// Message has cycles inside toJSON(), with `serialization: 'json'`
	'call stack size exceeded',
];

const getMethodName = (methodName, isSubprocess, parameters = '') => methodName === 'cancelSignal'
	? '`cancelSignal`\'s `controller.abort()`'
	: `${getNamespaceName(isSubprocess)}${methodName}(${parameters})`;

const getNamespaceName = isSubprocess => isSubprocess ? '' : 'subprocess.';

const getOtherProcessName = isSubprocess => isSubprocess ? 'parent process' : 'subprocess';

// When any error arises, we disconnect the IPC.
// Otherwise, it is likely that one of the processes will stop sending/receiving messages.
// This would leave the other process hanging.
const disconnect = anyProcess => {
	if (anyProcess.connected) {
		anyProcess.disconnect();
	}
};

const createDeferred = () => {
	const methods = {};
	const promise = new Promise((resolve, reject) => {
		Object.assign(methods, {resolve, reject});
	});
	return Object.assign(promise, methods);
};

// Retrieve stream targeted by the `to` option
const getToStream = (destination, to = 'stdin') => {
	const isWritable = true;
	const {options, fileDescriptors} = SUBPROCESS_OPTIONS.get(destination);
	const fdNumber = getFdNumber(fileDescriptors, to, isWritable);
	const destinationStream = destination.stdio[fdNumber];

	if (destinationStream === null) {
		throw new TypeError(getInvalidStdioOptionMessage(fdNumber, to, options, isWritable));
	}

	return destinationStream;
};

// Retrieve stream targeted by the `from` option
const getFromStream = (source, from = 'stdout') => {
	const isWritable = false;
	const {options, fileDescriptors} = SUBPROCESS_OPTIONS.get(source);
	const fdNumber = getFdNumber(fileDescriptors, from, isWritable);
	const sourceStream = fdNumber === 'all' ? source.all : source.stdio[fdNumber];

	if (sourceStream === null || sourceStream === undefined) {
		throw new TypeError(getInvalidStdioOptionMessage(fdNumber, from, options, isWritable));
	}

	return sourceStream;
};

// Keeps track of the options passed to each Execa call
const SUBPROCESS_OPTIONS = new WeakMap();

const getFdNumber = (fileDescriptors, fdName, isWritable) => {
	const fdNumber = parseFdNumber(fdName, isWritable);
	validateFdNumber(fdNumber, fdName, isWritable, fileDescriptors);
	return fdNumber;
};

const parseFdNumber = (fdName, isWritable) => {
	const fdNumber = parseFd(fdName);
	if (fdNumber !== undefined) {
		return fdNumber;
	}

	const {validOptions, defaultValue} = isWritable
		? {validOptions: '"stdin"', defaultValue: 'stdin'}
		: {validOptions: '"stdout", "stderr", "all"', defaultValue: 'stdout'};
	throw new TypeError(`"${getOptionName(isWritable)}" must not be "${fdName}".
It must be ${validOptions} or "fd3", "fd4" (and so on).
It is optional and defaults to "${defaultValue}".`);
};

const validateFdNumber = (fdNumber, fdName, isWritable, fileDescriptors) => {
	const fileDescriptor = fileDescriptors[getUsedDescriptor(fdNumber)];
	if (fileDescriptor === undefined) {
		throw new TypeError(`"${getOptionName(isWritable)}" must not be ${fdName}. That file descriptor does not exist.
Please set the "stdio" option to ensure that file descriptor exists.`);
	}

	if (fileDescriptor.direction === 'input' && !isWritable) {
		throw new TypeError(`"${getOptionName(isWritable)}" must not be ${fdName}. It must be a readable stream, not writable.`);
	}

	if (fileDescriptor.direction !== 'input' && isWritable) {
		throw new TypeError(`"${getOptionName(isWritable)}" must not be ${fdName}. It must be a writable stream, not readable.`);
	}
};

const getInvalidStdioOptionMessage = (fdNumber, fdName, options, isWritable) => {
	if (fdNumber === 'all' && !options.all) {
		return 'The "all" option must be true to use "from: \'all\'".';
	}

	const {optionName, optionValue} = getInvalidStdioOption(fdNumber, options);
	return `The "${optionName}: ${serializeOptionValue(optionValue)}" option is incompatible with using "${getOptionName(isWritable)}: ${serializeOptionValue(fdName)}".
Please set this option with "pipe" instead.`;
};

const getInvalidStdioOption = (fdNumber, {stdin, stdout, stderr, stdio}) => {
	const usedDescriptor = getUsedDescriptor(fdNumber);

	if (usedDescriptor === 0 && stdin !== undefined) {
		return {optionName: 'stdin', optionValue: stdin};
	}

	if (usedDescriptor === 1 && stdout !== undefined) {
		return {optionName: 'stdout', optionValue: stdout};
	}

	if (usedDescriptor === 2 && stderr !== undefined) {
		return {optionName: 'stderr', optionValue: stderr};
	}

	return {optionName: `stdio[${usedDescriptor}]`, optionValue: stdio[usedDescriptor]};
};

const getUsedDescriptor = fdNumber => fdNumber === 'all' ? 1 : fdNumber;

const getOptionName = isWritable => isWritable ? 'to' : 'from';

const serializeOptionValue = value => {
	if (typeof value === 'string') {
		return `'${value}'`;
	}

	return typeof value === 'number' ? `${value}` : 'Stream';
};

// Temporarily increase the maximum number of listeners on an eventEmitter
const incrementMaxListeners = (eventEmitter, maxListenersIncrement, signal) => {
	const maxListeners = eventEmitter.getMaxListeners();
	if (maxListeners === 0 || maxListeners === Number.POSITIVE_INFINITY) {
		return;
	}

	eventEmitter.setMaxListeners(maxListeners + maxListenersIncrement);
	addAbortListener(signal, () => {
		eventEmitter.setMaxListeners(eventEmitter.getMaxListeners() - maxListenersIncrement);
	});
};

// By default, Node.js keeps the subprocess alive while it has a `message` or `disconnect` listener.
// We replicate the same logic for the events that we proxy.
// This ensures the subprocess is kept alive while `getOneMessage()` and `getEachMessage()` are ongoing.
// This is not a problem with `sendMessage()` since Node.js handles that method automatically.
// We do not use `anyProcess.channel.ref()` since this would prevent the automatic `.channel.refCounted()` Node.js is doing.
// We keep a reference to `anyProcess.channel` since it might be `null` while `getOneMessage()` or `getEachMessage()` is still processing debounced messages.
// See https://github.com/nodejs/node/blob/2aaeaa863c35befa2ebaa98fb7737ec84df4d8e9/lib/internal/child_process.js#L547
const addReference = (channel, reference) => {
	if (reference) {
		addReferenceCount(channel);
	}
};

const addReferenceCount = channel => {
	channel.refCounted();
};

const removeReference = (channel, reference) => {
	if (reference) {
		removeReferenceCount(channel);
	}
};

const removeReferenceCount = channel => {
	channel.unrefCounted();
};

// To proxy events, we setup some global listeners on the `message` and `disconnect` events.
// Those should not keep the subprocess alive, so we remove the automatic counting that Node.js is doing.
// See https://github.com/nodejs/node/blob/1b965270a9c273d4cf70e8808e9d28b9ada7844f/lib/child_process.js#L180
const undoAddedReferences = (channel, isSubprocess) => {
	if (isSubprocess) {
		removeReferenceCount(channel);
		removeReferenceCount(channel);
	}
};

// Reverse it during `disconnect`
const redoAddedReferences = (channel, isSubprocess) => {
	if (isSubprocess) {
		addReferenceCount(channel);
		addReferenceCount(channel);
	}
};

// By default, Node.js buffers `message` events.
//  - Buffering happens when there is a `message` event is emitted but there is no handler.
//  - As soon as a `message` event handler is set, all buffered `message` events are emitted, emptying the buffer.
//  - This happens both in the current process and the subprocess.
//  - See https://github.com/nodejs/node/blob/501546e8f37059cd577041e23941b640d0d4d406/lib/internal/child_process.js#L719
// This is helpful. Notably, this allows sending messages to a subprocess that's still initializing.
// However, it has several problems.
//  - This works with `events.on()` but not `events.once()` since all buffered messages are emitted at once.
//    For example, users cannot call `await getOneMessage()`/`getEachMessage()` multiple times in a row.
//  - When a user intentionally starts listening to `message` at a specific point in time, past `message` events are replayed, which might be unexpected.
//  - Buffering is unlimited, which might lead to an out-of-memory crash.
//  - This does not work well with multiple consumers.
//    For example, Execa consumes events with both `result.ipcOutput` and manual IPC calls like `getOneMessage()`.
//    Since `result.ipcOutput` reads all incoming messages, no buffering happens for manual IPC calls.
//  - Forgetting to setup a `message` listener, or setting it up too late, is a programming mistake.
//    The default behavior does not allow users to realize they made that mistake.
// To solve those problems, instead of buffering messages, we debounce them.
// The `message` event so it is emitted at most once per macrotask.
const onMessage = async ({anyProcess, channel, isSubprocess, ipcEmitter}, wrappedMessage) => {
	if (handleStrictResponse(wrappedMessage) || handleAbort(wrappedMessage)) {
		return;
	}

	if (!INCOMING_MESSAGES.has(anyProcess)) {
		INCOMING_MESSAGES.set(anyProcess, []);
	}

	const incomingMessages = INCOMING_MESSAGES.get(anyProcess);
	incomingMessages.push(wrappedMessage);

	if (incomingMessages.length > 1) {
		return;
	}

	while (incomingMessages.length > 0) {
		// eslint-disable-next-line no-await-in-loop
		await waitForOutgoingMessages(anyProcess, ipcEmitter, wrappedMessage);
		// eslint-disable-next-line no-await-in-loop
		await scheduler.yield();

		// eslint-disable-next-line no-await-in-loop
		const message = await handleStrictRequest({
			wrappedMessage: incomingMessages[0],
			anyProcess,
			channel,
			isSubprocess,
			ipcEmitter,
		});

		incomingMessages.shift();
		ipcEmitter.emit('message', message);
		ipcEmitter.emit('message:done');
	}
};

// If the `message` event is currently debounced, the `disconnect` event must wait for it
const onDisconnect = async ({anyProcess, channel, isSubprocess, ipcEmitter, boundOnMessage}) => {
	abortOnDisconnect();

	const incomingMessages = INCOMING_MESSAGES.get(anyProcess);
	while (incomingMessages?.length > 0) {
		// eslint-disable-next-line no-await-in-loop
		await once$2(ipcEmitter, 'message:done');
	}

	anyProcess.removeListener('message', boundOnMessage);
	redoAddedReferences(channel, isSubprocess);
	ipcEmitter.connected = false;
	ipcEmitter.emit('disconnect');
};

const INCOMING_MESSAGES = new WeakMap();

// Forward the `message` and `disconnect` events from the process and subprocess to a proxy emitter.
// This prevents the `error` event from stopping IPC.
// This also allows debouncing the `message` event.
const getIpcEmitter = (anyProcess, channel, isSubprocess) => {
	if (IPC_EMITTERS.has(anyProcess)) {
		return IPC_EMITTERS.get(anyProcess);
	}

	// Use an `EventEmitter`, like the `process` that is being proxied
	// eslint-disable-next-line unicorn/prefer-event-target
	const ipcEmitter = new EventEmitter();
	ipcEmitter.connected = true;
	IPC_EMITTERS.set(anyProcess, ipcEmitter);
	forwardEvents({
		ipcEmitter,
		anyProcess,
		channel,
		isSubprocess,
	});
	return ipcEmitter;
};

const IPC_EMITTERS = new WeakMap();

// The `message` and `disconnect` events are buffered in the subprocess until the first listener is setup.
// However, unbuffering happens after one tick, so this give enough time for the caller to setup the listener on the proxy emitter first.
// See https://github.com/nodejs/node/blob/2aaeaa863c35befa2ebaa98fb7737ec84df4d8e9/lib/internal/child_process.js#L721
const forwardEvents = ({ipcEmitter, anyProcess, channel, isSubprocess}) => {
	const boundOnMessage = onMessage.bind(undefined, {
		anyProcess,
		channel,
		isSubprocess,
		ipcEmitter,
	});
	anyProcess.on('message', boundOnMessage);
	anyProcess.once('disconnect', onDisconnect.bind(undefined, {
		anyProcess,
		channel,
		isSubprocess,
		ipcEmitter,
		boundOnMessage,
	}));
	undoAddedReferences(channel, isSubprocess);
};

// Check whether there might still be some `message` events to receive
const isConnected = anyProcess => {
	const ipcEmitter = IPC_EMITTERS.get(anyProcess);
	return ipcEmitter === undefined
		? anyProcess.channel !== null
		: ipcEmitter.connected;
};

// When using the `strict` option, wrap the message with metadata during `sendMessage()`
const handleSendStrict = ({anyProcess, channel, isSubprocess, message, strict}) => {
	if (!strict) {
		return message;
	}

	const ipcEmitter = getIpcEmitter(anyProcess, channel, isSubprocess);
	const hasListeners = hasMessageListeners(anyProcess, ipcEmitter);
	return {
		id: count++,
		type: REQUEST_TYPE,
		message,
		hasListeners,
	};
};

let count = 0n;

// Handles when both processes are calling `sendMessage()` with `strict` at the same time.
// If neither process is listening, this would create a deadlock. We detect it and throw.
const validateStrictDeadlock = (outgoingMessages, wrappedMessage) => {
	if (wrappedMessage?.type !== REQUEST_TYPE || wrappedMessage.hasListeners) {
		return;
	}

	for (const {id} of outgoingMessages) {
		if (id !== undefined) {
			STRICT_RESPONSES[id].resolve({isDeadlock: true, hasListeners: false});
		}
	}
};

// The other process then sends the acknowledgment back as a response
const handleStrictRequest = async ({wrappedMessage, anyProcess, channel, isSubprocess, ipcEmitter}) => {
	if (wrappedMessage?.type !== REQUEST_TYPE || !anyProcess.connected) {
		return wrappedMessage;
	}

	const {id, message} = wrappedMessage;
	const response = {id, type: RESPONSE_TYPE, message: hasMessageListeners(anyProcess, ipcEmitter)};

	try {
		await sendMessage({
			anyProcess,
			channel,
			isSubprocess,
			ipc: true,
		}, response);
	} catch (error) {
		ipcEmitter.emit('strict:error', error);
	}

	return message;
};

// Reception of the acknowledgment response
const handleStrictResponse = wrappedMessage => {
	if (wrappedMessage?.type !== RESPONSE_TYPE) {
		return false;
	}

	const {id, message: hasListeners} = wrappedMessage;
	STRICT_RESPONSES[id]?.resolve({isDeadlock: false, hasListeners});
	return true;
};

// Wait for the other process to receive the message from `sendMessage()`
const waitForStrictResponse = async (wrappedMessage, anyProcess, isSubprocess) => {
	if (wrappedMessage?.type !== REQUEST_TYPE) {
		return;
	}

	const deferred = createDeferred();
	STRICT_RESPONSES[wrappedMessage.id] = deferred;
	const controller = new AbortController();

	try {
		const {isDeadlock, hasListeners} = await Promise.race([
			deferred,
			throwOnDisconnect$1(anyProcess, isSubprocess, controller),
		]);

		if (isDeadlock) {
			throwOnStrictDeadlockError(isSubprocess);
		}

		if (!hasListeners) {
			throwOnMissingStrict(isSubprocess);
		}
	} finally {
		controller.abort();
		delete STRICT_RESPONSES[wrappedMessage.id];
	}
};

const STRICT_RESPONSES = {};

const throwOnDisconnect$1 = async (anyProcess, isSubprocess, {signal}) => {
	incrementMaxListeners(anyProcess, 1, signal);
	await once$2(anyProcess, 'disconnect', {signal});
	throwOnStrictDisconnect(isSubprocess);
};

const REQUEST_TYPE = 'execa:ipc:request';
const RESPONSE_TYPE = 'execa:ipc:response';

// When `sendMessage()` is ongoing, any `message` being received waits before being emitted.
// This allows calling one or multiple `await sendMessage()` followed by `await getOneMessage()`/`await getEachMessage()`.
// Without running into a race condition when the other process sends a response too fast, before the current process set up a listener.
const startSendMessage = (anyProcess, wrappedMessage, strict) => {
	if (!OUTGOING_MESSAGES.has(anyProcess)) {
		OUTGOING_MESSAGES.set(anyProcess, new Set());
	}

	const outgoingMessages = OUTGOING_MESSAGES.get(anyProcess);
	const onMessageSent = createDeferred();
	const id = strict ? wrappedMessage.id : undefined;
	const outgoingMessage = {onMessageSent, id};
	outgoingMessages.add(outgoingMessage);
	return {outgoingMessages, outgoingMessage};
};

const endSendMessage = ({outgoingMessages, outgoingMessage}) => {
	outgoingMessages.delete(outgoingMessage);
	outgoingMessage.onMessageSent.resolve();
};

// Await while `sendMessage()` is ongoing, unless there is already a `message` listener
const waitForOutgoingMessages = async (anyProcess, ipcEmitter, wrappedMessage) => {
	while (!hasMessageListeners(anyProcess, ipcEmitter) && OUTGOING_MESSAGES.get(anyProcess)?.size > 0) {
		const outgoingMessages = [...OUTGOING_MESSAGES.get(anyProcess)];
		validateStrictDeadlock(outgoingMessages, wrappedMessage);
		// eslint-disable-next-line no-await-in-loop
		await Promise.all(outgoingMessages.map(({onMessageSent}) => onMessageSent));
	}
};

const OUTGOING_MESSAGES = new WeakMap();

// Whether any `message` listener is setup
const hasMessageListeners = (anyProcess, ipcEmitter) => ipcEmitter.listenerCount('message') > getMinListenerCount(anyProcess);

// When `buffer` is `false`, we set up a `message` listener that should be ignored.
// That listener is only meant to intercept `strict` acknowledgement responses.
const getMinListenerCount = anyProcess => SUBPROCESS_OPTIONS.has(anyProcess)
	&& !getFdSpecificValue(SUBPROCESS_OPTIONS.get(anyProcess).options.buffer, 'ipc')
	? 1
	: 0;

// Like `[sub]process.send()` but promise-based.
// We do not `await subprocess` during `.sendMessage()` nor `.getOneMessage()` since those methods are transient.
// Users would still need to `await subprocess` after the method is done.
// Also, this would prevent `unhandledRejection` event from being emitted, making it silent.
const sendMessage = ({anyProcess, channel, isSubprocess, ipc}, message, {strict = false} = {}) => {
	const methodName = 'sendMessage';
	validateIpcMethod({
		methodName,
		isSubprocess,
		ipc,
		isConnected: anyProcess.connected,
	});

	return sendMessageAsync({
		anyProcess,
		channel,
		methodName,
		isSubprocess,
		message,
		strict,
	});
};

const sendMessageAsync = async ({anyProcess, channel, methodName, isSubprocess, message, strict}) => {
	const wrappedMessage = handleSendStrict({
		anyProcess,
		channel,
		isSubprocess,
		message,
		strict,
	});
	const outgoingMessagesState = startSendMessage(anyProcess, wrappedMessage, strict);
	try {
		await sendOneMessage({
			anyProcess,
			methodName,
			isSubprocess,
			wrappedMessage,
			message,
		});
	} catch (error) {
		disconnect(anyProcess);
		throw error;
	} finally {
		endSendMessage(outgoingMessagesState);
	}
};

// Used internally by `cancelSignal`
const sendOneMessage = async ({anyProcess, methodName, isSubprocess, wrappedMessage, message}) => {
	const sendMethod = getSendMethod(anyProcess);

	try {
		await Promise.all([
			waitForStrictResponse(wrappedMessage, anyProcess, isSubprocess),
			sendMethod(wrappedMessage),
		]);
	} catch (error) {
		handleEpipeError({error, methodName, isSubprocess});
		handleSerializationError({
			error,
			methodName,
			isSubprocess,
			message,
		});
		throw error;
	}
};

// [sub]process.send() promisified, memoized
const getSendMethod = anyProcess => {
	if (PROCESS_SEND_METHODS.has(anyProcess)) {
		return PROCESS_SEND_METHODS.get(anyProcess);
	}

	const sendMethod = promisify(anyProcess.send.bind(anyProcess));
	PROCESS_SEND_METHODS.set(anyProcess, sendMethod);
	return sendMethod;
};

const PROCESS_SEND_METHODS = new WeakMap();

// Send an IPC message so the subprocess performs a graceful termination
const sendAbort = (subprocess, message) => {
	const methodName = 'cancelSignal';
	validateConnection(methodName, false, subprocess.connected);
	return sendOneMessage({
		anyProcess: subprocess,
		methodName,
		isSubprocess: false,
		wrappedMessage: {type: GRACEFUL_CANCEL_TYPE, message},
		message,
	});
};

// When the signal is being used, start listening for incoming messages.
// Unbuffering messages takes one microtask to complete, so this must be async.
const getCancelSignal = async ({anyProcess, channel, isSubprocess, ipc}) => {
	await startIpc({
		anyProcess,
		channel,
		isSubprocess,
		ipc,
	});
	return cancelController.signal;
};

const startIpc = async ({anyProcess, channel, isSubprocess, ipc}) => {
	if (cancelListening) {
		return;
	}

	cancelListening = true;

	if (!ipc) {
		throwOnMissingParent();
		return;
	}

	if (channel === null) {
		abortOnDisconnect();
		return;
	}

	getIpcEmitter(anyProcess, channel, isSubprocess);
	await scheduler.yield();
};

let cancelListening = false;

// Reception of IPC message to perform a graceful termination
const handleAbort = wrappedMessage => {
	if (wrappedMessage?.type !== GRACEFUL_CANCEL_TYPE) {
		return false;
	}

	cancelController.abort(wrappedMessage.message);
	return true;
};

const GRACEFUL_CANCEL_TYPE = 'execa:ipc:cancel';

// When the current process disconnects early, the subprocess `cancelSignal` is aborted.
// Otherwise, the signal would never be able to be aborted later on.
const abortOnDisconnect = () => {
	cancelController.abort(getAbortDisconnectError());
};

const cancelController = new AbortController();

// Validate the `gracefulCancel` option
const validateGracefulCancel = ({gracefulCancel, cancelSignal, ipc, serialization}) => {
	if (!gracefulCancel) {
		return;
	}

	if (cancelSignal === undefined) {
		throw new Error('The `cancelSignal` option must be defined when setting the `gracefulCancel` option.');
	}

	if (!ipc) {
		throw new Error('The `ipc` option cannot be false when setting the `gracefulCancel` option.');
	}

	if (serialization === 'json') {
		throw new Error('The `serialization` option cannot be \'json\' when setting the `gracefulCancel` option.');
	}
};

// Send abort reason to the subprocess when aborting the `cancelSignal` option and `gracefulCancel` is `true`
const throwOnGracefulCancel = ({
	subprocess,
	cancelSignal,
	gracefulCancel,
	forceKillAfterDelay,
	context,
	controller,
}) => gracefulCancel
	? [sendOnAbort({
		subprocess,
		cancelSignal,
		forceKillAfterDelay,
		context,
		controller,
	})]
	: [];

const sendOnAbort = async ({subprocess, cancelSignal, forceKillAfterDelay, context, controller: {signal}}) => {
	await onAbortedSignal(cancelSignal, signal);
	const reason = getReason(cancelSignal);
	await sendAbort(subprocess, reason);
	killOnTimeout({
		kill: subprocess.kill,
		forceKillAfterDelay,
		context,
		controllerSignal: signal,
	});
	context.terminationReason ??= 'gracefulCancel';
	throw cancelSignal.reason;
};

// The default `reason` is a DOMException, which is not serializable with V8
// See https://github.com/nodejs/node/issues/53225
const getReason = ({reason}) => {
	if (!(reason instanceof DOMException)) {
		return reason;
	}

	const error = new Error(reason.message);
	Object.defineProperty(error, 'stack', {
		value: reason.stack,
		enumerable: false,
		configurable: true,
		writable: true,
	});
	return error;
};

// Validate `timeout` option
const validateTimeout = ({timeout}) => {
	if (timeout !== undefined && (!Number.isFinite(timeout) || timeout < 0)) {
		throw new TypeError(`Expected the \`timeout\` option to be a non-negative integer, got \`${timeout}\` (${typeof timeout})`);
	}
};

// Fails when the `timeout` option is exceeded
const throwOnTimeout = (subprocess, timeout, context, controller) => timeout === 0 || timeout === undefined
	? []
	: [killAfterTimeout(subprocess, timeout, context, controller)];

const killAfterTimeout = async (subprocess, timeout, context, {signal}) => {
	await setTimeout$1(timeout, undefined, {signal});
	context.terminationReason ??= 'timeout';
	subprocess.kill();
	throw new DiscardedError();
};

// `execaNode()` is a shortcut for `execa(..., {node: true})`
const mapNode = ({options}) => {
	if (options.node === false) {
		throw new TypeError('The "node" option cannot be false with `execaNode()`.');
	}

	return {options: {...options, node: true}};
};

// Applies the `node: true` option, and the related `nodePath`/`nodeOptions` options.
// Modifies the file commands/arguments to ensure the same Node binary and flags are re-used.
// Also adds `ipc: true` and `shell: false`.
const handleNodeOption = (file, commandArguments, {
	node: shouldHandleNode = false,
	nodePath = execPath,
	nodeOptions = execArgv.filter(nodeOption => !nodeOption.startsWith('--inspect')),
	cwd,
	execPath: formerNodePath,
	...options
}) => {
	if (formerNodePath !== undefined) {
		throw new TypeError('The "execPath" option has been removed. Please use the "nodePath" option instead.');
	}

	const normalizedNodePath = safeNormalizeFileUrl(nodePath, 'The "nodePath" option');
	const resolvedNodePath = path.resolve(cwd, normalizedNodePath);
	const newOptions = {
		...options,
		nodePath: resolvedNodePath,
		node: shouldHandleNode,
		cwd,
	};

	if (!shouldHandleNode) {
		return [file, commandArguments, newOptions];
	}

	if (path.basename(file, '.exe') === 'node') {
		throw new TypeError('When the "node" option is true, the first argument does not need to be "node".');
	}

	return [
		resolvedNodePath,
		[...nodeOptions, file, ...commandArguments],
		{ipc: true, ...newOptions, shell: false},
	];
};

// Validate the `ipcInput` option
const validateIpcInputOption = ({ipcInput, ipc, serialization}) => {
	if (ipcInput === undefined) {
		return;
	}

	if (!ipc) {
		throw new Error('The `ipcInput` option cannot be set unless the `ipc` option is `true`.');
	}

	validateIpcInput[serialization](ipcInput);
};

const validateAdvancedInput = ipcInput => {
	try {
		serialize(ipcInput);
	} catch (error) {
		throw new Error('The `ipcInput` option is not serializable with a structured clone.', {cause: error});
	}
};

const validateJsonInput = ipcInput => {
	try {
		JSON.stringify(ipcInput);
	} catch (error) {
		throw new Error('The `ipcInput` option is not serializable with JSON.', {cause: error});
	}
};

const validateIpcInput = {
	advanced: validateAdvancedInput,
	json: validateJsonInput,
};

// When the `ipcInput` option is set, it is sent as an initial IPC message to the subprocess
const sendIpcInput = async (subprocess, ipcInput) => {
	if (ipcInput === undefined) {
		return;
	}

	await subprocess.sendMessage(ipcInput);
};

// Validate `encoding` option
const validateEncoding = ({encoding}) => {
	if (ENCODINGS.has(encoding)) {
		return;
	}

	const correctEncoding = getCorrectEncoding(encoding);
	if (correctEncoding !== undefined) {
		throw new TypeError(`Invalid option \`encoding: ${serializeEncoding(encoding)}\`.
Please rename it to ${serializeEncoding(correctEncoding)}.`);
	}

	const correctEncodings = [...ENCODINGS].map(correctEncoding => serializeEncoding(correctEncoding)).join(', ');
	throw new TypeError(`Invalid option \`encoding: ${serializeEncoding(encoding)}\`.
Please rename it to one of: ${correctEncodings}.`);
};

const TEXT_ENCODINGS = new Set(['utf8', 'utf16le']);
const BINARY_ENCODINGS = new Set(['buffer', 'hex', 'base64', 'base64url', 'latin1', 'ascii']);
const ENCODINGS = new Set([...TEXT_ENCODINGS, ...BINARY_ENCODINGS]);

const getCorrectEncoding = encoding => {
	if (encoding === null) {
		return 'buffer';
	}

	if (typeof encoding !== 'string') {
		return;
	}

	const lowerEncoding = encoding.toLowerCase();
	if (lowerEncoding in ENCODING_ALIASES) {
		return ENCODING_ALIASES[lowerEncoding];
	}

	if (ENCODINGS.has(lowerEncoding)) {
		return lowerEncoding;
	}
};

const ENCODING_ALIASES = {
	// eslint-disable-next-line unicorn/text-encoding-identifier-case
	'utf-8': 'utf8',
	'utf-16le': 'utf16le',
	'ucs-2': 'utf16le',
	ucs2: 'utf16le',
	binary: 'latin1',
};

const serializeEncoding = encoding => typeof encoding === 'string' ? `"${encoding}"` : String(encoding);

// Normalize `cwd` option
const normalizeCwd = (cwd = getDefaultCwd()) => {
	const cwdString = safeNormalizeFileUrl(cwd, 'The "cwd" option');
	return path.resolve(cwdString);
};

const getDefaultCwd = () => {
	try {
		return process$2.cwd();
	} catch (error) {
		error.message = `The current directory does not exist.\n${error.message}`;
		throw error;
	}
};

// When `cwd` option has an invalid value, provide with a better error message
const fixCwdError = (originalMessage, cwd) => {
	if (cwd === getDefaultCwd()) {
		return originalMessage;
	}

	let cwdStat;
	try {
		cwdStat = statSync(cwd);
	} catch (error) {
		return `The "cwd" option is invalid: ${cwd}.\n${error.message}\n${originalMessage}`;
	}

	if (!cwdStat.isDirectory()) {
		return `The "cwd" option is not a directory: ${cwd}.\n${originalMessage}`;
	}

	return originalMessage;
};

// Normalize the options object, and sometimes also the file paths and arguments.
// Applies default values, validate allowed options, normalize them.
const normalizeOptions = (filePath, rawArguments, rawOptions) => {
	rawOptions.cwd = normalizeCwd(rawOptions.cwd);
	const [processedFile, processedArguments, processedOptions] = handleNodeOption(filePath, rawArguments, rawOptions);

	const {command: file, args: commandArguments, options: initialOptions} = crossSpawn._parse(processedFile, processedArguments, processedOptions);

	const fdOptions = normalizeFdSpecificOptions(initialOptions);
	const options = addDefaultOptions(fdOptions);
	validateTimeout(options);
	validateEncoding(options);
	validateIpcInputOption(options);
	validateCancelSignal(options);
	validateGracefulCancel(options);
	options.shell = normalizeFileUrl(options.shell);
	options.env = getEnv(options);
	options.killSignal = normalizeKillSignal(options.killSignal);
	options.forceKillAfterDelay = normalizeForceKillAfterDelay(options.forceKillAfterDelay);
	options.lines = options.lines.map((lines, fdNumber) => lines && !BINARY_ENCODINGS.has(options.encoding) && options.buffer[fdNumber]);

	if (process$2.platform === 'win32' && path.basename(file, '.exe') === 'cmd') {
		// #116
		commandArguments.unshift('/q');
	}

	return {file, commandArguments, options};
};

const addDefaultOptions = ({
	extendEnv = true,
	preferLocal = false,
	cwd,
	localDir: localDirectory = cwd,
	encoding = 'utf8',
	reject = true,
	cleanup = true,
	all = false,
	windowsHide = true,
	killSignal = 'SIGTERM',
	forceKillAfterDelay = true,
	gracefulCancel = false,
	ipcInput,
	ipc = ipcInput !== undefined || gracefulCancel,
	serialization = 'advanced',
	...options
}) => ({
	...options,
	extendEnv,
	preferLocal,
	cwd,
	localDirectory,
	encoding,
	reject,
	cleanup,
	all,
	windowsHide,
	killSignal,
	forceKillAfterDelay,
	gracefulCancel,
	ipcInput,
	ipc,
	serialization,
});

const getEnv = ({env: envOption, extendEnv, preferLocal, node, localDirectory, nodePath}) => {
	const env = extendEnv ? {...process$2.env, ...envOption} : envOption;

	if (preferLocal || node) {
		return npmRunPathEnv({
			env,
			cwd: localDirectory,
			execPath: nodePath,
			preferLocal,
			addExecPath: node,
		});
	}

	return env;
};

// When the `shell` option is set, any command argument is concatenated as a single string by Node.js:
// https://github.com/nodejs/node/blob/e38ce27f3ca0a65f68a31cedd984cddb927d4002/lib/child_process.js#L614-L624
// However, since Node 24, it also prints a deprecation warning.
// To avoid this warning, we perform that same operation before calling `node:child_process`.
// Shells only understand strings, which is why Node.js performs that concatenation.
// However, we rely on users splitting command arguments as an array.
// For example, this allows us to easily detect which arguments are passed.
// So we do want users to pass array of arguments even with `shell: true`, but we also want to avoid any warning.
const concatenateShell = (file, commandArguments, options) => options.shell && commandArguments.length > 0
	? [[file, ...commandArguments].join(' '), [], options]
	: [file, commandArguments, options];

function stripFinalNewline(input) {
	if (typeof input === 'string') {
		return stripFinalNewlineString(input);
	}

	if (!(ArrayBuffer.isView(input) && input.BYTES_PER_ELEMENT === 1)) {
		throw new Error('Input must be a string or a Uint8Array');
	}

	return stripFinalNewlineBinary(input);
}

const stripFinalNewlineString = input =>
	input.at(-1) === LF
		? input.slice(0, input.at(-2) === CR ? -2 : -1)
		: input;

const stripFinalNewlineBinary = input =>
	input.at(-1) === LF_BINARY
		? input.subarray(0, input.at(-2) === CR_BINARY ? -2 : -1)
		: input;

const LF = '\n';
const LF_BINARY = LF.codePointAt(0);
const CR = '\r';
const CR_BINARY = CR.codePointAt(0);

function isStream(stream, {checkOpen = true} = {}) {
	return stream !== null
		&& typeof stream === 'object'
		&& (stream.writable || stream.readable || !checkOpen || (stream.writable === undefined && stream.readable === undefined))
		&& typeof stream.pipe === 'function';
}

function isWritableStream$1(stream, {checkOpen = true} = {}) {
	return isStream(stream, {checkOpen})
		&& (stream.writable || !checkOpen)
		&& typeof stream.write === 'function'
		&& typeof stream.end === 'function'
		&& typeof stream.writable === 'boolean'
		&& typeof stream.writableObjectMode === 'boolean'
		&& typeof stream.destroy === 'function'
		&& typeof stream.destroyed === 'boolean';
}

function isReadableStream$1(stream, {checkOpen = true} = {}) {
	return isStream(stream, {checkOpen})
		&& (stream.readable || !checkOpen)
		&& typeof stream.read === 'function'
		&& typeof stream.readable === 'boolean'
		&& typeof stream.readableObjectMode === 'boolean'
		&& typeof stream.destroy === 'function'
		&& typeof stream.destroyed === 'boolean';
}

function isDuplexStream(stream, options) {
	return isWritableStream$1(stream, options)
		&& isReadableStream$1(stream, options);
}

const a = Object.getPrototypeOf(
  Object.getPrototypeOf(
    /* istanbul ignore next */
    async function* () {
    }
  ).prototype
);
class c {
  #t;
  #n;
  #r = false;
  #e = void 0;
  constructor(e, t) {
    this.#t = e, this.#n = t;
  }
  next() {
    const e = () => this.#s();
    return this.#e = this.#e ? this.#e.then(e, e) : e(), this.#e;
  }
  return(e) {
    const t = () => this.#i(e);
    return this.#e ? this.#e.then(t, t) : t();
  }
  async #s() {
    if (this.#r)
      return {
        done: true,
        value: void 0
      };
    let e;
    try {
      e = await this.#t.read();
    } catch (t) {
      throw this.#e = void 0, this.#r = true, this.#t.releaseLock(), t;
    }
    return e.done && (this.#e = void 0, this.#r = true, this.#t.releaseLock()), e;
  }
  async #i(e) {
    if (this.#r)
      return {
        done: true,
        value: e
      };
    if (this.#r = true, !this.#n) {
      const t = this.#t.cancel(e);
      return this.#t.releaseLock(), await t, {
        done: true,
        value: e
      };
    }
    return this.#t.releaseLock(), {
      done: true,
      value: e
    };
  }
}
const n = Symbol();
function i() {
  return this[n].next();
}
Object.defineProperty(i, "name", { value: "next" });
function o(r) {
  return this[n].return(r);
}
Object.defineProperty(o, "name", { value: "return" });
const u = Object.create(a, {
  next: {
    enumerable: true,
    configurable: true,
    writable: true,
    value: i
  },
  return: {
    enumerable: true,
    configurable: true,
    writable: true,
    value: o
  }
});
function h({ preventCancel: r = false } = {}) {
  const e = this.getReader(), t = new c(
    e,
    r
  ), s = Object.create(u);
  return s[n] = t, s;
}

const getAsyncIterable = stream => {
	if (isReadableStream$1(stream, {checkOpen: false}) && nodeImports.on !== undefined) {
		return getStreamIterable(stream);
	}

	if (typeof stream?.[Symbol.asyncIterator] === 'function') {
		return stream;
	}

	// `ReadableStream[Symbol.asyncIterator]` support is missing in multiple browsers, so we ponyfill it
	if (toString.call(stream) === '[object ReadableStream]') {
		return h.call(stream);
	}

	throw new TypeError('The first argument must be a Readable, a ReadableStream, or an async iterable.');
};

const {toString} = Object.prototype;

// The default iterable for Node.js streams does not allow for multiple readers at once, so we re-implement it
const getStreamIterable = async function * (stream) {
	const controller = new AbortController();
	const state = {};
	handleStreamEnd(stream, controller, state);

	try {
		for await (const [chunk] of nodeImports.on(stream, 'data', {signal: controller.signal})) {
			yield chunk;
		}
	} catch (error) {
		// Stream failure, for example due to `stream.destroy(error)`
		if (state.error !== undefined) {
			throw state.error;
		// `error` event directly emitted on stream
		} else if (!controller.signal.aborted) {
			throw error;
		// Otherwise, stream completed successfully
		}
		// The `finally` block also runs when the caller throws, for example due to the `maxBuffer` option
	} finally {
		stream.destroy();
	}
};

const handleStreamEnd = async (stream, controller, state) => {
	try {
		await nodeImports.finished(stream, {
			cleanup: true,
			readable: true,
			writable: false,
			error: false,
		});
	} catch (error) {
		state.error = error;
	} finally {
		controller.abort();
	}
};

// Loaded by the Node entrypoint, but not by the browser one.
// This prevents using dynamic imports.
const nodeImports = {};

const getStreamContents$1 = async (stream, {init, convertChunk, getSize, truncateChunk, addChunk, getFinalChunk, finalize}, {maxBuffer = Number.POSITIVE_INFINITY} = {}) => {
	const asyncIterable = getAsyncIterable(stream);

	const state = init();
	state.length = 0;

	try {
		for await (const chunk of asyncIterable) {
			const chunkType = getChunkType(chunk);
			const convertedChunk = convertChunk[chunkType](chunk, state);
			appendChunk({
				convertedChunk,
				state,
				getSize,
				truncateChunk,
				addChunk,
				maxBuffer,
			});
		}

		appendFinalChunk({
			state,
			convertChunk,
			getSize,
			truncateChunk,
			addChunk,
			getFinalChunk,
			maxBuffer,
		});
		return finalize(state);
	} catch (error) {
		const normalizedError = typeof error === 'object' && error !== null ? error : new Error(error);
		normalizedError.bufferedData = finalize(state);
		throw normalizedError;
	}
};

const appendFinalChunk = ({state, getSize, truncateChunk, addChunk, getFinalChunk, maxBuffer}) => {
	const convertedChunk = getFinalChunk(state);
	if (convertedChunk !== undefined) {
		appendChunk({
			convertedChunk,
			state,
			getSize,
			truncateChunk,
			addChunk,
			maxBuffer,
		});
	}
};

const appendChunk = ({convertedChunk, state, getSize, truncateChunk, addChunk, maxBuffer}) => {
	const chunkSize = getSize(convertedChunk);
	const newLength = state.length + chunkSize;

	if (newLength <= maxBuffer) {
		addNewChunk(convertedChunk, state, addChunk, newLength);
		return;
	}

	const truncatedChunk = truncateChunk(convertedChunk, maxBuffer - state.length);

	if (truncatedChunk !== undefined) {
		addNewChunk(truncatedChunk, state, addChunk, maxBuffer);
	}

	throw new MaxBufferError();
};

const addNewChunk = (convertedChunk, state, addChunk, newLength) => {
	state.contents = addChunk(convertedChunk, state, newLength);
	state.length = newLength;
};

const getChunkType = chunk => {
	const typeOfChunk = typeof chunk;

	if (typeOfChunk === 'string') {
		return 'string';
	}

	if (typeOfChunk !== 'object' || chunk === null) {
		return 'others';
	}

	if (globalThis.Buffer?.isBuffer(chunk)) {
		return 'buffer';
	}

	const prototypeName = objectToString.call(chunk);

	if (prototypeName === '[object ArrayBuffer]') {
		return 'arrayBuffer';
	}

	if (prototypeName === '[object DataView]') {
		return 'dataView';
	}

	if (
		Number.isInteger(chunk.byteLength)
		&& Number.isInteger(chunk.byteOffset)
		&& objectToString.call(chunk.buffer) === '[object ArrayBuffer]'
	) {
		return 'typedArray';
	}

	return 'others';
};

const {toString: objectToString} = Object.prototype;

class MaxBufferError extends Error {
	name = 'MaxBufferError';

	constructor() {
		super('maxBuffer exceeded');
	}
}

const identity = value => value;

const noop$1 = () => undefined;

const getContentsProperty = ({contents}) => contents;

const throwObjectStream = chunk => {
	throw new Error(`Streams in object mode are not supported: ${String(chunk)}`);
};

const getLengthProperty = convertedChunk => convertedChunk.length;

async function getStreamAsArray(stream, options) {
	return getStreamContents$1(stream, arrayMethods, options);
}

const initArray = () => ({contents: []});

const increment = () => 1;

const addArrayChunk = (convertedChunk, {contents}) => {
	contents.push(convertedChunk);
	return contents;
};

const arrayMethods = {
	init: initArray,
	convertChunk: {
		string: identity,
		buffer: identity,
		arrayBuffer: identity,
		dataView: identity,
		typedArray: identity,
		others: identity,
	},
	getSize: increment,
	truncateChunk: noop$1,
	addChunk: addArrayChunk,
	getFinalChunk: noop$1,
	finalize: getContentsProperty,
};

async function getStreamAsArrayBuffer(stream, options) {
	return getStreamContents$1(stream, arrayBufferMethods, options);
}

const initArrayBuffer = () => ({contents: new ArrayBuffer(0)});

const useTextEncoder = chunk => textEncoder.encode(chunk);
const textEncoder = new TextEncoder();

const useUint8Array = chunk => new Uint8Array(chunk);

const useUint8ArrayWithOffset = chunk => new Uint8Array(chunk.buffer, chunk.byteOffset, chunk.byteLength);

const truncateArrayBufferChunk = (convertedChunk, chunkSize) => convertedChunk.slice(0, chunkSize);

// `contents` is an increasingly growing `Uint8Array`.
const addArrayBufferChunk = (convertedChunk, {contents, length: previousLength}, length) => {
	const newContents = hasArrayBufferResize() ? resizeArrayBuffer(contents, length) : resizeArrayBufferSlow(contents, length);
	new Uint8Array(newContents).set(convertedChunk, previousLength);
	return newContents;
};

// Without `ArrayBuffer.resize()`, `contents` size is always a power of 2.
// This means its last bytes are zeroes (not stream data), which need to be
// trimmed at the end with `ArrayBuffer.slice()`.
const resizeArrayBufferSlow = (contents, length) => {
	if (length <= contents.byteLength) {
		return contents;
	}

	const arrayBuffer = new ArrayBuffer(getNewContentsLength(length));
	new Uint8Array(arrayBuffer).set(new Uint8Array(contents), 0);
	return arrayBuffer;
};

// With `ArrayBuffer.resize()`, `contents` size matches exactly the size of
// the stream data. It does not include extraneous zeroes to trim at the end.
// The underlying `ArrayBuffer` does allocate a number of bytes that is a power
// of 2, but those bytes are only visible after calling `ArrayBuffer.resize()`.
const resizeArrayBuffer = (contents, length) => {
	if (length <= contents.maxByteLength) {
		contents.resize(length);
		return contents;
	}

	const arrayBuffer = new ArrayBuffer(length, {maxByteLength: getNewContentsLength(length)});
	new Uint8Array(arrayBuffer).set(new Uint8Array(contents), 0);
	return arrayBuffer;
};

// Retrieve the closest `length` that is both >= and a power of 2
const getNewContentsLength = length => SCALE_FACTOR ** Math.ceil(Math.log(length) / Math.log(SCALE_FACTOR));

const SCALE_FACTOR = 2;

const finalizeArrayBuffer = ({contents, length}) => hasArrayBufferResize() ? contents : contents.slice(0, length);

// `ArrayBuffer.slice()` is slow. When `ArrayBuffer.resize()` is available
// (Node >=20.0.0, Safari >=16.4 and Chrome), we can use it instead.
// eslint-disable-next-line no-warning-comments
// TODO: remove after dropping support for Node 20.
// eslint-disable-next-line no-warning-comments
// TODO: use `ArrayBuffer.transferToFixedLength()` instead once it is available
const hasArrayBufferResize = () => 'resize' in ArrayBuffer.prototype;

const arrayBufferMethods = {
	init: initArrayBuffer,
	convertChunk: {
		string: useTextEncoder,
		buffer: useUint8Array,
		arrayBuffer: useUint8Array,
		dataView: useUint8ArrayWithOffset,
		typedArray: useUint8ArrayWithOffset,
		others: throwObjectStream,
	},
	getSize: getLengthProperty,
	truncateChunk: truncateArrayBufferChunk,
	addChunk: addArrayBufferChunk,
	getFinalChunk: noop$1,
	finalize: finalizeArrayBuffer,
};

async function getStreamAsString(stream, options) {
	return getStreamContents$1(stream, stringMethods, options);
}

const initString = () => ({contents: '', textDecoder: new TextDecoder()});

const useTextDecoder = (chunk, {textDecoder}) => textDecoder.decode(chunk, {stream: true});

const addStringChunk = (convertedChunk, {contents}) => contents + convertedChunk;

const truncateStringChunk = (convertedChunk, chunkSize) => convertedChunk.slice(0, chunkSize);

const getFinalStringChunk = ({textDecoder}) => {
	const finalChunk = textDecoder.decode();
	return finalChunk === '' ? undefined : finalChunk;
};

const stringMethods = {
	init: initString,
	convertChunk: {
		string: identity,
		buffer: useTextDecoder,
		arrayBuffer: useTextDecoder,
		dataView: useTextDecoder,
		typedArray: useTextDecoder,
		others: throwObjectStream,
	},
	getSize: getLengthProperty,
	truncateChunk: truncateStringChunk,
	addChunk: addStringChunk,
	getFinalChunk: getFinalStringChunk,
	finalize: getContentsProperty,
};

// When the `maxBuffer` option is hit, a MaxBufferError is thrown.
// The stream is aborted, then specific information is kept for the error message.
const handleMaxBuffer = ({error, stream, readableObjectMode, lines, encoding, fdNumber}) => {
	if (!(error instanceof MaxBufferError)) {
		throw error;
	}

	if (fdNumber === 'all') {
		return error;
	}

	const unit = getMaxBufferUnit(readableObjectMode, lines, encoding);
	error.maxBufferInfo = {fdNumber, unit};
	stream.destroy();
	throw error;
};

const getMaxBufferUnit = (readableObjectMode, lines, encoding) => {
	if (readableObjectMode) {
		return 'objects';
	}

	if (lines) {
		return 'lines';
	}

	if (encoding === 'buffer') {
		return 'bytes';
	}

	return 'characters';
};

// Check the `maxBuffer` option with `result.ipcOutput`
const checkIpcMaxBuffer = (subprocess, ipcOutput, maxBuffer) => {
	if (ipcOutput.length !== maxBuffer) {
		return;
	}

	const error = new MaxBufferError();
	error.maxBufferInfo = {fdNumber: 'ipc'};
	throw error;
};

// Error message when `maxBuffer` is hit
const getMaxBufferMessage = (error, maxBuffer) => {
	const {streamName, threshold, unit} = getMaxBufferInfo(error, maxBuffer);
	return `Command's ${streamName} was larger than ${threshold} ${unit}`;
};

const getMaxBufferInfo = (error, maxBuffer) => {
	if (error?.maxBufferInfo === undefined) {
		return {streamName: 'output', threshold: maxBuffer[1], unit: 'bytes'};
	}

	const {maxBufferInfo: {fdNumber, unit}} = error;
	delete error.maxBufferInfo;

	const threshold = getFdSpecificValue(maxBuffer, fdNumber);
	if (fdNumber === 'ipc') {
		return {streamName: 'IPC output', threshold, unit: 'messages'};
	}

	return {streamName: getStreamName(fdNumber), threshold, unit};
};

// The only way to apply `maxBuffer` with `spawnSync()` is to use the native `maxBuffer` option Node.js provides.
// However, this has multiple limitations, and cannot behave the exact same way as the async behavior.
// When the `maxBuffer` is hit, a `ENOBUFS` error is thrown.
const isMaxBufferSync = (resultError, output, maxBuffer) => resultError?.code === 'ENOBUFS'
	&& output !== null
	&& output.some(result => result !== null && result.length > getMaxBufferSync(maxBuffer));

// When `maxBuffer` is hit, ensure the result is truncated
const truncateMaxBufferSync = (result, isMaxBuffer, maxBuffer) => {
	if (!isMaxBuffer) {
		return result;
	}

	const maxBufferValue = getMaxBufferSync(maxBuffer);
	return result.length > maxBufferValue ? result.slice(0, maxBufferValue) : result;
};

// `spawnSync()` does not allow differentiating `maxBuffer` per file descriptor, so we always use `stdout`
const getMaxBufferSync = ([, stdoutMaxBuffer]) => stdoutMaxBuffer;

// Computes `error.message`, `error.shortMessage` and `error.originalMessage`
const createMessages = ({
	stdio,
	all,
	ipcOutput,
	originalError,
	signal,
	signalDescription,
	exitCode,
	escapedCommand,
	timedOut,
	isCanceled,
	isGracefullyCanceled,
	isMaxBuffer,
	isForcefullyTerminated,
	forceKillAfterDelay,
	killSignal,
	maxBuffer,
	timeout,
	cwd,
}) => {
	const errorCode = originalError?.code;
	const prefix = getErrorPrefix({
		originalError,
		timedOut,
		timeout,
		isMaxBuffer,
		maxBuffer,
		errorCode,
		signal,
		signalDescription,
		exitCode,
		isCanceled,
		isGracefullyCanceled,
		isForcefullyTerminated,
		forceKillAfterDelay,
		killSignal,
	});
	const originalMessage = getOriginalMessage(originalError, cwd);
	const suffix = originalMessage === undefined ? '' : `\n${originalMessage}`;
	const shortMessage = `${prefix}: ${escapedCommand}${suffix}`;
	const messageStdio = all === undefined ? [stdio[2], stdio[1]] : [all];
	const message = [
		shortMessage,
		...messageStdio,
		...stdio.slice(3),
		ipcOutput.map(ipcMessage => serializeIpcMessage(ipcMessage)).join('\n'),
	]
		.map(messagePart => escapeLines(stripFinalNewline(serializeMessagePart(messagePart))))
		.filter(Boolean)
		.join('\n\n');
	return {originalMessage, shortMessage, message};
};

const getErrorPrefix = ({
	originalError,
	timedOut,
	timeout,
	isMaxBuffer,
	maxBuffer,
	errorCode,
	signal,
	signalDescription,
	exitCode,
	isCanceled,
	isGracefullyCanceled,
	isForcefullyTerminated,
	forceKillAfterDelay,
	killSignal,
}) => {
	const forcefulSuffix = getForcefulSuffix(isForcefullyTerminated, forceKillAfterDelay);

	if (timedOut) {
		return `Command timed out after ${timeout} milliseconds${forcefulSuffix}`;
	}

	if (isGracefullyCanceled) {
		if (signal === undefined) {
			return `Command was gracefully canceled with exit code ${exitCode}`;
		}

		return isForcefullyTerminated
			? `Command was gracefully canceled${forcefulSuffix}`
			: `Command was gracefully canceled with ${signal} (${signalDescription})`;
	}

	if (isCanceled) {
		return `Command was canceled${forcefulSuffix}`;
	}

	if (isMaxBuffer) {
		return `${getMaxBufferMessage(originalError, maxBuffer)}${forcefulSuffix}`;
	}

	if (errorCode !== undefined) {
		return `Command failed with ${errorCode}${forcefulSuffix}`;
	}

	if (isForcefullyTerminated) {
		return `Command was killed with ${killSignal} (${getSignalDescription(killSignal)})${forcefulSuffix}`;
	}

	if (signal !== undefined) {
		return `Command was killed with ${signal} (${signalDescription})`;
	}

	if (exitCode !== undefined) {
		return `Command failed with exit code ${exitCode}`;
	}

	return 'Command failed';
};

const getForcefulSuffix = (isForcefullyTerminated, forceKillAfterDelay) => isForcefullyTerminated
	? ` and was forcefully terminated after ${forceKillAfterDelay} milliseconds`
	: '';

const getOriginalMessage = (originalError, cwd) => {
	if (originalError instanceof DiscardedError) {
		return;
	}

	const originalMessage = isExecaError(originalError)
		? originalError.originalMessage
		: String(originalError?.message ?? originalError);
	const escapedOriginalMessage = escapeLines(fixCwdError(originalMessage, cwd));
	return escapedOriginalMessage === '' ? undefined : escapedOriginalMessage;
};

const serializeIpcMessage = ipcMessage => typeof ipcMessage === 'string'
	? ipcMessage
	: inspect(ipcMessage);

const serializeMessagePart = messagePart => Array.isArray(messagePart)
	? messagePart.map(messageItem => stripFinalNewline(serializeMessageItem(messageItem))).filter(Boolean).join('\n')
	: serializeMessageItem(messagePart);

const serializeMessageItem = messageItem => {
	if (typeof messageItem === 'string') {
		return messageItem;
	}

	if (isUint8Array(messageItem)) {
		return uint8ArrayToString(messageItem);
	}

	return '';
};

// Object returned on subprocess success
const makeSuccessResult = ({
	command,
	escapedCommand,
	stdio,
	all,
	ipcOutput,
	options: {cwd},
	startTime,
}) => omitUndefinedProperties({
	command,
	escapedCommand,
	cwd,
	durationMs: getDurationMs(startTime),
	failed: false,
	timedOut: false,
	isCanceled: false,
	isGracefullyCanceled: false,
	isTerminated: false,
	isMaxBuffer: false,
	isForcefullyTerminated: false,
	exitCode: 0,
	stdout: stdio[1],
	stderr: stdio[2],
	all,
	stdio,
	ipcOutput,
	pipedFrom: [],
});

// Object returned on subprocess failure before spawning
const makeEarlyError = ({
	error,
	command,
	escapedCommand,
	fileDescriptors,
	options,
	startTime,
	isSync,
}) => makeError({
	error,
	command,
	escapedCommand,
	startTime,
	timedOut: false,
	isCanceled: false,
	isGracefullyCanceled: false,
	isMaxBuffer: false,
	isForcefullyTerminated: false,
	stdio: Array.from({length: fileDescriptors.length}),
	ipcOutput: [],
	options,
	isSync,
});

// Object returned on subprocess failure
const makeError = ({
	error: originalError,
	command,
	escapedCommand,
	startTime,
	timedOut,
	isCanceled,
	isGracefullyCanceled,
	isMaxBuffer,
	isForcefullyTerminated,
	exitCode: rawExitCode,
	signal: rawSignal,
	stdio,
	all,
	ipcOutput,
	options: {
		timeoutDuration,
		timeout = timeoutDuration,
		forceKillAfterDelay,
		killSignal,
		cwd,
		maxBuffer,
	},
	isSync,
}) => {
	const {exitCode, signal, signalDescription} = normalizeExitPayload(rawExitCode, rawSignal);
	const {originalMessage, shortMessage, message} = createMessages({
		stdio,
		all,
		ipcOutput,
		originalError,
		signal,
		signalDescription,
		exitCode,
		escapedCommand,
		timedOut,
		isCanceled,
		isGracefullyCanceled,
		isMaxBuffer,
		isForcefullyTerminated,
		forceKillAfterDelay,
		killSignal,
		maxBuffer,
		timeout,
		cwd,
	});
	const error = getFinalError(originalError, message, isSync);
	Object.assign(error, getErrorProperties({
		error,
		command,
		escapedCommand,
		startTime,
		timedOut,
		isCanceled,
		isGracefullyCanceled,
		isMaxBuffer,
		isForcefullyTerminated,
		exitCode,
		signal,
		signalDescription,
		stdio,
		all,
		ipcOutput,
		cwd,
		originalMessage,
		shortMessage,
	}));
	return error;
};

const getErrorProperties = ({
	error,
	command,
	escapedCommand,
	startTime,
	timedOut,
	isCanceled,
	isGracefullyCanceled,
	isMaxBuffer,
	isForcefullyTerminated,
	exitCode,
	signal,
	signalDescription,
	stdio,
	all,
	ipcOutput,
	cwd,
	originalMessage,
	shortMessage,
}) => omitUndefinedProperties({
	shortMessage,
	originalMessage,
	command,
	escapedCommand,
	cwd,
	durationMs: getDurationMs(startTime),
	failed: true,
	timedOut,
	isCanceled,
	isGracefullyCanceled,
	isTerminated: signal !== undefined,
	isMaxBuffer,
	isForcefullyTerminated,
	exitCode,
	signal,
	signalDescription,
	code: error.cause?.code,
	stdout: stdio[1],
	stderr: stdio[2],
	all,
	stdio,
	ipcOutput,
	pipedFrom: [],
});

const omitUndefinedProperties = result => Object.fromEntries(Object.entries(result).filter(([, value]) => value !== undefined));

// `signal` and `exitCode` emitted on `subprocess.on('exit')` event can be `null`.
// We normalize them to `undefined`
const normalizeExitPayload = (rawExitCode, rawSignal) => {
	const exitCode = rawExitCode === null ? undefined : rawExitCode;
	const signal = rawSignal === null ? undefined : rawSignal;
	const signalDescription = signal === undefined ? undefined : getSignalDescription(rawSignal);
	return {exitCode, signal, signalDescription};
};

const toZeroIfInfinity = value => Number.isFinite(value) ? value : 0;

function parseNumber(milliseconds) {
	return {
		days: Math.trunc(milliseconds / 86_400_000),
		hours: Math.trunc(milliseconds / 3_600_000 % 24),
		minutes: Math.trunc(milliseconds / 60_000 % 60),
		seconds: Math.trunc(milliseconds / 1000 % 60),
		milliseconds: Math.trunc(milliseconds % 1000),
		microseconds: Math.trunc(toZeroIfInfinity(milliseconds * 1000) % 1000),
		nanoseconds: Math.trunc(toZeroIfInfinity(milliseconds * 1e6) % 1000),
	};
}

function parseBigint(milliseconds) {
	return {
		days: milliseconds / 86_400_000n,
		hours: milliseconds / 3_600_000n % 24n,
		minutes: milliseconds / 60_000n % 60n,
		seconds: milliseconds / 1000n % 60n,
		milliseconds: milliseconds % 1000n,
		microseconds: 0n,
		nanoseconds: 0n,
	};
}

function parseMilliseconds(milliseconds) {
	switch (typeof milliseconds) {
		case 'number': {
			if (Number.isFinite(milliseconds)) {
				return parseNumber(milliseconds);
			}

			break;
		}

		case 'bigint': {
			return parseBigint(milliseconds);
		}

		// No default
	}

	throw new TypeError('Expected a finite number or bigint');
}

const isZero = value => value === 0 || value === 0n;
const pluralize = (word, count) => (count === 1 || count === 1n) ? word : `${word}s`;

const SECOND_ROUNDING_EPSILON = 0.000_000_1;
const ONE_DAY_IN_MILLISECONDS = 24n * 60n * 60n * 1000n;

function prettyMilliseconds(milliseconds, options) {
	const isBigInt = typeof milliseconds === 'bigint';
	if (!isBigInt && !Number.isFinite(milliseconds)) {
		throw new TypeError('Expected a finite number or bigint');
	}

	options = {...options};

	const sign = milliseconds < 0 ? '-' : '';
	milliseconds = milliseconds < 0 ? -milliseconds : milliseconds; // Cannot use `Math.abs()` because of BigInt support.

	if (options.colonNotation) {
		options.compact = false;
		options.formatSubMilliseconds = false;
		options.separateMilliseconds = false;
		options.verbose = false;
	}

	if (options.compact) {
		options.unitCount = 1;
		options.secondsDecimalDigits = 0;
		options.millisecondsDecimalDigits = 0;
	}

	let result = [];

	const floorDecimals = (value, decimalDigits) => {
		const flooredInterimValue = Math.floor((value * (10 ** decimalDigits)) + SECOND_ROUNDING_EPSILON);
		const flooredValue = Math.round(flooredInterimValue) / (10 ** decimalDigits);
		return flooredValue.toFixed(decimalDigits);
	};

	const add = (value, long, short, valueString) => {
		if (
			(result.length === 0 || !options.colonNotation)
			&& isZero(value)
			&& !(options.colonNotation && short === 'm')) {
			return;
		}

		valueString ??= String(value);
		if (options.colonNotation) {
			const wholeDigits = valueString.includes('.') ? valueString.split('.')[0].length : valueString.length;
			const minLength = result.length > 0 ? 2 : 1;
			valueString = '0'.repeat(Math.max(0, minLength - wholeDigits)) + valueString;
		} else {
			valueString += options.verbose ? ' ' + pluralize(long, value) : short;
		}

		result.push(valueString);
	};

	const parsed = parseMilliseconds(milliseconds);
	const days = BigInt(parsed.days);

	if (options.hideYearAndDays) {
		add((BigInt(days) * 24n) + BigInt(parsed.hours), 'hour', 'h');
	} else {
		if (options.hideYear) {
			add(days, 'day', 'd');
		} else {
			add(days / 365n, 'year', 'y');
			add(days % 365n, 'day', 'd');
		}

		add(Number(parsed.hours), 'hour', 'h');
	}

	add(Number(parsed.minutes), 'minute', 'm');

	if (!options.hideSeconds) {
		if (
			options.separateMilliseconds
			|| options.formatSubMilliseconds
			|| (!options.colonNotation && milliseconds < 1000 && !options.subSecondsAsDecimals)
		) {
			const seconds = Number(parsed.seconds);
			const milliseconds = Number(parsed.milliseconds);
			const microseconds = Number(parsed.microseconds);
			const nanoseconds = Number(parsed.nanoseconds);

			add(seconds, 'second', 's');

			if (options.formatSubMilliseconds) {
				add(milliseconds, 'millisecond', 'ms');
				add(microseconds, 'microsecond', 'Âµs');
				add(nanoseconds, 'nanosecond', 'ns');
			} else {
				const millisecondsAndBelow
					= milliseconds
					+ (microseconds / 1000)
					+ (nanoseconds / 1e6);

				const millisecondsDecimalDigits
					= typeof options.millisecondsDecimalDigits === 'number'
						? options.millisecondsDecimalDigits
						: 0;

				const roundedMilliseconds = millisecondsAndBelow >= 1
					? Math.round(millisecondsAndBelow)
					: Math.ceil(millisecondsAndBelow);

				const millisecondsString = millisecondsDecimalDigits
					? millisecondsAndBelow.toFixed(millisecondsDecimalDigits)
					: roundedMilliseconds;

				add(
					Number.parseFloat(millisecondsString),
					'millisecond',
					'ms',
					millisecondsString,
				);
			}
		} else {
			const seconds = (
				(isBigInt ? Number(milliseconds % ONE_DAY_IN_MILLISECONDS) : milliseconds)
				/ 1000
			) % 60;
			const secondsDecimalDigits
				= typeof options.secondsDecimalDigits === 'number'
					? options.secondsDecimalDigits
					: 1;
			const secondsFixed = floorDecimals(seconds, secondsDecimalDigits);
			const secondsString = options.keepDecimalsOnWholeSeconds
				? secondsFixed
				: secondsFixed.replace(/\.0+$/, '');
			add(Number.parseFloat(secondsString), 'second', 's', secondsString);
		}
	}

	if (result.length === 0) {
		return sign + '0' + (options.verbose ? ' milliseconds' : 'ms');
	}

	const separator = options.colonNotation ? ':' : ' ';
	if (typeof options.unitCount === 'number') {
		result = result.slice(0, Math.max(options.unitCount, 1));
	}

	return sign + result.join(separator);
}

// When `verbose` is `short|full|custom`, print each command's error when it fails
const logError = (result, verboseInfo) => {
	if (result.failed) {
		verboseLog({
			type: 'error',
			verboseMessage: result.shortMessage,
			verboseInfo,
			result,
		});
	}
};

// When `verbose` is `short|full|custom`, print each command's completion, duration and error
const logResult = (result, verboseInfo) => {
	if (!isVerbose(verboseInfo)) {
		return;
	}

	logError(result, verboseInfo);
	logDuration(result, verboseInfo);
};

const logDuration = (result, verboseInfo) => {
	const verboseMessage = `(done in ${prettyMilliseconds(result.durationMs)})`;
	verboseLog({
		type: 'duration',
		verboseMessage,
		verboseInfo,
		result,
	});
};

// Applies the `reject` option.
// Also print the final log line with `verbose`.
const handleResult = (result, verboseInfo, {reject}) => {
	logResult(result, verboseInfo);

	if (result.failed && reject) {
		throw result;
	}

	return result;
};

// The `stdin`/`stdout`/`stderr` option can be of many types. This detects it.
const getStdioItemType = (value, optionName) => {
	if (isAsyncGenerator(value)) {
		return 'asyncGenerator';
	}

	if (isSyncGenerator(value)) {
		return 'generator';
	}

	if (isUrl(value)) {
		return 'fileUrl';
	}

	if (isFilePathObject(value)) {
		return 'filePath';
	}

	if (isWebStream(value)) {
		return 'webStream';
	}

	if (isStream(value, {checkOpen: false})) {
		return 'native';
	}

	if (isUint8Array(value)) {
		return 'uint8Array';
	}

	if (isAsyncIterableObject(value)) {
		return 'asyncIterable';
	}

	if (isIterableObject(value)) {
		return 'iterable';
	}

	if (isTransformStream(value)) {
		return getTransformStreamType({}, optionName);
	}

	if (isTransformOptions(value)) {
		return getTransformObjectType(value, optionName);
	}

	return 'native';
};

const getTransformObjectType = (value, optionName) => {
	if (isDuplexStream(value.transform, {checkOpen: false})) {
		return getDuplexType(value, optionName);
	}

	if (isTransformStream(value.transform)) {
		return getTransformStreamType(value, optionName);
	}

	return getGeneratorObjectType(value, optionName);
};

const getDuplexType = (value, optionName) => {
	validateNonGeneratorType(value, optionName, 'Duplex stream');
	return 'duplex';
};

const getTransformStreamType = (value, optionName) => {
	validateNonGeneratorType(value, optionName, 'web TransformStream');
	return 'webTransform';
};

const validateNonGeneratorType = ({final, binary, objectMode}, optionName, typeName) => {
	checkUndefinedOption(final, `${optionName}.final`, typeName);
	checkUndefinedOption(binary, `${optionName}.binary`, typeName);
	checkBooleanOption(objectMode, `${optionName}.objectMode`);
};

const checkUndefinedOption = (value, optionName, typeName) => {
	if (value !== undefined) {
		throw new TypeError(`The \`${optionName}\` option can only be defined when using a generator, not a ${typeName}.`);
	}
};

const getGeneratorObjectType = ({transform, final, binary, objectMode}, optionName) => {
	if (transform !== undefined && !isGenerator(transform)) {
		throw new TypeError(`The \`${optionName}.transform\` option must be a generator, a Duplex stream or a web TransformStream.`);
	}

	if (isDuplexStream(final, {checkOpen: false})) {
		throw new TypeError(`The \`${optionName}.final\` option must not be a Duplex stream.`);
	}

	if (isTransformStream(final)) {
		throw new TypeError(`The \`${optionName}.final\` option must not be a web TransformStream.`);
	}

	if (final !== undefined && !isGenerator(final)) {
		throw new TypeError(`The \`${optionName}.final\` option must be a generator.`);
	}

	checkBooleanOption(binary, `${optionName}.binary`);
	checkBooleanOption(objectMode, `${optionName}.objectMode`);

	return isAsyncGenerator(transform) || isAsyncGenerator(final) ? 'asyncGenerator' : 'generator';
};

const checkBooleanOption = (value, optionName) => {
	if (value !== undefined && typeof value !== 'boolean') {
		throw new TypeError(`The \`${optionName}\` option must use a boolean.`);
	}
};

const isGenerator = value => isAsyncGenerator(value) || isSyncGenerator(value);
const isAsyncGenerator = value => Object.prototype.toString.call(value) === '[object AsyncGeneratorFunction]';
const isSyncGenerator = value => Object.prototype.toString.call(value) === '[object GeneratorFunction]';
const isTransformOptions = value => isPlainObject(value)
	&& (value.transform !== undefined || value.final !== undefined);

const isUrl = value => Object.prototype.toString.call(value) === '[object URL]';
const isRegularUrl = value => isUrl(value) && value.protocol !== 'file:';

const isFilePathObject = value => isPlainObject(value)
	&& Object.keys(value).length > 0
	&& Object.keys(value).every(key => FILE_PATH_KEYS.has(key))
	&& isFilePathString(value.file);
const FILE_PATH_KEYS = new Set(['file', 'append']);
const isFilePathString = file => typeof file === 'string';

const isUnknownStdioString = (type, value) => type === 'native'
	&& typeof value === 'string'
	&& !KNOWN_STDIO_STRINGS.has(value);
const KNOWN_STDIO_STRINGS = new Set(['ipc', 'ignore', 'inherit', 'overlapped', 'pipe']);

const isReadableStream = value => Object.prototype.toString.call(value) === '[object ReadableStream]';
const isWritableStream = value => Object.prototype.toString.call(value) === '[object WritableStream]';
const isWebStream = value => isReadableStream(value) || isWritableStream(value);
const isTransformStream = value => isReadableStream(value?.readable) && isWritableStream(value?.writable);

const isAsyncIterableObject = value => isObject(value) && typeof value[Symbol.asyncIterator] === 'function';
const isIterableObject = value => isObject(value) && typeof value[Symbol.iterator] === 'function';
const isObject = value => typeof value === 'object' && value !== null;

// Types which modify `subprocess.std*`
const TRANSFORM_TYPES = new Set(['generator', 'asyncGenerator', 'duplex', 'webTransform']);
// Types which write to a file or a file descriptor
const FILE_TYPES = new Set(['fileUrl', 'filePath', 'fileNumber']);
// When two file descriptors of this type share the same target, we need to do some special logic
const SPECIAL_DUPLICATE_TYPES_SYNC = new Set(['fileUrl', 'filePath']);
const SPECIAL_DUPLICATE_TYPES = new Set([...SPECIAL_DUPLICATE_TYPES_SYNC, 'webStream', 'nodeStream']);
// Do not allow two file descriptors of this type sharing the same target
const FORBID_DUPLICATE_TYPES = new Set(['webTransform', 'duplex']);

// Convert types to human-friendly strings for error messages
const TYPE_TO_MESSAGE = {
	generator: 'a generator',
	asyncGenerator: 'an async generator',
	fileUrl: 'a file URL',
	filePath: 'a file path string',
	fileNumber: 'a file descriptor number',
	webStream: 'a web stream',
	nodeStream: 'a Node.js stream',
	webTransform: 'a web TransformStream',
	duplex: 'a Duplex stream',
	native: 'any value',
	iterable: 'an iterable',
	asyncIterable: 'an async iterable',
	string: 'a string',
	uint8Array: 'a Uint8Array',
};

/*
Retrieve the `objectMode`s of a single transform.
`objectMode` determines the return value's type, i.e. the `readableObjectMode`.
The chunk argument's type is based on the previous generator's return value, i.e. the `writableObjectMode` is based on the previous `readableObjectMode`.
The last input's generator is read by `subprocess.stdin` which:
- should not be in `objectMode` for performance reasons.
- can only be strings, Buffers and Uint8Arrays.
Therefore its `readableObjectMode` must be `false`.
The same applies to the first output's generator's `writableObjectMode`.
*/
const getTransformObjectModes = (objectMode, index, newTransforms, direction) => direction === 'output'
	? getOutputObjectModes(objectMode, index, newTransforms)
	: getInputObjectModes(objectMode, index, newTransforms);

const getOutputObjectModes = (objectMode, index, newTransforms) => {
	const writableObjectMode = index !== 0 && newTransforms[index - 1].value.readableObjectMode;
	const readableObjectMode = objectMode ?? writableObjectMode;
	return {writableObjectMode, readableObjectMode};
};

const getInputObjectModes = (objectMode, index, newTransforms) => {
	const writableObjectMode = index === 0
		? objectMode === true
		: newTransforms[index - 1].value.readableObjectMode;
	const readableObjectMode = index !== newTransforms.length - 1 && (objectMode ?? writableObjectMode);
	return {writableObjectMode, readableObjectMode};
};

// Retrieve the `objectMode` of a file descriptor, e.g. `stdout` or `stderr`
const getFdObjectMode = (stdioItems, direction) => {
	const lastTransform = stdioItems.findLast(({type}) => TRANSFORM_TYPES.has(type));
	if (lastTransform === undefined) {
		return false;
	}

	return direction === 'input'
		? lastTransform.value.writableObjectMode
		: lastTransform.value.readableObjectMode;
};

// Transforms generators/duplex/TransformStream can have multiple shapes.
// This normalizes it and applies default values.
const normalizeTransforms = (stdioItems, optionName, direction, options) => [
	...stdioItems.filter(({type}) => !TRANSFORM_TYPES.has(type)),
	...getTransforms(stdioItems, optionName, direction, options),
];

const getTransforms = (stdioItems, optionName, direction, {encoding}) => {
	const transforms = stdioItems.filter(({type}) => TRANSFORM_TYPES.has(type));
	const newTransforms = Array.from({length: transforms.length});

	for (const [index, stdioItem] of Object.entries(transforms)) {
		newTransforms[index] = normalizeTransform({
			stdioItem,
			index: Number(index),
			newTransforms,
			optionName,
			direction,
			encoding,
		});
	}

	return sortTransforms(newTransforms, direction);
};

const normalizeTransform = ({stdioItem, stdioItem: {type}, index, newTransforms, optionName, direction, encoding}) => {
	if (type === 'duplex') {
		return normalizeDuplex({stdioItem, optionName});
	}

	if (type === 'webTransform') {
		return normalizeTransformStream({
			stdioItem,
			index,
			newTransforms,
			direction,
		});
	}

	return normalizeGenerator({
		stdioItem,
		index,
		newTransforms,
		direction,
		encoding,
	});
};

const normalizeDuplex = ({
	stdioItem,
	stdioItem: {
		value: {
			transform,
			transform: {writableObjectMode, readableObjectMode},
			objectMode = readableObjectMode,
		},
	},
	optionName,
}) => {
	if (objectMode && !readableObjectMode) {
		throw new TypeError(`The \`${optionName}.objectMode\` option can only be \`true\` if \`new Duplex({objectMode: true})\` is used.`);
	}

	if (!objectMode && readableObjectMode) {
		throw new TypeError(`The \`${optionName}.objectMode\` option cannot be \`false\` if \`new Duplex({objectMode: true})\` is used.`);
	}

	return {
		...stdioItem,
		value: {transform, writableObjectMode, readableObjectMode},
	};
};

const normalizeTransformStream = ({stdioItem, stdioItem: {value}, index, newTransforms, direction}) => {
	const {transform, objectMode} = isPlainObject(value) ? value : {transform: value};
	const {writableObjectMode, readableObjectMode} = getTransformObjectModes(objectMode, index, newTransforms, direction);
	return ({
		...stdioItem,
		value: {transform, writableObjectMode, readableObjectMode},
	});
};

const normalizeGenerator = ({stdioItem, stdioItem: {value}, index, newTransforms, direction, encoding}) => {
	const {
		transform,
		final,
		binary: binaryOption = false,
		preserveNewlines = false,
		objectMode,
	} = isPlainObject(value) ? value : {transform: value};
	const binary = binaryOption || BINARY_ENCODINGS.has(encoding);
	const {writableObjectMode, readableObjectMode} = getTransformObjectModes(objectMode, index, newTransforms, direction);
	return {
		...stdioItem,
		value: {
			transform,
			final,
			binary,
			preserveNewlines,
			writableObjectMode,
			readableObjectMode,
		},
	};
};

const sortTransforms = (newTransforms, direction) => direction === 'input' ? newTransforms.reverse() : newTransforms;

// For `stdio[fdNumber]` beyond stdin/stdout/stderr, we need to guess whether the value passed is intended for inputs or outputs.
// This allows us to know whether to pipe _into_ or _from_ the stream.
// When `stdio[fdNumber]` is a single value, this guess is fairly straightforward.
// However, when it is an array instead, we also need to make sure the different values are not incompatible with each other.
const getStreamDirection = (stdioItems, fdNumber, optionName) => {
	const directions = stdioItems.map(stdioItem => getStdioItemDirection(stdioItem, fdNumber));

	if (directions.includes('input') && directions.includes('output')) {
		throw new TypeError(`The \`${optionName}\` option must not be an array of both readable and writable values.`);
	}

	return directions.find(Boolean) ?? DEFAULT_DIRECTION;
};

const getStdioItemDirection = ({type, value}, fdNumber) => KNOWN_DIRECTIONS[fdNumber] ?? guessStreamDirection[type](value);

// `stdin`/`stdout`/`stderr` have a known direction
const KNOWN_DIRECTIONS = ['input', 'output', 'output'];

const anyDirection = () => undefined;
const alwaysInput = () => 'input';

// `string` can only be added through the `input` option, i.e. does not need to be handled here
const guessStreamDirection = {
	generator: anyDirection,
	asyncGenerator: anyDirection,
	fileUrl: anyDirection,
	filePath: anyDirection,
	iterable: alwaysInput,
	asyncIterable: alwaysInput,
	uint8Array: alwaysInput,
	webStream: value => isWritableStream(value) ? 'output' : 'input',
	nodeStream(value) {
		if (!isReadableStream$1(value, {checkOpen: false})) {
			return 'output';
		}

		return isWritableStream$1(value, {checkOpen: false}) ? undefined : 'input';
	},
	webTransform: anyDirection,
	duplex: anyDirection,
	native(value) {
		const standardStreamDirection = getStandardStreamDirection(value);
		if (standardStreamDirection !== undefined) {
			return standardStreamDirection;
		}

		if (isStream(value, {checkOpen: false})) {
			return guessStreamDirection.nodeStream(value);
		}
	},
};

const getStandardStreamDirection = value => {
	if ([0, process$2.stdin].includes(value)) {
		return 'input';
	}

	if ([1, 2, process$2.stdout, process$2.stderr].includes(value)) {
		return 'output';
	}
};

// When ambiguous, we initially keep the direction as `undefined`.
// This allows arrays of `stdio` values to resolve the ambiguity.
// For example, `stdio[3]: DuplexStream` is ambiguous, but `stdio[3]: [DuplexStream, WritableStream]` is not.
// When the ambiguity remains, we default to `output` since it is the most common use case for additional file descriptors.
const DEFAULT_DIRECTION = 'output';

// The `ipc` option adds an `ipc` item to the `stdio` option
const normalizeIpcStdioArray = (stdioArray, ipc) => ipc && !stdioArray.includes('ipc')
	? [...stdioArray, 'ipc']
	: stdioArray;

// Add support for `stdin`/`stdout`/`stderr` as an alias for `stdio`.
// Also normalize the `stdio` option.
const normalizeStdioOption = ({stdio, ipc, buffer, ...options}, verboseInfo, isSync) => {
	const stdioArray = getStdioArray(stdio, options).map((stdioOption, fdNumber) => addDefaultValue(stdioOption, fdNumber));
	return isSync
		? normalizeStdioSync(stdioArray, buffer, verboseInfo)
		: normalizeIpcStdioArray(stdioArray, ipc);
};

const getStdioArray = (stdio, options) => {
	if (stdio === undefined) {
		return STANDARD_STREAMS_ALIASES.map(alias => options[alias]);
	}

	if (hasAlias(options)) {
		throw new Error(`It's not possible to provide \`stdio\` in combination with one of ${STANDARD_STREAMS_ALIASES.map(alias => `\`${alias}\``).join(', ')}`);
	}

	if (typeof stdio === 'string') {
		return [stdio, stdio, stdio];
	}

	if (!Array.isArray(stdio)) {
		throw new TypeError(`Expected \`stdio\` to be of type \`string\` or \`Array\`, got \`${typeof stdio}\``);
	}

	const length = Math.max(stdio.length, STANDARD_STREAMS_ALIASES.length);
	return Array.from({length}, (_, fdNumber) => stdio[fdNumber]);
};

const hasAlias = options => STANDARD_STREAMS_ALIASES.some(alias => options[alias] !== undefined);

const addDefaultValue = (stdioOption, fdNumber) => {
	if (Array.isArray(stdioOption)) {
		return stdioOption.map(item => addDefaultValue(item, fdNumber));
	}

	if (stdioOption === null || stdioOption === undefined) {
		return fdNumber >= STANDARD_STREAMS_ALIASES.length ? 'ignore' : 'pipe';
	}

	return stdioOption;
};

// Using `buffer: false` with synchronous methods implies `stdout`/`stderr`: `ignore`.
// Unless the output is needed, e.g. due to `verbose: 'full'` or to redirecting to a file.
const normalizeStdioSync = (stdioArray, buffer, verboseInfo) => stdioArray.map((stdioOption, fdNumber) =>
	!buffer[fdNumber]
	&& fdNumber !== 0
	&& !isFullVerbose(verboseInfo, fdNumber)
	&& isOutputPipeOnly(stdioOption)
		? 'ignore'
		: stdioOption);

const isOutputPipeOnly = stdioOption => stdioOption === 'pipe'
	|| (Array.isArray(stdioOption) && stdioOption.every(item => item === 'pipe'));

// When we use multiple `stdio` values for the same streams, we pass 'pipe' to `child_process.spawn()`.
// We then emulate the piping done by core Node.js.
// To do so, we transform the following values:
//  - Node.js streams are marked as `type: nodeStream`
//  - 'inherit' becomes `process.stdin|stdout|stderr`
//  - any file descriptor integer becomes `process.stdio[fdNumber]`
// All of the above transformations tell Execa to perform manual piping.
const handleNativeStream = ({stdioItem, stdioItem: {type}, isStdioArray, fdNumber, direction, isSync}) => {
	if (!isStdioArray || type !== 'native') {
		return stdioItem;
	}

	return isSync
		? handleNativeStreamSync({stdioItem, fdNumber, direction})
		: handleNativeStreamAsync({stdioItem, fdNumber});
};

// Synchronous methods use a different logic.
// 'inherit', file descriptors and process.std* are handled by readFileSync()/writeFileSync().
const handleNativeStreamSync = ({stdioItem, stdioItem: {value, optionName}, fdNumber, direction}) => {
	const targetFd = getTargetFd({
		value,
		optionName,
		fdNumber,
		direction,
	});
	if (targetFd !== undefined) {
		return targetFd;
	}

	if (isStream(value, {checkOpen: false})) {
		throw new TypeError(`The \`${optionName}: Stream\` option cannot both be an array and include a stream with synchronous methods.`);
	}

	return stdioItem;
};

const getTargetFd = ({value, optionName, fdNumber, direction}) => {
	const targetFdNumber = getTargetFdNumber(value, fdNumber);
	if (targetFdNumber === undefined) {
		return;
	}

	if (direction === 'output') {
		return {type: 'fileNumber', value: targetFdNumber, optionName};
	}

	if (tty.isatty(targetFdNumber)) {
		throw new TypeError(`The \`${optionName}: ${serializeOptionValue(value)}\` option is invalid: it cannot be a TTY with synchronous methods.`);
	}

	return {type: 'uint8Array', value: bufferToUint8Array(readFileSync(targetFdNumber)), optionName};
};

const getTargetFdNumber = (value, fdNumber) => {
	if (value === 'inherit') {
		return fdNumber;
	}

	if (typeof value === 'number') {
		return value;
	}

	const standardStreamIndex = STANDARD_STREAMS.indexOf(value);
	if (standardStreamIndex !== -1) {
		return standardStreamIndex;
	}
};

const handleNativeStreamAsync = ({stdioItem, stdioItem: {value, optionName}, fdNumber}) => {
	if (value === 'inherit') {
		return {type: 'nodeStream', value: getStandardStream(fdNumber, value, optionName), optionName};
	}

	if (typeof value === 'number') {
		return {type: 'nodeStream', value: getStandardStream(value, value, optionName), optionName};
	}

	if (isStream(value, {checkOpen: false})) {
		return {type: 'nodeStream', value, optionName};
	}

	return stdioItem;
};

// Node.js does not allow to easily retrieve file descriptors beyond stdin/stdout/stderr as streams.
//  - `fs.createReadStream()`/`fs.createWriteStream()` with the `fd` option do not work with character devices that use blocking reads/writes (such as interactive TTYs).
//  - Using a TCP `Socket` would work but be rather complex to implement.
// Since this is an edge case, we simply throw an error message.
// See https://github.com/sindresorhus/execa/pull/643#discussion_r1435905707
const getStandardStream = (fdNumber, value, optionName) => {
	const standardStream = STANDARD_STREAMS[fdNumber];

	if (standardStream === undefined) {
		throw new TypeError(`The \`${optionName}: ${value}\` option is invalid: no such standard stream.`);
	}

	return standardStream;
};

// Append the `stdin` option with the `input` and `inputFile` options
const handleInputOptions = ({input, inputFile}, fdNumber) => fdNumber === 0
	? [
		...handleInputOption(input),
		...handleInputFileOption(inputFile),
	]
	: [];

const handleInputOption = input => input === undefined ? [] : [{
	type: getInputType(input),
	value: input,
	optionName: 'input',
}];

const getInputType = input => {
	if (isReadableStream$1(input, {checkOpen: false})) {
		return 'nodeStream';
	}

	if (typeof input === 'string') {
		return 'string';
	}

	if (isUint8Array(input)) {
		return 'uint8Array';
	}

	throw new Error('The `input` option must be a string, a Uint8Array or a Node.js Readable stream.');
};

const handleInputFileOption = inputFile => inputFile === undefined ? [] : [{
	...getInputFileType(inputFile),
	optionName: 'inputFile',
}];

const getInputFileType = inputFile => {
	if (isUrl(inputFile)) {
		return {type: 'fileUrl', value: inputFile};
	}

	if (isFilePathString(inputFile)) {
		return {type: 'filePath', value: {file: inputFile}};
	}

	throw new Error('The `inputFile` option must be a file path string or a file URL.');
};

// Duplicates in the same file descriptor is most likely an error.
// However, this can be useful with generators.
const filterDuplicates = stdioItems => stdioItems.filter((stdioItemOne, indexOne) =>
	stdioItems.every((stdioItemTwo, indexTwo) => stdioItemOne.value !== stdioItemTwo.value
		|| indexOne >= indexTwo
		|| stdioItemOne.type === 'generator'
		|| stdioItemOne.type === 'asyncGenerator'));

// Check if two file descriptors are sharing the same target.
// For example `{stdout: {file: './output.txt'}, stderr: {file: './output.txt'}}`.
const getDuplicateStream = ({stdioItem: {type, value, optionName}, direction, fileDescriptors, isSync}) => {
	const otherStdioItems = getOtherStdioItems(fileDescriptors, type);
	if (otherStdioItems.length === 0) {
		return;
	}

	if (isSync) {
		validateDuplicateStreamSync({
			otherStdioItems,
			type,
			value,
			optionName,
			direction,
		});
		return;
	}

	if (SPECIAL_DUPLICATE_TYPES.has(type)) {
		return getDuplicateStreamInstance({
			otherStdioItems,
			type,
			value,
			optionName,
			direction,
		});
	}

	if (FORBID_DUPLICATE_TYPES.has(type)) {
		validateDuplicateTransform({
			otherStdioItems,
			type,
			value,
			optionName,
		});
	}
};

// Values shared by multiple file descriptors
const getOtherStdioItems = (fileDescriptors, type) => fileDescriptors
	.flatMap(({direction, stdioItems}) => stdioItems
		.filter(stdioItem => stdioItem.type === type)
		.map((stdioItem => ({...stdioItem, direction}))));

// With `execaSync()`, do not allow setting a file path both in input and output
const validateDuplicateStreamSync = ({otherStdioItems, type, value, optionName, direction}) => {
	if (SPECIAL_DUPLICATE_TYPES_SYNC.has(type)) {
		getDuplicateStreamInstance({
			otherStdioItems,
			type,
			value,
			optionName,
			direction,
		});
	}
};

// When two file descriptors share the file or stream, we need to re-use the same underlying stream.
// Otherwise, the stream would be closed twice when piping ends.
// This is only an issue with output file descriptors.
// This is not a problem with generator functions since those create a new instance for each file descriptor.
// We also forbid input and output file descriptors sharing the same file or stream, since that does not make sense.
const getDuplicateStreamInstance = ({otherStdioItems, type, value, optionName, direction}) => {
	const duplicateStdioItems = otherStdioItems.filter(stdioItem => hasSameValue(stdioItem, value));
	if (duplicateStdioItems.length === 0) {
		return;
	}

	const differentStdioItem = duplicateStdioItems.find(stdioItem => stdioItem.direction !== direction);
	throwOnDuplicateStream(differentStdioItem, optionName, type);

	return direction === 'output' ? duplicateStdioItems[0].stream : undefined;
};

const hasSameValue = ({type, value}, secondValue) => {
	if (type === 'filePath') {
		return value.file === secondValue.file;
	}

	if (type === 'fileUrl') {
		return value.href === secondValue.href;
	}

	return value === secondValue;
};

// We do not allow two file descriptors to share the same Duplex or TransformStream.
// This is because those are set directly to `subprocess.std*`.
// For example, this could result in `subprocess.stdout` and `subprocess.stderr` being the same value.
// This means reading from either would get data from both stdout and stderr.
const validateDuplicateTransform = ({otherStdioItems, type, value, optionName}) => {
	const duplicateStdioItem = otherStdioItems.find(({value: {transform}}) => transform === value.transform);
	throwOnDuplicateStream(duplicateStdioItem, optionName, type);
};

const throwOnDuplicateStream = (stdioItem, optionName, type) => {
	if (stdioItem !== undefined) {
		throw new TypeError(`The \`${stdioItem.optionName}\` and \`${optionName}\` options must not target ${TYPE_TO_MESSAGE[type]} that is the same.`);
	}
};

// Handle `input`, `inputFile`, `stdin`, `stdout` and `stderr` options, before spawning, in async/sync mode
// They are converted into an array of `fileDescriptors`.
// Each `fileDescriptor` is normalized, validated and contains all information necessary for further handling.
const handleStdio = (addProperties, options, verboseInfo, isSync) => {
	const stdio = normalizeStdioOption(options, verboseInfo, isSync);
	const initialFileDescriptors = stdio.map((stdioOption, fdNumber) => getFileDescriptor({
		stdioOption,
		fdNumber,
		options,
		isSync,
	}));
	const fileDescriptors = getFinalFileDescriptors({
		initialFileDescriptors,
		addProperties,
		options,
		isSync,
	});
	options.stdio = fileDescriptors.map(({stdioItems}) => forwardStdio(stdioItems));
	return fileDescriptors;
};

const getFileDescriptor = ({stdioOption, fdNumber, options, isSync}) => {
	const optionName = getStreamName(fdNumber);
	const {stdioItems: initialStdioItems, isStdioArray} = initializeStdioItems({
		stdioOption,
		fdNumber,
		options,
		optionName,
	});
	const direction = getStreamDirection(initialStdioItems, fdNumber, optionName);
	const stdioItems = initialStdioItems.map(stdioItem => handleNativeStream({
		stdioItem,
		isStdioArray,
		fdNumber,
		direction,
		isSync,
	}));
	const normalizedStdioItems = normalizeTransforms(stdioItems, optionName, direction, options);
	const objectMode = getFdObjectMode(normalizedStdioItems, direction);
	validateFileObjectMode(normalizedStdioItems, objectMode);
	return {direction, objectMode, stdioItems: normalizedStdioItems};
};

// We make sure passing an array with a single item behaves the same as passing that item without an array.
// This is what users would expect.
// For example, `stdout: ['ignore']` behaves the same as `stdout: 'ignore'`.
const initializeStdioItems = ({stdioOption, fdNumber, options, optionName}) => {
	const values = Array.isArray(stdioOption) ? stdioOption : [stdioOption];
	const initialStdioItems = [
		...values.map(value => initializeStdioItem(value, optionName)),
		...handleInputOptions(options, fdNumber),
	];

	const stdioItems = filterDuplicates(initialStdioItems);
	const isStdioArray = stdioItems.length > 1;
	validateStdioArray(stdioItems, isStdioArray, optionName);
	validateStreams(stdioItems);
	return {stdioItems, isStdioArray};
};

const initializeStdioItem = (value, optionName) => ({
	type: getStdioItemType(value, optionName),
	value,
	optionName,
});

const validateStdioArray = (stdioItems, isStdioArray, optionName) => {
	if (stdioItems.length === 0) {
		throw new TypeError(`The \`${optionName}\` option must not be an empty array.`);
	}

	if (!isStdioArray) {
		return;
	}

	for (const {value, optionName} of stdioItems) {
		if (INVALID_STDIO_ARRAY_OPTIONS.has(value)) {
			throw new Error(`The \`${optionName}\` option must not include \`${value}\`.`);
		}
	}
};

// Using those `stdio` values together with others for the same stream does not make sense, so we make it fail.
// However, we do allow it if the array has a single item.
const INVALID_STDIO_ARRAY_OPTIONS = new Set(['ignore', 'ipc']);

const validateStreams = stdioItems => {
	for (const stdioItem of stdioItems) {
		validateFileStdio(stdioItem);
	}
};

const validateFileStdio = ({type, value, optionName}) => {
	if (isRegularUrl(value)) {
		throw new TypeError(`The \`${optionName}: URL\` option must use the \`file:\` scheme.
For example, you can use the \`pathToFileURL()\` method of the \`url\` core module.`);
	}

	if (isUnknownStdioString(type, value)) {
		throw new TypeError(`The \`${optionName}: { file: '...' }\` option must be used instead of \`${optionName}: '...'\`.`);
	}
};

const validateFileObjectMode = (stdioItems, objectMode) => {
	if (!objectMode) {
		return;
	}

	const fileStdioItem = stdioItems.find(({type}) => FILE_TYPES.has(type));
	if (fileStdioItem !== undefined) {
		throw new TypeError(`The \`${fileStdioItem.optionName}\` option cannot use both files and transforms in objectMode.`);
	}
};

// Some `stdio` values require Execa to create streams.
// For example, file paths create file read/write streams.
// Those transformations are specified in `addProperties`, which is both direction-specific and type-specific.
const getFinalFileDescriptors = ({initialFileDescriptors, addProperties, options, isSync}) => {
	const fileDescriptors = [];

	try {
		for (const fileDescriptor of initialFileDescriptors) {
			fileDescriptors.push(getFinalFileDescriptor({
				fileDescriptor,
				fileDescriptors,
				addProperties,
				options,
				isSync,
			}));
		}

		return fileDescriptors;
	} catch (error) {
		cleanupCustomStreams(fileDescriptors);
		throw error;
	}
};

const getFinalFileDescriptor = ({
	fileDescriptor: {direction, objectMode, stdioItems},
	fileDescriptors,
	addProperties,
	options,
	isSync,
}) => {
	const finalStdioItems = stdioItems.map(stdioItem => addStreamProperties({
		stdioItem,
		addProperties,
		direction,
		options,
		fileDescriptors,
		isSync,
	}));
	return {direction, objectMode, stdioItems: finalStdioItems};
};

const addStreamProperties = ({stdioItem, addProperties, direction, options, fileDescriptors, isSync}) => {
	const duplicateStream = getDuplicateStream({
		stdioItem,
		direction,
		fileDescriptors,
		isSync,
	});

	if (duplicateStream !== undefined) {
		return {...stdioItem, stream: duplicateStream};
	}

	return {
		...stdioItem,
		...addProperties[direction][stdioItem.type](stdioItem, options),
	};
};

// The stream error handling is performed by the piping logic above, which cannot be performed before subprocess spawning.
// If the subprocess spawning fails (e.g. due to an invalid command), the streams need to be manually destroyed.
// We need to create those streams before subprocess spawning, in case their creation fails, e.g. when passing an invalid generator as argument.
// Like this, an exception would be thrown, which would prevent spawning a subprocess.
const cleanupCustomStreams = fileDescriptors => {
	for (const {stdioItems} of fileDescriptors) {
		for (const {stream} of stdioItems) {
			if (stream !== undefined && !isStandardStream(stream)) {
				stream.destroy();
			}
		}
	}
};

// When the `std*: Iterable | WebStream | URL | filePath`, `input` or `inputFile` option is used, we pipe to `subprocess.std*`.
// When the `std*: Array` option is used, we emulate some of the native values ('inherit', Node.js stream and file descriptor integer). To do so, we also need to pipe to `subprocess.std*`.
// Therefore the `std*` options must be either `pipe` or `overlapped`. Other values do not set `subprocess.std*`.
const forwardStdio = stdioItems => {
	if (stdioItems.length > 1) {
		return stdioItems.some(({value}) => value === 'overlapped') ? 'overlapped' : 'pipe';
	}

	const [{type, value}] = stdioItems;
	return type === 'native' ? value : 'pipe';
};

// Normalize `input`, `inputFile`, `stdin`, `stdout` and `stderr` options, before spawning, in sync mode
const handleStdioSync = (options, verboseInfo) => handleStdio(addPropertiesSync, options, verboseInfo, true);

const forbiddenIfSync = ({type, optionName}) => {
	throwInvalidSyncValue(optionName, TYPE_TO_MESSAGE[type]);
};

const forbiddenNativeIfSync = ({optionName, value}) => {
	if (value === 'ipc' || value === 'overlapped') {
		throwInvalidSyncValue(optionName, `"${value}"`);
	}

	return {};
};

const throwInvalidSyncValue = (optionName, value) => {
	throw new TypeError(`The \`${optionName}\` option cannot be ${value} with synchronous methods.`);
};

// Create streams used internally for redirecting when using specific values for the `std*` options, in sync mode.
// For example, `stdin: {file}` reads the file synchronously, then passes it as the `input` option.
const addProperties$1 = {
	generator() {},
	asyncGenerator: forbiddenIfSync,
	webStream: forbiddenIfSync,
	nodeStream: forbiddenIfSync,
	webTransform: forbiddenIfSync,
	duplex: forbiddenIfSync,
	asyncIterable: forbiddenIfSync,
	native: forbiddenNativeIfSync,
};

const addPropertiesSync = {
	input: {
		...addProperties$1,
		fileUrl: ({value}) => ({contents: [bufferToUint8Array(readFileSync(value))]}),
		filePath: ({value: {file}}) => ({contents: [bufferToUint8Array(readFileSync(file))]}),
		fileNumber: forbiddenIfSync,
		iterable: ({value}) => ({contents: [...value]}),
		string: ({value}) => ({contents: [value]}),
		uint8Array: ({value}) => ({contents: [value]}),
	},
	output: {
		...addProperties$1,
		fileUrl: ({value}) => ({path: value}),
		filePath: ({value: {file, append}}) => ({path: file, append}),
		fileNumber: ({value}) => ({path: value}),
		iterable: forbiddenIfSync,
		string: forbiddenIfSync,
		uint8Array: forbiddenIfSync,
	},
};

// Apply `stripFinalNewline` option, which applies to `result.stdout|stderr|all|stdio[*]`.
// If the `lines` option is used, it is applied on each line, but using a different function.
const stripNewline = (value, {stripFinalNewline: stripFinalNewline$1}, fdNumber) => getStripFinalNewline(stripFinalNewline$1, fdNumber) && value !== undefined && !Array.isArray(value)
	? stripFinalNewline(value)
	: value;

// Retrieve `stripFinalNewline` option value, including with `subprocess.all`
const getStripFinalNewline = (stripFinalNewline, fdNumber) => fdNumber === 'all'
	? stripFinalNewline[1] || stripFinalNewline[2]
	: stripFinalNewline[fdNumber];

// Split chunks line-wise for generators passed to the `std*` options
const getSplitLinesGenerator = (binary, preserveNewlines, skipped, state) => binary || skipped
	? undefined
	: initializeSplitLines(preserveNewlines, state);

// Same but for synchronous methods
const splitLinesSync = (chunk, preserveNewlines, objectMode) => objectMode
	? chunk.flatMap(item => splitLinesItemSync(item, preserveNewlines))
	: splitLinesItemSync(chunk, preserveNewlines);

const splitLinesItemSync = (chunk, preserveNewlines) => {
	const {transform, final} = initializeSplitLines(preserveNewlines, {});
	return [...transform(chunk), ...final()];
};

const initializeSplitLines = (preserveNewlines, state) => {
	state.previousChunks = '';
	return {
		transform: splitGenerator.bind(undefined, state, preserveNewlines),
		final: linesFinal.bind(undefined, state),
	};
};

// This imperative logic is much faster than using `String.split()` and uses very low memory.
const splitGenerator = function * (state, preserveNewlines, chunk) {
	if (typeof chunk !== 'string') {
		yield chunk;
		return;
	}

	let {previousChunks} = state;
	let start = -1;

	for (let end = 0; end < chunk.length; end += 1) {
		if (chunk[end] === '\n') {
			const newlineLength = getNewlineLength(chunk, end, preserveNewlines, state);
			let line = chunk.slice(start + 1, end + 1 - newlineLength);

			if (previousChunks.length > 0) {
				line = concatString(previousChunks, line);
				previousChunks = '';
			}

			yield line;
			start = end;
		}
	}

	if (start !== chunk.length - 1) {
		previousChunks = concatString(previousChunks, chunk.slice(start + 1));
	}

	state.previousChunks = previousChunks;
};

const getNewlineLength = (chunk, end, preserveNewlines, state) => {
	if (preserveNewlines) {
		return 0;
	}

	state.isWindowsNewline = end !== 0 && chunk[end - 1] === '\r';
	return state.isWindowsNewline ? 2 : 1;
};

const linesFinal = function * ({previousChunks}) {
	if (previousChunks.length > 0) {
		yield previousChunks;
	}
};

// Unless `preserveNewlines: true` is used, we strip the newline of each line.
// This re-adds them after the user `transform` code has run.
const getAppendNewlineGenerator = ({binary, preserveNewlines, readableObjectMode, state}) => binary || preserveNewlines || readableObjectMode
	? undefined
	: {transform: appendNewlineGenerator.bind(undefined, state)};

const appendNewlineGenerator = function * ({isWindowsNewline = false}, chunk) {
	const {unixNewline, windowsNewline, LF, concatBytes} = typeof chunk === 'string' ? linesStringInfo : linesUint8ArrayInfo;

	if (chunk.at(-1) === LF) {
		yield chunk;
		return;
	}

	const newline = isWindowsNewline ? windowsNewline : unixNewline;
	yield concatBytes(chunk, newline);
};

const concatString = (firstChunk, secondChunk) => `${firstChunk}${secondChunk}`;

const linesStringInfo = {
	windowsNewline: '\r\n',
	unixNewline: '\n',
	LF: '\n',
	concatBytes: concatString,
};

const concatUint8Array = (firstChunk, secondChunk) => {
	const chunk = new Uint8Array(firstChunk.length + secondChunk.length);
	chunk.set(firstChunk, 0);
	chunk.set(secondChunk, firstChunk.length);
	return chunk;
};

const linesUint8ArrayInfo = {
	windowsNewline: new Uint8Array([0x0D, 0x0A]),
	unixNewline: new Uint8Array([0x0A]),
	LF: 0x0A,
	concatBytes: concatUint8Array,
};

// Validate the type of chunk argument passed to transform generators
const getValidateTransformInput = (writableObjectMode, optionName) => writableObjectMode
	? undefined
	: validateStringTransformInput.bind(undefined, optionName);

const validateStringTransformInput = function * (optionName, chunk) {
	if (typeof chunk !== 'string' && !isUint8Array(chunk) && !Buffer$1.isBuffer(chunk)) {
		throw new TypeError(`The \`${optionName}\` option's transform must use "objectMode: true" to receive as input: ${typeof chunk}.`);
	}

	yield chunk;
};

// Validate the type of the value returned by transform generators
const getValidateTransformReturn = (readableObjectMode, optionName) => readableObjectMode
	? validateObjectTransformReturn.bind(undefined, optionName)
	: validateStringTransformReturn.bind(undefined, optionName);

const validateObjectTransformReturn = function * (optionName, chunk) {
	validateEmptyReturn(optionName, chunk);
	yield chunk;
};

const validateStringTransformReturn = function * (optionName, chunk) {
	validateEmptyReturn(optionName, chunk);

	if (typeof chunk !== 'string' && !isUint8Array(chunk)) {
		throw new TypeError(`The \`${optionName}\` option's function must yield a string or an Uint8Array, not ${typeof chunk}.`);
	}

	yield chunk;
};

const validateEmptyReturn = (optionName, chunk) => {
	if (chunk === null || chunk === undefined) {
		throw new TypeError(`The \`${optionName}\` option's function must not call \`yield ${chunk}\`.
Instead, \`yield\` should either be called with a value, or not be called at all. For example:
  if (condition) { yield value; }`);
	}
};

/*
When using binary encodings, add an internal generator that converts chunks from `Buffer` to `string` or `Uint8Array`.
Chunks might be Buffer, Uint8Array or strings since:
- `subprocess.stdout|stderr` emits Buffers
- `subprocess.stdin.write()` accepts Buffer, Uint8Array or string
- Previous generators might return Uint8Array or string

However, those are converted to Buffer:
- on writes: `Duplex.writable` `decodeStrings: true` default option
- on reads: `Duplex.readable` `readableEncoding: null` default option
*/
const getEncodingTransformGenerator = (binary, encoding, skipped) => {
	if (skipped) {
		return;
	}

	if (binary) {
		return {transform: encodingUint8ArrayGenerator.bind(undefined, new TextEncoder())};
	}

	const stringDecoder = new StringDecoder(encoding);
	return {
		transform: encodingStringGenerator.bind(undefined, stringDecoder),
		final: encodingStringFinal.bind(undefined, stringDecoder),
	};
};

const encodingUint8ArrayGenerator = function * (textEncoder, chunk) {
	if (Buffer$1.isBuffer(chunk)) {
		yield bufferToUint8Array(chunk);
	} else if (typeof chunk === 'string') {
		yield textEncoder.encode(chunk);
	} else {
		yield chunk;
	}
};

const encodingStringGenerator = function * (stringDecoder, chunk) {
	yield isUint8Array(chunk) ? stringDecoder.write(chunk) : chunk;
};

const encodingStringFinal = function * (stringDecoder) {
	const lastChunk = stringDecoder.end();
	if (lastChunk !== '') {
		yield lastChunk;
	}
};

// Applies a series of generator functions asynchronously
const pushChunks = callbackify(async (getChunks, state, getChunksArguments, transformStream) => {
	state.currentIterable = getChunks(...getChunksArguments);

	try {
		for await (const chunk of state.currentIterable) {
			transformStream.push(chunk);
		}
	} finally {
		delete state.currentIterable;
	}
});

// For each new chunk, apply each `transform()` method
const transformChunk = async function * (chunk, generators, index) {
	if (index === generators.length) {
		yield chunk;
		return;
	}

	const {transform = identityGenerator$1} = generators[index];
	for await (const transformedChunk of transform(chunk)) {
		yield * transformChunk(transformedChunk, generators, index + 1);
	}
};

// At the end, apply each `final()` method, followed by the `transform()` method of the next transforms
const finalChunks = async function * (generators) {
	for (const [index, {final}] of Object.entries(generators)) {
		yield * generatorFinalChunks(final, Number(index), generators);
	}
};

const generatorFinalChunks = async function * (final, index, generators) {
	if (final === undefined) {
		return;
	}

	for await (const finalChunk of final()) {
		yield * transformChunk(finalChunk, generators, index + 1);
	}
};

// Cancel any ongoing async generator when the Transform is destroyed, e.g. when the subprocess errors
const destroyTransform = callbackify(async ({currentIterable}, error) => {
	if (currentIterable !== undefined) {
		await (error ? currentIterable.throw(error) : currentIterable.return());
		return;
	}

	if (error) {
		throw error;
	}
});

const identityGenerator$1 = function * (chunk) {
	yield chunk;
};

// Duplicate the code from `run-async.js` but as synchronous functions
const pushChunksSync = (getChunksSync, getChunksArguments, transformStream, done) => {
	try {
		for (const chunk of getChunksSync(...getChunksArguments)) {
			transformStream.push(chunk);
		}

		done();
	} catch (error) {
		done(error);
	}
};

// Run synchronous generators with `execaSync()`
const runTransformSync = (generators, chunks) => [
	...chunks.flatMap(chunk => [...transformChunkSync(chunk, generators, 0)]),
	...finalChunksSync(generators),
];

const transformChunkSync = function * (chunk, generators, index) {
	if (index === generators.length) {
		yield chunk;
		return;
	}

	const {transform = identityGenerator} = generators[index];
	for (const transformedChunk of transform(chunk)) {
		yield * transformChunkSync(transformedChunk, generators, index + 1);
	}
};

const finalChunksSync = function * (generators) {
	for (const [index, {final}] of Object.entries(generators)) {
		yield * generatorFinalChunksSync(final, Number(index), generators);
	}
};

const generatorFinalChunksSync = function * (final, index, generators) {
	if (final === undefined) {
		return;
	}

	for (const finalChunk of final()) {
		yield * transformChunkSync(finalChunk, generators, index + 1);
	}
};

const identityGenerator = function * (chunk) {
	yield chunk;
};

/*
Generators can be used to transform/filter standard streams.

Generators have a simple syntax, yet allows all of the following:
- Sharing `state` between chunks
- Flushing logic, by using a `final` function
- Asynchronous logic
- Emitting multiple chunks from a single source chunk, even if spaced in time, by using multiple `yield`
- Filtering, by using no `yield`

Therefore, there is no need to allow Node.js or web transform streams.

The `highWaterMark` is kept as the default value, since this is what `subprocess.std*` uses.

Chunks are currently processed serially. We could add a `concurrency` option to parallelize in the future.

Transform an array of generator functions into a `Transform` stream.
`Duplex.from(generator)` cannot be used because it does not allow setting the `objectMode` and `highWaterMark`.
*/
const generatorToStream = ({
	value,
	value: {transform, final, writableObjectMode, readableObjectMode},
	optionName,
}, {encoding}) => {
	const state = {};
	const generators = addInternalGenerators(value, encoding, optionName);

	const transformAsync = isAsyncGenerator(transform);
	const finalAsync = isAsyncGenerator(final);
	const transformMethod = transformAsync
		? pushChunks.bind(undefined, transformChunk, state)
		: pushChunksSync.bind(undefined, transformChunkSync);
	const finalMethod = transformAsync || finalAsync
		? pushChunks.bind(undefined, finalChunks, state)
		: pushChunksSync.bind(undefined, finalChunksSync);
	const destroyMethod = transformAsync || finalAsync
		? destroyTransform.bind(undefined, state)
		: undefined;

	const stream = new Transform({
		writableObjectMode,
		writableHighWaterMark: getDefaultHighWaterMark(writableObjectMode),
		readableObjectMode,
		readableHighWaterMark: getDefaultHighWaterMark(readableObjectMode),
		transform(chunk, encoding, done) {
			transformMethod([chunk, generators, 0], this, done);
		},
		flush(done) {
			finalMethod([generators], this, done);
		},
		destroy: destroyMethod,
	});
	return {stream};
};

// Applies transform generators in sync mode
const runGeneratorsSync = (chunks, stdioItems, encoding, isInput) => {
	const generators = stdioItems.filter(({type}) => type === 'generator');
	const reversedGenerators = isInput ? generators.reverse() : generators;

	for (const {value, optionName} of reversedGenerators) {
		const generators = addInternalGenerators(value, encoding, optionName);
		chunks = runTransformSync(generators, chunks);
	}

	return chunks;
};

// Generators used internally to convert the chunk type, validate it, and split into lines
const addInternalGenerators = (
	{transform, final, binary, writableObjectMode, readableObjectMode, preserveNewlines},
	encoding,
	optionName,
) => {
	const state = {};
	return [
		{transform: getValidateTransformInput(writableObjectMode, optionName)},
		getEncodingTransformGenerator(binary, encoding, writableObjectMode),
		getSplitLinesGenerator(binary, preserveNewlines, writableObjectMode, state),
		{transform, final},
		{transform: getValidateTransformReturn(readableObjectMode, optionName)},
		getAppendNewlineGenerator({
			binary,
			preserveNewlines,
			readableObjectMode,
			state,
		}),
	].filter(Boolean);
};

// Apply `stdin`/`input`/`inputFile` options, before spawning, in sync mode, by converting it to the `input` option
const addInputOptionsSync = (fileDescriptors, options) => {
	for (const fdNumber of getInputFdNumbers(fileDescriptors)) {
		addInputOptionSync(fileDescriptors, fdNumber, options);
	}
};

const getInputFdNumbers = fileDescriptors => new Set(Object.entries(fileDescriptors)
	.filter(([, {direction}]) => direction === 'input')
	.map(([fdNumber]) => Number(fdNumber)));

const addInputOptionSync = (fileDescriptors, fdNumber, options) => {
	const {stdioItems} = fileDescriptors[fdNumber];
	const allStdioItems = stdioItems.filter(({contents}) => contents !== undefined);
	if (allStdioItems.length === 0) {
		return;
	}

	if (fdNumber !== 0) {
		const [{type, optionName}] = allStdioItems;
		throw new TypeError(`Only the \`stdin\` option, not \`${optionName}\`, can be ${TYPE_TO_MESSAGE[type]} with synchronous methods.`);
	}

	const allContents = allStdioItems.map(({contents}) => contents);
	const transformedContents = allContents.map(contents => applySingleInputGeneratorsSync(contents, stdioItems));
	options.input = joinToUint8Array(transformedContents);
};

const applySingleInputGeneratorsSync = (contents, stdioItems) => {
	const newContents = runGeneratorsSync(contents, stdioItems, 'utf8', true);
	validateSerializable(newContents);
	return joinToUint8Array(newContents);
};

const validateSerializable = newContents => {
	const invalidItem = newContents.find(item => typeof item !== 'string' && !isUint8Array(item));
	if (invalidItem !== undefined) {
		throw new TypeError(`The \`stdin\` option is invalid: when passing objects as input, a transform must be used to serialize them to strings or Uint8Arrays: ${invalidItem}.`);
	}
};

// `ignore` opts-out of `verbose` for a specific stream.
// `ipc` cannot use piping.
// `inherit` would result in double printing.
// They can also lead to double printing when passing file descriptor integers or `process.std*`.
// This only leaves with `pipe` and `overlapped`.
const shouldLogOutput = ({stdioItems, encoding, verboseInfo, fdNumber}) => fdNumber !== 'all'
	&& isFullVerbose(verboseInfo, fdNumber)
	&& !BINARY_ENCODINGS.has(encoding)
	&& fdUsesVerbose(fdNumber)
	&& (stdioItems.some(({type, value}) => type === 'native' && PIPED_STDIO_VALUES.has(value))
	|| stdioItems.every(({type}) => TRANSFORM_TYPES.has(type)));

// Printing input streams would be confusing.
// Files and streams can produce big outputs, which we don't want to print.
// We could print `stdio[3+]` but it often is redirected to files and streams, with the same issue.
// So we only print stdout and stderr.
const fdUsesVerbose = fdNumber => fdNumber === 1 || fdNumber === 2;

const PIPED_STDIO_VALUES = new Set(['pipe', 'overlapped']);

// `verbose: 'full'` printing logic with async methods
const logLines = async (linesIterable, stream, fdNumber, verboseInfo) => {
	for await (const line of linesIterable) {
		if (!isPipingStream(stream)) {
			logLine(line, fdNumber, verboseInfo);
		}
	}
};

// `verbose: 'full'` printing logic with sync methods
const logLinesSync = (linesArray, fdNumber, verboseInfo) => {
	for (const line of linesArray) {
		logLine(line, fdNumber, verboseInfo);
	}
};

// When `subprocess.stdout|stderr.pipe()` is called, `verbose` becomes a noop.
// This prevents the following problems:
//  - `.pipe()` achieves the same result as using `stdout: 'inherit'`, `stdout: stream`, etc. which also make `verbose` a noop.
//    For example, `subprocess.stdout.pipe(process.stdin)` would print each line twice.
//  - When chaining subprocesses with `subprocess.pipe(otherSubprocess)`, only the last one should print its output.
// Detecting whether `.pipe()` is impossible without monkey-patching it, so we use the following undocumented property.
// This is not a critical behavior since changes of the following property would only make `verbose` more verbose.
const isPipingStream = stream => stream._readableState.pipes.length > 0;

// When `verbose` is `full`, print stdout|stderr
const logLine = (line, fdNumber, verboseInfo) => {
	const verboseMessage = serializeVerboseMessage(line);
	verboseLog({
		type: 'output',
		verboseMessage,
		fdNumber,
		verboseInfo,
	});
};

// Apply `stdout`/`stderr` options, after spawning, in sync mode
const transformOutputSync = ({fileDescriptors, syncResult: {output}, options, isMaxBuffer, verboseInfo}) => {
	if (output === null) {
		return {output: Array.from({length: 3})};
	}

	const state = {};
	const outputFiles = new Set([]);
	const transformedOutput = output.map((result, fdNumber) =>
		transformOutputResultSync({
			result,
			fileDescriptors,
			fdNumber,
			state,
			outputFiles,
			isMaxBuffer,
			verboseInfo,
		}, options));
	return {output: transformedOutput, ...state};
};

const transformOutputResultSync = (
	{result, fileDescriptors, fdNumber, state, outputFiles, isMaxBuffer, verboseInfo},
	{buffer, encoding, lines, stripFinalNewline, maxBuffer},
) => {
	if (result === null) {
		return;
	}

	const truncatedResult = truncateMaxBufferSync(result, isMaxBuffer, maxBuffer);
	const uint8ArrayResult = bufferToUint8Array(truncatedResult);
	const {stdioItems, objectMode} = fileDescriptors[fdNumber];
	const chunks = runOutputGeneratorsSync([uint8ArrayResult], stdioItems, encoding, state);
	const {serializedResult, finalResult = serializedResult} = serializeChunks({
		chunks,
		objectMode,
		encoding,
		lines,
		stripFinalNewline,
		fdNumber,
	});

	logOutputSync({
		serializedResult,
		fdNumber,
		state,
		verboseInfo,
		encoding,
		stdioItems,
		objectMode,
	});

	const returnedResult = buffer[fdNumber] ? finalResult : undefined;

	try {
		if (state.error === undefined) {
			writeToFiles(serializedResult, stdioItems, outputFiles);
		}

		return returnedResult;
	} catch (error) {
		state.error = error;
		return returnedResult;
	}
};

// Applies transform generators to `stdout`/`stderr`
const runOutputGeneratorsSync = (chunks, stdioItems, encoding, state) => {
	try {
		return runGeneratorsSync(chunks, stdioItems, encoding, false);
	} catch (error) {
		state.error = error;
		return chunks;
	}
};

// The contents is converted to three stages:
//  - serializedResult: used when the target is a file path/URL or a file descriptor (including 'inherit')
//  - finalResult/returnedResult: returned as `result.std*`
const serializeChunks = ({chunks, objectMode, encoding, lines, stripFinalNewline, fdNumber}) => {
	if (objectMode) {
		return {serializedResult: chunks};
	}

	if (encoding === 'buffer') {
		return {serializedResult: joinToUint8Array(chunks)};
	}

	const serializedResult = joinToString(chunks, encoding);
	if (lines[fdNumber]) {
		return {serializedResult, finalResult: splitLinesSync(serializedResult, !stripFinalNewline[fdNumber], objectMode)};
	}

	return {serializedResult};
};

const logOutputSync = ({serializedResult, fdNumber, state, verboseInfo, encoding, stdioItems, objectMode}) => {
	if (!shouldLogOutput({
		stdioItems,
		encoding,
		verboseInfo,
		fdNumber,
	})) {
		return;
	}

	const linesArray = splitLinesSync(serializedResult, false, objectMode);

	try {
		logLinesSync(linesArray, fdNumber, verboseInfo);
	} catch (error) {
		state.error ??= error;
	}
};

// When the `std*` target is a file path/URL or a file descriptor
const writeToFiles = (serializedResult, stdioItems, outputFiles) => {
	for (const {path, append} of stdioItems.filter(({type}) => FILE_TYPES.has(type))) {
		const pathString = typeof path === 'string' ? path : path.toString();
		if (append || outputFiles.has(pathString)) {
			appendFileSync(path, serializedResult);
		} else {
			outputFiles.add(pathString);
			writeFileSync(path, serializedResult);
		}
	}
};

// Retrieve `result.all` with synchronous methods
const getAllSync = ([, stdout, stderr], options) => {
	if (!options.all) {
		return;
	}

	if (stdout === undefined) {
		return stderr;
	}

	if (stderr === undefined) {
		return stdout;
	}

	if (Array.isArray(stdout)) {
		return Array.isArray(stderr)
			? [...stdout, ...stderr]
			: [...stdout, stripNewline(stderr, options, 'all')];
	}

	if (Array.isArray(stderr)) {
		return [stripNewline(stdout, options, 'all'), ...stderr];
	}

	if (isUint8Array(stdout) && isUint8Array(stderr)) {
		return concatUint8Arrays([stdout, stderr]);
	}

	return `${stdout}${stderr}`;
};

// If `error` is emitted before `spawn`, `exit` will never be emitted.
// However, `error` might be emitted after `spawn`.
// In that case, `exit` will still be emitted.
// Since the `exit` event contains the signal name, we want to make sure we are listening for it.
// This function also takes into account the following unlikely cases:
//  - `exit` being emitted in the same microtask as `spawn`
//  - `error` being emitted multiple times
const waitForExit = async (subprocess, context) => {
	const [exitCode, signal] = await waitForExitOrError(subprocess);
	context.isForcefullyTerminated ??= false;
	return [exitCode, signal];
};

const waitForExitOrError = async subprocess => {
	const [spawnPayload, exitPayload] = await Promise.allSettled([
		once$2(subprocess, 'spawn'),
		once$2(subprocess, 'exit'),
	]);

	if (spawnPayload.status === 'rejected') {
		return [];
	}

	return exitPayload.status === 'rejected'
		? waitForSubprocessExit(subprocess)
		: exitPayload.value;
};

const waitForSubprocessExit = async subprocess => {
	try {
		return await once$2(subprocess, 'exit');
	} catch {
		return waitForSubprocessExit(subprocess);
	}
};

// Retrieve the final exit code and|or signal name
const waitForSuccessfulExit = async exitPromise => {
	const [exitCode, signal] = await exitPromise;

	if (!isSubprocessErrorExit(exitCode, signal) && isFailedExit(exitCode, signal)) {
		throw new DiscardedError();
	}

	return [exitCode, signal];
};

// When the subprocess fails due to an `error` event
const isSubprocessErrorExit = (exitCode, signal) => exitCode === undefined && signal === undefined;
// When the subprocess fails due to a non-0 exit code or to a signal termination
const isFailedExit = (exitCode, signal) => exitCode !== 0 || signal !== null;

// Retrieve exit code, signal name and error information, with synchronous methods
const getExitResultSync = ({error, status: exitCode, signal, output}, {maxBuffer}) => {
	const resultError = getResultError(error, exitCode, signal);
	const timedOut = resultError?.code === 'ETIMEDOUT';
	const isMaxBuffer = isMaxBufferSync(resultError, output, maxBuffer);
	return {
		resultError,
		exitCode,
		signal,
		timedOut,
		isMaxBuffer,
	};
};

const getResultError = (error, exitCode, signal) => {
	if (error !== undefined) {
		return error;
	}

	return isFailedExit(exitCode, signal) ? new DiscardedError() : undefined;
};

// Main shared logic for all sync methods: `execaSync()`, `$.sync()`
const execaCoreSync = (rawFile, rawArguments, rawOptions) => {
	const {file, commandArguments, command, escapedCommand, startTime, verboseInfo, options, fileDescriptors} = handleSyncArguments(rawFile, rawArguments, rawOptions);
	const result = spawnSubprocessSync({
		file,
		commandArguments,
		options,
		command,
		escapedCommand,
		verboseInfo,
		fileDescriptors,
		startTime,
	});
	return handleResult(result, verboseInfo, options);
};

// Compute arguments to pass to `child_process.spawnSync()`
const handleSyncArguments = (rawFile, rawArguments, rawOptions) => {
	const {command, escapedCommand, startTime, verboseInfo} = handleCommand(rawFile, rawArguments, rawOptions);
	const syncOptions = normalizeSyncOptions(rawOptions);
	const {file, commandArguments, options} = normalizeOptions(rawFile, rawArguments, syncOptions);
	validateSyncOptions(options);
	const fileDescriptors = handleStdioSync(options, verboseInfo);
	return {
		file,
		commandArguments,
		command,
		escapedCommand,
		startTime,
		verboseInfo,
		options,
		fileDescriptors,
	};
};

// Options normalization logic specific to sync methods
const normalizeSyncOptions = options => options.node && !options.ipc ? {...options, ipc: false} : options;

// Options validation logic specific to sync methods
const validateSyncOptions = ({ipc, ipcInput, detached, cancelSignal}) => {
	if (ipcInput) {
		throwInvalidSyncOption('ipcInput');
	}

	if (ipc) {
		throwInvalidSyncOption('ipc: true');
	}

	if (detached) {
		throwInvalidSyncOption('detached: true');
	}

	if (cancelSignal) {
		throwInvalidSyncOption('cancelSignal');
	}
};

const throwInvalidSyncOption = value => {
	throw new TypeError(`The "${value}" option cannot be used with synchronous methods.`);
};

const spawnSubprocessSync = ({file, commandArguments, options, command, escapedCommand, verboseInfo, fileDescriptors, startTime}) => {
	const syncResult = runSubprocessSync({
		file,
		commandArguments,
		options,
		command,
		escapedCommand,
		fileDescriptors,
		startTime,
	});
	if (syncResult.failed) {
		return syncResult;
	}

	const {resultError, exitCode, signal, timedOut, isMaxBuffer} = getExitResultSync(syncResult, options);
	const {output, error = resultError} = transformOutputSync({
		fileDescriptors,
		syncResult,
		options,
		isMaxBuffer,
		verboseInfo,
	});
	const stdio = output.map((stdioOutput, fdNumber) => stripNewline(stdioOutput, options, fdNumber));
	const all = stripNewline(getAllSync(output, options), options, 'all');
	return getSyncResult({
		error,
		exitCode,
		signal,
		timedOut,
		isMaxBuffer,
		stdio,
		all,
		options,
		command,
		escapedCommand,
		startTime,
	});
};

const runSubprocessSync = ({file, commandArguments, options, command, escapedCommand, fileDescriptors, startTime}) => {
	try {
		addInputOptionsSync(fileDescriptors, options);
		const normalizedOptions = normalizeSpawnSyncOptions(options);
		return spawnSync(...concatenateShell(file, commandArguments, normalizedOptions));
	} catch (error) {
		return makeEarlyError({
			error,
			command,
			escapedCommand,
			fileDescriptors,
			options,
			startTime,
			isSync: true,
		});
	}
};

// The `encoding` option is handled by Execa, not by `child_process.spawnSync()`
const normalizeSpawnSyncOptions = ({encoding, maxBuffer, ...options}) => ({...options, encoding: 'buffer', maxBuffer: getMaxBufferSync(maxBuffer)});

const getSyncResult = ({error, exitCode, signal, timedOut, isMaxBuffer, stdio, all, options, command, escapedCommand, startTime}) => error === undefined
	? makeSuccessResult({
		command,
		escapedCommand,
		stdio,
		all,
		ipcOutput: [],
		options,
		startTime,
	})
	: makeError({
		error,
		command,
		escapedCommand,
		timedOut,
		isCanceled: false,
		isGracefullyCanceled: false,
		isMaxBuffer,
		isForcefullyTerminated: false,
		exitCode,
		signal,
		stdio,
		all,
		ipcOutput: [],
		options,
		startTime,
		isSync: true,
	});

// Like `[sub]process.once('message')` but promise-based
const getOneMessage = ({anyProcess, channel, isSubprocess, ipc}, {reference = true, filter} = {}) => {
	validateIpcMethod({
		methodName: 'getOneMessage',
		isSubprocess,
		ipc,
		isConnected: isConnected(anyProcess),
	});

	return getOneMessageAsync({
		anyProcess,
		channel,
		isSubprocess,
		filter,
		reference,
	});
};

const getOneMessageAsync = async ({anyProcess, channel, isSubprocess, filter, reference}) => {
	addReference(channel, reference);
	const ipcEmitter = getIpcEmitter(anyProcess, channel, isSubprocess);
	const controller = new AbortController();
	try {
		return await Promise.race([
			getMessage(ipcEmitter, filter, controller),
			throwOnDisconnect(ipcEmitter, isSubprocess, controller),
			throwOnStrictError(ipcEmitter, isSubprocess, controller),
		]);
	} catch (error) {
		disconnect(anyProcess);
		throw error;
	} finally {
		controller.abort();
		removeReference(channel, reference);
	}
};

const getMessage = async (ipcEmitter, filter, {signal}) => {
	if (filter === undefined) {
		const [message] = await once$2(ipcEmitter, 'message', {signal});
		return message;
	}

	for await (const [message] of on(ipcEmitter, 'message', {signal})) {
		if (filter(message)) {
			return message;
		}
	}
};

const throwOnDisconnect = async (ipcEmitter, isSubprocess, {signal}) => {
	await once$2(ipcEmitter, 'disconnect', {signal});
	throwOnEarlyDisconnect(isSubprocess);
};

const throwOnStrictError = async (ipcEmitter, isSubprocess, {signal}) => {
	const [error] = await once$2(ipcEmitter, 'strict:error', {signal});
	throw getStrictResponseError(error, isSubprocess);
};

// Like `[sub]process.on('message')` but promise-based
const getEachMessage = ({anyProcess, channel, isSubprocess, ipc}, {reference = true} = {}) => loopOnMessages({
	anyProcess,
	channel,
	isSubprocess,
	ipc,
	shouldAwait: !isSubprocess,
	reference,
});

// Same but used internally
const loopOnMessages = ({anyProcess, channel, isSubprocess, ipc, shouldAwait, reference}) => {
	validateIpcMethod({
		methodName: 'getEachMessage',
		isSubprocess,
		ipc,
		isConnected: isConnected(anyProcess),
	});

	addReference(channel, reference);
	const ipcEmitter = getIpcEmitter(anyProcess, channel, isSubprocess);
	const controller = new AbortController();
	const state = {};
	stopOnDisconnect(anyProcess, ipcEmitter, controller);
	abortOnStrictError({
		ipcEmitter,
		isSubprocess,
		controller,
		state,
	});
	return iterateOnMessages({
		anyProcess,
		channel,
		ipcEmitter,
		isSubprocess,
		shouldAwait,
		controller,
		state,
		reference,
	});
};

const stopOnDisconnect = async (anyProcess, ipcEmitter, controller) => {
	try {
		await once$2(ipcEmitter, 'disconnect', {signal: controller.signal});
		controller.abort();
	} catch {}
};

const abortOnStrictError = async ({ipcEmitter, isSubprocess, controller, state}) => {
	try {
		const [error] = await once$2(ipcEmitter, 'strict:error', {signal: controller.signal});
		state.error = getStrictResponseError(error, isSubprocess);
		controller.abort();
	} catch {}
};

const iterateOnMessages = async function * ({anyProcess, channel, ipcEmitter, isSubprocess, shouldAwait, controller, state, reference}) {
	try {
		for await (const [message] of on(ipcEmitter, 'message', {signal: controller.signal})) {
			throwIfStrictError(state);
			yield message;
		}
	} catch {
		throwIfStrictError(state);
	} finally {
		controller.abort();
		removeReference(channel, reference);

		if (!isSubprocess) {
			disconnect(anyProcess);
		}

		if (shouldAwait) {
			await anyProcess;
		}
	}
};

const throwIfStrictError = ({error}) => {
	if (error) {
		throw error;
	}
};

// Add promise-based IPC methods in current process
const addIpcMethods = (subprocess, {ipc}) => {
	Object.assign(subprocess, getIpcMethods(subprocess, false, ipc));
};

// Get promise-based IPC in the subprocess
const getIpcExport = () => {
	const anyProcess = process$2;
	const isSubprocess = true;
	const ipc = process$2.channel !== undefined;

	return {
		...getIpcMethods(anyProcess, isSubprocess, ipc),
		getCancelSignal: getCancelSignal.bind(undefined, {
			anyProcess,
			channel: anyProcess.channel,
			isSubprocess,
			ipc,
		}),
	};
};

// Retrieve the `ipc` shared by both the current process and the subprocess
const getIpcMethods = (anyProcess, isSubprocess, ipc) => ({
	sendMessage: sendMessage.bind(undefined, {
		anyProcess,
		channel: anyProcess.channel,
		isSubprocess,
		ipc,
	}),
	getOneMessage: getOneMessage.bind(undefined, {
		anyProcess,
		channel: anyProcess.channel,
		isSubprocess,
		ipc,
	}),
	getEachMessage: getEachMessage.bind(undefined, {
		anyProcess,
		channel: anyProcess.channel,
		isSubprocess,
		ipc,
	}),
});

// When the subprocess fails to spawn.
// We ensure the returned error is always both a promise and a subprocess.
const handleEarlyError = ({error, command, escapedCommand, fileDescriptors, options, startTime, verboseInfo}) => {
	cleanupCustomStreams(fileDescriptors);

	const subprocess = new ChildProcess();
	createDummyStreams(subprocess, fileDescriptors);
	Object.assign(subprocess, {readable: readable$1, writable, duplex});

	const earlyError = makeEarlyError({
		error,
		command,
		escapedCommand,
		fileDescriptors,
		options,
		startTime,
		isSync: false,
	});
	const promise = handleDummyPromise(earlyError, verboseInfo, options);
	return {subprocess, promise};
};

const createDummyStreams = (subprocess, fileDescriptors) => {
	const stdin = createDummyStream();
	const stdout = createDummyStream();
	const stderr = createDummyStream();
	const extraStdio = Array.from({length: fileDescriptors.length - 3}, createDummyStream);
	const all = createDummyStream();
	const stdio = [stdin, stdout, stderr, ...extraStdio];
	Object.assign(subprocess, {
		stdin,
		stdout,
		stderr,
		all,
		stdio,
	});
};

const createDummyStream = () => {
	const stream = new PassThrough();
	stream.end();
	return stream;
};

const readable$1 = () => new Readable({read() {}});
const writable = () => new Writable({write() {}});
const duplex = () => new Duplex({read() {}, write() {}});

const handleDummyPromise = async (error, verboseInfo, options) => handleResult(error, verboseInfo, options);

// Handle `input`, `inputFile`, `stdin`, `stdout` and `stderr` options, before spawning, in async mode
const handleStdioAsync = (options, verboseInfo) => handleStdio(addPropertiesAsync, options, verboseInfo, false);

const forbiddenIfAsync = ({type, optionName}) => {
	throw new TypeError(`The \`${optionName}\` option cannot be ${TYPE_TO_MESSAGE[type]}.`);
};

// Create streams used internally for piping when using specific values for the `std*` options, in async mode.
// For example, `stdout: {file}` creates a file stream, which is piped from/to.
const addProperties = {
	fileNumber: forbiddenIfAsync,
	generator: generatorToStream,
	asyncGenerator: generatorToStream,
	nodeStream: ({value}) => ({stream: value}),
	webTransform({value: {transform, writableObjectMode, readableObjectMode}}) {
		const objectMode = writableObjectMode || readableObjectMode;
		const stream = Duplex.fromWeb(transform, {objectMode});
		return {stream};
	},
	duplex: ({value: {transform}}) => ({stream: transform}),
	native() {},
};

const addPropertiesAsync = {
	input: {
		...addProperties,
		fileUrl: ({value}) => ({stream: createReadStream(value)}),
		filePath: ({value: {file}}) => ({stream: createReadStream(file)}),
		webStream: ({value}) => ({stream: Readable.fromWeb(value)}),
		iterable: ({value}) => ({stream: Readable.from(value)}),
		asyncIterable: ({value}) => ({stream: Readable.from(value)}),
		string: ({value}) => ({stream: Readable.from(value)}),
		uint8Array: ({value}) => ({stream: Readable.from(Buffer$1.from(value))}),
	},
	output: {
		...addProperties,
		fileUrl: ({value}) => ({stream: createWriteStream(value)}),
		filePath: ({value: {file, append}}) => ({stream: createWriteStream(file, append ? {flags: 'a'} : {})}),
		webStream: ({value}) => ({stream: Writable.fromWeb(value)}),
		iterable: forbiddenIfAsync,
		asyncIterable: forbiddenIfAsync,
		string: forbiddenIfAsync,
		uint8Array: forbiddenIfAsync,
	},
};

function mergeStreams(streams) {
	if (!Array.isArray(streams)) {
		throw new TypeError(`Expected an array, got \`${typeof streams}\`.`);
	}

	for (const stream of streams) {
		validateStream(stream);
	}

	const objectMode = streams.some(({readableObjectMode}) => readableObjectMode);
	const highWaterMark = getHighWaterMark(streams, objectMode);
	const passThroughStream = new MergedStream({
		objectMode,
		writableHighWaterMark: highWaterMark,
		readableHighWaterMark: highWaterMark,
	});

	for (const stream of streams) {
		passThroughStream.add(stream);
	}

	return passThroughStream;
}

const getHighWaterMark = (streams, objectMode) => {
	if (streams.length === 0) {
		return getDefaultHighWaterMark(objectMode);
	}

	const highWaterMarks = streams
		.filter(({readableObjectMode}) => readableObjectMode === objectMode)
		.map(({readableHighWaterMark}) => readableHighWaterMark);
	return Math.max(...highWaterMarks);
};

class MergedStream extends PassThrough {
	#streams = new Set([]);
	#ended = new Set([]);
	#aborted = new Set([]);
	#onFinished;
	#unpipeEvent = Symbol('unpipe');
	#streamPromises = new WeakMap();

	add(stream) {
		validateStream(stream);

		if (this.#streams.has(stream)) {
			return;
		}

		this.#streams.add(stream);

		this.#onFinished ??= onMergedStreamFinished(this, this.#streams, this.#unpipeEvent);
		const streamPromise = endWhenStreamsDone({
			passThroughStream: this,
			stream,
			streams: this.#streams,
			ended: this.#ended,
			aborted: this.#aborted,
			onFinished: this.#onFinished,
			unpipeEvent: this.#unpipeEvent,
		});
		this.#streamPromises.set(stream, streamPromise);

		stream.pipe(this, {end: false});
	}

	async remove(stream) {
		validateStream(stream);

		if (!this.#streams.has(stream)) {
			return false;
		}

		const streamPromise = this.#streamPromises.get(stream);
		if (streamPromise === undefined) {
			return false;
		}

		this.#streamPromises.delete(stream);

		stream.unpipe(this);
		await streamPromise;
		return true;
	}
}

const onMergedStreamFinished = async (passThroughStream, streams, unpipeEvent) => {
	updateMaxListeners(passThroughStream, PASSTHROUGH_LISTENERS_COUNT);
	const controller = new AbortController();

	try {
		await Promise.race([
			onMergedStreamEnd(passThroughStream, controller),
			onInputStreamsUnpipe(passThroughStream, streams, unpipeEvent, controller),
		]);
	} finally {
		controller.abort();
		updateMaxListeners(passThroughStream, -PASSTHROUGH_LISTENERS_COUNT);
	}
};

const onMergedStreamEnd = async (passThroughStream, {signal}) => {
	try {
		await finished(passThroughStream, {signal, cleanup: true});
	} catch (error) {
		errorOrAbortStream(passThroughStream, error);
		throw error;
	}
};

const onInputStreamsUnpipe = async (passThroughStream, streams, unpipeEvent, {signal}) => {
	for await (const [unpipedStream] of on(passThroughStream, 'unpipe', {signal})) {
		if (streams.has(unpipedStream)) {
			unpipedStream.emit(unpipeEvent);
		}
	}
};

const validateStream = stream => {
	if (typeof stream?.pipe !== 'function') {
		throw new TypeError(`Expected a readable stream, got: \`${typeof stream}\`.`);
	}
};

const endWhenStreamsDone = async ({passThroughStream, stream, streams, ended, aborted, onFinished, unpipeEvent}) => {
	updateMaxListeners(passThroughStream, PASSTHROUGH_LISTENERS_PER_STREAM);
	const controller = new AbortController();

	try {
		await Promise.race([
			afterMergedStreamFinished(onFinished, stream, controller),
			onInputStreamEnd({
				passThroughStream,
				stream,
				streams,
				ended,
				aborted,
				controller,
			}),
			onInputStreamUnpipe({
				stream,
				streams,
				ended,
				aborted,
				unpipeEvent,
				controller,
			}),
		]);
	} finally {
		controller.abort();
		updateMaxListeners(passThroughStream, -PASSTHROUGH_LISTENERS_PER_STREAM);
	}

	if (streams.size > 0 && streams.size === ended.size + aborted.size) {
		if (ended.size === 0 && aborted.size > 0) {
			abortStream(passThroughStream);
		} else {
			endStream(passThroughStream);
		}
	}
};

const afterMergedStreamFinished = async (onFinished, stream, {signal}) => {
	try {
		await onFinished;
		if (!signal.aborted) {
			abortStream(stream);
		}
	} catch (error) {
		if (!signal.aborted) {
			errorOrAbortStream(stream, error);
		}
	}
};

const onInputStreamEnd = async ({passThroughStream, stream, streams, ended, aborted, controller: {signal}}) => {
	try {
		await finished(stream, {
			signal,
			cleanup: true,
			readable: true,
			writable: false,
		});
		if (streams.has(stream)) {
			ended.add(stream);
		}
	} catch (error) {
		if (signal.aborted || !streams.has(stream)) {
			return;
		}

		if (isAbortError(error)) {
			aborted.add(stream);
		} else {
			errorStream(passThroughStream, error);
		}
	}
};

const onInputStreamUnpipe = async ({stream, streams, ended, aborted, unpipeEvent, controller: {signal}}) => {
	await once$2(stream, unpipeEvent, {signal});

	if (!stream.readable) {
		return once$2(signal, 'abort', {signal});
	}

	streams.delete(stream);
	ended.delete(stream);
	aborted.delete(stream);
};

const endStream = stream => {
	if (stream.writable) {
		stream.end();
	}
};

const errorOrAbortStream = (stream, error) => {
	if (isAbortError(error)) {
		abortStream(stream);
	} else {
		errorStream(stream, error);
	}
};

// This is the error thrown by `finished()` on `stream.destroy()`
const isAbortError = error => error?.code === 'ERR_STREAM_PREMATURE_CLOSE';

const abortStream = stream => {
	if (stream.readable || stream.writable) {
		stream.destroy();
	}
};

// `stream.destroy(error)` crashes the process with `uncaughtException` if no `error` event listener exists on `stream`.
// We take care of error handling on user behalf, so we do not want this to happen.
const errorStream = (stream, error) => {
	if (!stream.destroyed) {
		stream.once('error', noop);
		stream.destroy(error);
	}
};

const noop = () => {};

const updateMaxListeners = (passThroughStream, increment) => {
	const maxListeners = passThroughStream.getMaxListeners();
	if (maxListeners !== 0 && maxListeners !== Number.POSITIVE_INFINITY) {
		passThroughStream.setMaxListeners(maxListeners + increment);
	}
};

// Number of times `passThroughStream.on()` is called regardless of streams:
//  - once due to `finished(passThroughStream)`
//  - once due to `on(passThroughStream)`
const PASSTHROUGH_LISTENERS_COUNT = 2;

// Number of times `passThroughStream.on()` is called per stream:
//  - once due to `stream.pipe(passThroughStream)`
const PASSTHROUGH_LISTENERS_PER_STREAM = 1;

// Similar to `Stream.pipeline(source, destination)`, but does not destroy standard streams
const pipeStreams = (source, destination) => {
	source.pipe(destination);
	onSourceFinish(source, destination);
	onDestinationFinish(source, destination);
};

// `source.pipe(destination)` makes `destination` end when `source` ends.
// But it does not propagate aborts or errors. This function does it.
const onSourceFinish = async (source, destination) => {
	if (isStandardStream(source) || isStandardStream(destination)) {
		return;
	}

	try {
		await finished(source, {cleanup: true, readable: true, writable: false});
	} catch {}

	endDestinationStream(destination);
};

const endDestinationStream = destination => {
	if (destination.writable) {
		destination.end();
	}
};

// We do the same thing in the other direction as well.
const onDestinationFinish = async (source, destination) => {
	if (isStandardStream(source) || isStandardStream(destination)) {
		return;
	}

	try {
		await finished(destination, {cleanup: true, readable: false, writable: true});
	} catch {}

	abortSourceStream(source);
};

const abortSourceStream = source => {
	if (source.readable) {
		source.destroy();
	}
};

// Handle `input`, `inputFile`, `stdin`, `stdout` and `stderr` options, after spawning, in async mode
// When multiple input streams are used, we merge them to ensure the output stream ends only once each input stream has ended
const pipeOutputAsync = (subprocess, fileDescriptors, controller) => {
	const pipeGroups = new Map();

	for (const [fdNumber, {stdioItems, direction}] of Object.entries(fileDescriptors)) {
		for (const {stream} of stdioItems.filter(({type}) => TRANSFORM_TYPES.has(type))) {
			pipeTransform(subprocess, stream, direction, fdNumber);
		}

		for (const {stream} of stdioItems.filter(({type}) => !TRANSFORM_TYPES.has(type))) {
			pipeStdioItem({
				subprocess,
				stream,
				direction,
				fdNumber,
				pipeGroups,
				controller,
			});
		}
	}

	for (const [outputStream, inputStreams] of pipeGroups.entries()) {
		const inputStream = inputStreams.length === 1 ? inputStreams[0] : mergeStreams(inputStreams);
		pipeStreams(inputStream, outputStream);
	}
};

// When using transforms, `subprocess.stdin|stdout|stderr|stdio` is directly mutated
const pipeTransform = (subprocess, stream, direction, fdNumber) => {
	if (direction === 'output') {
		pipeStreams(subprocess.stdio[fdNumber], stream);
	} else {
		pipeStreams(stream, subprocess.stdio[fdNumber]);
	}

	const streamProperty = SUBPROCESS_STREAM_PROPERTIES[fdNumber];
	if (streamProperty !== undefined) {
		subprocess[streamProperty] = stream;
	}

	subprocess.stdio[fdNumber] = stream;
};

const SUBPROCESS_STREAM_PROPERTIES = ['stdin', 'stdout', 'stderr'];

// Most `std*` option values involve piping `subprocess.std*` to a stream.
// The stream is either passed by the user or created internally.
const pipeStdioItem = ({subprocess, stream, direction, fdNumber, pipeGroups, controller}) => {
	if (stream === undefined) {
		return;
	}

	setStandardStreamMaxListeners(stream, controller);

	const [inputStream, outputStream] = direction === 'output'
		? [stream, subprocess.stdio[fdNumber]]
		: [subprocess.stdio[fdNumber], stream];
	const outputStreams = pipeGroups.get(inputStream) ?? [];
	pipeGroups.set(inputStream, [...outputStreams, outputStream]);
};

// Multiple subprocesses might be piping from/to `process.std*` at the same time.
// This is not necessarily an error and should not print a `maxListeners` warning.
const setStandardStreamMaxListeners = (stream, {signal}) => {
	if (isStandardStream(stream)) {
		incrementMaxListeners(stream, MAX_LISTENERS_INCREMENT, signal);
	}
};

// `source.pipe(destination)` adds at most 1 listener for each event.
// If `stdin` option is an array, the values might be combined with `merge-streams`.
// That library also listens for `source` end, which adds 1 more listener.
const MAX_LISTENERS_INCREMENT = 2;

/**
 * This is not the set of all possible signals.
 *
 * It IS, however, the set of all signals that trigger
 * an exit on either Linux or BSD systems.  Linux is a
 * superset of the signal names supported on BSD, and
 * the unknown signals just fail to register, so we can
 * catch that easily enough.
 *
 * Windows signals are a different set, since there are
 * signals that terminate Windows processes, but don't
 * terminate (or don't even exist) on Posix systems.
 *
 * Don't bother with SIGKILL.  It's uncatchable, which
 * means that we can't fire any callbacks anyway.
 *
 * If a user does happen to register a handler on a non-
 * fatal signal like SIGWINCH or something, and then
 * exit, it'll end up firing `process.emit('exit')`, so
 * the handler will be fired anyway.
 *
 * SIGBUS, SIGFPE, SIGSEGV and SIGILL, when not raised
 * artificially, inherently leave the process in a
 * state from which it is not safe to try and enter JS
 * listeners.
 */
const signals = [];
signals.push('SIGHUP', 'SIGINT', 'SIGTERM');
if (process.platform !== 'win32') {
    signals.push('SIGALRM', 'SIGABRT', 'SIGVTALRM', 'SIGXCPU', 'SIGXFSZ', 'SIGUSR2', 'SIGTRAP', 'SIGSYS', 'SIGQUIT', 'SIGIOT'
    // should detect profiler and enable/disable accordingly.
    // see #21
    // 'SIGPROF'
    );
}
if (process.platform === 'linux') {
    signals.push('SIGIO', 'SIGPOLL', 'SIGPWR', 'SIGSTKFLT');
}

// Note: since nyc uses this module to output coverage, any lines
// that are in the direct sync flow of nyc's outputCoverage are
// ignored, since we can never get coverage for them.
// grab a reference to node's real process object right away
const processOk = (process) => !!process &&
    typeof process === 'object' &&
    typeof process.removeListener === 'function' &&
    typeof process.emit === 'function' &&
    typeof process.reallyExit === 'function' &&
    typeof process.listeners === 'function' &&
    typeof process.kill === 'function' &&
    typeof process.pid === 'number' &&
    typeof process.on === 'function';
const kExitEmitter = Symbol.for('signal-exit emitter');
const global$3 = globalThis;
const ObjectDefineProperty = Object.defineProperty.bind(Object);
// teeny special purpose ee
class Emitter {
    emitted = {
        afterExit: false,
        exit: false,
    };
    listeners = {
        afterExit: [],
        exit: [],
    };
    count = 0;
    id = Math.random();
    constructor() {
        if (global$3[kExitEmitter]) {
            return global$3[kExitEmitter];
        }
        ObjectDefineProperty(global$3, kExitEmitter, {
            value: this,
            writable: false,
            enumerable: false,
            configurable: false,
        });
    }
    on(ev, fn) {
        this.listeners[ev].push(fn);
    }
    removeListener(ev, fn) {
        const list = this.listeners[ev];
        const i = list.indexOf(fn);
        /* c8 ignore start */
        if (i === -1) {
            return;
        }
        /* c8 ignore stop */
        if (i === 0 && list.length === 1) {
            list.length = 0;
        }
        else {
            list.splice(i, 1);
        }
    }
    emit(ev, code, signal) {
        if (this.emitted[ev]) {
            return false;
        }
        this.emitted[ev] = true;
        let ret = false;
        for (const fn of this.listeners[ev]) {
            ret = fn(code, signal) === true || ret;
        }
        if (ev === 'exit') {
            ret = this.emit('afterExit', code, signal) || ret;
        }
        return ret;
    }
}
class SignalExitBase {
}
const signalExitWrap = (handler) => {
    return {
        onExit(cb, opts) {
            return handler.onExit(cb, opts);
        },
        load() {
            return handler.load();
        },
        unload() {
            return handler.unload();
        },
    };
};
class SignalExitFallback extends SignalExitBase {
    onExit() {
        return () => { };
    }
    load() { }
    unload() { }
}
class SignalExit extends SignalExitBase {
    // "SIGHUP" throws an `ENOSYS` error on Windows,
    // so use a supported signal instead
    /* c8 ignore start */
    #hupSig = process$1.platform === 'win32' ? 'SIGINT' : 'SIGHUP';
    /* c8 ignore stop */
    #emitter = new Emitter();
    #process;
    #originalProcessEmit;
    #originalProcessReallyExit;
    #sigListeners = {};
    #loaded = false;
    constructor(process) {
        super();
        this.#process = process;
        // { <signal>: <listener fn>, ... }
        this.#sigListeners = {};
        for (const sig of signals) {
            this.#sigListeners[sig] = () => {
                // If there are no other listeners, an exit is coming!
                // Simplest way: remove us and then re-send the signal.
                // We know that this will kill the process, so we can
                // safely emit now.
                const listeners = this.#process.listeners(sig);
                let { count } = this.#emitter;
                // This is a workaround for the fact that signal-exit v3 and signal
                // exit v4 are not aware of each other, and each will attempt to let
                // the other handle it, so neither of them do. To correct this, we
                // detect if we're the only handler *except* for previous versions
                // of signal-exit, and increment by the count of listeners it has
                // created.
                /* c8 ignore start */
                const p = process;
                if (typeof p.__signal_exit_emitter__ === 'object' &&
                    typeof p.__signal_exit_emitter__.count === 'number') {
                    count += p.__signal_exit_emitter__.count;
                }
                /* c8 ignore stop */
                if (listeners.length === count) {
                    this.unload();
                    const ret = this.#emitter.emit('exit', null, sig);
                    /* c8 ignore start */
                    const s = sig === 'SIGHUP' ? this.#hupSig : sig;
                    if (!ret)
                        process.kill(process.pid, s);
                    /* c8 ignore stop */
                }
            };
        }
        this.#originalProcessReallyExit = process.reallyExit;
        this.#originalProcessEmit = process.emit;
    }
    onExit(cb, opts) {
        /* c8 ignore start */
        if (!processOk(this.#process)) {
            return () => { };
        }
        /* c8 ignore stop */
        if (this.#loaded === false) {
            this.load();
        }
        const ev = opts?.alwaysLast ? 'afterExit' : 'exit';
        this.#emitter.on(ev, cb);
        return () => {
            this.#emitter.removeListener(ev, cb);
            if (this.#emitter.listeners['exit'].length === 0 &&
                this.#emitter.listeners['afterExit'].length === 0) {
                this.unload();
            }
        };
    }
    load() {
        if (this.#loaded) {
            return;
        }
        this.#loaded = true;
        // This is the number of onSignalExit's that are in play.
        // It's important so that we can count the correct number of
        // listeners on signals, and don't wait for the other one to
        // handle it instead of us.
        this.#emitter.count += 1;
        for (const sig of signals) {
            try {
                const fn = this.#sigListeners[sig];
                if (fn)
                    this.#process.on(sig, fn);
            }
            catch (_) { }
        }
        this.#process.emit = (ev, ...a) => {
            return this.#processEmit(ev, ...a);
        };
        this.#process.reallyExit = (code) => {
            return this.#processReallyExit(code);
        };
    }
    unload() {
        if (!this.#loaded) {
            return;
        }
        this.#loaded = false;
        signals.forEach(sig => {
            const listener = this.#sigListeners[sig];
            /* c8 ignore start */
            if (!listener) {
                throw new Error('Listener not defined for signal: ' + sig);
            }
            /* c8 ignore stop */
            try {
                this.#process.removeListener(sig, listener);
                /* c8 ignore start */
            }
            catch (_) { }
            /* c8 ignore stop */
        });
        this.#process.emit = this.#originalProcessEmit;
        this.#process.reallyExit = this.#originalProcessReallyExit;
        this.#emitter.count -= 1;
    }
    #processReallyExit(code) {
        /* c8 ignore start */
        if (!processOk(this.#process)) {
            return 0;
        }
        this.#process.exitCode = code || 0;
        /* c8 ignore stop */
        this.#emitter.emit('exit', this.#process.exitCode, null);
        return this.#originalProcessReallyExit.call(this.#process, this.#process.exitCode);
    }
    #processEmit(ev, ...args) {
        const og = this.#originalProcessEmit;
        if (ev === 'exit' && processOk(this.#process)) {
            if (typeof args[0] === 'number') {
                this.#process.exitCode = args[0];
                /* c8 ignore start */
            }
            /* c8 ignore start */
            const ret = og.call(this.#process, ev, ...args);
            /* c8 ignore start */
            this.#emitter.emit('exit', this.#process.exitCode, null);
            /* c8 ignore stop */
            return ret;
        }
        else {
            return og.call(this.#process, ev, ...args);
        }
    }
}
const process$1 = globalThis.process;
// wrap so that we call the method on the actual handler, without
// exporting it directly.
const { 
/**
 * Called when the process is exiting, whether via signal, explicit
 * exit, or running out of stuff to do.
 *
 * If the global process object is not suitable for instrumentation,
 * then this will be a no-op.
 *
 * Returns a function that may be used to unload signal-exit.
 */
onExit} = signalExitWrap(processOk(process$1) ? new SignalExit(process$1) : new SignalExitFallback());

// If the `cleanup` option is used, call `subprocess.kill()` when the parent process exits
const cleanupOnExit = (subprocess, {cleanup, detached}, {signal}) => {
	if (!cleanup || detached) {
		return;
	}

	const removeExitHandler = onExit(() => {
		subprocess.kill();
	});
	addAbortListener(signal, () => {
		removeExitHandler();
	});
};

// Normalize and validate arguments passed to `source.pipe(destination)`
const normalizePipeArguments = ({source, sourcePromise, boundOptions, createNested}, ...pipeArguments) => {
	const startTime = getStartTime();
	const {
		destination,
		destinationStream,
		destinationError,
		from,
		unpipeSignal,
	} = getDestinationStream(boundOptions, createNested, pipeArguments);
	const {sourceStream, sourceError} = getSourceStream(source, from);
	const {options: sourceOptions, fileDescriptors} = SUBPROCESS_OPTIONS.get(source);
	return {
		sourcePromise,
		sourceStream,
		sourceOptions,
		sourceError,
		destination,
		destinationStream,
		destinationError,
		unpipeSignal,
		fileDescriptors,
		startTime,
	};
};

const getDestinationStream = (boundOptions, createNested, pipeArguments) => {
	try {
		const {
			destination,
			pipeOptions: {from, to, unpipeSignal} = {},
		} = getDestination(boundOptions, createNested, ...pipeArguments);
		const destinationStream = getToStream(destination, to);
		return {
			destination,
			destinationStream,
			from,
			unpipeSignal,
		};
	} catch (error) {
		return {destinationError: error};
	}
};

// Piping subprocesses can use three syntaxes:
//  - source.pipe('command', commandArguments, pipeOptionsOrDestinationOptions)
//  - source.pipe`command commandArgument` or source.pipe(pipeOptionsOrDestinationOptions)`command commandArgument`
//  - source.pipe(execa(...), pipeOptions)
const getDestination = (boundOptions, createNested, firstArgument, ...pipeArguments) => {
	if (Array.isArray(firstArgument)) {
		const destination = createNested(mapDestinationArguments, boundOptions)(firstArgument, ...pipeArguments);
		return {destination, pipeOptions: boundOptions};
	}

	if (typeof firstArgument === 'string' || firstArgument instanceof URL || isDenoExecPath(firstArgument)) {
		if (Object.keys(boundOptions).length > 0) {
			throw new TypeError('Please use .pipe("file", ..., options) or .pipe(execa("file", ..., options)) instead of .pipe(options)("file", ...).');
		}

		const [rawFile, rawArguments, rawOptions] = normalizeParameters(firstArgument, ...pipeArguments);
		const destination = createNested(mapDestinationArguments)(rawFile, rawArguments, rawOptions);
		return {destination, pipeOptions: rawOptions};
	}

	if (SUBPROCESS_OPTIONS.has(firstArgument)) {
		if (Object.keys(boundOptions).length > 0) {
			throw new TypeError('Please use .pipe(options)`command` or .pipe($(options)`command`) instead of .pipe(options)($`command`).');
		}

		return {destination: firstArgument, pipeOptions: pipeArguments[0]};
	}

	throw new TypeError(`The first argument must be a template string, an options object, or an Execa subprocess: ${firstArgument}`);
};

// Force `stdin: 'pipe'` with the destination subprocess
const mapDestinationArguments = ({options}) => ({options: {...options, stdin: 'pipe', piped: true}});

const getSourceStream = (source, from) => {
	try {
		const sourceStream = getFromStream(source, from);
		return {sourceStream};
	} catch (error) {
		return {sourceError: error};
	}
};

// When passing invalid arguments to `source.pipe()`, throw asynchronously.
// We also abort both subprocesses.
const handlePipeArgumentsError = ({
	sourceStream,
	sourceError,
	destinationStream,
	destinationError,
	fileDescriptors,
	sourceOptions,
	startTime,
}) => {
	const error = getPipeArgumentsError({
		sourceStream,
		sourceError,
		destinationStream,
		destinationError,
	});
	if (error !== undefined) {
		throw createNonCommandError({
			error,
			fileDescriptors,
			sourceOptions,
			startTime,
		});
	}
};

const getPipeArgumentsError = ({sourceStream, sourceError, destinationStream, destinationError}) => {
	if (sourceError !== undefined && destinationError !== undefined) {
		return destinationError;
	}

	if (destinationError !== undefined) {
		abortSourceStream(sourceStream);
		return destinationError;
	}

	if (sourceError !== undefined) {
		endDestinationStream(destinationStream);
		return sourceError;
	}
};

// Specific error return value when passing invalid arguments to `subprocess.pipe()` or when using `unpipeSignal`
const createNonCommandError = ({error, fileDescriptors, sourceOptions, startTime}) => makeEarlyError({
	error,
	command: PIPE_COMMAND_MESSAGE,
	escapedCommand: PIPE_COMMAND_MESSAGE,
	fileDescriptors,
	options: sourceOptions,
	startTime,
	isSync: false,
});

const PIPE_COMMAND_MESSAGE = 'source.pipe(destination)';

// Like Bash, we await both subprocesses. This is unlike some other shells which only await the destination subprocess.
// Like Bash with the `pipefail` option, if either subprocess fails, the whole pipe fails.
// Like Bash, if both subprocesses fail, we return the failure of the destination.
// This ensures both subprocesses' errors are present, using `error.pipedFrom`.
const waitForBothSubprocesses = async subprocessPromises => {
	const [
		{status: sourceStatus, reason: sourceReason, value: sourceResult = sourceReason},
		{status: destinationStatus, reason: destinationReason, value: destinationResult = destinationReason},
	] = await subprocessPromises;

	if (!destinationResult.pipedFrom.includes(sourceResult)) {
		destinationResult.pipedFrom.push(sourceResult);
	}

	if (destinationStatus === 'rejected') {
		throw destinationResult;
	}

	if (sourceStatus === 'rejected') {
		throw sourceResult;
	}

	return destinationResult;
};

// The piping behavior is like Bash.
// In particular, when one subprocess exits, the other is not terminated by a signal.
// Instead, its stdout (for the source) or stdin (for the destination) closes.
// If the subprocess uses it, it will make it error with SIGPIPE or EPIPE (for the source) or end (for the destination).
// If it does not use it, it will continue running.
// This allows for subprocesses to gracefully exit and lower the coupling between subprocesses.
const pipeSubprocessStream = (sourceStream, destinationStream, maxListenersController) => {
	const mergedStream = MERGED_STREAMS.has(destinationStream)
		? pipeMoreSubprocessStream(sourceStream, destinationStream)
		: pipeFirstSubprocessStream(sourceStream, destinationStream);
	incrementMaxListeners(sourceStream, SOURCE_LISTENERS_PER_PIPE, maxListenersController.signal);
	incrementMaxListeners(destinationStream, DESTINATION_LISTENERS_PER_PIPE, maxListenersController.signal);
	cleanupMergedStreamsMap(destinationStream);
	return mergedStream;
};

// We use `merge-streams` to allow for multiple sources to pipe to the same destination.
const pipeFirstSubprocessStream = (sourceStream, destinationStream) => {
	const mergedStream = mergeStreams([sourceStream]);
	pipeStreams(mergedStream, destinationStream);
	MERGED_STREAMS.set(destinationStream, mergedStream);
	return mergedStream;
};

const pipeMoreSubprocessStream = (sourceStream, destinationStream) => {
	const mergedStream = MERGED_STREAMS.get(destinationStream);
	mergedStream.add(sourceStream);
	return mergedStream;
};

const cleanupMergedStreamsMap = async destinationStream => {
	try {
		await finished(destinationStream, {cleanup: true, readable: false, writable: true});
	} catch {}

	MERGED_STREAMS.delete(destinationStream);
};

const MERGED_STREAMS = new WeakMap();

// Number of listeners set up on `sourceStream` by each `sourceStream.pipe(destinationStream)`
// Those are added by `merge-streams`
const SOURCE_LISTENERS_PER_PIPE = 2;
// Number of listeners set up on `destinationStream` by each `sourceStream.pipe(destinationStream)`
// Those are added by `finished()` in `cleanupMergedStreamsMap()`
const DESTINATION_LISTENERS_PER_PIPE = 1;

// When passing an `unpipeSignal` option, abort piping when the signal is aborted.
// However, do not terminate the subprocesses.
const unpipeOnAbort = (unpipeSignal, unpipeContext) => unpipeSignal === undefined
	? []
	: [unpipeOnSignalAbort(unpipeSignal, unpipeContext)];

const unpipeOnSignalAbort = async (unpipeSignal, {sourceStream, mergedStream, fileDescriptors, sourceOptions, startTime}) => {
	await aborted(unpipeSignal, sourceStream);
	await mergedStream.remove(sourceStream);
	const error = new Error('Pipe canceled by `unpipeSignal` option.');
	throw createNonCommandError({
		error,
		fileDescriptors,
		sourceOptions,
		startTime,
	});
};

// Pipe a subprocess' `stdout`/`stderr`/`stdio` into another subprocess' `stdin`
const pipeToSubprocess = (sourceInfo, ...pipeArguments) => {
	if (isPlainObject(pipeArguments[0])) {
		return pipeToSubprocess.bind(undefined, {
			...sourceInfo,
			boundOptions: {...sourceInfo.boundOptions, ...pipeArguments[0]},
		});
	}

	const {destination, ...normalizedInfo} = normalizePipeArguments(sourceInfo, ...pipeArguments);
	const promise = handlePipePromise({...normalizedInfo, destination});
	promise.pipe = pipeToSubprocess.bind(undefined, {
		...sourceInfo,
		source: destination,
		sourcePromise: promise,
		boundOptions: {},
	});
	return promise;
};

// Asynchronous logic when piping subprocesses
const handlePipePromise = async ({
	sourcePromise,
	sourceStream,
	sourceOptions,
	sourceError,
	destination,
	destinationStream,
	destinationError,
	unpipeSignal,
	fileDescriptors,
	startTime,
}) => {
	const subprocessPromises = getSubprocessPromises(sourcePromise, destination);
	handlePipeArgumentsError({
		sourceStream,
		sourceError,
		destinationStream,
		destinationError,
		fileDescriptors,
		sourceOptions,
		startTime,
	});
	const maxListenersController = new AbortController();
	try {
		const mergedStream = pipeSubprocessStream(sourceStream, destinationStream, maxListenersController);
		return await Promise.race([
			waitForBothSubprocesses(subprocessPromises),
			...unpipeOnAbort(unpipeSignal, {
				sourceStream,
				mergedStream,
				sourceOptions,
				fileDescriptors,
				startTime,
			}),
		]);
	} finally {
		maxListenersController.abort();
	}
};

// `.pipe()` awaits the subprocess promises.
// When invalid arguments are passed to `.pipe()`, we throw an error, which prevents awaiting them.
// We need to ensure this does not create unhandled rejections.
const getSubprocessPromises = (sourcePromise, destination) => Promise.allSettled([sourcePromise, destination]);

// Iterate over lines of `subprocess.stdout`, used by `subprocess.readable|duplex|iterable()`
const iterateOnSubprocessStream = ({subprocessStdout, subprocess, binary, shouldEncode, encoding, preserveNewlines}) => {
	const controller = new AbortController();
	stopReadingOnExit(subprocess, controller);
	return iterateOnStream({
		stream: subprocessStdout,
		controller,
		binary,
		shouldEncode: !subprocessStdout.readableObjectMode && shouldEncode,
		encoding,
		shouldSplit: !subprocessStdout.readableObjectMode,
		preserveNewlines,
	});
};

const stopReadingOnExit = async (subprocess, controller) => {
	try {
		await subprocess;
	} catch {} finally {
		controller.abort();
	}
};

// Iterate over lines of `subprocess.stdout`, used by `result.stdout` and the `verbose: 'full'` option.
// Applies the `lines` and `encoding` options.
const iterateForResult = ({stream, onStreamEnd, lines, encoding, stripFinalNewline, allMixed}) => {
	const controller = new AbortController();
	stopReadingOnStreamEnd(onStreamEnd, controller, stream);
	const objectMode = stream.readableObjectMode && !allMixed;
	return iterateOnStream({
		stream,
		controller,
		binary: encoding === 'buffer',
		shouldEncode: !objectMode,
		encoding,
		shouldSplit: !objectMode && lines,
		preserveNewlines: !stripFinalNewline,
	});
};

const stopReadingOnStreamEnd = async (onStreamEnd, controller, stream) => {
	try {
		await onStreamEnd;
	} catch {
		stream.destroy();
	} finally {
		controller.abort();
	}
};

const iterateOnStream = ({stream, controller, binary, shouldEncode, encoding, shouldSplit, preserveNewlines}) => {
	const onStdoutChunk = on(stream, 'data', {
		signal: controller.signal,
		highWaterMark: HIGH_WATER_MARK,
		// Backward compatibility with older name for this option
		// See https://github.com/nodejs/node/pull/52080#discussion_r1525227861
		// @todo Remove after removing support for Node 21
		highWatermark: HIGH_WATER_MARK,
	});
	return iterateOnData({
		onStdoutChunk,
		controller,
		binary,
		shouldEncode,
		encoding,
		shouldSplit,
		preserveNewlines,
	});
};

const DEFAULT_OBJECT_HIGH_WATER_MARK = getDefaultHighWaterMark(true);

// The `highWaterMark` of `events.on()` is measured in number of events, not in bytes.
// Not knowing the average amount of bytes per `data` event, we use the same heuristic as streams in objectMode, since they have the same issue.
// Therefore, we use the value of `getDefaultHighWaterMark(true)`.
// Note: this option does not exist on Node 18, but this is ok since the logic works without it. It just consumes more memory.
const HIGH_WATER_MARK = DEFAULT_OBJECT_HIGH_WATER_MARK;

const iterateOnData = async function * ({onStdoutChunk, controller, binary, shouldEncode, encoding, shouldSplit, preserveNewlines}) {
	const generators = getGenerators({
		binary,
		shouldEncode,
		encoding,
		shouldSplit,
		preserveNewlines,
	});

	try {
		for await (const [chunk] of onStdoutChunk) {
			yield * transformChunkSync(chunk, generators, 0);
		}
	} catch (error) {
		if (!controller.signal.aborted) {
			throw error;
		}
	} finally {
		yield * finalChunksSync(generators);
	}
};

const getGenerators = ({binary, shouldEncode, encoding, shouldSplit, preserveNewlines}) => [
	getEncodingTransformGenerator(binary, encoding, !shouldEncode),
	getSplitLinesGenerator(binary, preserveNewlines, !shouldSplit, {}),
].filter(Boolean);

// Retrieve `result.stdout|stderr|all|stdio[*]`
const getStreamOutput = async ({stream, onStreamEnd, fdNumber, encoding, buffer, maxBuffer, lines, allMixed, stripFinalNewline, verboseInfo, streamInfo}) => {
	const logPromise = logOutputAsync({
		stream,
		onStreamEnd,
		fdNumber,
		encoding,
		allMixed,
		verboseInfo,
		streamInfo,
	});

	if (!buffer) {
		await Promise.all([resumeStream(stream), logPromise]);
		return;
	}

	const stripFinalNewlineValue = getStripFinalNewline(stripFinalNewline, fdNumber);
	const iterable = iterateForResult({
		stream,
		onStreamEnd,
		lines,
		encoding,
		stripFinalNewline: stripFinalNewlineValue,
		allMixed,
	});
	const [output] = await Promise.all([
		getStreamContents({
			stream,
			iterable,
			fdNumber,
			encoding,
			maxBuffer,
			lines,
		}),
		logPromise,
	]);
	return output;
};

const logOutputAsync = async ({stream, onStreamEnd, fdNumber, encoding, allMixed, verboseInfo, streamInfo: {fileDescriptors}}) => {
	if (!shouldLogOutput({
		stdioItems: fileDescriptors[fdNumber]?.stdioItems,
		encoding,
		verboseInfo,
		fdNumber,
	})) {
		return;
	}

	const linesIterable = iterateForResult({
		stream,
		onStreamEnd,
		lines: true,
		encoding,
		stripFinalNewline: true,
		allMixed,
	});
	await logLines(linesIterable, stream, fdNumber, verboseInfo);
};

// When using `buffer: false`, users need to read `subprocess.stdout|stderr|all` right away
// See https://github.com/sindresorhus/execa/issues/730 and https://github.com/sindresorhus/execa/pull/729#discussion_r1465496310
const resumeStream = async stream => {
	await setImmediate$1();
	if (stream.readableFlowing === null) {
		stream.resume();
	}
};

const getStreamContents = async ({stream, stream: {readableObjectMode}, iterable, fdNumber, encoding, maxBuffer, lines}) => {
	try {
		if (readableObjectMode || lines) {
			return await getStreamAsArray(iterable, {maxBuffer});
		}

		if (encoding === 'buffer') {
			return new Uint8Array(await getStreamAsArrayBuffer(iterable, {maxBuffer}));
		}

		return await getStreamAsString(iterable, {maxBuffer});
	} catch (error) {
		return handleBufferedData(handleMaxBuffer({
			error,
			stream,
			readableObjectMode,
			lines,
			encoding,
			fdNumber,
		}));
	}
};

// On failure, `result.stdout|stderr|all` should contain the currently buffered stream
// They are automatically closed and flushed by Node.js when the subprocess exits
// When `buffer` is `false`, `streamPromise` is `undefined` and there is no buffered data to retrieve
const getBufferedData = async streamPromise => {
	try {
		return await streamPromise;
	} catch (error) {
		return handleBufferedData(error);
	}
};

// Ensure we are returning Uint8Arrays when using `encoding: 'buffer'`
const handleBufferedData = ({bufferedData}) => isArrayBuffer(bufferedData)
	? new Uint8Array(bufferedData)
	: bufferedData;

// Wraps `finished(stream)` to handle the following case:
//  - When the subprocess exits, Node.js automatically calls `subprocess.stdin.destroy()`, which we need to ignore.
//  - However, we still need to throw if `subprocess.stdin.destroy()` is called before subprocess exit.
const waitForStream = async (stream, fdNumber, streamInfo, {isSameDirection, stopOnExit = false} = {}) => {
	const state = handleStdinDestroy(stream, streamInfo);
	const abortController = new AbortController();
	try {
		await Promise.race([
			...(stopOnExit ? [streamInfo.exitPromise] : []),
			finished(stream, {cleanup: true, signal: abortController.signal}),
		]);
	} catch (error) {
		if (!state.stdinCleanedUp) {
			handleStreamError(error, fdNumber, streamInfo, isSameDirection);
		}
	} finally {
		abortController.abort();
	}
};

// If `subprocess.stdin` is destroyed before being fully written to, it is considered aborted and should throw an error.
// This can happen for example when user called `subprocess.stdin.destroy()` before `subprocess.stdin.end()`.
// However, Node.js calls `subprocess.stdin.destroy()` on exit for cleanup purposes.
// https://github.com/nodejs/node/blob/0b4cdb4b42956cbd7019058e409e06700a199e11/lib/internal/child_process.js#L278
// This is normal and should not throw an error.
// Therefore, we need to differentiate between both situations to know whether to throw an error.
// Unfortunately, events (`close`, `error`, `end`, `exit`) cannot be used because `.destroy()` can take an arbitrary amount of time.
// For example, `stdin: 'pipe'` is implemented as a TCP socket, and its `.destroy()` method waits for TCP disconnection.
// Therefore `.destroy()` might end before or after subprocess exit, based on OS speed and load.
// The only way to detect this is to spy on `subprocess.stdin._destroy()` by wrapping it.
// If `subprocess.exitCode` or `subprocess.signalCode` is set, it means `.destroy()` is being called by Node.js itself.
const handleStdinDestroy = (stream, {originalStreams: [originalStdin], subprocess}) => {
	const state = {stdinCleanedUp: false};
	if (stream === originalStdin) {
		spyOnStdinDestroy(stream, subprocess, state);
	}

	return state;
};

const spyOnStdinDestroy = (subprocessStdin, subprocess, state) => {
	const {_destroy} = subprocessStdin;
	subprocessStdin._destroy = (...destroyArguments) => {
		setStdinCleanedUp(subprocess, state);
		_destroy.call(subprocessStdin, ...destroyArguments);
	};
};

const setStdinCleanedUp = ({exitCode, signalCode}, state) => {
	if (exitCode !== null || signalCode !== null) {
		state.stdinCleanedUp = true;
	}
};

// We ignore EPIPEs on writable streams and aborts on readable streams since those can happen normally.
// When one stream errors, the error is propagated to the other streams on the same file descriptor.
// Those other streams might have a different direction due to the above.
// When this happens, the direction of both the initial stream and the others should then be taken into account.
// Therefore, we keep track of whether a stream error is currently propagating.
const handleStreamError = (error, fdNumber, streamInfo, isSameDirection) => {
	if (!shouldIgnoreStreamError(error, fdNumber, streamInfo, isSameDirection)) {
		throw error;
	}
};

const shouldIgnoreStreamError = (error, fdNumber, streamInfo, isSameDirection = true) => {
	if (streamInfo.propagating) {
		return isStreamEpipe(error) || isStreamAbort(error);
	}

	streamInfo.propagating = true;
	return isInputFileDescriptor(streamInfo, fdNumber) === isSameDirection
		? isStreamEpipe(error)
		: isStreamAbort(error);
};

// Unfortunately, we cannot use the stream's class or properties to know whether it is readable or writable.
// For example, `subprocess.stdin` is technically a Duplex, but can only be used as a writable.
// Therefore, we need to use the file descriptor's direction (`stdin` is input, `stdout` is output, etc.).
// However, while `subprocess.std*` and transforms follow that direction, any stream passed the `std*` option has the opposite direction.
// For example, `subprocess.stdin` is a writable, but the `stdin` option is a readable.
const isInputFileDescriptor = ({fileDescriptors}, fdNumber) => fdNumber !== 'all' && fileDescriptors[fdNumber].direction === 'input';

// When `stream.destroy()` is called without an `error` argument, stream is aborted.
// This is the only way to abort a readable stream, which can be useful in some instances.
// Therefore, we ignore this error on readable streams.
const isStreamAbort = error => error?.code === 'ERR_STREAM_PREMATURE_CLOSE';

// When `stream.write()` is called but the underlying source has been closed, `EPIPE` is emitted.
// When piping subprocesses, the source subprocess usually decides when to stop piping.
// However, there are some instances when the destination does instead, such as `... | head -n1`.
// It notifies the source by using `EPIPE`.
// Therefore, we ignore this error on writable streams.
const isStreamEpipe = error => error?.code === 'EPIPE';

// Read the contents of `subprocess.std*` and|or wait for its completion
const waitForStdioStreams = ({subprocess, encoding, buffer, maxBuffer, lines, stripFinalNewline, verboseInfo, streamInfo}) => subprocess.stdio.map((stream, fdNumber) => waitForSubprocessStream({
	stream,
	fdNumber,
	encoding,
	buffer: buffer[fdNumber],
	maxBuffer: maxBuffer[fdNumber],
	lines: lines[fdNumber],
	allMixed: false,
	stripFinalNewline,
	verboseInfo,
	streamInfo,
}));

// Read the contents of `subprocess.std*` or `subprocess.all` and|or wait for its completion
const waitForSubprocessStream = async ({stream, fdNumber, encoding, buffer, maxBuffer, lines, allMixed, stripFinalNewline, verboseInfo, streamInfo}) => {
	if (!stream) {
		return;
	}

	const onStreamEnd = waitForStream(stream, fdNumber, streamInfo);
	if (isInputFileDescriptor(streamInfo, fdNumber)) {
		await onStreamEnd;
		return;
	}

	const [output] = await Promise.all([
		getStreamOutput({
			stream,
			onStreamEnd,
			fdNumber,
			encoding,
			buffer,
			maxBuffer,
			lines,
			allMixed,
			stripFinalNewline,
			verboseInfo,
			streamInfo,
		}),
		onStreamEnd,
	]);
	return output;
};

// `all` interleaves `stdout` and `stderr`
const makeAllStream = ({stdout, stderr}, {all}) => all && (stdout || stderr)
	? mergeStreams([stdout, stderr].filter(Boolean))
	: undefined;

// Read the contents of `subprocess.all` and|or wait for its completion
const waitForAllStream = ({subprocess, encoding, buffer, maxBuffer, lines, stripFinalNewline, verboseInfo, streamInfo}) => waitForSubprocessStream({
	...getAllStream(subprocess, buffer),
	fdNumber: 'all',
	encoding,
	maxBuffer: maxBuffer[1] + maxBuffer[2],
	lines: lines[1] || lines[2],
	allMixed: getAllMixed(subprocess),
	stripFinalNewline,
	verboseInfo,
	streamInfo,
});

const getAllStream = ({stdout, stderr, all}, [, bufferStdout, bufferStderr]) => {
	const buffer = bufferStdout || bufferStderr;
	if (!buffer) {
		return {stream: all, buffer};
	}

	if (!bufferStdout) {
		return {stream: stderr, buffer};
	}

	if (!bufferStderr) {
		return {stream: stdout, buffer};
	}

	return {stream: all, buffer};
};

// When `subprocess.stdout` is in objectMode but not `subprocess.stderr` (or the opposite), we need to use both:
//  - `getStreamAsArray()` for the chunks in objectMode, to return as an array without changing each chunk
//  - `getStreamAsArrayBuffer()` or `getStream()` for the chunks not in objectMode, to convert them from Buffers to string or Uint8Array
// We do this by emulating the Buffer -> string|Uint8Array conversion performed by `get-stream` with our own, which is identical.
const getAllMixed = ({all, stdout, stderr}) => all
	&& stdout
	&& stderr
	&& stdout.readableObjectMode !== stderr.readableObjectMode;

// When `verbose` is `'full'`, print IPC messages from the subprocess
const shouldLogIpc = verboseInfo => isFullVerbose(verboseInfo, 'ipc');

const logIpcOutput = (message, verboseInfo) => {
	const verboseMessage = serializeVerboseMessage(message);
	verboseLog({
		type: 'ipc',
		verboseMessage,
		fdNumber: 'ipc',
		verboseInfo,
	});
};

// Iterate through IPC messages sent by the subprocess
const waitForIpcOutput = async ({
	subprocess,
	buffer: bufferArray,
	maxBuffer: maxBufferArray,
	ipc,
	ipcOutput,
	verboseInfo,
}) => {
	if (!ipc) {
		return ipcOutput;
	}

	const isVerbose = shouldLogIpc(verboseInfo);
	const buffer = getFdSpecificValue(bufferArray, 'ipc');
	const maxBuffer = getFdSpecificValue(maxBufferArray, 'ipc');

	for await (const message of loopOnMessages({
		anyProcess: subprocess,
		channel: subprocess.channel,
		isSubprocess: false,
		ipc,
		shouldAwait: false,
		reference: true,
	})) {
		if (buffer) {
			checkIpcMaxBuffer(subprocess, ipcOutput, maxBuffer);
			ipcOutput.push(message);
		}

		if (isVerbose) {
			logIpcOutput(message, verboseInfo);
		}
	}

	return ipcOutput;
};

const getBufferedIpcOutput = async (ipcOutputPromise, ipcOutput) => {
	await Promise.allSettled([ipcOutputPromise]);
	return ipcOutput;
};

// Retrieve result of subprocess: exit code, signal, error, streams (stdout/stderr/all)
const waitForSubprocessResult = async ({
	subprocess,
	options: {
		encoding,
		buffer,
		maxBuffer,
		lines,
		timeoutDuration: timeout,
		cancelSignal,
		gracefulCancel,
		forceKillAfterDelay,
		stripFinalNewline,
		ipc,
		ipcInput,
	},
	context,
	verboseInfo,
	fileDescriptors,
	originalStreams,
	onInternalError,
	controller,
}) => {
	const exitPromise = waitForExit(subprocess, context);
	const streamInfo = {
		originalStreams,
		fileDescriptors,
		subprocess,
		exitPromise,
		propagating: false,
	};

	const stdioPromises = waitForStdioStreams({
		subprocess,
		encoding,
		buffer,
		maxBuffer,
		lines,
		stripFinalNewline,
		verboseInfo,
		streamInfo,
	});
	const allPromise = waitForAllStream({
		subprocess,
		encoding,
		buffer,
		maxBuffer,
		lines,
		stripFinalNewline,
		verboseInfo,
		streamInfo,
	});
	const ipcOutput = [];
	const ipcOutputPromise = waitForIpcOutput({
		subprocess,
		buffer,
		maxBuffer,
		ipc,
		ipcOutput,
		verboseInfo,
	});
	const originalPromises = waitForOriginalStreams(originalStreams, subprocess, streamInfo);
	const customStreamsEndPromises = waitForCustomStreamsEnd(fileDescriptors, streamInfo);

	try {
		return await Promise.race([
			Promise.all([
				{},
				waitForSuccessfulExit(exitPromise),
				Promise.all(stdioPromises),
				allPromise,
				ipcOutputPromise,
				sendIpcInput(subprocess, ipcInput),
				...originalPromises,
				...customStreamsEndPromises,
			]),
			onInternalError,
			throwOnSubprocessError(subprocess, controller),
			...throwOnTimeout(subprocess, timeout, context, controller),
			...throwOnCancel({
				subprocess,
				cancelSignal,
				gracefulCancel,
				context,
				controller,
			}),
			...throwOnGracefulCancel({
				subprocess,
				cancelSignal,
				gracefulCancel,
				forceKillAfterDelay,
				context,
				controller,
			}),
		]);
	} catch (error) {
		context.terminationReason ??= 'other';
		return Promise.all([
			{error},
			exitPromise,
			Promise.all(stdioPromises.map(stdioPromise => getBufferedData(stdioPromise))),
			getBufferedData(allPromise),
			getBufferedIpcOutput(ipcOutputPromise, ipcOutput),
			Promise.allSettled(originalPromises),
			Promise.allSettled(customStreamsEndPromises),
		]);
	}
};

// Transforms replace `subprocess.std*`, which means they are not exposed to users.
// However, we still want to wait for their completion.
const waitForOriginalStreams = (originalStreams, subprocess, streamInfo) =>
	originalStreams.map((stream, fdNumber) => stream === subprocess.stdio[fdNumber]
		? undefined
		: waitForStream(stream, fdNumber, streamInfo));

// Some `stdin`/`stdout`/`stderr` options create a stream, e.g. when passing a file path.
// The `.pipe()` method automatically ends that stream when `subprocess` ends.
// This makes sure we wait for the completion of those streams, in order to catch any error.
const waitForCustomStreamsEnd = (fileDescriptors, streamInfo) => fileDescriptors.flatMap(({stdioItems}, fdNumber) => stdioItems
	.filter(({value, stream = value}) => isStream(stream, {checkOpen: false}) && !isStandardStream(stream))
	.map(({type, value, stream = value}) => waitForStream(stream, fdNumber, streamInfo, {
		isSameDirection: TRANSFORM_TYPES.has(type),
		stopOnExit: type === 'native',
	})));

// Fails when the subprocess emits an `error` event
const throwOnSubprocessError = async (subprocess, {signal}) => {
	const [error] = await once$2(subprocess, 'error', {signal});
	throw error;
};

// When using multiple `.readable()`/`.writable()`/`.duplex()`, `final` and `destroy` should wait for other streams
const initializeConcurrentStreams = () => ({
	readableDestroy: new WeakMap(),
	writableFinal: new WeakMap(),
	writableDestroy: new WeakMap(),
});

// Each file descriptor + `waitName` has its own array of promises.
// Each promise is a single `.readable()`/`.writable()`/`.duplex()` call.
const addConcurrentStream = (concurrentStreams, stream, waitName) => {
	const weakMap = concurrentStreams[waitName];
	if (!weakMap.has(stream)) {
		weakMap.set(stream, []);
	}

	const promises = weakMap.get(stream);
	const promise = createDeferred();
	promises.push(promise);
	const resolve = promise.resolve.bind(promise);
	return {resolve, promises};
};

// Wait for other streams, but stop waiting when subprocess ends
const waitForConcurrentStreams = async ({resolve, promises}, subprocess) => {
	resolve();
	const [isSubprocessExit] = await Promise.race([
		Promise.allSettled([true, subprocess]),
		Promise.all([false, ...promises]),
	]);
	return !isSubprocessExit;
};

const safeWaitForSubprocessStdin = async subprocessStdin => {
	if (subprocessStdin === undefined) {
		return;
	}

	try {
		await waitForSubprocessStdin(subprocessStdin);
	} catch {}
};

const safeWaitForSubprocessStdout = async subprocessStdout => {
	if (subprocessStdout === undefined) {
		return;
	}

	try {
		await waitForSubprocessStdout(subprocessStdout);
	} catch {}
};

const waitForSubprocessStdin = async subprocessStdin => {
	await finished(subprocessStdin, {cleanup: true, readable: false, writable: true});
};

const waitForSubprocessStdout = async subprocessStdout => {
	await finished(subprocessStdout, {cleanup: true, readable: true, writable: false});
};

// When `readable` or `writable` aborts/errors, awaits the subprocess, for the reason mentioned above
const waitForSubprocess = async (subprocess, error) => {
	await subprocess;
	if (error) {
		throw error;
	}
};

const destroyOtherStream = (stream, isOpen, error) => {
	if (error && !isStreamAbort(error)) {
		stream.destroy(error);
	} else if (isOpen) {
		stream.destroy();
	}
};

// Create a `Readable` stream that forwards from `stdout` and awaits the subprocess
const createReadable = ({subprocess, concurrentStreams, encoding}, {from, binary: binaryOption = true, preserveNewlines = true} = {}) => {
	const binary = binaryOption || BINARY_ENCODINGS.has(encoding);
	const {subprocessStdout, waitReadableDestroy} = getSubprocessStdout(subprocess, from, concurrentStreams);
	const {readableEncoding, readableObjectMode, readableHighWaterMark} = getReadableOptions(subprocessStdout, binary);
	const {read, onStdoutDataDone} = getReadableMethods({
		subprocessStdout,
		subprocess,
		binary,
		encoding,
		preserveNewlines,
	});
	const readable = new Readable({
		read,
		destroy: callbackify(onReadableDestroy.bind(undefined, {subprocessStdout, subprocess, waitReadableDestroy})),
		highWaterMark: readableHighWaterMark,
		objectMode: readableObjectMode,
		encoding: readableEncoding,
	});
	onStdoutFinished({
		subprocessStdout,
		onStdoutDataDone,
		readable,
		subprocess,
	});
	return readable;
};

// Retrieve `stdout` (or other stream depending on `from`)
const getSubprocessStdout = (subprocess, from, concurrentStreams) => {
	const subprocessStdout = getFromStream(subprocess, from);
	const waitReadableDestroy = addConcurrentStream(concurrentStreams, subprocessStdout, 'readableDestroy');
	return {subprocessStdout, waitReadableDestroy};
};

const getReadableOptions = ({readableEncoding, readableObjectMode, readableHighWaterMark}, binary) => binary
	? {readableEncoding, readableObjectMode, readableHighWaterMark}
	: {readableEncoding, readableObjectMode: true, readableHighWaterMark: DEFAULT_OBJECT_HIGH_WATER_MARK};

const getReadableMethods = ({subprocessStdout, subprocess, binary, encoding, preserveNewlines}) => {
	const onStdoutDataDone = createDeferred();
	const onStdoutData = iterateOnSubprocessStream({
		subprocessStdout,
		subprocess,
		binary,
		shouldEncode: !binary,
		encoding,
		preserveNewlines,
	});

	return {
		read() {
			onRead(this, onStdoutData, onStdoutDataDone);
		},
		onStdoutDataDone,
	};
};

// Forwards data from `stdout` to `readable`
const onRead = async (readable, onStdoutData, onStdoutDataDone) => {
	try {
		const {value, done} = await onStdoutData.next();
		if (done) {
			onStdoutDataDone.resolve();
		} else {
			readable.push(value);
		}
	} catch {}
};

// When `subprocess.stdout` ends/aborts/errors, do the same on `readable`.
// Await the subprocess, for the same reason as above.
const onStdoutFinished = async ({subprocessStdout, onStdoutDataDone, readable, subprocess, subprocessStdin}) => {
	try {
		await waitForSubprocessStdout(subprocessStdout);
		await subprocess;
		await safeWaitForSubprocessStdin(subprocessStdin);
		await onStdoutDataDone;

		if (readable.readable) {
			readable.push(null);
		}
	} catch (error) {
		await safeWaitForSubprocessStdin(subprocessStdin);
		destroyOtherReadable(readable, error);
	}
};

// When `readable` aborts/errors, do the same on `subprocess.stdout`
const onReadableDestroy = async ({subprocessStdout, subprocess, waitReadableDestroy}, error) => {
	if (await waitForConcurrentStreams(waitReadableDestroy, subprocess)) {
		destroyOtherReadable(subprocessStdout, error);
		await waitForSubprocess(subprocess, error);
	}
};

const destroyOtherReadable = (stream, error) => {
	destroyOtherStream(stream, stream.readable, error);
};

// Create a `Writable` stream that forwards to `stdin` and awaits the subprocess
const createWritable = ({subprocess, concurrentStreams}, {to} = {}) => {
	const {subprocessStdin, waitWritableFinal, waitWritableDestroy} = getSubprocessStdin(subprocess, to, concurrentStreams);
	const writable = new Writable({
		...getWritableMethods(subprocessStdin, subprocess, waitWritableFinal),
		destroy: callbackify(onWritableDestroy.bind(undefined, {
			subprocessStdin,
			subprocess,
			waitWritableFinal,
			waitWritableDestroy,
		})),
		highWaterMark: subprocessStdin.writableHighWaterMark,
		objectMode: subprocessStdin.writableObjectMode,
	});
	onStdinFinished(subprocessStdin, writable);
	return writable;
};

// Retrieve `stdin` (or other stream depending on `to`)
const getSubprocessStdin = (subprocess, to, concurrentStreams) => {
	const subprocessStdin = getToStream(subprocess, to);
	const waitWritableFinal = addConcurrentStream(concurrentStreams, subprocessStdin, 'writableFinal');
	const waitWritableDestroy = addConcurrentStream(concurrentStreams, subprocessStdin, 'writableDestroy');
	return {subprocessStdin, waitWritableFinal, waitWritableDestroy};
};

const getWritableMethods = (subprocessStdin, subprocess, waitWritableFinal) => ({
	write: onWrite.bind(undefined, subprocessStdin),
	final: callbackify(onWritableFinal.bind(undefined, subprocessStdin, subprocess, waitWritableFinal)),
});

// Forwards data from `writable` to `stdin`
const onWrite = (subprocessStdin, chunk, encoding, done) => {
	if (subprocessStdin.write(chunk, encoding)) {
		done();
	} else {
		subprocessStdin.once('drain', done);
	}
};

// Ensures that the writable `final` and readable `end` events awaits the subprocess.
// Like this, any subprocess failure is propagated as a stream `error` event, instead of being lost.
// The user does not need to `await` the subprocess anymore, but now needs to await the stream completion or error.
// When multiple writables are targeting the same stream, they wait for each other, unless the subprocess ends first.
const onWritableFinal = async (subprocessStdin, subprocess, waitWritableFinal) => {
	if (await waitForConcurrentStreams(waitWritableFinal, subprocess)) {
		if (subprocessStdin.writable) {
			subprocessStdin.end();
		}

		await subprocess;
	}
};

// When `subprocess.stdin` ends/aborts/errors, do the same on `writable`.
const onStdinFinished = async (subprocessStdin, writable, subprocessStdout) => {
	try {
		await waitForSubprocessStdin(subprocessStdin);
		if (writable.writable) {
			writable.end();
		}
	} catch (error) {
		await safeWaitForSubprocessStdout(subprocessStdout);
		destroyOtherWritable(writable, error);
	}
};

// When `writable` aborts/errors, do the same on `subprocess.stdin`
const onWritableDestroy = async ({subprocessStdin, subprocess, waitWritableFinal, waitWritableDestroy}, error) => {
	await waitForConcurrentStreams(waitWritableFinal, subprocess);
	if (await waitForConcurrentStreams(waitWritableDestroy, subprocess)) {
		destroyOtherWritable(subprocessStdin, error);
		await waitForSubprocess(subprocess, error);
	}
};

const destroyOtherWritable = (stream, error) => {
	destroyOtherStream(stream, stream.writable, error);
};

// Create a `Duplex` stream combining both `subprocess.readable()` and `subprocess.writable()`
const createDuplex = ({subprocess, concurrentStreams, encoding}, {from, to, binary: binaryOption = true, preserveNewlines = true} = {}) => {
	const binary = binaryOption || BINARY_ENCODINGS.has(encoding);
	const {subprocessStdout, waitReadableDestroy} = getSubprocessStdout(subprocess, from, concurrentStreams);
	const {subprocessStdin, waitWritableFinal, waitWritableDestroy} = getSubprocessStdin(subprocess, to, concurrentStreams);
	const {readableEncoding, readableObjectMode, readableHighWaterMark} = getReadableOptions(subprocessStdout, binary);
	const {read, onStdoutDataDone} = getReadableMethods({
		subprocessStdout,
		subprocess,
		binary,
		encoding,
		preserveNewlines,
	});
	const duplex = new Duplex({
		read,
		...getWritableMethods(subprocessStdin, subprocess, waitWritableFinal),
		destroy: callbackify(onDuplexDestroy.bind(undefined, {
			subprocessStdout,
			subprocessStdin,
			subprocess,
			waitReadableDestroy,
			waitWritableFinal,
			waitWritableDestroy,
		})),
		readableHighWaterMark,
		writableHighWaterMark: subprocessStdin.writableHighWaterMark,
		readableObjectMode,
		writableObjectMode: subprocessStdin.writableObjectMode,
		encoding: readableEncoding,
	});
	onStdoutFinished({
		subprocessStdout,
		onStdoutDataDone,
		readable: duplex,
		subprocess,
		subprocessStdin,
	});
	onStdinFinished(subprocessStdin, duplex, subprocessStdout);
	return duplex;
};

const onDuplexDestroy = async ({subprocessStdout, subprocessStdin, subprocess, waitReadableDestroy, waitWritableFinal, waitWritableDestroy}, error) => {
	await Promise.all([
		onReadableDestroy({subprocessStdout, subprocess, waitReadableDestroy}, error),
		onWritableDestroy({
			subprocessStdin,
			subprocess,
			waitWritableFinal,
			waitWritableDestroy,
		}, error),
	]);
};

// Convert the subprocess to an async iterable
const createIterable = (subprocess, encoding, {
	from,
	binary: binaryOption = false,
	preserveNewlines = false,
} = {}) => {
	const binary = binaryOption || BINARY_ENCODINGS.has(encoding);
	const subprocessStdout = getFromStream(subprocess, from);
	const onStdoutData = iterateOnSubprocessStream({
		subprocessStdout,
		subprocess,
		binary,
		shouldEncode: true,
		encoding,
		preserveNewlines,
	});
	return iterateOnStdoutData(onStdoutData, subprocessStdout, subprocess);
};

const iterateOnStdoutData = async function * (onStdoutData, subprocessStdout, subprocess) {
	try {
		yield * onStdoutData;
	} finally {
		if (subprocessStdout.readable) {
			subprocessStdout.destroy();
		}

		await subprocess;
	}
};

// Add methods to convert the subprocess to a stream or iterable
const addConvertedStreams = (subprocess, {encoding}) => {
	const concurrentStreams = initializeConcurrentStreams();
	subprocess.readable = createReadable.bind(undefined, {subprocess, concurrentStreams, encoding});
	subprocess.writable = createWritable.bind(undefined, {subprocess, concurrentStreams});
	subprocess.duplex = createDuplex.bind(undefined, {subprocess, concurrentStreams, encoding});
	subprocess.iterable = createIterable.bind(undefined, subprocess, encoding);
	subprocess[Symbol.asyncIterator] = createIterable.bind(undefined, subprocess, encoding, {});
};

// The return value is a mixin of `subprocess` and `Promise`
const mergePromise = (subprocess, promise) => {
	for (const [property, descriptor] of descriptors) {
		const value = descriptor.value.bind(promise);
		Reflect.defineProperty(subprocess, property, {...descriptor, value});
	}
};

// eslint-disable-next-line unicorn/prefer-top-level-await
const nativePromisePrototype = (async () => {})().constructor.prototype;

const descriptors = ['then', 'catch', 'finally'].map(property => [
	property,
	Reflect.getOwnPropertyDescriptor(nativePromisePrototype, property),
]);

// Main shared logic for all async methods: `execa()`, `$`, `execaNode()`
const execaCoreAsync = (rawFile, rawArguments, rawOptions, createNested) => {
	const {file, commandArguments, command, escapedCommand, startTime, verboseInfo, options, fileDescriptors} = handleAsyncArguments(rawFile, rawArguments, rawOptions);
	const {subprocess, promise} = spawnSubprocessAsync({
		file,
		commandArguments,
		options,
		startTime,
		verboseInfo,
		command,
		escapedCommand,
		fileDescriptors,
	});
	subprocess.pipe = pipeToSubprocess.bind(undefined, {
		source: subprocess,
		sourcePromise: promise,
		boundOptions: {},
		createNested,
	});
	mergePromise(subprocess, promise);
	SUBPROCESS_OPTIONS.set(subprocess, {options, fileDescriptors});
	return subprocess;
};

// Compute arguments to pass to `child_process.spawn()`
const handleAsyncArguments = (rawFile, rawArguments, rawOptions) => {
	const {command, escapedCommand, startTime, verboseInfo} = handleCommand(rawFile, rawArguments, rawOptions);
	const {file, commandArguments, options: normalizedOptions} = normalizeOptions(rawFile, rawArguments, rawOptions);
	const options = handleAsyncOptions(normalizedOptions);
	const fileDescriptors = handleStdioAsync(options, verboseInfo);
	return {
		file,
		commandArguments,
		command,
		escapedCommand,
		startTime,
		verboseInfo,
		options,
		fileDescriptors,
	};
};

// Options normalization logic specific to async methods.
// Prevent passing the `timeout` option directly to `child_process.spawn()`.
const handleAsyncOptions = ({timeout, signal, ...options}) => {
	if (signal !== undefined) {
		throw new TypeError('The "signal" option has been renamed to "cancelSignal" instead.');
	}

	return {...options, timeoutDuration: timeout};
};

const spawnSubprocessAsync = ({file, commandArguments, options, startTime, verboseInfo, command, escapedCommand, fileDescriptors}) => {
	let subprocess;
	try {
		subprocess = spawn(...concatenateShell(file, commandArguments, options));
	} catch (error) {
		return handleEarlyError({
			error,
			command,
			escapedCommand,
			fileDescriptors,
			options,
			startTime,
			verboseInfo,
		});
	}

	const controller = new AbortController();
	setMaxListeners(Number.POSITIVE_INFINITY, controller.signal);

	const originalStreams = [...subprocess.stdio];
	pipeOutputAsync(subprocess, fileDescriptors, controller);
	cleanupOnExit(subprocess, options, controller);

	const context = {};
	const onInternalError = createDeferred();
	subprocess.kill = subprocessKill.bind(undefined, {
		kill: subprocess.kill.bind(subprocess),
		options,
		onInternalError,
		context,
		controller,
	});
	subprocess.all = makeAllStream(subprocess, options);
	addConvertedStreams(subprocess, options);
	addIpcMethods(subprocess, options);

	const promise = handlePromise({
		subprocess,
		options,
		startTime,
		verboseInfo,
		fileDescriptors,
		originalStreams,
		command,
		escapedCommand,
		context,
		onInternalError,
		controller,
	});
	return {subprocess, promise};
};

// Asynchronous logic, as opposed to the previous logic which can be run synchronously, i.e. can be returned to user right away
const handlePromise = async ({subprocess, options, startTime, verboseInfo, fileDescriptors, originalStreams, command, escapedCommand, context, onInternalError, controller}) => {
	const [
		errorInfo,
		[exitCode, signal],
		stdioResults,
		allResult,
		ipcOutput,
	] = await waitForSubprocessResult({
		subprocess,
		options,
		context,
		verboseInfo,
		fileDescriptors,
		originalStreams,
		onInternalError,
		controller,
	});
	controller.abort();
	onInternalError.resolve();

	const stdio = stdioResults.map((stdioResult, fdNumber) => stripNewline(stdioResult, options, fdNumber));
	const all = stripNewline(allResult, options, 'all');
	const result = getAsyncResult({
		errorInfo,
		exitCode,
		signal,
		stdio,
		all,
		ipcOutput,
		context,
		options,
		command,
		escapedCommand,
		startTime,
	});
	return handleResult(result, verboseInfo, options);
};

const getAsyncResult = ({errorInfo, exitCode, signal, stdio, all, ipcOutput, context, options, command, escapedCommand, startTime}) => 'error' in errorInfo
	? makeError({
		error: errorInfo.error,
		command,
		escapedCommand,
		timedOut: context.terminationReason === 'timeout',
		isCanceled: context.terminationReason === 'cancel' || context.terminationReason === 'gracefulCancel',
		isGracefullyCanceled: context.terminationReason === 'gracefulCancel',
		isMaxBuffer: errorInfo.error instanceof MaxBufferError,
		isForcefullyTerminated: context.isForcefullyTerminated,
		exitCode,
		signal,
		stdio,
		all,
		ipcOutput,
		options,
		startTime,
		isSync: false,
	})
	: makeSuccessResult({
		command,
		escapedCommand,
		stdio,
		all,
		ipcOutput,
		options,
		startTime,
	});

// Deep merge specific options like `env`. Shallow merge the other ones.
const mergeOptions = (boundOptions, options) => {
	const newOptions = Object.fromEntries(
		Object.entries(options).map(([optionName, optionValue]) => [
			optionName,
			mergeOption(optionName, boundOptions[optionName], optionValue),
		]),
	);
	return {...boundOptions, ...newOptions};
};

const mergeOption = (optionName, boundOptionValue, optionValue) => {
	if (DEEP_OPTIONS.has(optionName) && isPlainObject(boundOptionValue) && isPlainObject(optionValue)) {
		return {...boundOptionValue, ...optionValue};
	}

	return optionValue;
};

const DEEP_OPTIONS = new Set(['env', ...FD_SPECIFIC_OPTIONS]);

// Wraps every exported methods to provide the following features:
//  - template string syntax: execa`command argument`
//  - options binding: boundExeca = execa(options)
//  - optional argument/options: execa(file), execa(file, args), execa(file, options), execa(file, args, options)
// `mapArguments()` and `setBoundExeca()` allows for method-specific logic.
const createExeca = (mapArguments, boundOptions, deepOptions, setBoundExeca) => {
	const createNested = (mapArguments, boundOptions, setBoundExeca) => createExeca(mapArguments, boundOptions, deepOptions, setBoundExeca);
	const boundExeca = (...execaArguments) => callBoundExeca({
		mapArguments,
		deepOptions,
		boundOptions,
		setBoundExeca,
		createNested,
	}, ...execaArguments);

	if (setBoundExeca !== undefined) {
		setBoundExeca(boundExeca, createNested, boundOptions);
	}

	return boundExeca;
};

const callBoundExeca = ({mapArguments, deepOptions = {}, boundOptions = {}, setBoundExeca, createNested}, firstArgument, ...nextArguments) => {
	if (isPlainObject(firstArgument)) {
		return createNested(mapArguments, mergeOptions(boundOptions, firstArgument), setBoundExeca);
	}

	const {file, commandArguments, options, isSync} = parseArguments({
		mapArguments,
		firstArgument,
		nextArguments,
		deepOptions,
		boundOptions,
	});
	return isSync
		? execaCoreSync(file, commandArguments, options)
		: execaCoreAsync(file, commandArguments, options, createNested);
};

const parseArguments = ({mapArguments, firstArgument, nextArguments, deepOptions, boundOptions}) => {
	const callArguments = isTemplateString(firstArgument)
		? parseTemplates(firstArgument, nextArguments)
		: [firstArgument, ...nextArguments];
	const [initialFile, initialArguments, initialOptions] = normalizeParameters(...callArguments);
	const mergedOptions = mergeOptions(mergeOptions(deepOptions, boundOptions), initialOptions);
	const {
		file = initialFile,
		commandArguments = initialArguments,
		options = mergedOptions,
		isSync = false,
	} = mapArguments({file: initialFile, commandArguments: initialArguments, options: mergedOptions});
	return {
		file,
		commandArguments,
		options,
		isSync,
	};
};

// Main logic for `execaCommand()`
const mapCommandAsync = ({file, commandArguments}) => parseCommand(file, commandArguments);

// Main logic for `execaCommandSync()`
const mapCommandSync = ({file, commandArguments}) => ({...parseCommand(file, commandArguments), isSync: true});

// Convert `execaCommand(command)` into `execa(file, ...commandArguments)`
const parseCommand = (command, unusedArguments) => {
	if (unusedArguments.length > 0) {
		throw new TypeError(`The command and its arguments must be passed as a single string: ${command} ${unusedArguments}.`);
	}

	const [file, ...commandArguments] = parseCommandString(command);
	return {file, commandArguments};
};

// Convert `command` string into an array of file or arguments to pass to $`${...fileOrCommandArguments}`
const parseCommandString = command => {
	if (typeof command !== 'string') {
		throw new TypeError(`The command must be a string: ${String(command)}.`);
	}

	const trimmedCommand = command.trim();
	if (trimmedCommand === '') {
		return [];
	}

	const tokens = [];
	for (const token of trimmedCommand.split(SPACES_REGEXP)) {
		// Allow spaces to be escaped by a backslash if not meant as a delimiter
		const previousToken = tokens.at(-1);
		if (previousToken && previousToken.endsWith('\\')) {
			// Merge previous token with current one
			tokens[tokens.length - 1] = `${previousToken.slice(0, -1)} ${token}`;
		} else {
			tokens.push(token);
		}
	}

	return tokens;
};

const SPACES_REGEXP = / +/g;

// Sets `$.sync` and `$.s`
const setScriptSync = (boundExeca, createNested, boundOptions) => {
	boundExeca.sync = createNested(mapScriptSync, boundOptions);
	boundExeca.s = boundExeca.sync;
};

// Main logic for `$`
const mapScriptAsync = ({options}) => getScriptOptions(options);

// Main logic for `$.sync`
const mapScriptSync = ({options}) => ({...getScriptOptions(options), isSync: true});

// `$` is like `execa` but with script-friendly options: `{stdin: 'inherit', preferLocal: true}`
const getScriptOptions = options => ({options: {...getScriptStdinOption(options), ...options}});

const getScriptStdinOption = ({input, inputFile, stdio}) => input === undefined && inputFile === undefined && stdio === undefined
	? {stdin: 'inherit'}
	: {};

// When using $(...).pipe(...), most script-friendly options should apply to both commands.
// However, some options (like `stdin: 'inherit'`) would create issues with piping, i.e. cannot be deep.
const deepScriptOptions = {preferLocal: true};

const execa = createExeca(() => ({}));
createExeca(() => ({isSync: true}));
createExeca(mapCommandAsync);
createExeca(mapCommandSync);
createExeca(mapNode);
createExeca(mapScriptAsync, {}, deepScriptOptions, setScriptSync);

getIpcExport();

const netstat = async type => {
	const {stdout} = await execa('netstat', ['-anv', '-p', type]);
	return stdout;
};

const macos = async () => {
	const [tcp, udp] = await Promise.all([
		netstat('tcp'),
		netstat('udp'),
	]);

	// Column headers are on the second line
	const headerStart = tcp.indexOf('\n') + 1;
	const header = tcp.slice(headerStart, tcp.indexOf('\n', headerStart));

	return {
		stdout: [tcp, udp].join('\n'),
		addressColumn: 3,
		// Some versions of macOS print two extra columns for rxbytes and
		// txbytes before pid. Unfortunately headers can't be parsed because
		// they're space separated but some contain spaces, so we use this
		// heuristic to distinguish the two netstat versions.
		pidColumn: header.includes('rxbytes') ? 10 : 8,
	};
};

const linux = async () => {
	const {stdout} = await execa('ss', ['-tunlp']);
	return {stdout, addressColumn: 4, pidColumn: 6};
};

const windows = async () => {
	const {stdout} = await execa('netstat', ['-ano']);
	return {stdout, addressColumn: 1, pidColumn: 4};
};

const isProtocol = value => /^\s*(tcp|udp)/i.test(value);

const stripIpv6Brackets = host =>
	host?.startsWith('[') && host.endsWith(']') ? host.slice(1, -1) : host;

const normalizeHost = host => {
	const normalizedHost = stripIpv6Brackets(host);
	if (normalizedHost === 'localhost') {
		return '127.0.0.1';
	}

	if (normalizedHost === '::ffff:127.0.0.1') {
		return '127.0.0.1';
	}

	if (normalizedHost === '::') {
		return '*';
	}

	return normalizedHost;
};

const parsePid = pid => {
	if (typeof pid !== 'string') {
		return;
	}

	// Linux ss: users:(("node",pid=1337,fd=123))
	const linuxMatch = /pid=(?<pid>\d+)/.exec(pid);
	if (linuxMatch?.groups?.pid) {
		return Number.parseInt(linuxMatch.groups.pid, 10);
	}

	// MacOS netstat - handles both old format (macOS 15 and older) and new format (macOS 26+)
	// Old format: "1337" or ",1337" or ",pid=1337"
	// New format: "prog:1337" (macOS 26+)
	const macMatch = /(?:^|",|",pid=|[A-Za-z]+:)(?<pid>\d+)/.exec(pid);
	if (macMatch?.groups?.pid) {
		return Number.parseInt(macMatch.groups.pid, 10);
	}

	// Windows netstat -ano: 1337
	if (/^\d+$/.test(pid)) {
		return Number.parseInt(pid, 10);
	}
};

const parseAddress = address => {
	// Match "...:123" or "... .123" with the port at the end; keep host greedy to the last separator
	const match = /^(?<host>.+?)[.:](?<port>\d+)$/.exec(address);
	const rawHost = match?.groups?.host ?? address;
	const host = normalizeHost(rawHost);
	const port = match?.groups?.port ? Number.parseInt(match.groups.port, 10) : undefined;
	return {host, port};
};

const isLocalhostAddress = host => host === '127.0.0.1' || host === '::1';

const createHostFilter = host => {
	const normalizedHost = normalizeHost(host);
	if (normalizedHost === '*' || normalizedHost === '0.0.0.0' || normalizedHost === '::') {
		return {type: 'all'};
	}

	if (normalizedHost === undefined) {
		return {type: 'localhost'};
	}

	return {type: 'specific', host: normalizedHost};
};

const applyHostFilter = (lines, addressColumn, hostFilter) => {
	if (hostFilter.type === 'all') {
		return lines;
	}

	if (hostFilter.type === 'localhost') {
		return lines.filter(line => {
			const {host} = parseAddress(line[addressColumn]);
			return isLocalhostAddress(host);
		});
	}

	// Specific host
	return lines.filter(line => {
		const {host} = parseAddress(line[addressColumn]);
		return host === hostFilter.host;
	});
};

const validatePid = pid => {
	if (!Number.isInteger(pid)) {
		throw new TypeError(`Expected an integer, got ${typeof pid}`);
	}
};

const platformImplementations = {darwin: macos, linux};
const implementation = platformImplementations[process$2.platform] ?? windows;

const getList = async () => {
	const {stdout, addressColumn, pidColumn} = await implementation();

	const lines = stdout
		.split('\n')
		.filter(line => isProtocol(line))
		.map(line => line.match(/\S+/g) || []);
	return {lines, addressColumn, pidColumn};
};

const getPidsToPortsMap = async pids => {
	const resultMap = new Map(pids.map(pid => [pid, new Set()]));

	// Get all ports from all interfaces for pidToPorts - user wants to know ALL ports this PID uses
	for (const [port, pid] of await allPortsWithPid({host: '*'})) {
		resultMap.get(pid)?.add(port);
	}

	return resultMap;
};

async function pidToPorts(pid) {
	if (Array.isArray(pid)) {
		return getPidsToPortsMap(pid);
	}

	validatePid(pid);
	const resultMap = await getPidsToPortsMap([pid]);
	return resultMap.get(pid);
}

async function allPortsWithPid(options) {
	const {lines, addressColumn, pidColumn} = await getList();
	const hostFilter = createHostFilter(options?.host);

	const resultMap = new Map();

	// Apply host filtering to all lines, then extract ports
	const filteredLines = applyHostFilter(lines, addressColumn, hostFilter);

	for (const line of filteredLines) {
		const {port} = parseAddress(line[addressColumn]);
		const pid = parsePid(line[pidColumn]);

		if (port !== undefined && pid !== undefined) {
			resultMap.set(port, pid);
		}
	}

	return resultMap;
}

/**
 * Gets the port number that the process is listening on.
 * @returns The port number that the process is listening on, or undefined if the process is not listening on any port.
 * NOTE: Can't move this to @workflow/utils because it's being imported into @workflow/errors for RetryableError (inside workflow runtime)
 */
async function getPort() {
    try {
        const pid = process.pid;
        const ports = await pidToPorts(pid);
        if (!ports || ports.size === 0) {
            return undefined;
        }
        const smallest = Math.min(...ports);
        return smallest;
    }
    catch {
        // If port detection fails (e.g., `ss` command not available in production),
        // return undefined and fall back to default port
        return undefined;
    }
}

// ============================================================
// Trace Context Propagation Utilities
// ============================================================
/**
 * Serializes the current trace context into a format that can be passed through queues
 * @returns A record of strings representing the trace context
 */
async function serializeTraceCarrier() {
    const otel = await OtelApi.value;
    if (!otel)
        return {};
    const carrier = {};
    // Inject the current context into the carrier
    otel.propagation.inject(otel.context.active(), carrier);
    return carrier;
}
/**
 * Deserializes trace context and returns a context that can be used to continue the trace
 * @param traceCarrier The serialized trace context
 * @returns OpenTelemetry context with the restored trace
 */
async function deserializeTraceCarrier(traceCarrier) {
    const otel = await OtelApi.value;
    if (!otel)
        return;
    // Extract the context from the carrier
    return otel.propagation.extract(otel.context.active(), traceCarrier);
}
/**
 * Runs a function within the context of a deserialized trace
 * @param traceCarrier The serialized trace carrier (optional)
 * @param fn The function to run within the trace context
 * @returns The result of the function
 */
async function withTraceContext(traceCarrier, fn) {
    if (!traceCarrier) {
        return fn();
    }
    const otel = await OtelApi.value;
    if (!otel)
        return fn();
    const extractedContext = await deserializeTraceCarrier(traceCarrier);
    if (!extractedContext) {
        return fn();
    }
    return otel.context.with(extractedContext, async () => await fn());
}
const OtelApi = once$1(async () => {
    try {
        return await import('./index_DqQ8k47W.mjs');
    }
    catch {
        console.warn('OpenTelemetry not available, tracing will be disabled');
        return null;
    }
});
const Tracer = once$1(async () => {
    const api = await OtelApi.value;
    if (!api)
        return null;
    return api.trace.getTracer('workflow');
});
async function trace(spanName, ...args) {
    const [tracer, otel] = await Promise.all([Tracer.value, OtelApi.value]);
    const { fn, opts } = typeof args[0] === 'function'
        ? { fn: args[0], opts: {} }
        : { fn: args[1], opts: args[0] };
    if (!fn)
        throw new Error('Function to trace must be provided');
    if (!tracer || !otel) {
        return await fn();
    }
    return tracer.startActiveSpan(spanName, opts, async (span) => {
        try {
            const result = await fn(span);
            span.setStatus({ code: otel.SpanStatusCode.OK });
            return result;
        }
        catch (e) {
            span.setStatus({
                code: otel.SpanStatusCode.ERROR,
                message: e.message,
            });
            throw e;
        }
        finally {
            span.end();
        }
    });
}
async function getSpanContextForTraceCarrier(carrier) {
    const [deserialized, otel] = await Promise.all([
        deserializeTraceCarrier(carrier),
        OtelApi.value,
    ]);
    if (!deserialized || !otel)
        return;
    return otel.trace.getSpanContext(deserialized);
}
async function getActiveSpan() {
    const otel = await OtelApi.value;
    if (!otel)
        return null;
    return otel.trace.getActiveSpan();
}

function createLogger(namespace) {
    const baseDebug = debug(`workflow:${namespace}`);
    const logger = (level) => {
        const levelDebug = baseDebug.extend(level);
        return (message, metadata) => {
            levelDebug(message, metadata);
            if (levelDebug.enabled) {
                getActiveSpan()
                    .then((span) => {
                    span?.addEvent(`${level}.${namespace}`, { message, ...metadata });
                })
                    .catch(() => {
                    // Silently ignore telemetry errors
                });
            }
        };
    };
    return {
        debug: logger('debug'),
        info: logger('info'),
        warn: logger('warn'),
        error: logger('error'),
    };
}
const stepLogger = createLogger('step');
const runtimeLogger = createLogger('runtime');
const webhookLogger = createLogger('webhook');
const eventsLogger = createLogger('events');
createLogger('adapter');

/**
 * Utils used by the bundler when transforming code
 */
const registeredSteps = new Map();
/**
 * Register a step function to be served in the server bundle
 */
function registerStepFunction(stepId, stepFn) {
    registeredSteps.set(stepId, stepFn);
}
/**
 * Find a registered step function by name
 */
function getStepFunction(stepId) {
    return registeredSteps.get(stepId);
}

/**
 * Creates a lazily-evaluated, memoized version of the provided function.
 *
 * The returned object exposes a `value` getter that calls `fn` only once,
 * caches its result, and returns the cached value on subsequent accesses.
 *
 * @typeParam T - The return type of the provided function.
 * @param fn - The function to be called once and whose result will be cached.
 * @returns An object with a `value` property that returns the memoized result of `fn`.
 */
function once(fn) {
    const result = {
        get value() {
            const value = fn();
            Object.defineProperty(result, 'value', { value });
            return value;
        },
    };
    return result;
}

const getDataDirFromEnv = () => {
    return process.env.WORKFLOW_EMBEDDED_DATA_DIR || '.workflow-data';
};
const DEFAULT_RESOLVE_DATA_OPTION$1 = 'all';
const getPortFromEnv = () => {
    const port = process.env.PORT;
    if (port) {
        return Number(port);
    }
    return undefined;
};
const config = once(() => {
    const dataDir = getDataDirFromEnv();
    const port = getPortFromEnv();
    return { dataDir, port };
});

// src/transports.ts
async function streamToBuffer$1(stream) {
  let totalLength = 0;
  const reader = stream.getReader();
  const chunks = [];
  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      chunks.push(value);
      totalLength += value.length;
    }
  } finally {
    reader.releaseLock();
  }
  return Buffer.concat(chunks, totalLength);
}
var JsonTransport$1 = class JsonTransport {
  contentType = "application/json";
  replacer;
  reviver;
  constructor(options = {}) {
    this.replacer = options.replacer;
    this.reviver = options.reviver;
  }
  serialize(value) {
    return Buffer.from(JSON.stringify(value, this.replacer), "utf8");
  }
  async deserialize(stream) {
    const buffer = await streamToBuffer$1(stream);
    return JSON.parse(buffer.toString("utf8"), this.reviver);
  }
};

// src/dev.ts
var devRouteHandlers$1 = /* @__PURE__ */ new Map();
var wildcardRouteHandlers$1 = /* @__PURE__ */ new Map();
function clearDevHandlers$1() {
  devRouteHandlers$1.clear();
  wildcardRouteHandlers$1.clear();
}
if (process.env.NODE_ENV === "test" || process.env.VITEST) {
  globalThis.__clearDevHandlers = clearDevHandlers$1;
}

// Event type enum
const EventTypeSchema = z$1.enum([
    'step_completed',
    'step_failed',
    'step_retrying',
    'step_started',
    'hook_created',
    'hook_received',
    'hook_disposed',
    'wait_created',
    'wait_completed',
    'workflow_completed',
    'workflow_failed',
    'workflow_started',
]);
// Base event schema with common properties
const BaseEventSchema = z$1.object({
    eventType: EventTypeSchema,
    correlationId: z$1.string().optional(),
});
// Event schemas (shared between creation requests and server responses)
const StepCompletedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('step_completed'),
    correlationId: z$1.string(),
    eventData: z$1.object({
        result: z$1.any(),
    }),
});
const StepFailedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('step_failed'),
    correlationId: z$1.string(),
    eventData: z$1.object({
        error: z$1.any(),
        stack: z$1.string().optional(),
        fatal: z$1.boolean().optional(),
    }),
});
// TODO: this is not actually used anywhere yet, we could remove it
// on client and server if needed
const StepRetryingEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('step_retrying'),
    correlationId: z$1.string(),
    eventData: z$1.object({
        attempt: z$1.number().min(1),
    }),
});
const StepStartedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('step_started'),
    correlationId: z$1.string(),
});
const HookCreatedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('hook_created'),
    correlationId: z$1.string(),
});
const HookReceivedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('hook_received'),
    correlationId: z$1.string(),
    eventData: z$1.object({
        payload: z$1.any(), // Serialized payload
    }),
});
const HookDisposedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('hook_disposed'),
    correlationId: z$1.string(),
});
const WaitCreatedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('wait_created'),
    correlationId: z$1.string(),
    eventData: z$1.object({
        resumeAt: z$1.coerce.date(),
    }),
});
const WaitCompletedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('wait_completed'),
    correlationId: z$1.string(),
});
// TODO: not used yet
const WorkflowCompletedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('workflow_completed'),
});
// TODO: not used yet
const WorkflowFailedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('workflow_failed'),
    eventData: z$1.object({
        error: z$1.any(),
    }),
});
// TODO: not used yet
const WorkflowStartedEventSchema = BaseEventSchema.extend({
    eventType: z$1.literal('workflow_started'),
});
// Discriminated union (used for both creation requests and server responses)
const CreateEventSchema = z$1.discriminatedUnion('eventType', [
    StepCompletedEventSchema,
    StepFailedEventSchema,
    StepRetryingEventSchema,
    StepStartedEventSchema,
    HookCreatedEventSchema,
    HookReceivedEventSchema,
    HookDisposedEventSchema,
    WaitCreatedEventSchema,
    WaitCompletedEventSchema,
    WorkflowCompletedEventSchema,
    WorkflowFailedEventSchema,
    WorkflowStartedEventSchema,
]);
// Server response include runId, eventId, and createdAt
const EventSchema = CreateEventSchema.and(z$1.object({
    runId: z$1.string(),
    eventId: z$1.string(),
    createdAt: z$1.coerce.date(),
}));

const zodJsonSchema = z$1.lazy(() => {
    return z$1.union([
        z$1.string(),
        z$1.number(),
        z$1.boolean(),
        z$1.null(),
        z$1.array(zodJsonSchema),
        z$1.record(z$1.string(), zodJsonSchema),
    ]);
});
// Shared schema for paginated responses
const PaginatedResponseSchema = (dataSchema) => z$1.object({
    data: z$1.array(dataSchema),
    cursor: z$1.string().nullable(),
    hasMore: z$1.boolean(),
});
/**
 * A standard error schema shape for propogating errors from runs and steps
 */
const StructuredErrorSchema = z$1.object({
    message: z$1.string(),
    stack: z$1.string().optional(),
    code: z$1.string().optional(), // TODO: currently unused. make this an enum maybe
});

// Hook schemas
const HookSchema = z$1.object({
    runId: z$1.string(),
    hookId: z$1.string(),
    token: z$1.string(),
    ownerId: z$1.string(),
    projectId: z$1.string(),
    environment: z$1.string(),
    metadata: zodJsonSchema.optional(),
    createdAt: z$1.coerce.date(),
});

const QueuePrefix = z$2.union([
    z$2.literal('__wkf_step_'),
    z$2.literal('__wkf_workflow_'),
]);
const ValidQueueName = z$2.templateLiteral([QueuePrefix, z$2.string()]);
const MessageId = z$2
    .string()
    .brand()
    .describe('A stored queue message ID');
/**
 * OpenTelemetry trace context for distributed tracing
 */
const TraceCarrierSchema$1 = z$2.record(z$2.string(), z$2.string());
const WorkflowInvokePayloadSchema$1 = z$2.object({
    runId: z$2.string(),
    traceCarrier: TraceCarrierSchema$1.optional(),
});
const StepInvokePayloadSchema$1 = z$2.object({
    workflowName: z$2.string(),
    workflowRunId: z$2.string(),
    workflowStartedAt: z$2.number(),
    stepId: z$2.string(),
    traceCarrier: TraceCarrierSchema$1.optional(),
});
const QueuePayloadSchema = z$2.union([
    WorkflowInvokePayloadSchema$1,
    StepInvokePayloadSchema$1,
]);

// Workflow run schemas
const WorkflowRunStatusSchema = z$1.enum([
    'pending',
    'running',
    'completed',
    'failed',
    'paused',
    'cancelled',
]);
/**
 * Base schema for the Workflow runs. Prefer using WorkflowRunSchema
 * which implements a discriminatedUnion for various states
 */
const WorkflowRunBaseSchema = z$1.object({
    runId: z$1.string(),
    status: WorkflowRunStatusSchema,
    deploymentId: z$1.string(),
    workflowName: z$1.string(),
    executionContext: z$1.record(z$1.string(), z$1.any()).optional(),
    input: z$1.array(z$1.any()),
    output: z$1.any().optional(),
    error: StructuredErrorSchema.optional(),
    startedAt: z$1.coerce.date().optional(),
    completedAt: z$1.coerce.date().optional(),
    createdAt: z$1.coerce.date(),
    updatedAt: z$1.coerce.date(),
});
// Discriminated union based on status
const WorkflowRunSchema = z$1.discriminatedUnion('status', [
    // Non-final states
    WorkflowRunBaseSchema.extend({
        status: z$1.enum(['pending', 'running', 'paused']),
        output: z$1.undefined(),
        error: z$1.undefined(),
        completedAt: z$1.undefined(),
    }),
    // Cancelled state
    WorkflowRunBaseSchema.extend({
        status: z$1.literal('cancelled'),
        output: z$1.undefined(),
        error: z$1.undefined(),
        completedAt: z$1.coerce.date(),
    }),
    // Completed state
    WorkflowRunBaseSchema.extend({
        status: z$1.literal('completed'),
        output: z$1.any(),
        error: z$1.undefined(),
        completedAt: z$1.coerce.date(),
    }),
    // Failed state
    WorkflowRunBaseSchema.extend({
        status: z$1.literal('failed'),
        output: z$1.undefined(),
        error: StructuredErrorSchema,
        completedAt: z$1.coerce.date(),
    }),
]);

// Step schemas
const StepStatusSchema = z$1.enum([
    'pending',
    'running',
    'completed',
    'failed',
    'cancelled',
]);
// TODO: implement a discriminated union here just like the run schema
const StepSchema = z$1.object({
    runId: z$1.string(),
    stepId: z$1.string(),
    stepName: z$1.string(),
    status: StepStatusSchema,
    input: z$1.array(z$1.any()),
    output: z$1.any().optional(),
    error: StructuredErrorSchema.optional(),
    attempt: z$1.number(),
    startedAt: z$1.coerce.date().optional(),
    completedAt: z$1.coerce.date().optional(),
    createdAt: z$1.coerce.date(),
    updatedAt: z$1.coerce.date(),
    retryAfter: z$1.coerce.date().optional(),
});

const ENCODING = "0123456789ABCDEFGHJKMNPQRSTVWXYZ"; // Crockford's Base32
const ENCODING_LEN = 32; // from ENCODING.length;
const RANDOM_LEN = 16;
const TIME_LEN = 10;
const TIME_MAX = 281474976710655; // from Math.pow(2, 48) - 1;

var ULIDErrorCode;
(function (ULIDErrorCode) {
    ULIDErrorCode["Base32IncorrectEncoding"] = "B32_ENC_INVALID";
    ULIDErrorCode["DecodeTimeInvalidCharacter"] = "DEC_TIME_CHAR";
    ULIDErrorCode["DecodeTimeValueMalformed"] = "DEC_TIME_MALFORMED";
    ULIDErrorCode["EncodeTimeNegative"] = "ENC_TIME_NEG";
    ULIDErrorCode["EncodeTimeSizeExceeded"] = "ENC_TIME_SIZE_EXCEED";
    ULIDErrorCode["EncodeTimeValueMalformed"] = "ENC_TIME_MALFORMED";
    ULIDErrorCode["PRNGDetectFailure"] = "PRNG_DETECT";
    ULIDErrorCode["ULIDInvalid"] = "ULID_INVALID";
    ULIDErrorCode["Unexpected"] = "UNEXPECTED";
    ULIDErrorCode["UUIDInvalid"] = "UUID_INVALID";
})(ULIDErrorCode || (ULIDErrorCode = {}));
class ULIDError extends Error {
    constructor(errorCode, message) {
        super(`${message} (${errorCode})`);
        this.name = "ULIDError";
        this.code = errorCode;
    }
}

function randomChar(prng) {
    // Currently PRNGs generate fractions from 0 to _less than_ 1, so no "%" is necessary.
    // However, just in case a future PRNG can generate 1,
    // we are applying "% ENCODING LEN" to wrap back to the first character
    const randomPosition = Math.floor(prng() * ENCODING_LEN) % ENCODING_LEN;
    return ENCODING.charAt(randomPosition);
}
function replaceCharAt(str, index, char) {
    if (index > str.length - 1) {
        return str;
    }
    return str.substr(0, index) + char + str.substr(index + 1);
}
function incrementBase32(str) {
    let done = undefined, index = str.length, char, charIndex, output = str;
    const maxCharIndex = ENCODING_LEN - 1;
    while (!done && index-- >= 0) {
        char = output[index];
        charIndex = ENCODING.indexOf(char);
        if (charIndex === -1) {
            throw new ULIDError(ULIDErrorCode.Base32IncorrectEncoding, "Incorrectly encoded string");
        }
        if (charIndex === maxCharIndex) {
            output = replaceCharAt(output, index, ENCODING[0]);
            continue;
        }
        done = replaceCharAt(output, index, ENCODING[charIndex + 1]);
    }
    if (typeof done === "string") {
        return done;
    }
    throw new ULIDError(ULIDErrorCode.Base32IncorrectEncoding, "Failed incrementing string");
}

/**
 * Decode time from a ULID
 * @param id The ULID
 * @returns The decoded timestamp
 */
function decodeTime(id) {
    if (id.length !== TIME_LEN + RANDOM_LEN) {
        throw new ULIDError(ULIDErrorCode.DecodeTimeValueMalformed, "Malformed ULID");
    }
    const time = id
        .substr(0, TIME_LEN)
        .toUpperCase()
        .split("")
        .reverse()
        .reduce((carry, char, index) => {
        const encodingIndex = ENCODING.indexOf(char);
        if (encodingIndex === -1) {
            throw new ULIDError(ULIDErrorCode.DecodeTimeInvalidCharacter, `Time decode error: Invalid character: ${char}`);
        }
        return (carry += encodingIndex * Math.pow(ENCODING_LEN, index));
    }, 0);
    if (time > TIME_MAX) {
        throw new ULIDError(ULIDErrorCode.DecodeTimeValueMalformed, `Malformed ULID: timestamp too large: ${time}`);
    }
    return time;
}
/**
 * Detect the best PRNG (pseudo-random number generator)
 * @param root The root to check from (global/window)
 * @returns The PRNG function
 */
function detectPRNG(root) {
    const rootLookup = detectRoot();
    const globalCrypto = (rootLookup && (rootLookup.crypto || rootLookup.msCrypto)) ||
        (typeof crypto !== "undefined" ? crypto : null);
    if (typeof globalCrypto?.getRandomValues === "function") {
        return () => {
            const buffer = new Uint8Array(1);
            globalCrypto.getRandomValues(buffer);
            return buffer[0] / 0xff;
        };
    }
    else if (typeof globalCrypto?.randomBytes === "function") {
        return () => globalCrypto.randomBytes(1).readUInt8() / 0xff;
    }
    else if (crypto?.randomBytes) {
        return () => crypto.randomBytes(1).readUInt8() / 0xff;
    }
    throw new ULIDError(ULIDErrorCode.PRNGDetectFailure, "Failed to find a reliable PRNG");
}
function detectRoot() {
    if (inWebWorker())
        return self;
    if (typeof window !== "undefined") {
        return window;
    }
    if (typeof global !== "undefined") {
        return global;
    }
    if (typeof globalThis !== "undefined") {
        return globalThis;
    }
    return null;
}
function encodeRandom(len, prng) {
    let str = "";
    for (; len > 0; len--) {
        str = randomChar(prng) + str;
    }
    return str;
}
/**
 * Encode the time portion of a ULID
 * @param now The current timestamp
 * @param len Length to generate
 * @returns The encoded time
 */
function encodeTime(now, len = TIME_LEN) {
    if (isNaN(now)) {
        throw new ULIDError(ULIDErrorCode.EncodeTimeValueMalformed, `Time must be a number: ${now}`);
    }
    else if (now > TIME_MAX) {
        throw new ULIDError(ULIDErrorCode.EncodeTimeSizeExceeded, `Cannot encode a time larger than ${TIME_MAX}: ${now}`);
    }
    else if (now < 0) {
        throw new ULIDError(ULIDErrorCode.EncodeTimeNegative, `Time must be positive: ${now}`);
    }
    else if (Number.isInteger(now) === false) {
        throw new ULIDError(ULIDErrorCode.EncodeTimeValueMalformed, `Time must be an integer: ${now}`);
    }
    let mod, str = "";
    for (let currentLen = len; currentLen > 0; currentLen--) {
        mod = now % ENCODING_LEN;
        str = ENCODING.charAt(mod) + str;
        now = (now - mod) / ENCODING_LEN;
    }
    return str;
}
function inWebWorker() {
    // @ts-ignore
    return typeof WorkerGlobalScope !== "undefined" && self instanceof WorkerGlobalScope;
}
/**
 * Create a ULID factory to generate monotonically-increasing
 *  ULIDs
 * @param prng The PRNG to use
 * @returns A ulid factory
 * @example
 *  const ulid = monotonicFactory();
 *  ulid(); // "01HNZXD07M5CEN5XA66EMZSRZW"
 */
function monotonicFactory(prng) {
    const currentPRNG = prng || detectPRNG();
    let lastTime = 0, lastRandom;
    return function _ulid(seedTime) {
        const seed = !seedTime || isNaN(seedTime) ? Date.now() : seedTime;
        if (seed <= lastTime) {
            const incrementedRandom = (lastRandom = incrementBase32(lastRandom));
            return encodeTime(lastTime, TIME_LEN) + incrementedRandom;
        }
        lastTime = seed;
        const newRandom = (lastRandom = encodeRandom(RANDOM_LEN, currentPRNG));
        return encodeTime(seed, TIME_LEN) + newRandom;
    };
}

var undici = {};

var symbols$4;
var hasRequiredSymbols$4;

function requireSymbols$4 () {
	if (hasRequiredSymbols$4) return symbols$4;
	hasRequiredSymbols$4 = 1;
	symbols$4 = {
	  kClose: Symbol('close'),
	  kDestroy: Symbol('destroy'),
	  kDispatch: Symbol('dispatch'),
	  kUrl: Symbol('url'),
	  kWriting: Symbol('writing'),
	  kResuming: Symbol('resuming'),
	  kQueue: Symbol('queue'),
	  kConnect: Symbol('connect'),
	  kConnecting: Symbol('connecting'),
	  kKeepAliveDefaultTimeout: Symbol('default keep alive timeout'),
	  kKeepAliveMaxTimeout: Symbol('max keep alive timeout'),
	  kKeepAliveTimeoutThreshold: Symbol('keep alive timeout threshold'),
	  kKeepAliveTimeoutValue: Symbol('keep alive timeout'),
	  kKeepAlive: Symbol('keep alive'),
	  kHeadersTimeout: Symbol('headers timeout'),
	  kBodyTimeout: Symbol('body timeout'),
	  kServerName: Symbol('server name'),
	  kLocalAddress: Symbol('local address'),
	  kHost: Symbol('host'),
	  kNoRef: Symbol('no ref'),
	  kBodyUsed: Symbol('used'),
	  kBody: Symbol('abstracted request body'),
	  kRunning: Symbol('running'),
	  kBlocking: Symbol('blocking'),
	  kPending: Symbol('pending'),
	  kSize: Symbol('size'),
	  kBusy: Symbol('busy'),
	  kQueued: Symbol('queued'),
	  kFree: Symbol('free'),
	  kConnected: Symbol('connected'),
	  kClosed: Symbol('closed'),
	  kNeedDrain: Symbol('need drain'),
	  kReset: Symbol('reset'),
	  kDestroyed: Symbol.for('nodejs.stream.destroyed'),
	  kResume: Symbol('resume'),
	  kOnError: Symbol('on error'),
	  kMaxHeadersSize: Symbol('max headers size'),
	  kRunningIdx: Symbol('running index'),
	  kPendingIdx: Symbol('pending index'),
	  kError: Symbol('error'),
	  kClients: Symbol('clients'),
	  kClient: Symbol('client'),
	  kParser: Symbol('parser'),
	  kOnDestroyed: Symbol('destroy callbacks'),
	  kPipelining: Symbol('pipelining'),
	  kSocket: Symbol('socket'),
	  kHostHeader: Symbol('host header'),
	  kConnector: Symbol('connector'),
	  kStrictContentLength: Symbol('strict content length'),
	  kMaxRedirections: Symbol('maxRedirections'),
	  kMaxRequests: Symbol('maxRequestsPerClient'),
	  kProxy: Symbol('proxy agent options'),
	  kCounter: Symbol('socket request counter'),
	  kInterceptors: Symbol('dispatch interceptors'),
	  kMaxResponseSize: Symbol('max response size'),
	  kHTTP2Session: Symbol('http2Session'),
	  kHTTP2SessionState: Symbol('http2Session state'),
	  kRetryHandlerDefaultRetry: Symbol('retry agent default retry'),
	  kConstruct: Symbol('constructable'),
	  kListeners: Symbol('listeners'),
	  kHTTPContext: Symbol('http context'),
	  kMaxConcurrentStreams: Symbol('max concurrent streams'),
	  kNoProxyAgent: Symbol('no proxy agent'),
	  kHttpProxyAgent: Symbol('http proxy agent'),
	  kHttpsProxyAgent: Symbol('https proxy agent')
	};
	return symbols$4;
}

var errors;
var hasRequiredErrors;

function requireErrors () {
	if (hasRequiredErrors) return errors;
	hasRequiredErrors = 1;

	class UndiciError extends Error {
	  constructor (message) {
	    super(message);
	    this.name = 'UndiciError';
	    this.code = 'UND_ERR';
	  }
	}

	class ConnectTimeoutError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'ConnectTimeoutError';
	    this.message = message || 'Connect Timeout Error';
	    this.code = 'UND_ERR_CONNECT_TIMEOUT';
	  }
	}

	class HeadersTimeoutError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'HeadersTimeoutError';
	    this.message = message || 'Headers Timeout Error';
	    this.code = 'UND_ERR_HEADERS_TIMEOUT';
	  }
	}

	class HeadersOverflowError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'HeadersOverflowError';
	    this.message = message || 'Headers Overflow Error';
	    this.code = 'UND_ERR_HEADERS_OVERFLOW';
	  }
	}

	class BodyTimeoutError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'BodyTimeoutError';
	    this.message = message || 'Body Timeout Error';
	    this.code = 'UND_ERR_BODY_TIMEOUT';
	  }
	}

	class ResponseStatusCodeError extends UndiciError {
	  constructor (message, statusCode, headers, body) {
	    super(message);
	    this.name = 'ResponseStatusCodeError';
	    this.message = message || 'Response Status Code Error';
	    this.code = 'UND_ERR_RESPONSE_STATUS_CODE';
	    this.body = body;
	    this.status = statusCode;
	    this.statusCode = statusCode;
	    this.headers = headers;
	  }
	}

	class InvalidArgumentError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'InvalidArgumentError';
	    this.message = message || 'Invalid Argument Error';
	    this.code = 'UND_ERR_INVALID_ARG';
	  }
	}

	class InvalidReturnValueError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'InvalidReturnValueError';
	    this.message = message || 'Invalid Return Value Error';
	    this.code = 'UND_ERR_INVALID_RETURN_VALUE';
	  }
	}

	class AbortError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'AbortError';
	    this.message = message || 'The operation was aborted';
	  }
	}

	class RequestAbortedError extends AbortError {
	  constructor (message) {
	    super(message);
	    this.name = 'AbortError';
	    this.message = message || 'Request aborted';
	    this.code = 'UND_ERR_ABORTED';
	  }
	}

	class InformationalError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'InformationalError';
	    this.message = message || 'Request information';
	    this.code = 'UND_ERR_INFO';
	  }
	}

	class RequestContentLengthMismatchError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'RequestContentLengthMismatchError';
	    this.message = message || 'Request body length does not match content-length header';
	    this.code = 'UND_ERR_REQ_CONTENT_LENGTH_MISMATCH';
	  }
	}

	class ResponseContentLengthMismatchError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'ResponseContentLengthMismatchError';
	    this.message = message || 'Response body length does not match content-length header';
	    this.code = 'UND_ERR_RES_CONTENT_LENGTH_MISMATCH';
	  }
	}

	class ClientDestroyedError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'ClientDestroyedError';
	    this.message = message || 'The client is destroyed';
	    this.code = 'UND_ERR_DESTROYED';
	  }
	}

	class ClientClosedError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'ClientClosedError';
	    this.message = message || 'The client is closed';
	    this.code = 'UND_ERR_CLOSED';
	  }
	}

	class SocketError extends UndiciError {
	  constructor (message, socket) {
	    super(message);
	    this.name = 'SocketError';
	    this.message = message || 'Socket error';
	    this.code = 'UND_ERR_SOCKET';
	    this.socket = socket;
	  }
	}

	class NotSupportedError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'NotSupportedError';
	    this.message = message || 'Not supported error';
	    this.code = 'UND_ERR_NOT_SUPPORTED';
	  }
	}

	class BalancedPoolMissingUpstreamError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'MissingUpstreamError';
	    this.message = message || 'No upstream has been added to the BalancedPool';
	    this.code = 'UND_ERR_BPL_MISSING_UPSTREAM';
	  }
	}

	class HTTPParserError extends Error {
	  constructor (message, code, data) {
	    super(message);
	    this.name = 'HTTPParserError';
	    this.code = code ? `HPE_${code}` : undefined;
	    this.data = data ? data.toString() : undefined;
	  }
	}

	class ResponseExceededMaxSizeError extends UndiciError {
	  constructor (message) {
	    super(message);
	    this.name = 'ResponseExceededMaxSizeError';
	    this.message = message || 'Response content exceeded max size';
	    this.code = 'UND_ERR_RES_EXCEEDED_MAX_SIZE';
	  }
	}

	class RequestRetryError extends UndiciError {
	  constructor (message, code, { headers, data }) {
	    super(message);
	    this.name = 'RequestRetryError';
	    this.message = message || 'Request retry error';
	    this.code = 'UND_ERR_REQ_RETRY';
	    this.statusCode = code;
	    this.data = data;
	    this.headers = headers;
	  }
	}

	class SecureProxyConnectionError extends UndiciError {
	  constructor (cause, message, options) {
	    super(message, { cause, ...(options ?? {}) });
	    this.name = 'SecureProxyConnectionError';
	    this.message = message || 'Secure Proxy Connection failed';
	    this.code = 'UND_ERR_PRX_TLS';
	    this.cause = cause;
	  }
	}

	errors = {
	  AbortError,
	  HTTPParserError,
	  UndiciError,
	  HeadersTimeoutError,
	  HeadersOverflowError,
	  BodyTimeoutError,
	  RequestContentLengthMismatchError,
	  ConnectTimeoutError,
	  ResponseStatusCodeError,
	  InvalidArgumentError,
	  InvalidReturnValueError,
	  RequestAbortedError,
	  ClientDestroyedError,
	  ClientClosedError,
	  InformationalError,
	  SocketError,
	  NotSupportedError,
	  ResponseContentLengthMismatchError,
	  BalancedPoolMissingUpstreamError,
	  ResponseExceededMaxSizeError,
	  RequestRetryError,
	  SecureProxyConnectionError
	};
	return errors;
}

var constants$4;
var hasRequiredConstants$4;

function requireConstants$4 () {
	if (hasRequiredConstants$4) return constants$4;
	hasRequiredConstants$4 = 1;

	/** @type {Record<string, string | undefined>} */
	const headerNameLowerCasedRecord = {};

	// https://developer.mozilla.org/docs/Web/HTTP/Headers
	const wellknownHeaderNames = [
	  'Accept',
	  'Accept-Encoding',
	  'Accept-Language',
	  'Accept-Ranges',
	  'Access-Control-Allow-Credentials',
	  'Access-Control-Allow-Headers',
	  'Access-Control-Allow-Methods',
	  'Access-Control-Allow-Origin',
	  'Access-Control-Expose-Headers',
	  'Access-Control-Max-Age',
	  'Access-Control-Request-Headers',
	  'Access-Control-Request-Method',
	  'Age',
	  'Allow',
	  'Alt-Svc',
	  'Alt-Used',
	  'Authorization',
	  'Cache-Control',
	  'Clear-Site-Data',
	  'Connection',
	  'Content-Disposition',
	  'Content-Encoding',
	  'Content-Language',
	  'Content-Length',
	  'Content-Location',
	  'Content-Range',
	  'Content-Security-Policy',
	  'Content-Security-Policy-Report-Only',
	  'Content-Type',
	  'Cookie',
	  'Cross-Origin-Embedder-Policy',
	  'Cross-Origin-Opener-Policy',
	  'Cross-Origin-Resource-Policy',
	  'Date',
	  'Device-Memory',
	  'Downlink',
	  'ECT',
	  'ETag',
	  'Expect',
	  'Expect-CT',
	  'Expires',
	  'Forwarded',
	  'From',
	  'Host',
	  'If-Match',
	  'If-Modified-Since',
	  'If-None-Match',
	  'If-Range',
	  'If-Unmodified-Since',
	  'Keep-Alive',
	  'Last-Modified',
	  'Link',
	  'Location',
	  'Max-Forwards',
	  'Origin',
	  'Permissions-Policy',
	  'Pragma',
	  'Proxy-Authenticate',
	  'Proxy-Authorization',
	  'RTT',
	  'Range',
	  'Referer',
	  'Referrer-Policy',
	  'Refresh',
	  'Retry-After',
	  'Sec-WebSocket-Accept',
	  'Sec-WebSocket-Extensions',
	  'Sec-WebSocket-Key',
	  'Sec-WebSocket-Protocol',
	  'Sec-WebSocket-Version',
	  'Server',
	  'Server-Timing',
	  'Service-Worker-Allowed',
	  'Service-Worker-Navigation-Preload',
	  'Set-Cookie',
	  'SourceMap',
	  'Strict-Transport-Security',
	  'Supports-Loading-Mode',
	  'TE',
	  'Timing-Allow-Origin',
	  'Trailer',
	  'Transfer-Encoding',
	  'Upgrade',
	  'Upgrade-Insecure-Requests',
	  'User-Agent',
	  'Vary',
	  'Via',
	  'WWW-Authenticate',
	  'X-Content-Type-Options',
	  'X-DNS-Prefetch-Control',
	  'X-Frame-Options',
	  'X-Permitted-Cross-Domain-Policies',
	  'X-Powered-By',
	  'X-Requested-With',
	  'X-XSS-Protection'
	];

	for (let i = 0; i < wellknownHeaderNames.length; ++i) {
	  const key = wellknownHeaderNames[i];
	  const lowerCasedKey = key.toLowerCase();
	  headerNameLowerCasedRecord[key] = headerNameLowerCasedRecord[lowerCasedKey] =
	    lowerCasedKey;
	}

	// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.
	Object.setPrototypeOf(headerNameLowerCasedRecord, null);

	constants$4 = {
	  wellknownHeaderNames,
	  headerNameLowerCasedRecord
	};
	return constants$4;
}

var tree_1;
var hasRequiredTree;

function requireTree () {
	if (hasRequiredTree) return tree_1;
	hasRequiredTree = 1;

	const {
	  wellknownHeaderNames,
	  headerNameLowerCasedRecord
	} = requireConstants$4();

	class TstNode {
	  /** @type {any} */
	  value = null
	  /** @type {null | TstNode} */
	  left = null
	  /** @type {null | TstNode} */
	  middle = null
	  /** @type {null | TstNode} */
	  right = null
	  /** @type {number} */
	  code
	  /**
	   * @param {string} key
	   * @param {any} value
	   * @param {number} index
	   */
	  constructor (key, value, index) {
	    if (index === undefined || index >= key.length) {
	      throw new TypeError('Unreachable')
	    }
	    const code = this.code = key.charCodeAt(index);
	    // check code is ascii string
	    if (code > 0x7F) {
	      throw new TypeError('key must be ascii string')
	    }
	    if (key.length !== ++index) {
	      this.middle = new TstNode(key, value, index);
	    } else {
	      this.value = value;
	    }
	  }

	  /**
	   * @param {string} key
	   * @param {any} value
	   */
	  add (key, value) {
	    const length = key.length;
	    if (length === 0) {
	      throw new TypeError('Unreachable')
	    }
	    let index = 0;
	    let node = this;
	    while (true) {
	      const code = key.charCodeAt(index);
	      // check code is ascii string
	      if (code > 0x7F) {
	        throw new TypeError('key must be ascii string')
	      }
	      if (node.code === code) {
	        if (length === ++index) {
	          node.value = value;
	          break
	        } else if (node.middle !== null) {
	          node = node.middle;
	        } else {
	          node.middle = new TstNode(key, value, index);
	          break
	        }
	      } else if (node.code < code) {
	        if (node.left !== null) {
	          node = node.left;
	        } else {
	          node.left = new TstNode(key, value, index);
	          break
	        }
	      } else if (node.right !== null) {
	        node = node.right;
	      } else {
	        node.right = new TstNode(key, value, index);
	        break
	      }
	    }
	  }

	  /**
	   * @param {Uint8Array} key
	   * @return {TstNode | null}
	   */
	  search (key) {
	    const keylength = key.length;
	    let index = 0;
	    let node = this;
	    while (node !== null && index < keylength) {
	      let code = key[index];
	      // A-Z
	      // First check if it is bigger than 0x5a.
	      // Lowercase letters have higher char codes than uppercase ones.
	      // Also we assume that headers will mostly contain lowercase characters.
	      if (code <= 0x5a && code >= 0x41) {
	        // Lowercase for uppercase.
	        code |= 32;
	      }
	      while (node !== null) {
	        if (code === node.code) {
	          if (keylength === ++index) {
	            // Returns Node since it is the last key.
	            return node
	          }
	          node = node.middle;
	          break
	        }
	        node = node.code < code ? node.left : node.right;
	      }
	    }
	    return null
	  }
	}

	class TernarySearchTree {
	  /** @type {TstNode | null} */
	  node = null

	  /**
	   * @param {string} key
	   * @param {any} value
	   * */
	  insert (key, value) {
	    if (this.node === null) {
	      this.node = new TstNode(key, value, 0);
	    } else {
	      this.node.add(key, value);
	    }
	  }

	  /**
	   * @param {Uint8Array} key
	   * @return {any}
	   */
	  lookup (key) {
	    return this.node?.search(key)?.value ?? null
	  }
	}

	const tree = new TernarySearchTree();

	for (let i = 0; i < wellknownHeaderNames.length; ++i) {
	  const key = headerNameLowerCasedRecord[wellknownHeaderNames[i]];
	  tree.insert(key, key);
	}

	tree_1 = {
	  TernarySearchTree,
	  tree
	};
	return tree_1;
}

var util$7;
var hasRequiredUtil$7;

function requireUtil$7 () {
	if (hasRequiredUtil$7) return util$7;
	hasRequiredUtil$7 = 1;

	const assert = require$$0$4;
	const { kDestroyed, kBodyUsed, kListeners, kBody } = requireSymbols$4();
	const { IncomingMessage } = require$$2;
	const stream = require$$0$5;
	const net = require$$4;
	const { Blob } = require$$0$3;
	const nodeUtil = require$$0$6;
	const { stringify } = require$$7;
	const { EventEmitter: EE } = require$$8;
	const { InvalidArgumentError } = requireErrors();
	const { headerNameLowerCasedRecord } = requireConstants$4();
	const { tree } = requireTree();

	const [nodeMajor, nodeMinor] = process.versions.node.split('.').map(v => Number(v));

	class BodyAsyncIterable {
	  constructor (body) {
	    this[kBody] = body;
	    this[kBodyUsed] = false;
	  }

	  async * [Symbol.asyncIterator] () {
	    assert(!this[kBodyUsed], 'disturbed');
	    this[kBodyUsed] = true;
	    yield * this[kBody];
	  }
	}

	function wrapRequestBody (body) {
	  if (isStream(body)) {
	    // TODO (fix): Provide some way for the user to cache the file to e.g. /tmp
	    // so that it can be dispatched again?
	    // TODO (fix): Do we need 100-expect support to provide a way to do this properly?
	    if (bodyLength(body) === 0) {
	      body
	        .on('data', function () {
	          assert(false);
	        });
	    }

	    if (typeof body.readableDidRead !== 'boolean') {
	      body[kBodyUsed] = false;
	      EE.prototype.on.call(body, 'data', function () {
	        this[kBodyUsed] = true;
	      });
	    }

	    return body
	  } else if (body && typeof body.pipeTo === 'function') {
	    // TODO (fix): We can't access ReadableStream internal state
	    // to determine whether or not it has been disturbed. This is just
	    // a workaround.
	    return new BodyAsyncIterable(body)
	  } else if (
	    body &&
	    typeof body !== 'string' &&
	    !ArrayBuffer.isView(body) &&
	    isIterable(body)
	  ) {
	    // TODO: Should we allow re-using iterable if !this.opts.idempotent
	    // or through some other flag?
	    return new BodyAsyncIterable(body)
	  } else {
	    return body
	  }
	}

	function nop () {}

	function isStream (obj) {
	  return obj && typeof obj === 'object' && typeof obj.pipe === 'function' && typeof obj.on === 'function'
	}

	// based on https://github.com/node-fetch/fetch-blob/blob/8ab587d34080de94140b54f07168451e7d0b655e/index.js#L229-L241 (MIT License)
	function isBlobLike (object) {
	  if (object === null) {
	    return false
	  } else if (object instanceof Blob) {
	    return true
	  } else if (typeof object !== 'object') {
	    return false
	  } else {
	    const sTag = object[Symbol.toStringTag];

	    return (sTag === 'Blob' || sTag === 'File') && (
	      ('stream' in object && typeof object.stream === 'function') ||
	      ('arrayBuffer' in object && typeof object.arrayBuffer === 'function')
	    )
	  }
	}

	function buildURL (url, queryParams) {
	  if (url.includes('?') || url.includes('#')) {
	    throw new Error('Query params cannot be passed when url already contains "?" or "#".')
	  }

	  const stringified = stringify(queryParams);

	  if (stringified) {
	    url += '?' + stringified;
	  }

	  return url
	}

	function isValidPort (port) {
	  const value = parseInt(port, 10);
	  return (
	    value === Number(port) &&
	    value >= 0 &&
	    value <= 65535
	  )
	}

	function isHttpOrHttpsPrefixed (value) {
	  return (
	    value != null &&
	    value[0] === 'h' &&
	    value[1] === 't' &&
	    value[2] === 't' &&
	    value[3] === 'p' &&
	    (
	      value[4] === ':' ||
	      (
	        value[4] === 's' &&
	        value[5] === ':'
	      )
	    )
	  )
	}

	function parseURL (url) {
	  if (typeof url === 'string') {
	    url = new URL(url);

	    if (!isHttpOrHttpsPrefixed(url.origin || url.protocol)) {
	      throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')
	    }

	    return url
	  }

	  if (!url || typeof url !== 'object') {
	    throw new InvalidArgumentError('Invalid URL: The URL argument must be a non-null object.')
	  }

	  if (!(url instanceof URL)) {
	    if (url.port != null && url.port !== '' && isValidPort(url.port) === false) {
	      throw new InvalidArgumentError('Invalid URL: port must be a valid integer or a string representation of an integer.')
	    }

	    if (url.path != null && typeof url.path !== 'string') {
	      throw new InvalidArgumentError('Invalid URL path: the path must be a string or null/undefined.')
	    }

	    if (url.pathname != null && typeof url.pathname !== 'string') {
	      throw new InvalidArgumentError('Invalid URL pathname: the pathname must be a string or null/undefined.')
	    }

	    if (url.hostname != null && typeof url.hostname !== 'string') {
	      throw new InvalidArgumentError('Invalid URL hostname: the hostname must be a string or null/undefined.')
	    }

	    if (url.origin != null && typeof url.origin !== 'string') {
	      throw new InvalidArgumentError('Invalid URL origin: the origin must be a string or null/undefined.')
	    }

	    if (!isHttpOrHttpsPrefixed(url.origin || url.protocol)) {
	      throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')
	    }

	    const port = url.port != null
	      ? url.port
	      : (url.protocol === 'https:' ? 443 : 80);
	    let origin = url.origin != null
	      ? url.origin
	      : `${url.protocol || ''}//${url.hostname || ''}:${port}`;
	    let path = url.path != null
	      ? url.path
	      : `${url.pathname || ''}${url.search || ''}`;

	    if (origin[origin.length - 1] === '/') {
	      origin = origin.slice(0, origin.length - 1);
	    }

	    if (path && path[0] !== '/') {
	      path = `/${path}`;
	    }
	    // new URL(path, origin) is unsafe when `path` contains an absolute URL
	    // From https://developer.mozilla.org/en-US/docs/Web/API/URL/URL:
	    // If first parameter is a relative URL, second param is required, and will be used as the base URL.
	    // If first parameter is an absolute URL, a given second param will be ignored.
	    return new URL(`${origin}${path}`)
	  }

	  if (!isHttpOrHttpsPrefixed(url.origin || url.protocol)) {
	    throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')
	  }

	  return url
	}

	function parseOrigin (url) {
	  url = parseURL(url);

	  if (url.pathname !== '/' || url.search || url.hash) {
	    throw new InvalidArgumentError('invalid url')
	  }

	  return url
	}

	function getHostname (host) {
	  if (host[0] === '[') {
	    const idx = host.indexOf(']');

	    assert(idx !== -1);
	    return host.substring(1, idx)
	  }

	  const idx = host.indexOf(':');
	  if (idx === -1) return host

	  return host.substring(0, idx)
	}

	// IP addresses are not valid server names per RFC6066
	// > Currently, the only server names supported are DNS hostnames
	function getServerName (host) {
	  if (!host) {
	    return null
	  }

	  assert.strictEqual(typeof host, 'string');

	  const servername = getHostname(host);
	  if (net.isIP(servername)) {
	    return ''
	  }

	  return servername
	}

	function deepClone (obj) {
	  return JSON.parse(JSON.stringify(obj))
	}

	function isAsyncIterable (obj) {
	  return !!(obj != null && typeof obj[Symbol.asyncIterator] === 'function')
	}

	function isIterable (obj) {
	  return !!(obj != null && (typeof obj[Symbol.iterator] === 'function' || typeof obj[Symbol.asyncIterator] === 'function'))
	}

	function bodyLength (body) {
	  if (body == null) {
	    return 0
	  } else if (isStream(body)) {
	    const state = body._readableState;
	    return state && state.objectMode === false && state.ended === true && Number.isFinite(state.length)
	      ? state.length
	      : null
	  } else if (isBlobLike(body)) {
	    return body.size != null ? body.size : null
	  } else if (isBuffer(body)) {
	    return body.byteLength
	  }

	  return null
	}

	function isDestroyed (body) {
	  return body && !!(body.destroyed || body[kDestroyed] || (stream.isDestroyed?.(body)))
	}

	function destroy (stream, err) {
	  if (stream == null || !isStream(stream) || isDestroyed(stream)) {
	    return
	  }

	  if (typeof stream.destroy === 'function') {
	    if (Object.getPrototypeOf(stream).constructor === IncomingMessage) {
	      // See: https://github.com/nodejs/node/pull/38505/files
	      stream.socket = null;
	    }

	    stream.destroy(err);
	  } else if (err) {
	    queueMicrotask(() => {
	      stream.emit('error', err);
	    });
	  }

	  if (stream.destroyed !== true) {
	    stream[kDestroyed] = true;
	  }
	}

	const KEEPALIVE_TIMEOUT_EXPR = /timeout=(\d+)/;
	function parseKeepAliveTimeout (val) {
	  const m = val.toString().match(KEEPALIVE_TIMEOUT_EXPR);
	  return m ? parseInt(m[1], 10) * 1000 : null
	}

	/**
	 * Retrieves a header name and returns its lowercase value.
	 * @param {string | Buffer} value Header name
	 * @returns {string}
	 */
	function headerNameToString (value) {
	  return typeof value === 'string'
	    ? headerNameLowerCasedRecord[value] ?? value.toLowerCase()
	    : tree.lookup(value) ?? value.toString('latin1').toLowerCase()
	}

	/**
	 * Receive the buffer as a string and return its lowercase value.
	 * @param {Buffer} value Header name
	 * @returns {string}
	 */
	function bufferToLowerCasedHeaderName (value) {
	  return tree.lookup(value) ?? value.toString('latin1').toLowerCase()
	}

	/**
	 * @param {Record<string, string | string[]> | (Buffer | string | (Buffer | string)[])[]} headers
	 * @param {Record<string, string | string[]>} [obj]
	 * @returns {Record<string, string | string[]>}
	 */
	function parseHeaders (headers, obj) {
	  if (obj === undefined) obj = {};
	  for (let i = 0; i < headers.length; i += 2) {
	    const key = headerNameToString(headers[i]);
	    let val = obj[key];

	    if (val) {
	      if (typeof val === 'string') {
	        val = [val];
	        obj[key] = val;
	      }
	      val.push(headers[i + 1].toString('utf8'));
	    } else {
	      const headersValue = headers[i + 1];
	      if (typeof headersValue === 'string') {
	        obj[key] = headersValue;
	      } else {
	        obj[key] = Array.isArray(headersValue) ? headersValue.map(x => x.toString('utf8')) : headersValue.toString('utf8');
	      }
	    }
	  }

	  // See https://github.com/nodejs/node/pull/46528
	  if ('content-length' in obj && 'content-disposition' in obj) {
	    obj['content-disposition'] = Buffer.from(obj['content-disposition']).toString('latin1');
	  }

	  return obj
	}

	function parseRawHeaders (headers) {
	  const len = headers.length;
	  const ret = new Array(len);

	  let hasContentLength = false;
	  let contentDispositionIdx = -1;
	  let key;
	  let val;
	  let kLen = 0;

	  for (let n = 0; n < headers.length; n += 2) {
	    key = headers[n];
	    val = headers[n + 1];

	    typeof key !== 'string' && (key = key.toString());
	    typeof val !== 'string' && (val = val.toString('utf8'));

	    kLen = key.length;
	    if (kLen === 14 && key[7] === '-' && (key === 'content-length' || key.toLowerCase() === 'content-length')) {
	      hasContentLength = true;
	    } else if (kLen === 19 && key[7] === '-' && (key === 'content-disposition' || key.toLowerCase() === 'content-disposition')) {
	      contentDispositionIdx = n + 1;
	    }
	    ret[n] = key;
	    ret[n + 1] = val;
	  }

	  // See https://github.com/nodejs/node/pull/46528
	  if (hasContentLength && contentDispositionIdx !== -1) {
	    ret[contentDispositionIdx] = Buffer.from(ret[contentDispositionIdx]).toString('latin1');
	  }

	  return ret
	}

	function isBuffer (buffer) {
	  // See, https://github.com/mcollina/undici/pull/319
	  return buffer instanceof Uint8Array || Buffer.isBuffer(buffer)
	}

	function validateHandler (handler, method, upgrade) {
	  if (!handler || typeof handler !== 'object') {
	    throw new InvalidArgumentError('handler must be an object')
	  }

	  if (typeof handler.onConnect !== 'function') {
	    throw new InvalidArgumentError('invalid onConnect method')
	  }

	  if (typeof handler.onError !== 'function') {
	    throw new InvalidArgumentError('invalid onError method')
	  }

	  if (typeof handler.onBodySent !== 'function' && handler.onBodySent !== undefined) {
	    throw new InvalidArgumentError('invalid onBodySent method')
	  }

	  if (upgrade || method === 'CONNECT') {
	    if (typeof handler.onUpgrade !== 'function') {
	      throw new InvalidArgumentError('invalid onUpgrade method')
	    }
	  } else {
	    if (typeof handler.onHeaders !== 'function') {
	      throw new InvalidArgumentError('invalid onHeaders method')
	    }

	    if (typeof handler.onData !== 'function') {
	      throw new InvalidArgumentError('invalid onData method')
	    }

	    if (typeof handler.onComplete !== 'function') {
	      throw new InvalidArgumentError('invalid onComplete method')
	    }
	  }
	}

	// A body is disturbed if it has been read from and it cannot
	// be re-used without losing state or data.
	function isDisturbed (body) {
	  // TODO (fix): Why is body[kBodyUsed] needed?
	  return !!(body && (stream.isDisturbed(body) || body[kBodyUsed]))
	}

	function isErrored (body) {
	  return !!(body && stream.isErrored(body))
	}

	function isReadable (body) {
	  return !!(body && stream.isReadable(body))
	}

	function getSocketInfo (socket) {
	  return {
	    localAddress: socket.localAddress,
	    localPort: socket.localPort,
	    remoteAddress: socket.remoteAddress,
	    remotePort: socket.remotePort,
	    remoteFamily: socket.remoteFamily,
	    timeout: socket.timeout,
	    bytesWritten: socket.bytesWritten,
	    bytesRead: socket.bytesRead
	  }
	}

	/** @type {globalThis['ReadableStream']} */
	function ReadableStreamFrom (iterable) {
	  // We cannot use ReadableStream.from here because it does not return a byte stream.

	  let iterator;
	  return new ReadableStream(
	    {
	      async start () {
	        iterator = iterable[Symbol.asyncIterator]();
	      },
	      async pull (controller) {
	        const { done, value } = await iterator.next();
	        if (done) {
	          queueMicrotask(() => {
	            controller.close();
	            controller.byobRequest?.respond(0);
	          });
	        } else {
	          const buf = Buffer.isBuffer(value) ? value : Buffer.from(value);
	          if (buf.byteLength) {
	            controller.enqueue(new Uint8Array(buf));
	          }
	        }
	        return controller.desiredSize > 0
	      },
	      async cancel (reason) {
	        await iterator.return();
	      },
	      type: 'bytes'
	    }
	  )
	}

	// The chunk should be a FormData instance and contains
	// all the required methods.
	function isFormDataLike (object) {
	  return (
	    object &&
	    typeof object === 'object' &&
	    typeof object.append === 'function' &&
	    typeof object.delete === 'function' &&
	    typeof object.get === 'function' &&
	    typeof object.getAll === 'function' &&
	    typeof object.has === 'function' &&
	    typeof object.set === 'function' &&
	    object[Symbol.toStringTag] === 'FormData'
	  )
	}

	function addAbortListener (signal, listener) {
	  if ('addEventListener' in signal) {
	    signal.addEventListener('abort', listener, { once: true });
	    return () => signal.removeEventListener('abort', listener)
	  }
	  signal.addListener('abort', listener);
	  return () => signal.removeListener('abort', listener)
	}

	const hasToWellFormed = typeof String.prototype.toWellFormed === 'function';
	const hasIsWellFormed = typeof String.prototype.isWellFormed === 'function';

	/**
	 * @param {string} val
	 */
	function toUSVString (val) {
	  return hasToWellFormed ? `${val}`.toWellFormed() : nodeUtil.toUSVString(val)
	}

	/**
	 * @param {string} val
	 */
	// TODO: move this to webidl
	function isUSVString (val) {
	  return hasIsWellFormed ? `${val}`.isWellFormed() : toUSVString(val) === `${val}`
	}

	/**
	 * @see https://tools.ietf.org/html/rfc7230#section-3.2.6
	 * @param {number} c
	 */
	function isTokenCharCode (c) {
	  switch (c) {
	    case 0x22:
	    case 0x28:
	    case 0x29:
	    case 0x2c:
	    case 0x2f:
	    case 0x3a:
	    case 0x3b:
	    case 0x3c:
	    case 0x3d:
	    case 0x3e:
	    case 0x3f:
	    case 0x40:
	    case 0x5b:
	    case 0x5c:
	    case 0x5d:
	    case 0x7b:
	    case 0x7d:
	      // DQUOTE and "(),/:;<=>?@[\]{}"
	      return false
	    default:
	      // VCHAR %x21-7E
	      return c >= 0x21 && c <= 0x7e
	  }
	}

	/**
	 * @param {string} characters
	 */
	function isValidHTTPToken (characters) {
	  if (characters.length === 0) {
	    return false
	  }
	  for (let i = 0; i < characters.length; ++i) {
	    if (!isTokenCharCode(characters.charCodeAt(i))) {
	      return false
	    }
	  }
	  return true
	}

	// headerCharRegex have been lifted from
	// https://github.com/nodejs/node/blob/main/lib/_http_common.js

	/**
	 * Matches if val contains an invalid field-vchar
	 *  field-value    = *( field-content / obs-fold )
	 *  field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]
	 *  field-vchar    = VCHAR / obs-text
	 */
	const headerCharRegex = /[^\t\x20-\x7e\x80-\xff]/;

	/**
	 * @param {string} characters
	 */
	function isValidHeaderValue (characters) {
	  return !headerCharRegex.test(characters)
	}

	// Parsed accordingly to RFC 9110
	// https://www.rfc-editor.org/rfc/rfc9110#field.content-range
	function parseRangeHeader (range) {
	  if (range == null || range === '') return { start: 0, end: null, size: null }

	  const m = range ? range.match(/^bytes (\d+)-(\d+)\/(\d+)?$/) : null;
	  return m
	    ? {
	        start: parseInt(m[1]),
	        end: m[2] ? parseInt(m[2]) : null,
	        size: m[3] ? parseInt(m[3]) : null
	      }
	    : null
	}

	function addListener (obj, name, listener) {
	  const listeners = (obj[kListeners] ??= []);
	  listeners.push([name, listener]);
	  obj.on(name, listener);
	  return obj
	}

	function removeAllListeners (obj) {
	  for (const [name, listener] of obj[kListeners] ?? []) {
	    obj.removeListener(name, listener);
	  }
	  obj[kListeners] = null;
	}

	function errorRequest (client, request, err) {
	  try {
	    request.onError(err);
	    assert(request.aborted);
	  } catch (err) {
	    client.emit('error', err);
	  }
	}

	const kEnumerableProperty = Object.create(null);
	kEnumerableProperty.enumerable = true;

	const normalizedMethodRecordsBase = {
	  delete: 'DELETE',
	  DELETE: 'DELETE',
	  get: 'GET',
	  GET: 'GET',
	  head: 'HEAD',
	  HEAD: 'HEAD',
	  options: 'OPTIONS',
	  OPTIONS: 'OPTIONS',
	  post: 'POST',
	  POST: 'POST',
	  put: 'PUT',
	  PUT: 'PUT'
	};

	const normalizedMethodRecords = {
	  ...normalizedMethodRecordsBase,
	  patch: 'patch',
	  PATCH: 'PATCH'
	};

	// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.
	Object.setPrototypeOf(normalizedMethodRecordsBase, null);
	Object.setPrototypeOf(normalizedMethodRecords, null);

	util$7 = {
	  kEnumerableProperty,
	  nop,
	  isDisturbed,
	  isErrored,
	  isReadable,
	  toUSVString,
	  isUSVString,
	  isBlobLike,
	  parseOrigin,
	  parseURL,
	  getServerName,
	  isStream,
	  isIterable,
	  isAsyncIterable,
	  isDestroyed,
	  headerNameToString,
	  bufferToLowerCasedHeaderName,
	  addListener,
	  removeAllListeners,
	  errorRequest,
	  parseRawHeaders,
	  parseHeaders,
	  parseKeepAliveTimeout,
	  destroy,
	  bodyLength,
	  deepClone,
	  ReadableStreamFrom,
	  isBuffer,
	  validateHandler,
	  getSocketInfo,
	  isFormDataLike,
	  buildURL,
	  addAbortListener,
	  isValidHTTPToken,
	  isValidHeaderValue,
	  isTokenCharCode,
	  parseRangeHeader,
	  normalizedMethodRecordsBase,
	  normalizedMethodRecords,
	  isValidPort,
	  isHttpOrHttpsPrefixed,
	  nodeMajor,
	  nodeMinor,
	  safeHTTPMethods: ['GET', 'HEAD', 'OPTIONS', 'TRACE'],
	  wrapRequestBody
	};
	return util$7;
}

var diagnostics;
var hasRequiredDiagnostics;

function requireDiagnostics () {
	if (hasRequiredDiagnostics) return diagnostics;
	hasRequiredDiagnostics = 1;
	const diagnosticsChannel = require$$0$7;
	const util = require$$0$6;

	const undiciDebugLog = util.debuglog('undici');
	const fetchDebuglog = util.debuglog('fetch');
	const websocketDebuglog = util.debuglog('websocket');
	let isClientSet = false;
	const channels = {
	  // Client
	  beforeConnect: diagnosticsChannel.channel('undici:client:beforeConnect'),
	  connected: diagnosticsChannel.channel('undici:client:connected'),
	  connectError: diagnosticsChannel.channel('undici:client:connectError'),
	  sendHeaders: diagnosticsChannel.channel('undici:client:sendHeaders'),
	  // Request
	  create: diagnosticsChannel.channel('undici:request:create'),
	  bodySent: diagnosticsChannel.channel('undici:request:bodySent'),
	  headers: diagnosticsChannel.channel('undici:request:headers'),
	  trailers: diagnosticsChannel.channel('undici:request:trailers'),
	  error: diagnosticsChannel.channel('undici:request:error'),
	  // WebSocket
	  open: diagnosticsChannel.channel('undici:websocket:open'),
	  close: diagnosticsChannel.channel('undici:websocket:close'),
	  socketError: diagnosticsChannel.channel('undici:websocket:socket_error'),
	  ping: diagnosticsChannel.channel('undici:websocket:ping'),
	  pong: diagnosticsChannel.channel('undici:websocket:pong')
	};

	if (undiciDebugLog.enabled || fetchDebuglog.enabled) {
	  const debuglog = fetchDebuglog.enabled ? fetchDebuglog : undiciDebugLog;

	  // Track all Client events
	  diagnosticsChannel.channel('undici:client:beforeConnect').subscribe(evt => {
	    const {
	      connectParams: { version, protocol, port, host }
	    } = evt;
	    debuglog(
	      'connecting to %s using %s%s',
	      `${host}${port ? `:${port}` : ''}`,
	      protocol,
	      version
	    );
	  });

	  diagnosticsChannel.channel('undici:client:connected').subscribe(evt => {
	    const {
	      connectParams: { version, protocol, port, host }
	    } = evt;
	    debuglog(
	      'connected to %s using %s%s',
	      `${host}${port ? `:${port}` : ''}`,
	      protocol,
	      version
	    );
	  });

	  diagnosticsChannel.channel('undici:client:connectError').subscribe(evt => {
	    const {
	      connectParams: { version, protocol, port, host },
	      error
	    } = evt;
	    debuglog(
	      'connection to %s using %s%s errored - %s',
	      `${host}${port ? `:${port}` : ''}`,
	      protocol,
	      version,
	      error.message
	    );
	  });

	  diagnosticsChannel.channel('undici:client:sendHeaders').subscribe(evt => {
	    const {
	      request: { method, path, origin }
	    } = evt;
	    debuglog('sending request to %s %s/%s', method, origin, path);
	  });

	  // Track Request events
	  diagnosticsChannel.channel('undici:request:headers').subscribe(evt => {
	    const {
	      request: { method, path, origin },
	      response: { statusCode }
	    } = evt;
	    debuglog(
	      'received response to %s %s/%s - HTTP %d',
	      method,
	      origin,
	      path,
	      statusCode
	    );
	  });

	  diagnosticsChannel.channel('undici:request:trailers').subscribe(evt => {
	    const {
	      request: { method, path, origin }
	    } = evt;
	    debuglog('trailers received from %s %s/%s', method, origin, path);
	  });

	  diagnosticsChannel.channel('undici:request:error').subscribe(evt => {
	    const {
	      request: { method, path, origin },
	      error
	    } = evt;
	    debuglog(
	      'request to %s %s/%s errored - %s',
	      method,
	      origin,
	      path,
	      error.message
	    );
	  });

	  isClientSet = true;
	}

	if (websocketDebuglog.enabled) {
	  if (!isClientSet) {
	    const debuglog = undiciDebugLog.enabled ? undiciDebugLog : websocketDebuglog;
	    diagnosticsChannel.channel('undici:client:beforeConnect').subscribe(evt => {
	      const {
	        connectParams: { version, protocol, port, host }
	      } = evt;
	      debuglog(
	        'connecting to %s%s using %s%s',
	        host,
	        port ? `:${port}` : '',
	        protocol,
	        version
	      );
	    });

	    diagnosticsChannel.channel('undici:client:connected').subscribe(evt => {
	      const {
	        connectParams: { version, protocol, port, host }
	      } = evt;
	      debuglog(
	        'connected to %s%s using %s%s',
	        host,
	        port ? `:${port}` : '',
	        protocol,
	        version
	      );
	    });

	    diagnosticsChannel.channel('undici:client:connectError').subscribe(evt => {
	      const {
	        connectParams: { version, protocol, port, host },
	        error
	      } = evt;
	      debuglog(
	        'connection to %s%s using %s%s errored - %s',
	        host,
	        port ? `:${port}` : '',
	        protocol,
	        version,
	        error.message
	      );
	    });

	    diagnosticsChannel.channel('undici:client:sendHeaders').subscribe(evt => {
	      const {
	        request: { method, path, origin }
	      } = evt;
	      debuglog('sending request to %s %s/%s', method, origin, path);
	    });
	  }

	  // Track all WebSocket events
	  diagnosticsChannel.channel('undici:websocket:open').subscribe(evt => {
	    const {
	      address: { address, port }
	    } = evt;
	    websocketDebuglog('connection opened %s%s', address, port ? `:${port}` : '');
	  });

	  diagnosticsChannel.channel('undici:websocket:close').subscribe(evt => {
	    const { websocket, code, reason } = evt;
	    websocketDebuglog(
	      'closed connection to %s - %s %s',
	      websocket.url,
	      code,
	      reason
	    );
	  });

	  diagnosticsChannel.channel('undici:websocket:socket_error').subscribe(err => {
	    websocketDebuglog('connection errored - %s', err.message);
	  });

	  diagnosticsChannel.channel('undici:websocket:ping').subscribe(evt => {
	    websocketDebuglog('ping received');
	  });

	  diagnosticsChannel.channel('undici:websocket:pong').subscribe(evt => {
	    websocketDebuglog('pong received');
	  });
	}

	diagnostics = {
	  channels
	};
	return diagnostics;
}

var request$1;
var hasRequiredRequest$1;

function requireRequest$1 () {
	if (hasRequiredRequest$1) return request$1;
	hasRequiredRequest$1 = 1;

	const {
	  InvalidArgumentError,
	  NotSupportedError
	} = requireErrors();
	const assert = require$$0$4;
	const {
	  isValidHTTPToken,
	  isValidHeaderValue,
	  isStream,
	  destroy,
	  isBuffer,
	  isFormDataLike,
	  isIterable,
	  isBlobLike,
	  buildURL,
	  validateHandler,
	  getServerName,
	  normalizedMethodRecords
	} = requireUtil$7();
	const { channels } = requireDiagnostics();
	const { headerNameLowerCasedRecord } = requireConstants$4();

	// Verifies that a given path is valid does not contain control chars \x00 to \x20
	const invalidPathRegex = /[^\u0021-\u00ff]/;

	const kHandler = Symbol('handler');

	class Request {
	  constructor (origin, {
	    path,
	    method,
	    body,
	    headers,
	    query,
	    idempotent,
	    blocking,
	    upgrade,
	    headersTimeout,
	    bodyTimeout,
	    reset,
	    throwOnError,
	    expectContinue,
	    servername
	  }, handler) {
	    if (typeof path !== 'string') {
	      throw new InvalidArgumentError('path must be a string')
	    } else if (
	      path[0] !== '/' &&
	      !(path.startsWith('http://') || path.startsWith('https://')) &&
	      method !== 'CONNECT'
	    ) {
	      throw new InvalidArgumentError('path must be an absolute URL or start with a slash')
	    } else if (invalidPathRegex.test(path)) {
	      throw new InvalidArgumentError('invalid request path')
	    }

	    if (typeof method !== 'string') {
	      throw new InvalidArgumentError('method must be a string')
	    } else if (normalizedMethodRecords[method] === undefined && !isValidHTTPToken(method)) {
	      throw new InvalidArgumentError('invalid request method')
	    }

	    if (upgrade && typeof upgrade !== 'string') {
	      throw new InvalidArgumentError('upgrade must be a string')
	    }

	    if (headersTimeout != null && (!Number.isFinite(headersTimeout) || headersTimeout < 0)) {
	      throw new InvalidArgumentError('invalid headersTimeout')
	    }

	    if (bodyTimeout != null && (!Number.isFinite(bodyTimeout) || bodyTimeout < 0)) {
	      throw new InvalidArgumentError('invalid bodyTimeout')
	    }

	    if (reset != null && typeof reset !== 'boolean') {
	      throw new InvalidArgumentError('invalid reset')
	    }

	    if (expectContinue != null && typeof expectContinue !== 'boolean') {
	      throw new InvalidArgumentError('invalid expectContinue')
	    }

	    this.headersTimeout = headersTimeout;

	    this.bodyTimeout = bodyTimeout;

	    this.throwOnError = throwOnError === true;

	    this.method = method;

	    this.abort = null;

	    if (body == null) {
	      this.body = null;
	    } else if (isStream(body)) {
	      this.body = body;

	      const rState = this.body._readableState;
	      if (!rState || !rState.autoDestroy) {
	        this.endHandler = function autoDestroy () {
	          destroy(this);
	        };
	        this.body.on('end', this.endHandler);
	      }

	      this.errorHandler = err => {
	        if (this.abort) {
	          this.abort(err);
	        } else {
	          this.error = err;
	        }
	      };
	      this.body.on('error', this.errorHandler);
	    } else if (isBuffer(body)) {
	      this.body = body.byteLength ? body : null;
	    } else if (ArrayBuffer.isView(body)) {
	      this.body = body.buffer.byteLength ? Buffer.from(body.buffer, body.byteOffset, body.byteLength) : null;
	    } else if (body instanceof ArrayBuffer) {
	      this.body = body.byteLength ? Buffer.from(body) : null;
	    } else if (typeof body === 'string') {
	      this.body = body.length ? Buffer.from(body) : null;
	    } else if (isFormDataLike(body) || isIterable(body) || isBlobLike(body)) {
	      this.body = body;
	    } else {
	      throw new InvalidArgumentError('body must be a string, a Buffer, a Readable stream, an iterable, or an async iterable')
	    }

	    this.completed = false;

	    this.aborted = false;

	    this.upgrade = upgrade || null;

	    this.path = query ? buildURL(path, query) : path;

	    this.origin = origin;

	    this.idempotent = idempotent == null
	      ? method === 'HEAD' || method === 'GET'
	      : idempotent;

	    this.blocking = blocking == null ? false : blocking;

	    this.reset = reset == null ? null : reset;

	    this.host = null;

	    this.contentLength = null;

	    this.contentType = null;

	    this.headers = [];

	    // Only for H2
	    this.expectContinue = expectContinue != null ? expectContinue : false;

	    if (Array.isArray(headers)) {
	      if (headers.length % 2 !== 0) {
	        throw new InvalidArgumentError('headers array must be even')
	      }
	      for (let i = 0; i < headers.length; i += 2) {
	        processHeader(this, headers[i], headers[i + 1]);
	      }
	    } else if (headers && typeof headers === 'object') {
	      if (headers[Symbol.iterator]) {
	        for (const header of headers) {
	          if (!Array.isArray(header) || header.length !== 2) {
	            throw new InvalidArgumentError('headers must be in key-value pair format')
	          }
	          processHeader(this, header[0], header[1]);
	        }
	      } else {
	        const keys = Object.keys(headers);
	        for (let i = 0; i < keys.length; ++i) {
	          processHeader(this, keys[i], headers[keys[i]]);
	        }
	      }
	    } else if (headers != null) {
	      throw new InvalidArgumentError('headers must be an object or an array')
	    }

	    validateHandler(handler, method, upgrade);

	    this.servername = servername || getServerName(this.host);

	    this[kHandler] = handler;

	    if (channels.create.hasSubscribers) {
	      channels.create.publish({ request: this });
	    }
	  }

	  onBodySent (chunk) {
	    if (this[kHandler].onBodySent) {
	      try {
	        return this[kHandler].onBodySent(chunk)
	      } catch (err) {
	        this.abort(err);
	      }
	    }
	  }

	  onRequestSent () {
	    if (channels.bodySent.hasSubscribers) {
	      channels.bodySent.publish({ request: this });
	    }

	    if (this[kHandler].onRequestSent) {
	      try {
	        return this[kHandler].onRequestSent()
	      } catch (err) {
	        this.abort(err);
	      }
	    }
	  }

	  onConnect (abort) {
	    assert(!this.aborted);
	    assert(!this.completed);

	    if (this.error) {
	      abort(this.error);
	    } else {
	      this.abort = abort;
	      return this[kHandler].onConnect(abort)
	    }
	  }

	  onResponseStarted () {
	    return this[kHandler].onResponseStarted?.()
	  }

	  onHeaders (statusCode, headers, resume, statusText) {
	    assert(!this.aborted);
	    assert(!this.completed);

	    if (channels.headers.hasSubscribers) {
	      channels.headers.publish({ request: this, response: { statusCode, headers, statusText } });
	    }

	    try {
	      return this[kHandler].onHeaders(statusCode, headers, resume, statusText)
	    } catch (err) {
	      this.abort(err);
	    }
	  }

	  onData (chunk) {
	    assert(!this.aborted);
	    assert(!this.completed);

	    try {
	      return this[kHandler].onData(chunk)
	    } catch (err) {
	      this.abort(err);
	      return false
	    }
	  }

	  onUpgrade (statusCode, headers, socket) {
	    assert(!this.aborted);
	    assert(!this.completed);

	    return this[kHandler].onUpgrade(statusCode, headers, socket)
	  }

	  onComplete (trailers) {
	    this.onFinally();

	    assert(!this.aborted);

	    this.completed = true;
	    if (channels.trailers.hasSubscribers) {
	      channels.trailers.publish({ request: this, trailers });
	    }

	    try {
	      return this[kHandler].onComplete(trailers)
	    } catch (err) {
	      // TODO (fix): This might be a bad idea?
	      this.onError(err);
	    }
	  }

	  onError (error) {
	    this.onFinally();

	    if (channels.error.hasSubscribers) {
	      channels.error.publish({ request: this, error });
	    }

	    if (this.aborted) {
	      return
	    }
	    this.aborted = true;

	    return this[kHandler].onError(error)
	  }

	  onFinally () {
	    if (this.errorHandler) {
	      this.body.off('error', this.errorHandler);
	      this.errorHandler = null;
	    }

	    if (this.endHandler) {
	      this.body.off('end', this.endHandler);
	      this.endHandler = null;
	    }
	  }

	  addHeader (key, value) {
	    processHeader(this, key, value);
	    return this
	  }
	}

	function processHeader (request, key, val) {
	  if (val && (typeof val === 'object' && !Array.isArray(val))) {
	    throw new InvalidArgumentError(`invalid ${key} header`)
	  } else if (val === undefined) {
	    return
	  }

	  let headerName = headerNameLowerCasedRecord[key];

	  if (headerName === undefined) {
	    headerName = key.toLowerCase();
	    if (headerNameLowerCasedRecord[headerName] === undefined && !isValidHTTPToken(headerName)) {
	      throw new InvalidArgumentError('invalid header key')
	    }
	  }

	  if (Array.isArray(val)) {
	    const arr = [];
	    for (let i = 0; i < val.length; i++) {
	      if (typeof val[i] === 'string') {
	        if (!isValidHeaderValue(val[i])) {
	          throw new InvalidArgumentError(`invalid ${key} header`)
	        }
	        arr.push(val[i]);
	      } else if (val[i] === null) {
	        arr.push('');
	      } else if (typeof val[i] === 'object') {
	        throw new InvalidArgumentError(`invalid ${key} header`)
	      } else {
	        arr.push(`${val[i]}`);
	      }
	    }
	    val = arr;
	  } else if (typeof val === 'string') {
	    if (!isValidHeaderValue(val)) {
	      throw new InvalidArgumentError(`invalid ${key} header`)
	    }
	  } else if (val === null) {
	    val = '';
	  } else {
	    val = `${val}`;
	  }

	  if (request.host === null && headerName === 'host') {
	    if (typeof val !== 'string') {
	      throw new InvalidArgumentError('invalid host header')
	    }
	    // Consumed by Client
	    request.host = val;
	  } else if (request.contentLength === null && headerName === 'content-length') {
	    request.contentLength = parseInt(val, 10);
	    if (!Number.isFinite(request.contentLength)) {
	      throw new InvalidArgumentError('invalid content-length header')
	    }
	  } else if (request.contentType === null && headerName === 'content-type') {
	    request.contentType = val;
	    request.headers.push(key, val);
	  } else if (headerName === 'transfer-encoding' || headerName === 'keep-alive' || headerName === 'upgrade') {
	    throw new InvalidArgumentError(`invalid ${headerName} header`)
	  } else if (headerName === 'connection') {
	    const value = typeof val === 'string' ? val.toLowerCase() : null;
	    if (value !== 'close' && value !== 'keep-alive') {
	      throw new InvalidArgumentError('invalid connection header')
	    }

	    if (value === 'close') {
	      request.reset = true;
	    }
	  } else if (headerName === 'expect') {
	    throw new NotSupportedError('expect header not supported')
	  } else {
	    request.headers.push(key, val);
	  }
	}

	request$1 = Request;
	return request$1;
}

var dispatcher;
var hasRequiredDispatcher;

function requireDispatcher () {
	if (hasRequiredDispatcher) return dispatcher;
	hasRequiredDispatcher = 1;
	const EventEmitter = require$$8;

	class Dispatcher extends EventEmitter {
	  dispatch () {
	    throw new Error('not implemented')
	  }

	  close () {
	    throw new Error('not implemented')
	  }

	  destroy () {
	    throw new Error('not implemented')
	  }

	  compose (...args) {
	    // So we handle [interceptor1, interceptor2] or interceptor1, interceptor2, ...
	    const interceptors = Array.isArray(args[0]) ? args[0] : args;
	    let dispatch = this.dispatch.bind(this);

	    for (const interceptor of interceptors) {
	      if (interceptor == null) {
	        continue
	      }

	      if (typeof interceptor !== 'function') {
	        throw new TypeError(`invalid interceptor, expected function received ${typeof interceptor}`)
	      }

	      dispatch = interceptor(dispatch);

	      if (dispatch == null || typeof dispatch !== 'function' || dispatch.length !== 2) {
	        throw new TypeError('invalid interceptor')
	      }
	    }

	    return new ComposedDispatcher(this, dispatch)
	  }
	}

	class ComposedDispatcher extends Dispatcher {
	  #dispatcher = null
	  #dispatch = null

	  constructor (dispatcher, dispatch) {
	    super();
	    this.#dispatcher = dispatcher;
	    this.#dispatch = dispatch;
	  }

	  dispatch (...args) {
	    this.#dispatch(...args);
	  }

	  close (...args) {
	    return this.#dispatcher.close(...args)
	  }

	  destroy (...args) {
	    return this.#dispatcher.destroy(...args)
	  }
	}

	dispatcher = Dispatcher;
	return dispatcher;
}

var dispatcherBase;
var hasRequiredDispatcherBase;

function requireDispatcherBase () {
	if (hasRequiredDispatcherBase) return dispatcherBase;
	hasRequiredDispatcherBase = 1;

	const Dispatcher = requireDispatcher();
	const {
	  ClientDestroyedError,
	  ClientClosedError,
	  InvalidArgumentError
	} = requireErrors();
	const { kDestroy, kClose, kClosed, kDestroyed, kDispatch, kInterceptors } = requireSymbols$4();

	const kOnDestroyed = Symbol('onDestroyed');
	const kOnClosed = Symbol('onClosed');
	const kInterceptedDispatch = Symbol('Intercepted Dispatch');

	class DispatcherBase extends Dispatcher {
	  constructor () {
	    super();

	    this[kDestroyed] = false;
	    this[kOnDestroyed] = null;
	    this[kClosed] = false;
	    this[kOnClosed] = [];
	  }

	  get destroyed () {
	    return this[kDestroyed]
	  }

	  get closed () {
	    return this[kClosed]
	  }

	  get interceptors () {
	    return this[kInterceptors]
	  }

	  set interceptors (newInterceptors) {
	    if (newInterceptors) {
	      for (let i = newInterceptors.length - 1; i >= 0; i--) {
	        const interceptor = this[kInterceptors][i];
	        if (typeof interceptor !== 'function') {
	          throw new InvalidArgumentError('interceptor must be an function')
	        }
	      }
	    }

	    this[kInterceptors] = newInterceptors;
	  }

	  close (callback) {
	    if (callback === undefined) {
	      return new Promise((resolve, reject) => {
	        this.close((err, data) => {
	          return err ? reject(err) : resolve(data)
	        });
	      })
	    }

	    if (typeof callback !== 'function') {
	      throw new InvalidArgumentError('invalid callback')
	    }

	    if (this[kDestroyed]) {
	      queueMicrotask(() => callback(new ClientDestroyedError(), null));
	      return
	    }

	    if (this[kClosed]) {
	      if (this[kOnClosed]) {
	        this[kOnClosed].push(callback);
	      } else {
	        queueMicrotask(() => callback(null, null));
	      }
	      return
	    }

	    this[kClosed] = true;
	    this[kOnClosed].push(callback);

	    const onClosed = () => {
	      const callbacks = this[kOnClosed];
	      this[kOnClosed] = null;
	      for (let i = 0; i < callbacks.length; i++) {
	        callbacks[i](null, null);
	      }
	    };

	    // Should not error.
	    this[kClose]()
	      .then(() => this.destroy())
	      .then(() => {
	        queueMicrotask(onClosed);
	      });
	  }

	  destroy (err, callback) {
	    if (typeof err === 'function') {
	      callback = err;
	      err = null;
	    }

	    if (callback === undefined) {
	      return new Promise((resolve, reject) => {
	        this.destroy(err, (err, data) => {
	          return err ? /* istanbul ignore next: should never error */ reject(err) : resolve(data)
	        });
	      })
	    }

	    if (typeof callback !== 'function') {
	      throw new InvalidArgumentError('invalid callback')
	    }

	    if (this[kDestroyed]) {
	      if (this[kOnDestroyed]) {
	        this[kOnDestroyed].push(callback);
	      } else {
	        queueMicrotask(() => callback(null, null));
	      }
	      return
	    }

	    if (!err) {
	      err = new ClientDestroyedError();
	    }

	    this[kDestroyed] = true;
	    this[kOnDestroyed] = this[kOnDestroyed] || [];
	    this[kOnDestroyed].push(callback);

	    const onDestroyed = () => {
	      const callbacks = this[kOnDestroyed];
	      this[kOnDestroyed] = null;
	      for (let i = 0; i < callbacks.length; i++) {
	        callbacks[i](null, null);
	      }
	    };

	    // Should not error.
	    this[kDestroy](err).then(() => {
	      queueMicrotask(onDestroyed);
	    });
	  }

	  [kInterceptedDispatch] (opts, handler) {
	    if (!this[kInterceptors] || this[kInterceptors].length === 0) {
	      this[kInterceptedDispatch] = this[kDispatch];
	      return this[kDispatch](opts, handler)
	    }

	    let dispatch = this[kDispatch].bind(this);
	    for (let i = this[kInterceptors].length - 1; i >= 0; i--) {
	      dispatch = this[kInterceptors][i](dispatch);
	    }
	    this[kInterceptedDispatch] = dispatch;
	    return dispatch(opts, handler)
	  }

	  dispatch (opts, handler) {
	    if (!handler || typeof handler !== 'object') {
	      throw new InvalidArgumentError('handler must be an object')
	    }

	    try {
	      if (!opts || typeof opts !== 'object') {
	        throw new InvalidArgumentError('opts must be an object.')
	      }

	      if (this[kDestroyed] || this[kOnDestroyed]) {
	        throw new ClientDestroyedError()
	      }

	      if (this[kClosed]) {
	        throw new ClientClosedError()
	      }

	      return this[kInterceptedDispatch](opts, handler)
	    } catch (err) {
	      if (typeof handler.onError !== 'function') {
	        throw new InvalidArgumentError('invalid onError method')
	      }

	      handler.onError(err);

	      return false
	    }
	  }
	}

	dispatcherBase = DispatcherBase;
	return dispatcherBase;
}

var connect;
var hasRequiredConnect;

function requireConnect () {
	if (hasRequiredConnect) return connect;
	hasRequiredConnect = 1;

	const net = require$$4;
	const assert = require$$0$4;
	const util = requireUtil$7();
	const { InvalidArgumentError, ConnectTimeoutError } = requireErrors();

	let tls; // include tls conditionally since it is not always available

	// TODO: session re-use does not wait for the first
	// connection to resolve the session and might therefore
	// resolve the same servername multiple times even when
	// re-use is enabled.

	let SessionCache;
	// FIXME: remove workaround when the Node bug is fixed
	// https://github.com/nodejs/node/issues/49344#issuecomment-1741776308
	if (commonjsGlobal.FinalizationRegistry && !(process.env.NODE_V8_COVERAGE || process.env.UNDICI_NO_FG)) {
	  SessionCache = class WeakSessionCache {
	    constructor (maxCachedSessions) {
	      this._maxCachedSessions = maxCachedSessions;
	      this._sessionCache = new Map();
	      this._sessionRegistry = new commonjsGlobal.FinalizationRegistry((key) => {
	        if (this._sessionCache.size < this._maxCachedSessions) {
	          return
	        }

	        const ref = this._sessionCache.get(key);
	        if (ref !== undefined && ref.deref() === undefined) {
	          this._sessionCache.delete(key);
	        }
	      });
	    }

	    get (sessionKey) {
	      const ref = this._sessionCache.get(sessionKey);
	      return ref ? ref.deref() : null
	    }

	    set (sessionKey, session) {
	      if (this._maxCachedSessions === 0) {
	        return
	      }

	      this._sessionCache.set(sessionKey, new WeakRef(session));
	      this._sessionRegistry.register(session, sessionKey);
	    }
	  };
	} else {
	  SessionCache = class SimpleSessionCache {
	    constructor (maxCachedSessions) {
	      this._maxCachedSessions = maxCachedSessions;
	      this._sessionCache = new Map();
	    }

	    get (sessionKey) {
	      return this._sessionCache.get(sessionKey)
	    }

	    set (sessionKey, session) {
	      if (this._maxCachedSessions === 0) {
	        return
	      }

	      if (this._sessionCache.size >= this._maxCachedSessions) {
	        // remove the oldest session
	        const { value: oldestKey } = this._sessionCache.keys().next();
	        this._sessionCache.delete(oldestKey);
	      }

	      this._sessionCache.set(sessionKey, session);
	    }
	  };
	}

	function buildConnector ({ allowH2, maxCachedSessions, socketPath, timeout, session: customSession, ...opts }) {
	  if (maxCachedSessions != null && (!Number.isInteger(maxCachedSessions) || maxCachedSessions < 0)) {
	    throw new InvalidArgumentError('maxCachedSessions must be a positive integer or zero')
	  }

	  const options = { path: socketPath, ...opts };
	  const sessionCache = new SessionCache(maxCachedSessions == null ? 100 : maxCachedSessions);
	  timeout = timeout == null ? 10e3 : timeout;
	  allowH2 = allowH2 != null ? allowH2 : false;
	  return function connect ({ hostname, host, protocol, port, servername, localAddress, httpSocket }, callback) {
	    let socket;
	    if (protocol === 'https:') {
	      if (!tls) {
	        tls = require$$4$1;
	      }
	      servername = servername || options.servername || util.getServerName(host) || null;

	      const sessionKey = servername || hostname;
	      const session = customSession || sessionCache.get(sessionKey) || null;

	      assert(sessionKey);

	      socket = tls.connect({
	        highWaterMark: 16384, // TLS in node can't have bigger HWM anyway...
	        ...options,
	        servername,
	        session,
	        localAddress,
	        // TODO(HTTP/2): Add support for h2c
	        ALPNProtocols: allowH2 ? ['http/1.1', 'h2'] : ['http/1.1'],
	        socket: httpSocket, // upgrade socket connection
	        port: port || 443,
	        host: hostname
	      });

	      socket
	        .on('session', function (session) {
	          // TODO (fix): Can a session become invalid once established? Don't think so?
	          sessionCache.set(sessionKey, session);
	        });
	    } else {
	      assert(!httpSocket, 'httpSocket can only be sent on TLS update');
	      socket = net.connect({
	        highWaterMark: 64 * 1024, // Same as nodejs fs streams.
	        ...options,
	        localAddress,
	        port: port || 80,
	        host: hostname
	      });
	    }

	    // Set TCP keep alive options on the socket here instead of in connect() for the case of assigning the socket
	    if (options.keepAlive == null || options.keepAlive) {
	      const keepAliveInitialDelay = options.keepAliveInitialDelay === undefined ? 60e3 : options.keepAliveInitialDelay;
	      socket.setKeepAlive(true, keepAliveInitialDelay);
	    }

	    const cancelTimeout = setupTimeout(() => onConnectTimeout(socket), timeout);

	    socket
	      .setNoDelay(true)
	      .once(protocol === 'https:' ? 'secureConnect' : 'connect', function () {
	        cancelTimeout();

	        if (callback) {
	          const cb = callback;
	          callback = null;
	          cb(null, this);
	        }
	      })
	      .on('error', function (err) {
	        cancelTimeout();

	        if (callback) {
	          const cb = callback;
	          callback = null;
	          cb(err);
	        }
	      });

	    return socket
	  }
	}

	function setupTimeout (onConnectTimeout, timeout) {
	  if (!timeout) {
	    return () => {}
	  }

	  let s1 = null;
	  let s2 = null;
	  const timeoutId = setTimeout(() => {
	    // setImmediate is added to make sure that we prioritize socket error events over timeouts
	    s1 = setImmediate(() => {
	      if (process.platform === 'win32') {
	        // Windows needs an extra setImmediate probably due to implementation differences in the socket logic
	        s2 = setImmediate(() => onConnectTimeout());
	      } else {
	        onConnectTimeout();
	      }
	    });
	  }, timeout);
	  return () => {
	    clearTimeout(timeoutId);
	    clearImmediate(s1);
	    clearImmediate(s2);
	  }
	}

	function onConnectTimeout (socket) {
	  let message = 'Connect Timeout Error';
	  if (Array.isArray(socket.autoSelectFamilyAttemptedAddresses)) {
	    message += ` (attempted addresses: ${socket.autoSelectFamilyAttemptedAddresses.join(', ')})`;
	  }
	  util.destroy(socket, new ConnectTimeoutError(message));
	}

	connect = buildConnector;
	return connect;
}

var timers;
var hasRequiredTimers;

function requireTimers () {
	if (hasRequiredTimers) return timers;
	hasRequiredTimers = 1;

	const TICK_MS = 499;

	let fastNow = Date.now();
	let fastNowTimeout;

	const fastTimers = [];

	function onTimeout () {
	  fastNow = Date.now();

	  let len = fastTimers.length;
	  let idx = 0;
	  while (idx < len) {
	    const timer = fastTimers[idx];

	    if (timer.state === 0) {
	      timer.state = fastNow + timer.delay - TICK_MS;
	    } else if (timer.state > 0 && fastNow >= timer.state) {
	      timer.state = -1;
	      timer.callback(timer.opaque);
	    }

	    if (timer.state === -1) {
	      timer.state = -2;
	      if (idx !== len - 1) {
	        fastTimers[idx] = fastTimers.pop();
	      } else {
	        fastTimers.pop();
	      }
	      len -= 1;
	    } else {
	      idx += 1;
	    }
	  }

	  if (fastTimers.length > 0) {
	    refreshTimeout();
	  }
	}

	function refreshTimeout () {
	  if (fastNowTimeout?.refresh) {
	    fastNowTimeout.refresh();
	  } else {
	    clearTimeout(fastNowTimeout);
	    fastNowTimeout = setTimeout(onTimeout, TICK_MS);
	    if (fastNowTimeout.unref) {
	      fastNowTimeout.unref();
	    }
	  }
	}

	class Timeout {
	  constructor (callback, delay, opaque) {
	    this.callback = callback;
	    this.delay = delay;
	    this.opaque = opaque;

	    //  -2 not in timer list
	    //  -1 in timer list but inactive
	    //   0 in timer list waiting for time
	    // > 0 in timer list waiting for time to expire
	    this.state = -2;

	    this.refresh();
	  }

	  refresh () {
	    if (this.state === -2) {
	      fastTimers.push(this);
	      if (!fastNowTimeout || fastTimers.length === 1) {
	        refreshTimeout();
	      }
	    }

	    this.state = 0;
	  }

	  clear () {
	    this.state = -1;
	  }
	}

	timers = {
	  setTimeout (callback, delay, opaque) {
	    return delay <= 1e3
	      ? setTimeout(callback, delay, opaque)
	      : new Timeout(callback, delay, opaque)
	  },
	  clearTimeout (timeout) {
	    if (timeout instanceof Timeout) {
	      timeout.clear();
	    } else {
	      clearTimeout(timeout);
	    }
	  }
	};
	return timers;
}

var constants$3 = {};

var utils = {};

var hasRequiredUtils;

function requireUtils () {
	if (hasRequiredUtils) return utils;
	hasRequiredUtils = 1;
	Object.defineProperty(utils, "__esModule", { value: true });
	utils.enumToMap = void 0;
	function enumToMap(obj) {
	    const res = {};
	    Object.keys(obj).forEach((key) => {
	        const value = obj[key];
	        if (typeof value === 'number') {
	            res[key] = value;
	        }
	    });
	    return res;
	}
	utils.enumToMap = enumToMap;
	
	return utils;
}

var hasRequiredConstants$3;

function requireConstants$3 () {
	if (hasRequiredConstants$3) return constants$3;
	hasRequiredConstants$3 = 1;
	(function (exports) {
		Object.defineProperty(exports, "__esModule", { value: true });
		exports.SPECIAL_HEADERS = exports.HEADER_STATE = exports.MINOR = exports.MAJOR = exports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS = exports.TOKEN = exports.STRICT_TOKEN = exports.HEX = exports.URL_CHAR = exports.STRICT_URL_CHAR = exports.USERINFO_CHARS = exports.MARK = exports.ALPHANUM = exports.NUM = exports.HEX_MAP = exports.NUM_MAP = exports.ALPHA = exports.FINISH = exports.H_METHOD_MAP = exports.METHOD_MAP = exports.METHODS_RTSP = exports.METHODS_ICE = exports.METHODS_HTTP = exports.METHODS = exports.LENIENT_FLAGS = exports.FLAGS = exports.TYPE = exports.ERROR = void 0;
		const utils_1 = requireUtils();
		(function (ERROR) {
		    ERROR[ERROR["OK"] = 0] = "OK";
		    ERROR[ERROR["INTERNAL"] = 1] = "INTERNAL";
		    ERROR[ERROR["STRICT"] = 2] = "STRICT";
		    ERROR[ERROR["LF_EXPECTED"] = 3] = "LF_EXPECTED";
		    ERROR[ERROR["UNEXPECTED_CONTENT_LENGTH"] = 4] = "UNEXPECTED_CONTENT_LENGTH";
		    ERROR[ERROR["CLOSED_CONNECTION"] = 5] = "CLOSED_CONNECTION";
		    ERROR[ERROR["INVALID_METHOD"] = 6] = "INVALID_METHOD";
		    ERROR[ERROR["INVALID_URL"] = 7] = "INVALID_URL";
		    ERROR[ERROR["INVALID_CONSTANT"] = 8] = "INVALID_CONSTANT";
		    ERROR[ERROR["INVALID_VERSION"] = 9] = "INVALID_VERSION";
		    ERROR[ERROR["INVALID_HEADER_TOKEN"] = 10] = "INVALID_HEADER_TOKEN";
		    ERROR[ERROR["INVALID_CONTENT_LENGTH"] = 11] = "INVALID_CONTENT_LENGTH";
		    ERROR[ERROR["INVALID_CHUNK_SIZE"] = 12] = "INVALID_CHUNK_SIZE";
		    ERROR[ERROR["INVALID_STATUS"] = 13] = "INVALID_STATUS";
		    ERROR[ERROR["INVALID_EOF_STATE"] = 14] = "INVALID_EOF_STATE";
		    ERROR[ERROR["INVALID_TRANSFER_ENCODING"] = 15] = "INVALID_TRANSFER_ENCODING";
		    ERROR[ERROR["CB_MESSAGE_BEGIN"] = 16] = "CB_MESSAGE_BEGIN";
		    ERROR[ERROR["CB_HEADERS_COMPLETE"] = 17] = "CB_HEADERS_COMPLETE";
		    ERROR[ERROR["CB_MESSAGE_COMPLETE"] = 18] = "CB_MESSAGE_COMPLETE";
		    ERROR[ERROR["CB_CHUNK_HEADER"] = 19] = "CB_CHUNK_HEADER";
		    ERROR[ERROR["CB_CHUNK_COMPLETE"] = 20] = "CB_CHUNK_COMPLETE";
		    ERROR[ERROR["PAUSED"] = 21] = "PAUSED";
		    ERROR[ERROR["PAUSED_UPGRADE"] = 22] = "PAUSED_UPGRADE";
		    ERROR[ERROR["PAUSED_H2_UPGRADE"] = 23] = "PAUSED_H2_UPGRADE";
		    ERROR[ERROR["USER"] = 24] = "USER";
		})(exports.ERROR || (exports.ERROR = {}));
		(function (TYPE) {
		    TYPE[TYPE["BOTH"] = 0] = "BOTH";
		    TYPE[TYPE["REQUEST"] = 1] = "REQUEST";
		    TYPE[TYPE["RESPONSE"] = 2] = "RESPONSE";
		})(exports.TYPE || (exports.TYPE = {}));
		(function (FLAGS) {
		    FLAGS[FLAGS["CONNECTION_KEEP_ALIVE"] = 1] = "CONNECTION_KEEP_ALIVE";
		    FLAGS[FLAGS["CONNECTION_CLOSE"] = 2] = "CONNECTION_CLOSE";
		    FLAGS[FLAGS["CONNECTION_UPGRADE"] = 4] = "CONNECTION_UPGRADE";
		    FLAGS[FLAGS["CHUNKED"] = 8] = "CHUNKED";
		    FLAGS[FLAGS["UPGRADE"] = 16] = "UPGRADE";
		    FLAGS[FLAGS["CONTENT_LENGTH"] = 32] = "CONTENT_LENGTH";
		    FLAGS[FLAGS["SKIPBODY"] = 64] = "SKIPBODY";
		    FLAGS[FLAGS["TRAILING"] = 128] = "TRAILING";
		    // 1 << 8 is unused
		    FLAGS[FLAGS["TRANSFER_ENCODING"] = 512] = "TRANSFER_ENCODING";
		})(exports.FLAGS || (exports.FLAGS = {}));
		(function (LENIENT_FLAGS) {
		    LENIENT_FLAGS[LENIENT_FLAGS["HEADERS"] = 1] = "HEADERS";
		    LENIENT_FLAGS[LENIENT_FLAGS["CHUNKED_LENGTH"] = 2] = "CHUNKED_LENGTH";
		    LENIENT_FLAGS[LENIENT_FLAGS["KEEP_ALIVE"] = 4] = "KEEP_ALIVE";
		})(exports.LENIENT_FLAGS || (exports.LENIENT_FLAGS = {}));
		var METHODS;
		(function (METHODS) {
		    METHODS[METHODS["DELETE"] = 0] = "DELETE";
		    METHODS[METHODS["GET"] = 1] = "GET";
		    METHODS[METHODS["HEAD"] = 2] = "HEAD";
		    METHODS[METHODS["POST"] = 3] = "POST";
		    METHODS[METHODS["PUT"] = 4] = "PUT";
		    /* pathological */
		    METHODS[METHODS["CONNECT"] = 5] = "CONNECT";
		    METHODS[METHODS["OPTIONS"] = 6] = "OPTIONS";
		    METHODS[METHODS["TRACE"] = 7] = "TRACE";
		    /* WebDAV */
		    METHODS[METHODS["COPY"] = 8] = "COPY";
		    METHODS[METHODS["LOCK"] = 9] = "LOCK";
		    METHODS[METHODS["MKCOL"] = 10] = "MKCOL";
		    METHODS[METHODS["MOVE"] = 11] = "MOVE";
		    METHODS[METHODS["PROPFIND"] = 12] = "PROPFIND";
		    METHODS[METHODS["PROPPATCH"] = 13] = "PROPPATCH";
		    METHODS[METHODS["SEARCH"] = 14] = "SEARCH";
		    METHODS[METHODS["UNLOCK"] = 15] = "UNLOCK";
		    METHODS[METHODS["BIND"] = 16] = "BIND";
		    METHODS[METHODS["REBIND"] = 17] = "REBIND";
		    METHODS[METHODS["UNBIND"] = 18] = "UNBIND";
		    METHODS[METHODS["ACL"] = 19] = "ACL";
		    /* subversion */
		    METHODS[METHODS["REPORT"] = 20] = "REPORT";
		    METHODS[METHODS["MKACTIVITY"] = 21] = "MKACTIVITY";
		    METHODS[METHODS["CHECKOUT"] = 22] = "CHECKOUT";
		    METHODS[METHODS["MERGE"] = 23] = "MERGE";
		    /* upnp */
		    METHODS[METHODS["M-SEARCH"] = 24] = "M-SEARCH";
		    METHODS[METHODS["NOTIFY"] = 25] = "NOTIFY";
		    METHODS[METHODS["SUBSCRIBE"] = 26] = "SUBSCRIBE";
		    METHODS[METHODS["UNSUBSCRIBE"] = 27] = "UNSUBSCRIBE";
		    /* RFC-5789 */
		    METHODS[METHODS["PATCH"] = 28] = "PATCH";
		    METHODS[METHODS["PURGE"] = 29] = "PURGE";
		    /* CalDAV */
		    METHODS[METHODS["MKCALENDAR"] = 30] = "MKCALENDAR";
		    /* RFC-2068, section 19.6.1.2 */
		    METHODS[METHODS["LINK"] = 31] = "LINK";
		    METHODS[METHODS["UNLINK"] = 32] = "UNLINK";
		    /* icecast */
		    METHODS[METHODS["SOURCE"] = 33] = "SOURCE";
		    /* RFC-7540, section 11.6 */
		    METHODS[METHODS["PRI"] = 34] = "PRI";
		    /* RFC-2326 RTSP */
		    METHODS[METHODS["DESCRIBE"] = 35] = "DESCRIBE";
		    METHODS[METHODS["ANNOUNCE"] = 36] = "ANNOUNCE";
		    METHODS[METHODS["SETUP"] = 37] = "SETUP";
		    METHODS[METHODS["PLAY"] = 38] = "PLAY";
		    METHODS[METHODS["PAUSE"] = 39] = "PAUSE";
		    METHODS[METHODS["TEARDOWN"] = 40] = "TEARDOWN";
		    METHODS[METHODS["GET_PARAMETER"] = 41] = "GET_PARAMETER";
		    METHODS[METHODS["SET_PARAMETER"] = 42] = "SET_PARAMETER";
		    METHODS[METHODS["REDIRECT"] = 43] = "REDIRECT";
		    METHODS[METHODS["RECORD"] = 44] = "RECORD";
		    /* RAOP */
		    METHODS[METHODS["FLUSH"] = 45] = "FLUSH";
		})(METHODS = exports.METHODS || (exports.METHODS = {}));
		exports.METHODS_HTTP = [
		    METHODS.DELETE,
		    METHODS.GET,
		    METHODS.HEAD,
		    METHODS.POST,
		    METHODS.PUT,
		    METHODS.CONNECT,
		    METHODS.OPTIONS,
		    METHODS.TRACE,
		    METHODS.COPY,
		    METHODS.LOCK,
		    METHODS.MKCOL,
		    METHODS.MOVE,
		    METHODS.PROPFIND,
		    METHODS.PROPPATCH,
		    METHODS.SEARCH,
		    METHODS.UNLOCK,
		    METHODS.BIND,
		    METHODS.REBIND,
		    METHODS.UNBIND,
		    METHODS.ACL,
		    METHODS.REPORT,
		    METHODS.MKACTIVITY,
		    METHODS.CHECKOUT,
		    METHODS.MERGE,
		    METHODS['M-SEARCH'],
		    METHODS.NOTIFY,
		    METHODS.SUBSCRIBE,
		    METHODS.UNSUBSCRIBE,
		    METHODS.PATCH,
		    METHODS.PURGE,
		    METHODS.MKCALENDAR,
		    METHODS.LINK,
		    METHODS.UNLINK,
		    METHODS.PRI,
		    // TODO(indutny): should we allow it with HTTP?
		    METHODS.SOURCE,
		];
		exports.METHODS_ICE = [
		    METHODS.SOURCE,
		];
		exports.METHODS_RTSP = [
		    METHODS.OPTIONS,
		    METHODS.DESCRIBE,
		    METHODS.ANNOUNCE,
		    METHODS.SETUP,
		    METHODS.PLAY,
		    METHODS.PAUSE,
		    METHODS.TEARDOWN,
		    METHODS.GET_PARAMETER,
		    METHODS.SET_PARAMETER,
		    METHODS.REDIRECT,
		    METHODS.RECORD,
		    METHODS.FLUSH,
		    // For AirPlay
		    METHODS.GET,
		    METHODS.POST,
		];
		exports.METHOD_MAP = utils_1.enumToMap(METHODS);
		exports.H_METHOD_MAP = {};
		Object.keys(exports.METHOD_MAP).forEach((key) => {
		    if (/^H/.test(key)) {
		        exports.H_METHOD_MAP[key] = exports.METHOD_MAP[key];
		    }
		});
		(function (FINISH) {
		    FINISH[FINISH["SAFE"] = 0] = "SAFE";
		    FINISH[FINISH["SAFE_WITH_CB"] = 1] = "SAFE_WITH_CB";
		    FINISH[FINISH["UNSAFE"] = 2] = "UNSAFE";
		})(exports.FINISH || (exports.FINISH = {}));
		exports.ALPHA = [];
		for (let i = 'A'.charCodeAt(0); i <= 'Z'.charCodeAt(0); i++) {
		    // Upper case
		    exports.ALPHA.push(String.fromCharCode(i));
		    // Lower case
		    exports.ALPHA.push(String.fromCharCode(i + 0x20));
		}
		exports.NUM_MAP = {
		    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,
		    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,
		};
		exports.HEX_MAP = {
		    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,
		    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,
		    A: 0XA, B: 0XB, C: 0XC, D: 0XD, E: 0XE, F: 0XF,
		    a: 0xa, b: 0xb, c: 0xc, d: 0xd, e: 0xe, f: 0xf,
		};
		exports.NUM = [
		    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
		];
		exports.ALPHANUM = exports.ALPHA.concat(exports.NUM);
		exports.MARK = ['-', '_', '.', '!', '~', '*', '\'', '(', ')'];
		exports.USERINFO_CHARS = exports.ALPHANUM
		    .concat(exports.MARK)
		    .concat(['%', ';', ':', '&', '=', '+', '$', ',']);
		// TODO(indutny): use RFC
		exports.STRICT_URL_CHAR = [
		    '!', '"', '$', '%', '&', '\'',
		    '(', ')', '*', '+', ',', '-', '.', '/',
		    ':', ';', '<', '=', '>',
		    '@', '[', '\\', ']', '^', '_',
		    '`',
		    '{', '|', '}', '~',
		].concat(exports.ALPHANUM);
		exports.URL_CHAR = exports.STRICT_URL_CHAR
		    .concat(['\t', '\f']);
		// All characters with 0x80 bit set to 1
		for (let i = 0x80; i <= 0xff; i++) {
		    exports.URL_CHAR.push(i);
		}
		exports.HEX = exports.NUM.concat(['a', 'b', 'c', 'd', 'e', 'f', 'A', 'B', 'C', 'D', 'E', 'F']);
		/* Tokens as defined by rfc 2616. Also lowercases them.
		 *        token       = 1*<any CHAR except CTLs or separators>
		 *     separators     = "(" | ")" | "<" | ">" | "@"
		 *                    | "," | ";" | ":" | "\" | <">
		 *                    | "/" | "[" | "]" | "?" | "="
		 *                    | "{" | "}" | SP | HT
		 */
		exports.STRICT_TOKEN = [
		    '!', '#', '$', '%', '&', '\'',
		    '*', '+', '-', '.',
		    '^', '_', '`',
		    '|', '~',
		].concat(exports.ALPHANUM);
		exports.TOKEN = exports.STRICT_TOKEN.concat([' ']);
		/*
		 * Verify that a char is a valid visible (printable) US-ASCII
		 * character or %x80-FF
		 */
		exports.HEADER_CHARS = ['\t'];
		for (let i = 32; i <= 255; i++) {
		    if (i !== 127) {
		        exports.HEADER_CHARS.push(i);
		    }
		}
		// ',' = \x44
		exports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS.filter((c) => c !== 44);
		exports.MAJOR = exports.NUM_MAP;
		exports.MINOR = exports.MAJOR;
		var HEADER_STATE;
		(function (HEADER_STATE) {
		    HEADER_STATE[HEADER_STATE["GENERAL"] = 0] = "GENERAL";
		    HEADER_STATE[HEADER_STATE["CONNECTION"] = 1] = "CONNECTION";
		    HEADER_STATE[HEADER_STATE["CONTENT_LENGTH"] = 2] = "CONTENT_LENGTH";
		    HEADER_STATE[HEADER_STATE["TRANSFER_ENCODING"] = 3] = "TRANSFER_ENCODING";
		    HEADER_STATE[HEADER_STATE["UPGRADE"] = 4] = "UPGRADE";
		    HEADER_STATE[HEADER_STATE["CONNECTION_KEEP_ALIVE"] = 5] = "CONNECTION_KEEP_ALIVE";
		    HEADER_STATE[HEADER_STATE["CONNECTION_CLOSE"] = 6] = "CONNECTION_CLOSE";
		    HEADER_STATE[HEADER_STATE["CONNECTION_UPGRADE"] = 7] = "CONNECTION_UPGRADE";
		    HEADER_STATE[HEADER_STATE["TRANSFER_ENCODING_CHUNKED"] = 8] = "TRANSFER_ENCODING_CHUNKED";
		})(HEADER_STATE = exports.HEADER_STATE || (exports.HEADER_STATE = {}));
		exports.SPECIAL_HEADERS = {
		    'connection': HEADER_STATE.CONNECTION,
		    'content-length': HEADER_STATE.CONTENT_LENGTH,
		    'proxy-connection': HEADER_STATE.CONNECTION,
		    'transfer-encoding': HEADER_STATE.TRANSFER_ENCODING,
		    'upgrade': HEADER_STATE.UPGRADE,
		};
		
	} (constants$3));
	return constants$3;
}

var llhttpWasm;
var hasRequiredLlhttpWasm;

function requireLlhttpWasm () {
	if (hasRequiredLlhttpWasm) return llhttpWasm;
	hasRequiredLlhttpWasm = 1;

	const { Buffer } = require$$0$3;

	llhttpWasm = Buffer.from('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', 'base64');
	return llhttpWasm;
}

var llhttp_simdWasm;
var hasRequiredLlhttp_simdWasm;

function requireLlhttp_simdWasm () {
	if (hasRequiredLlhttp_simdWasm) return llhttp_simdWasm;
	hasRequiredLlhttp_simdWasm = 1;

	const { Buffer } = require$$0$3;

	llhttp_simdWasm = Buffer.from('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', 'base64');
	return llhttp_simdWasm;
}

var constants$2;
var hasRequiredConstants$2;

function requireConstants$2 () {
	if (hasRequiredConstants$2) return constants$2;
	hasRequiredConstants$2 = 1;

	const corsSafeListedMethods = ['GET', 'HEAD', 'POST'];
	const corsSafeListedMethodsSet = new Set(corsSafeListedMethods);

	const nullBodyStatus = [101, 204, 205, 304];

	const redirectStatus = [301, 302, 303, 307, 308];
	const redirectStatusSet = new Set(redirectStatus);

	// https://fetch.spec.whatwg.org/#block-bad-port
	const badPorts = [
	  '1', '7', '9', '11', '13', '15', '17', '19', '20', '21', '22', '23', '25', '37', '42', '43', '53', '69', '77', '79',
	  '87', '95', '101', '102', '103', '104', '109', '110', '111', '113', '115', '117', '119', '123', '135', '137',
	  '139', '143', '161', '179', '389', '427', '465', '512', '513', '514', '515', '526', '530', '531', '532',
	  '540', '548', '554', '556', '563', '587', '601', '636', '989', '990', '993', '995', '1719', '1720', '1723',
	  '2049', '3659', '4045', '4190', '5060', '5061', '6000', '6566', '6665', '6666', '6667', '6668', '6669', '6679',
	  '6697', '10080'
	];

	const badPortsSet = new Set(badPorts);

	// https://w3c.github.io/webappsec-referrer-policy/#referrer-policies
	const referrerPolicy = [
	  '',
	  'no-referrer',
	  'no-referrer-when-downgrade',
	  'same-origin',
	  'origin',
	  'strict-origin',
	  'origin-when-cross-origin',
	  'strict-origin-when-cross-origin',
	  'unsafe-url'
	];
	const referrerPolicySet = new Set(referrerPolicy);

	const requestRedirect = ['follow', 'manual', 'error'];

	const safeMethods = ['GET', 'HEAD', 'OPTIONS', 'TRACE'];
	const safeMethodsSet = new Set(safeMethods);

	const requestMode = ['navigate', 'same-origin', 'no-cors', 'cors'];

	const requestCredentials = ['omit', 'same-origin', 'include'];

	const requestCache = [
	  'default',
	  'no-store',
	  'reload',
	  'no-cache',
	  'force-cache',
	  'only-if-cached'
	];

	// https://fetch.spec.whatwg.org/#request-body-header-name
	const requestBodyHeader = [
	  'content-encoding',
	  'content-language',
	  'content-location',
	  'content-type',
	  // See https://github.com/nodejs/undici/issues/2021
	  // 'Content-Length' is a forbidden header name, which is typically
	  // removed in the Headers implementation. However, undici doesn't
	  // filter out headers, so we add it here.
	  'content-length'
	];

	// https://fetch.spec.whatwg.org/#enumdef-requestduplex
	const requestDuplex = [
	  'half'
	];

	// http://fetch.spec.whatwg.org/#forbidden-method
	const forbiddenMethods = ['CONNECT', 'TRACE', 'TRACK'];
	const forbiddenMethodsSet = new Set(forbiddenMethods);

	const subresource = [
	  'audio',
	  'audioworklet',
	  'font',
	  'image',
	  'manifest',
	  'paintworklet',
	  'script',
	  'style',
	  'track',
	  'video',
	  'xslt',
	  ''
	];
	const subresourceSet = new Set(subresource);

	constants$2 = {
	  subresource,
	  forbiddenMethods,
	  requestBodyHeader,
	  referrerPolicy,
	  requestRedirect,
	  requestMode,
	  requestCredentials,
	  requestCache,
	  redirectStatus,
	  corsSafeListedMethods,
	  nullBodyStatus,
	  safeMethods,
	  badPorts,
	  requestDuplex,
	  subresourceSet,
	  badPortsSet,
	  redirectStatusSet,
	  corsSafeListedMethodsSet,
	  safeMethodsSet,
	  forbiddenMethodsSet,
	  referrerPolicySet
	};
	return constants$2;
}

var global$2;
var hasRequiredGlobal$1;

function requireGlobal$1 () {
	if (hasRequiredGlobal$1) return global$2;
	hasRequiredGlobal$1 = 1;

	// In case of breaking changes, increase the version
	// number to avoid conflicts.
	const globalOrigin = Symbol.for('undici.globalOrigin.1');

	function getGlobalOrigin () {
	  return globalThis[globalOrigin]
	}

	function setGlobalOrigin (newOrigin) {
	  if (newOrigin === undefined) {
	    Object.defineProperty(globalThis, globalOrigin, {
	      value: undefined,
	      writable: true,
	      enumerable: false,
	      configurable: false
	    });

	    return
	  }

	  const parsedURL = new URL(newOrigin);

	  if (parsedURL.protocol !== 'http:' && parsedURL.protocol !== 'https:') {
	    throw new TypeError(`Only http & https urls are allowed, received ${parsedURL.protocol}`)
	  }

	  Object.defineProperty(globalThis, globalOrigin, {
	    value: parsedURL,
	    writable: true,
	    enumerable: false,
	    configurable: false
	  });
	}

	global$2 = {
	  getGlobalOrigin,
	  setGlobalOrigin
	};
	return global$2;
}

var dataUrl;
var hasRequiredDataUrl;

function requireDataUrl () {
	if (hasRequiredDataUrl) return dataUrl;
	hasRequiredDataUrl = 1;

	const assert = require$$0$4;

	const encoder = new TextEncoder();

	/**
	 * @see https://mimesniff.spec.whatwg.org/#http-token-code-point
	 */
	const HTTP_TOKEN_CODEPOINTS = /^[!#$%&'*+\-.^_|~A-Za-z0-9]+$/;
	const HTTP_WHITESPACE_REGEX = /[\u000A\u000D\u0009\u0020]/; // eslint-disable-line
	const ASCII_WHITESPACE_REPLACE_REGEX = /[\u0009\u000A\u000C\u000D\u0020]/g; // eslint-disable-line
	/**
	 * @see https://mimesniff.spec.whatwg.org/#http-quoted-string-token-code-point
	 */
	const HTTP_QUOTED_STRING_TOKENS = /^[\u0009\u0020-\u007E\u0080-\u00FF]+$/; // eslint-disable-line

	// https://fetch.spec.whatwg.org/#data-url-processor
	/** @param {URL} dataURL */
	function dataURLProcessor (dataURL) {
	  // 1. Assert: dataURLâs scheme is "data".
	  assert(dataURL.protocol === 'data:');

	  // 2. Let input be the result of running the URL
	  // serializer on dataURL with exclude fragment
	  // set to true.
	  let input = URLSerializer(dataURL, true);

	  // 3. Remove the leading "data:" string from input.
	  input = input.slice(5);

	  // 4. Let position point at the start of input.
	  const position = { position: 0 };

	  // 5. Let mimeType be the result of collecting a
	  // sequence of code points that are not equal
	  // to U+002C (,), given position.
	  let mimeType = collectASequenceOfCodePointsFast(
	    ',',
	    input,
	    position
	  );

	  // 6. Strip leading and trailing ASCII whitespace
	  // from mimeType.
	  // Undici implementation note: we need to store the
	  // length because if the mimetype has spaces removed,
	  // the wrong amount will be sliced from the input in
	  // step #9
	  const mimeTypeLength = mimeType.length;
	  mimeType = removeASCIIWhitespace(mimeType, true, true);

	  // 7. If position is past the end of input, then
	  // return failure
	  if (position.position >= input.length) {
	    return 'failure'
	  }

	  // 8. Advance position by 1.
	  position.position++;

	  // 9. Let encodedBody be the remainder of input.
	  const encodedBody = input.slice(mimeTypeLength + 1);

	  // 10. Let body be the percent-decoding of encodedBody.
	  let body = stringPercentDecode(encodedBody);

	  // 11. If mimeType ends with U+003B (;), followed by
	  // zero or more U+0020 SPACE, followed by an ASCII
	  // case-insensitive match for "base64", then:
	  if (/;(\u0020){0,}base64$/i.test(mimeType)) {
	    // 1. Let stringBody be the isomorphic decode of body.
	    const stringBody = isomorphicDecode(body);

	    // 2. Set body to the forgiving-base64 decode of
	    // stringBody.
	    body = forgivingBase64(stringBody);

	    // 3. If body is failure, then return failure.
	    if (body === 'failure') {
	      return 'failure'
	    }

	    // 4. Remove the last 6 code points from mimeType.
	    mimeType = mimeType.slice(0, -6);

	    // 5. Remove trailing U+0020 SPACE code points from mimeType,
	    // if any.
	    mimeType = mimeType.replace(/(\u0020)+$/, '');

	    // 6. Remove the last U+003B (;) code point from mimeType.
	    mimeType = mimeType.slice(0, -1);
	  }

	  // 12. If mimeType starts with U+003B (;), then prepend
	  // "text/plain" to mimeType.
	  if (mimeType.startsWith(';')) {
	    mimeType = 'text/plain' + mimeType;
	  }

	  // 13. Let mimeTypeRecord be the result of parsing
	  // mimeType.
	  let mimeTypeRecord = parseMIMEType(mimeType);

	  // 14. If mimeTypeRecord is failure, then set
	  // mimeTypeRecord to text/plain;charset=US-ASCII.
	  if (mimeTypeRecord === 'failure') {
	    mimeTypeRecord = parseMIMEType('text/plain;charset=US-ASCII');
	  }

	  // 15. Return a new data: URL struct whose MIME
	  // type is mimeTypeRecord and body is body.
	  // https://fetch.spec.whatwg.org/#data-url-struct
	  return { mimeType: mimeTypeRecord, body }
	}

	// https://url.spec.whatwg.org/#concept-url-serializer
	/**
	 * @param {URL} url
	 * @param {boolean} excludeFragment
	 */
	function URLSerializer (url, excludeFragment = false) {
	  if (!excludeFragment) {
	    return url.href
	  }

	  const href = url.href;
	  const hashLength = url.hash.length;

	  const serialized = hashLength === 0 ? href : href.substring(0, href.length - hashLength);

	  if (!hashLength && href.endsWith('#')) {
	    return serialized.slice(0, -1)
	  }

	  return serialized
	}

	// https://infra.spec.whatwg.org/#collect-a-sequence-of-code-points
	/**
	 * @param {(char: string) => boolean} condition
	 * @param {string} input
	 * @param {{ position: number }} position
	 */
	function collectASequenceOfCodePoints (condition, input, position) {
	  // 1. Let result be the empty string.
	  let result = '';

	  // 2. While position doesnât point past the end of input and the
	  // code point at position within input meets the condition condition:
	  while (position.position < input.length && condition(input[position.position])) {
	    // 1. Append that code point to the end of result.
	    result += input[position.position];

	    // 2. Advance position by 1.
	    position.position++;
	  }

	  // 3. Return result.
	  return result
	}

	/**
	 * A faster collectASequenceOfCodePoints that only works when comparing a single character.
	 * @param {string} char
	 * @param {string} input
	 * @param {{ position: number }} position
	 */
	function collectASequenceOfCodePointsFast (char, input, position) {
	  const idx = input.indexOf(char, position.position);
	  const start = position.position;

	  if (idx === -1) {
	    position.position = input.length;
	    return input.slice(start)
	  }

	  position.position = idx;
	  return input.slice(start, position.position)
	}

	// https://url.spec.whatwg.org/#string-percent-decode
	/** @param {string} input */
	function stringPercentDecode (input) {
	  // 1. Let bytes be the UTF-8 encoding of input.
	  const bytes = encoder.encode(input);

	  // 2. Return the percent-decoding of bytes.
	  return percentDecode(bytes)
	}

	/**
	 * @param {number} byte
	 */
	function isHexCharByte (byte) {
	  // 0-9 A-F a-f
	  return (byte >= 0x30 && byte <= 0x39) || (byte >= 0x41 && byte <= 0x46) || (byte >= 0x61 && byte <= 0x66)
	}

	/**
	 * @param {number} byte
	 */
	function hexByteToNumber (byte) {
	  return (
	    // 0-9
	    byte >= 0x30 && byte <= 0x39
	      ? (byte - 48)
	    // Convert to uppercase
	    // ((byte & 0xDF) - 65) + 10
	      : ((byte & 0xDF) - 55)
	  )
	}

	// https://url.spec.whatwg.org/#percent-decode
	/** @param {Uint8Array} input */
	function percentDecode (input) {
	  const length = input.length;
	  // 1. Let output be an empty byte sequence.
	  /** @type {Uint8Array} */
	  const output = new Uint8Array(length);
	  let j = 0;
	  // 2. For each byte byte in input:
	  for (let i = 0; i < length; ++i) {
	    const byte = input[i];

	    // 1. If byte is not 0x25 (%), then append byte to output.
	    if (byte !== 0x25) {
	      output[j++] = byte;

	    // 2. Otherwise, if byte is 0x25 (%) and the next two bytes
	    // after byte in input are not in the ranges
	    // 0x30 (0) to 0x39 (9), 0x41 (A) to 0x46 (F),
	    // and 0x61 (a) to 0x66 (f), all inclusive, append byte
	    // to output.
	    } else if (
	      byte === 0x25 &&
	      !(isHexCharByte(input[i + 1]) && isHexCharByte(input[i + 2]))
	    ) {
	      output[j++] = 0x25;

	    // 3. Otherwise:
	    } else {
	      // 1. Let bytePoint be the two bytes after byte in input,
	      // decoded, and then interpreted as hexadecimal number.
	      // 2. Append a byte whose value is bytePoint to output.
	      output[j++] = (hexByteToNumber(input[i + 1]) << 4) | hexByteToNumber(input[i + 2]);

	      // 3. Skip the next two bytes in input.
	      i += 2;
	    }
	  }

	  // 3. Return output.
	  return length === j ? output : output.subarray(0, j)
	}

	// https://mimesniff.spec.whatwg.org/#parse-a-mime-type
	/** @param {string} input */
	function parseMIMEType (input) {
	  // 1. Remove any leading and trailing HTTP whitespace
	  // from input.
	  input = removeHTTPWhitespace(input, true, true);

	  // 2. Let position be a position variable for input,
	  // initially pointing at the start of input.
	  const position = { position: 0 };

	  // 3. Let type be the result of collecting a sequence
	  // of code points that are not U+002F (/) from
	  // input, given position.
	  const type = collectASequenceOfCodePointsFast(
	    '/',
	    input,
	    position
	  );

	  // 4. If type is the empty string or does not solely
	  // contain HTTP token code points, then return failure.
	  // https://mimesniff.spec.whatwg.org/#http-token-code-point
	  if (type.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(type)) {
	    return 'failure'
	  }

	  // 5. If position is past the end of input, then return
	  // failure
	  if (position.position > input.length) {
	    return 'failure'
	  }

	  // 6. Advance position by 1. (This skips past U+002F (/).)
	  position.position++;

	  // 7. Let subtype be the result of collecting a sequence of
	  // code points that are not U+003B (;) from input, given
	  // position.
	  let subtype = collectASequenceOfCodePointsFast(
	    ';',
	    input,
	    position
	  );

	  // 8. Remove any trailing HTTP whitespace from subtype.
	  subtype = removeHTTPWhitespace(subtype, false, true);

	  // 9. If subtype is the empty string or does not solely
	  // contain HTTP token code points, then return failure.
	  if (subtype.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(subtype)) {
	    return 'failure'
	  }

	  const typeLowercase = type.toLowerCase();
	  const subtypeLowercase = subtype.toLowerCase();

	  // 10. Let mimeType be a new MIME type record whose type
	  // is type, in ASCII lowercase, and subtype is subtype,
	  // in ASCII lowercase.
	  // https://mimesniff.spec.whatwg.org/#mime-type
	  const mimeType = {
	    type: typeLowercase,
	    subtype: subtypeLowercase,
	    /** @type {Map<string, string>} */
	    parameters: new Map(),
	    // https://mimesniff.spec.whatwg.org/#mime-type-essence
	    essence: `${typeLowercase}/${subtypeLowercase}`
	  };

	  // 11. While position is not past the end of input:
	  while (position.position < input.length) {
	    // 1. Advance position by 1. (This skips past U+003B (;).)
	    position.position++;

	    // 2. Collect a sequence of code points that are HTTP
	    // whitespace from input given position.
	    collectASequenceOfCodePoints(
	      // https://fetch.spec.whatwg.org/#http-whitespace
	      char => HTTP_WHITESPACE_REGEX.test(char),
	      input,
	      position
	    );

	    // 3. Let parameterName be the result of collecting a
	    // sequence of code points that are not U+003B (;)
	    // or U+003D (=) from input, given position.
	    let parameterName = collectASequenceOfCodePoints(
	      (char) => char !== ';' && char !== '=',
	      input,
	      position
	    );

	    // 4. Set parameterName to parameterName, in ASCII
	    // lowercase.
	    parameterName = parameterName.toLowerCase();

	    // 5. If position is not past the end of input, then:
	    if (position.position < input.length) {
	      // 1. If the code point at position within input is
	      // U+003B (;), then continue.
	      if (input[position.position] === ';') {
	        continue
	      }

	      // 2. Advance position by 1. (This skips past U+003D (=).)
	      position.position++;
	    }

	    // 6. If position is past the end of input, then break.
	    if (position.position > input.length) {
	      break
	    }

	    // 7. Let parameterValue be null.
	    let parameterValue = null;

	    // 8. If the code point at position within input is
	    // U+0022 ("), then:
	    if (input[position.position] === '"') {
	      // 1. Set parameterValue to the result of collecting
	      // an HTTP quoted string from input, given position
	      // and the extract-value flag.
	      parameterValue = collectAnHTTPQuotedString(input, position, true);

	      // 2. Collect a sequence of code points that are not
	      // U+003B (;) from input, given position.
	      collectASequenceOfCodePointsFast(
	        ';',
	        input,
	        position
	      );

	    // 9. Otherwise:
	    } else {
	      // 1. Set parameterValue to the result of collecting
	      // a sequence of code points that are not U+003B (;)
	      // from input, given position.
	      parameterValue = collectASequenceOfCodePointsFast(
	        ';',
	        input,
	        position
	      );

	      // 2. Remove any trailing HTTP whitespace from parameterValue.
	      parameterValue = removeHTTPWhitespace(parameterValue, false, true);

	      // 3. If parameterValue is the empty string, then continue.
	      if (parameterValue.length === 0) {
	        continue
	      }
	    }

	    // 10. If all of the following are true
	    // - parameterName is not the empty string
	    // - parameterName solely contains HTTP token code points
	    // - parameterValue solely contains HTTP quoted-string token code points
	    // - mimeTypeâs parameters[parameterName] does not exist
	    // then set mimeTypeâs parameters[parameterName] to parameterValue.
	    if (
	      parameterName.length !== 0 &&
	      HTTP_TOKEN_CODEPOINTS.test(parameterName) &&
	      (parameterValue.length === 0 || HTTP_QUOTED_STRING_TOKENS.test(parameterValue)) &&
	      !mimeType.parameters.has(parameterName)
	    ) {
	      mimeType.parameters.set(parameterName, parameterValue);
	    }
	  }

	  // 12. Return mimeType.
	  return mimeType
	}

	// https://infra.spec.whatwg.org/#forgiving-base64-decode
	/** @param {string} data */
	function forgivingBase64 (data) {
	  // 1. Remove all ASCII whitespace from data.
	  data = data.replace(ASCII_WHITESPACE_REPLACE_REGEX, '');  // eslint-disable-line

	  let dataLength = data.length;
	  // 2. If dataâs code point length divides by 4 leaving
	  // no remainder, then:
	  if (dataLength % 4 === 0) {
	    // 1. If data ends with one or two U+003D (=) code points,
	    // then remove them from data.
	    if (data.charCodeAt(dataLength - 1) === 0x003D) {
	      --dataLength;
	      if (data.charCodeAt(dataLength - 1) === 0x003D) {
	        --dataLength;
	      }
	    }
	  }

	  // 3. If dataâs code point length divides by 4 leaving
	  // a remainder of 1, then return failure.
	  if (dataLength % 4 === 1) {
	    return 'failure'
	  }

	  // 4. If data contains a code point that is not one of
	  //  U+002B (+)
	  //  U+002F (/)
	  //  ASCII alphanumeric
	  // then return failure.
	  if (/[^+/0-9A-Za-z]/.test(data.length === dataLength ? data : data.substring(0, dataLength))) {
	    return 'failure'
	  }

	  const buffer = Buffer.from(data, 'base64');
	  return new Uint8Array(buffer.buffer, buffer.byteOffset, buffer.byteLength)
	}

	// https://fetch.spec.whatwg.org/#collect-an-http-quoted-string
	// tests: https://fetch.spec.whatwg.org/#example-http-quoted-string
	/**
	 * @param {string} input
	 * @param {{ position: number }} position
	 * @param {boolean?} extractValue
	 */
	function collectAnHTTPQuotedString (input, position, extractValue) {
	  // 1. Let positionStart be position.
	  const positionStart = position.position;

	  // 2. Let value be the empty string.
	  let value = '';

	  // 3. Assert: the code point at position within input
	  // is U+0022 (").
	  assert(input[position.position] === '"');

	  // 4. Advance position by 1.
	  position.position++;

	  // 5. While true:
	  while (true) {
	    // 1. Append the result of collecting a sequence of code points
	    // that are not U+0022 (") or U+005C (\) from input, given
	    // position, to value.
	    value += collectASequenceOfCodePoints(
	      (char) => char !== '"' && char !== '\\',
	      input,
	      position
	    );

	    // 2. If position is past the end of input, then break.
	    if (position.position >= input.length) {
	      break
	    }

	    // 3. Let quoteOrBackslash be the code point at position within
	    // input.
	    const quoteOrBackslash = input[position.position];

	    // 4. Advance position by 1.
	    position.position++;

	    // 5. If quoteOrBackslash is U+005C (\), then:
	    if (quoteOrBackslash === '\\') {
	      // 1. If position is past the end of input, then append
	      // U+005C (\) to value and break.
	      if (position.position >= input.length) {
	        value += '\\';
	        break
	      }

	      // 2. Append the code point at position within input to value.
	      value += input[position.position];

	      // 3. Advance position by 1.
	      position.position++;

	    // 6. Otherwise:
	    } else {
	      // 1. Assert: quoteOrBackslash is U+0022 (").
	      assert(quoteOrBackslash === '"');

	      // 2. Break.
	      break
	    }
	  }

	  // 6. If the extract-value flag is set, then return value.
	  if (extractValue) {
	    return value
	  }

	  // 7. Return the code points from positionStart to position,
	  // inclusive, within input.
	  return input.slice(positionStart, position.position)
	}

	/**
	 * @see https://mimesniff.spec.whatwg.org/#serialize-a-mime-type
	 */
	function serializeAMimeType (mimeType) {
	  assert(mimeType !== 'failure');
	  const { parameters, essence } = mimeType;

	  // 1. Let serialization be the concatenation of mimeTypeâs
	  //    type, U+002F (/), and mimeTypeâs subtype.
	  let serialization = essence;

	  // 2. For each name â value of mimeTypeâs parameters:
	  for (let [name, value] of parameters.entries()) {
	    // 1. Append U+003B (;) to serialization.
	    serialization += ';';

	    // 2. Append name to serialization.
	    serialization += name;

	    // 3. Append U+003D (=) to serialization.
	    serialization += '=';

	    // 4. If value does not solely contain HTTP token code
	    //    points or value is the empty string, then:
	    if (!HTTP_TOKEN_CODEPOINTS.test(value)) {
	      // 1. Precede each occurrence of U+0022 (") or
	      //    U+005C (\) in value with U+005C (\).
	      value = value.replace(/(\\|")/g, '\\$1');

	      // 2. Prepend U+0022 (") to value.
	      value = '"' + value;

	      // 3. Append U+0022 (") to value.
	      value += '"';
	    }

	    // 5. Append value to serialization.
	    serialization += value;
	  }

	  // 3. Return serialization.
	  return serialization
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#http-whitespace
	 * @param {number} char
	 */
	function isHTTPWhiteSpace (char) {
	  // "\r\n\t "
	  return char === 0x00d || char === 0x00a || char === 0x009 || char === 0x020
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#http-whitespace
	 * @param {string} str
	 * @param {boolean} [leading=true]
	 * @param {boolean} [trailing=true]
	 */
	function removeHTTPWhitespace (str, leading = true, trailing = true) {
	  return removeChars(str, leading, trailing, isHTTPWhiteSpace)
	}

	/**
	 * @see https://infra.spec.whatwg.org/#ascii-whitespace
	 * @param {number} char
	 */
	function isASCIIWhitespace (char) {
	  // "\r\n\t\f "
	  return char === 0x00d || char === 0x00a || char === 0x009 || char === 0x00c || char === 0x020
	}

	/**
	 * @see https://infra.spec.whatwg.org/#strip-leading-and-trailing-ascii-whitespace
	 * @param {string} str
	 * @param {boolean} [leading=true]
	 * @param {boolean} [trailing=true]
	 */
	function removeASCIIWhitespace (str, leading = true, trailing = true) {
	  return removeChars(str, leading, trailing, isASCIIWhitespace)
	}

	/**
	 * @param {string} str
	 * @param {boolean} leading
	 * @param {boolean} trailing
	 * @param {(charCode: number) => boolean} predicate
	 * @returns
	 */
	function removeChars (str, leading, trailing, predicate) {
	  let lead = 0;
	  let trail = str.length - 1;

	  if (leading) {
	    while (lead < str.length && predicate(str.charCodeAt(lead))) lead++;
	  }

	  if (trailing) {
	    while (trail > 0 && predicate(str.charCodeAt(trail))) trail--;
	  }

	  return lead === 0 && trail === str.length - 1 ? str : str.slice(lead, trail + 1)
	}

	/**
	 * @see https://infra.spec.whatwg.org/#isomorphic-decode
	 * @param {Uint8Array} input
	 * @returns {string}
	 */
	function isomorphicDecode (input) {
	  // 1. To isomorphic decode a byte sequence input, return a string whose code point
	  //    length is equal to inputâs length and whose code points have the same values
	  //    as the values of inputâs bytes, in the same order.
	  const length = input.length;
	  if ((2 << 15) - 1 > length) {
	    return String.fromCharCode.apply(null, input)
	  }
	  let result = ''; let i = 0;
	  let addition = (2 << 15) - 1;
	  while (i < length) {
	    if (i + addition > length) {
	      addition = length - i;
	    }
	    result += String.fromCharCode.apply(null, input.subarray(i, i += addition));
	  }
	  return result
	}

	/**
	 * @see https://mimesniff.spec.whatwg.org/#minimize-a-supported-mime-type
	 * @param {Exclude<ReturnType<typeof parseMIMEType>, 'failure'>} mimeType
	 */
	function minimizeSupportedMimeType (mimeType) {
	  switch (mimeType.essence) {
	    case 'application/ecmascript':
	    case 'application/javascript':
	    case 'application/x-ecmascript':
	    case 'application/x-javascript':
	    case 'text/ecmascript':
	    case 'text/javascript':
	    case 'text/javascript1.0':
	    case 'text/javascript1.1':
	    case 'text/javascript1.2':
	    case 'text/javascript1.3':
	    case 'text/javascript1.4':
	    case 'text/javascript1.5':
	    case 'text/jscript':
	    case 'text/livescript':
	    case 'text/x-ecmascript':
	    case 'text/x-javascript':
	      // 1. If mimeType is a JavaScript MIME type, then return "text/javascript".
	      return 'text/javascript'
	    case 'application/json':
	    case 'text/json':
	      // 2. If mimeType is a JSON MIME type, then return "application/json".
	      return 'application/json'
	    case 'image/svg+xml':
	      // 3. If mimeTypeâs essence is "image/svg+xml", then return "image/svg+xml".
	      return 'image/svg+xml'
	    case 'text/xml':
	    case 'application/xml':
	      // 4. If mimeType is an XML MIME type, then return "application/xml".
	      return 'application/xml'
	  }

	  // 2. If mimeType is a JSON MIME type, then return "application/json".
	  if (mimeType.subtype.endsWith('+json')) {
	    return 'application/json'
	  }

	  // 4. If mimeType is an XML MIME type, then return "application/xml".
	  if (mimeType.subtype.endsWith('+xml')) {
	    return 'application/xml'
	  }

	  // 5. If mimeType is supported by the user agent, then return mimeTypeâs essence.
	  // Technically, node doesn't support any mimetypes.

	  // 6. Return the empty string.
	  return ''
	}

	dataUrl = {
	  dataURLProcessor,
	  URLSerializer,
	  collectASequenceOfCodePoints,
	  collectASequenceOfCodePointsFast,
	  stringPercentDecode,
	  parseMIMEType,
	  collectAnHTTPQuotedString,
	  serializeAMimeType,
	  removeChars,
	  removeHTTPWhitespace,
	  minimizeSupportedMimeType,
	  HTTP_TOKEN_CODEPOINTS,
	  isomorphicDecode
	};
	return dataUrl;
}

var webidl_1;
var hasRequiredWebidl;

function requireWebidl () {
	if (hasRequiredWebidl) return webidl_1;
	hasRequiredWebidl = 1;

	const { types, inspect } = require$$0$6;
	const { toUSVString } = requireUtil$7();

	/** @type {import('../../../types/webidl').Webidl} */
	const webidl = {};
	webidl.converters = {};
	webidl.util = {};
	webidl.errors = {};

	webidl.errors.exception = function (message) {
	  return new TypeError(`${message.header}: ${message.message}`)
	};

	webidl.errors.conversionFailed = function (context) {
	  const plural = context.types.length === 1 ? '' : ' one of';
	  const message =
	    `${context.argument} could not be converted to` +
	    `${plural}: ${context.types.join(', ')}.`;

	  return webidl.errors.exception({
	    header: context.prefix,
	    message
	  })
	};

	webidl.errors.invalidArgument = function (context) {
	  return webidl.errors.exception({
	    header: context.prefix,
	    message: `"${context.value}" is an invalid ${context.type}.`
	  })
	};

	// https://webidl.spec.whatwg.org/#implements
	webidl.brandCheck = function (V, I, opts) {
	  if (opts?.strict !== false) {
	    if (!(V instanceof I)) {
	      const err = new TypeError('Illegal invocation');
	      err.code = 'ERR_INVALID_THIS'; // node compat.
	      throw err
	    }
	  } else {
	    if (V?.[Symbol.toStringTag] !== I.prototype[Symbol.toStringTag]) {
	      const err = new TypeError('Illegal invocation');
	      err.code = 'ERR_INVALID_THIS'; // node compat.
	      throw err
	    }
	  }
	};

	webidl.argumentLengthCheck = function ({ length }, min, ctx) {
	  if (length < min) {
	    throw webidl.errors.exception({
	      message: `${min} argument${min !== 1 ? 's' : ''} required, ` +
	               `but${length ? ' only' : ''} ${length} found.`,
	      header: ctx
	    })
	  }
	};

	webidl.illegalConstructor = function () {
	  throw webidl.errors.exception({
	    header: 'TypeError',
	    message: 'Illegal constructor'
	  })
	};

	// https://tc39.es/ecma262/#sec-ecmascript-data-types-and-values
	webidl.util.Type = function (V) {
	  switch (typeof V) {
	    case 'undefined': return 'Undefined'
	    case 'boolean': return 'Boolean'
	    case 'string': return 'String'
	    case 'symbol': return 'Symbol'
	    case 'number': return 'Number'
	    case 'bigint': return 'BigInt'
	    case 'function':
	    case 'object': {
	      if (V === null) {
	        return 'Null'
	      }

	      return 'Object'
	    }
	  }
	};

	// https://webidl.spec.whatwg.org/#abstract-opdef-converttoint
	webidl.util.ConvertToInt = function (V, bitLength, signedness, opts) {
	  let upperBound;
	  let lowerBound;

	  // 1. If bitLength is 64, then:
	  if (bitLength === 64) {
	    // 1. Let upperBound be 2^53 â 1.
	    upperBound = Math.pow(2, 53) - 1;

	    // 2. If signedness is "unsigned", then let lowerBound be 0.
	    if (signedness === 'unsigned') {
	      lowerBound = 0;
	    } else {
	      // 3. Otherwise let lowerBound be â2^53 + 1.
	      lowerBound = Math.pow(-2, 53) + 1;
	    }
	  } else if (signedness === 'unsigned') {
	    // 2. Otherwise, if signedness is "unsigned", then:

	    // 1. Let lowerBound be 0.
	    lowerBound = 0;

	    // 2. Let upperBound be 2^bitLength â 1.
	    upperBound = Math.pow(2, bitLength) - 1;
	  } else {
	    // 3. Otherwise:

	    // 1. Let lowerBound be -2^bitLength â 1.
	    lowerBound = Math.pow(-2, bitLength) - 1;

	    // 2. Let upperBound be 2^bitLength â 1 â 1.
	    upperBound = Math.pow(2, bitLength - 1) - 1;
	  }

	  // 4. Let x be ? ToNumber(V).
	  let x = Number(V);

	  // 5. If x is â0, then set x to +0.
	  if (x === 0) {
	    x = 0;
	  }

	  // 6. If the conversion is to an IDL type associated
	  //    with the [EnforceRange] extended attribute, then:
	  if (opts?.enforceRange === true) {
	    // 1. If x is NaN, +â, or ââ, then throw a TypeError.
	    if (
	      Number.isNaN(x) ||
	      x === Number.POSITIVE_INFINITY ||
	      x === Number.NEGATIVE_INFINITY
	    ) {
	      throw webidl.errors.exception({
	        header: 'Integer conversion',
	        message: `Could not convert ${webidl.util.Stringify(V)} to an integer.`
	      })
	    }

	    // 2. Set x to IntegerPart(x).
	    x = webidl.util.IntegerPart(x);

	    // 3. If x < lowerBound or x > upperBound, then
	    //    throw a TypeError.
	    if (x < lowerBound || x > upperBound) {
	      throw webidl.errors.exception({
	        header: 'Integer conversion',
	        message: `Value must be between ${lowerBound}-${upperBound}, got ${x}.`
	      })
	    }

	    // 4. Return x.
	    return x
	  }

	  // 7. If x is not NaN and the conversion is to an IDL
	  //    type associated with the [Clamp] extended
	  //    attribute, then:
	  if (!Number.isNaN(x) && opts?.clamp === true) {
	    // 1. Set x to min(max(x, lowerBound), upperBound).
	    x = Math.min(Math.max(x, lowerBound), upperBound);

	    // 2. Round x to the nearest integer, choosing the
	    //    even integer if it lies halfway between two,
	    //    and choosing +0 rather than â0.
	    if (Math.floor(x) % 2 === 0) {
	      x = Math.floor(x);
	    } else {
	      x = Math.ceil(x);
	    }

	    // 3. Return x.
	    return x
	  }

	  // 8. If x is NaN, +0, +â, or ââ, then return +0.
	  if (
	    Number.isNaN(x) ||
	    (x === 0 && Object.is(0, x)) ||
	    x === Number.POSITIVE_INFINITY ||
	    x === Number.NEGATIVE_INFINITY
	  ) {
	    return 0
	  }

	  // 9. Set x to IntegerPart(x).
	  x = webidl.util.IntegerPart(x);

	  // 10. Set x to x modulo 2^bitLength.
	  x = x % Math.pow(2, bitLength);

	  // 11. If signedness is "signed" and x â¥ 2^bitLength â 1,
	  //    then return x â 2^bitLength.
	  if (signedness === 'signed' && x >= Math.pow(2, bitLength) - 1) {
	    return x - Math.pow(2, bitLength)
	  }

	  // 12. Otherwise, return x.
	  return x
	};

	// https://webidl.spec.whatwg.org/#abstract-opdef-integerpart
	webidl.util.IntegerPart = function (n) {
	  // 1. Let r be floor(abs(n)).
	  const r = Math.floor(Math.abs(n));

	  // 2. If n < 0, then return -1 Ã r.
	  if (n < 0) {
	    return -1 * r
	  }

	  // 3. Otherwise, return r.
	  return r
	};

	webidl.util.Stringify = function (V) {
	  const type = webidl.util.Type(V);

	  switch (type) {
	    case 'Symbol':
	      return `Symbol(${V.description})`
	    case 'Object':
	      return inspect(V)
	    case 'String':
	      return `"${V}"`
	    default:
	      return `${V}`
	  }
	};

	// https://webidl.spec.whatwg.org/#es-sequence
	webidl.sequenceConverter = function (converter) {
	  return (V, prefix, argument, Iterable) => {
	    // 1. If Type(V) is not Object, throw a TypeError.
	    if (webidl.util.Type(V) !== 'Object') {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: `${argument} (${webidl.util.Stringify(V)}) is not iterable.`
	      })
	    }

	    // 2. Let method be ? GetMethod(V, @@iterator).
	    /** @type {Generator} */
	    const method = typeof Iterable === 'function' ? Iterable() : V?.[Symbol.iterator]?.();
	    const seq = [];
	    let index = 0;

	    // 3. If method is undefined, throw a TypeError.
	    if (
	      method === undefined ||
	      typeof method.next !== 'function'
	    ) {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: `${argument} is not iterable.`
	      })
	    }

	    // https://webidl.spec.whatwg.org/#create-sequence-from-iterable
	    while (true) {
	      const { done, value } = method.next();

	      if (done) {
	        break
	      }

	      seq.push(converter(value, prefix, `${argument}[${index++}]`));
	    }

	    return seq
	  }
	};

	// https://webidl.spec.whatwg.org/#es-to-record
	webidl.recordConverter = function (keyConverter, valueConverter) {
	  return (O, prefix, argument) => {
	    // 1. If Type(O) is not Object, throw a TypeError.
	    if (webidl.util.Type(O) !== 'Object') {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: `${argument} ("${webidl.util.Type(O)}") is not an Object.`
	      })
	    }

	    // 2. Let result be a new empty instance of record<K, V>.
	    const result = {};

	    if (!types.isProxy(O)) {
	      // 1. Let desc be ? O.[[GetOwnProperty]](key).
	      const keys = [...Object.getOwnPropertyNames(O), ...Object.getOwnPropertySymbols(O)];

	      for (const key of keys) {
	        // 1. Let typedKey be key converted to an IDL value of type K.
	        const typedKey = keyConverter(key, prefix, argument);

	        // 2. Let value be ? Get(O, key).
	        // 3. Let typedValue be value converted to an IDL value of type V.
	        const typedValue = valueConverter(O[key], prefix, argument);

	        // 4. Set result[typedKey] to typedValue.
	        result[typedKey] = typedValue;
	      }

	      // 5. Return result.
	      return result
	    }

	    // 3. Let keys be ? O.[[OwnPropertyKeys]]().
	    const keys = Reflect.ownKeys(O);

	    // 4. For each key of keys.
	    for (const key of keys) {
	      // 1. Let desc be ? O.[[GetOwnProperty]](key).
	      const desc = Reflect.getOwnPropertyDescriptor(O, key);

	      // 2. If desc is not undefined and desc.[[Enumerable]] is true:
	      if (desc?.enumerable) {
	        // 1. Let typedKey be key converted to an IDL value of type K.
	        const typedKey = keyConverter(key, prefix, argument);

	        // 2. Let value be ? Get(O, key).
	        // 3. Let typedValue be value converted to an IDL value of type V.
	        const typedValue = valueConverter(O[key], prefix, argument);

	        // 4. Set result[typedKey] to typedValue.
	        result[typedKey] = typedValue;
	      }
	    }

	    // 5. Return result.
	    return result
	  }
	};

	webidl.interfaceConverter = function (i) {
	  return (V, prefix, argument, opts) => {
	    if (opts?.strict !== false && !(V instanceof i)) {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: `Expected ${argument} ("${webidl.util.Stringify(V)}") to be an instance of ${i.name}.`
	      })
	    }

	    return V
	  }
	};

	webidl.dictionaryConverter = function (converters) {
	  return (dictionary, prefix, argument) => {
	    const type = webidl.util.Type(dictionary);
	    const dict = {};

	    if (type === 'Null' || type === 'Undefined') {
	      return dict
	    } else if (type !== 'Object') {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: `Expected ${dictionary} to be one of: Null, Undefined, Object.`
	      })
	    }

	    for (const options of converters) {
	      const { key, defaultValue, required, converter } = options;

	      if (required === true) {
	        if (!Object.hasOwn(dictionary, key)) {
	          throw webidl.errors.exception({
	            header: prefix,
	            message: `Missing required key "${key}".`
	          })
	        }
	      }

	      let value = dictionary[key];
	      const hasDefault = Object.hasOwn(options, 'defaultValue');

	      // Only use defaultValue if value is undefined and
	      // a defaultValue options was provided.
	      if (hasDefault && value !== null) {
	        value ??= defaultValue();
	      }

	      // A key can be optional and have no default value.
	      // When this happens, do not perform a conversion,
	      // and do not assign the key a value.
	      if (required || hasDefault || value !== undefined) {
	        value = converter(value, prefix, `${argument}.${key}`);

	        if (
	          options.allowedValues &&
	          !options.allowedValues.includes(value)
	        ) {
	          throw webidl.errors.exception({
	            header: prefix,
	            message: `${value} is not an accepted type. Expected one of ${options.allowedValues.join(', ')}.`
	          })
	        }

	        dict[key] = value;
	      }
	    }

	    return dict
	  }
	};

	webidl.nullableConverter = function (converter) {
	  return (V, prefix, argument) => {
	    if (V === null) {
	      return V
	    }

	    return converter(V, prefix, argument)
	  }
	};

	// https://webidl.spec.whatwg.org/#es-DOMString
	webidl.converters.DOMString = function (V, prefix, argument, opts) {
	  // 1. If V is null and the conversion is to an IDL type
	  //    associated with the [LegacyNullToEmptyString]
	  //    extended attribute, then return the DOMString value
	  //    that represents the empty string.
	  if (V === null && opts?.legacyNullToEmptyString) {
	    return ''
	  }

	  // 2. Let x be ? ToString(V).
	  if (typeof V === 'symbol') {
	    throw webidl.errors.exception({
	      header: prefix,
	      message: `${argument} is a symbol, which cannot be converted to a DOMString.`
	    })
	  }

	  // 3. Return the IDL DOMString value that represents the
	  //    same sequence of code units as the one the
	  //    ECMAScript String value x represents.
	  return String(V)
	};

	// https://webidl.spec.whatwg.org/#es-ByteString
	webidl.converters.ByteString = function (V, prefix, argument) {
	  // 1. Let x be ? ToString(V).
	  // Note: DOMString converter perform ? ToString(V)
	  const x = webidl.converters.DOMString(V, prefix, argument);

	  // 2. If the value of any element of x is greater than
	  //    255, then throw a TypeError.
	  for (let index = 0; index < x.length; index++) {
	    if (x.charCodeAt(index) > 255) {
	      throw new TypeError(
	        'Cannot convert argument to a ByteString because the character at ' +
	        `index ${index} has a value of ${x.charCodeAt(index)} which is greater than 255.`
	      )
	    }
	  }

	  // 3. Return an IDL ByteString value whose length is the
	  //    length of x, and where the value of each element is
	  //    the value of the corresponding element of x.
	  return x
	};

	// https://webidl.spec.whatwg.org/#es-USVString
	// TODO: rewrite this so we can control the errors thrown
	webidl.converters.USVString = toUSVString;

	// https://webidl.spec.whatwg.org/#es-boolean
	webidl.converters.boolean = function (V) {
	  // 1. Let x be the result of computing ToBoolean(V).
	  const x = Boolean(V);

	  // 2. Return the IDL boolean value that is the one that represents
	  //    the same truth value as the ECMAScript Boolean value x.
	  return x
	};

	// https://webidl.spec.whatwg.org/#es-any
	webidl.converters.any = function (V) {
	  return V
	};

	// https://webidl.spec.whatwg.org/#es-long-long
	webidl.converters['long long'] = function (V, prefix, argument) {
	  // 1. Let x be ? ConvertToInt(V, 64, "signed").
	  const x = webidl.util.ConvertToInt(V, 64, 'signed', undefined, prefix, argument);

	  // 2. Return the IDL long long value that represents
	  //    the same numeric value as x.
	  return x
	};

	// https://webidl.spec.whatwg.org/#es-unsigned-long-long
	webidl.converters['unsigned long long'] = function (V, prefix, argument) {
	  // 1. Let x be ? ConvertToInt(V, 64, "unsigned").
	  const x = webidl.util.ConvertToInt(V, 64, 'unsigned', undefined, prefix, argument);

	  // 2. Return the IDL unsigned long long value that
	  //    represents the same numeric value as x.
	  return x
	};

	// https://webidl.spec.whatwg.org/#es-unsigned-long
	webidl.converters['unsigned long'] = function (V, prefix, argument) {
	  // 1. Let x be ? ConvertToInt(V, 32, "unsigned").
	  const x = webidl.util.ConvertToInt(V, 32, 'unsigned', undefined, prefix, argument);

	  // 2. Return the IDL unsigned long value that
	  //    represents the same numeric value as x.
	  return x
	};

	// https://webidl.spec.whatwg.org/#es-unsigned-short
	webidl.converters['unsigned short'] = function (V, prefix, argument, opts) {
	  // 1. Let x be ? ConvertToInt(V, 16, "unsigned").
	  const x = webidl.util.ConvertToInt(V, 16, 'unsigned', opts, prefix, argument);

	  // 2. Return the IDL unsigned short value that represents
	  //    the same numeric value as x.
	  return x
	};

	// https://webidl.spec.whatwg.org/#idl-ArrayBuffer
	webidl.converters.ArrayBuffer = function (V, prefix, argument, opts) {
	  // 1. If Type(V) is not Object, or V does not have an
	  //    [[ArrayBufferData]] internal slot, then throw a
	  //    TypeError.
	  // see: https://tc39.es/ecma262/#sec-properties-of-the-arraybuffer-instances
	  // see: https://tc39.es/ecma262/#sec-properties-of-the-sharedarraybuffer-instances
	  if (
	    webidl.util.Type(V) !== 'Object' ||
	    !types.isAnyArrayBuffer(V)
	  ) {
	    throw webidl.errors.conversionFailed({
	      prefix,
	      argument: `${argument} ("${webidl.util.Stringify(V)}")`,
	      types: ['ArrayBuffer']
	    })
	  }

	  // 2. If the conversion is not to an IDL type associated
	  //    with the [AllowShared] extended attribute, and
	  //    IsSharedArrayBuffer(V) is true, then throw a
	  //    TypeError.
	  if (opts?.allowShared === false && types.isSharedArrayBuffer(V)) {
	    throw webidl.errors.exception({
	      header: 'ArrayBuffer',
	      message: 'SharedArrayBuffer is not allowed.'
	    })
	  }

	  // 3. If the conversion is not to an IDL type associated
	  //    with the [AllowResizable] extended attribute, and
	  //    IsResizableArrayBuffer(V) is true, then throw a
	  //    TypeError.
	  if (V.resizable || V.growable) {
	    throw webidl.errors.exception({
	      header: 'ArrayBuffer',
	      message: 'Received a resizable ArrayBuffer.'
	    })
	  }

	  // 4. Return the IDL ArrayBuffer value that is a
	  //    reference to the same object as V.
	  return V
	};

	webidl.converters.TypedArray = function (V, T, prefix, name, opts) {
	  // 1. Let T be the IDL type V is being converted to.

	  // 2. If Type(V) is not Object, or V does not have a
	  //    [[TypedArrayName]] internal slot with a value
	  //    equal to Tâs name, then throw a TypeError.
	  if (
	    webidl.util.Type(V) !== 'Object' ||
	    !types.isTypedArray(V) ||
	    V.constructor.name !== T.name
	  ) {
	    throw webidl.errors.conversionFailed({
	      prefix,
	      argument: `${name} ("${webidl.util.Stringify(V)}")`,
	      types: [T.name]
	    })
	  }

	  // 3. If the conversion is not to an IDL type associated
	  //    with the [AllowShared] extended attribute, and
	  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is
	  //    true, then throw a TypeError.
	  if (opts?.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {
	    throw webidl.errors.exception({
	      header: 'ArrayBuffer',
	      message: 'SharedArrayBuffer is not allowed.'
	    })
	  }

	  // 4. If the conversion is not to an IDL type associated
	  //    with the [AllowResizable] extended attribute, and
	  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is
	  //    true, then throw a TypeError.
	  if (V.buffer.resizable || V.buffer.growable) {
	    throw webidl.errors.exception({
	      header: 'ArrayBuffer',
	      message: 'Received a resizable ArrayBuffer.'
	    })
	  }

	  // 5. Return the IDL value of type T that is a reference
	  //    to the same object as V.
	  return V
	};

	webidl.converters.DataView = function (V, prefix, name, opts) {
	  // 1. If Type(V) is not Object, or V does not have a
	  //    [[DataView]] internal slot, then throw a TypeError.
	  if (webidl.util.Type(V) !== 'Object' || !types.isDataView(V)) {
	    throw webidl.errors.exception({
	      header: prefix,
	      message: `${name} is not a DataView.`
	    })
	  }

	  // 2. If the conversion is not to an IDL type associated
	  //    with the [AllowShared] extended attribute, and
	  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is true,
	  //    then throw a TypeError.
	  if (opts?.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {
	    throw webidl.errors.exception({
	      header: 'ArrayBuffer',
	      message: 'SharedArrayBuffer is not allowed.'
	    })
	  }

	  // 3. If the conversion is not to an IDL type associated
	  //    with the [AllowResizable] extended attribute, and
	  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is
	  //    true, then throw a TypeError.
	  if (V.buffer.resizable || V.buffer.growable) {
	    throw webidl.errors.exception({
	      header: 'ArrayBuffer',
	      message: 'Received a resizable ArrayBuffer.'
	    })
	  }

	  // 4. Return the IDL DataView value that is a reference
	  //    to the same object as V.
	  return V
	};

	// https://webidl.spec.whatwg.org/#BufferSource
	webidl.converters.BufferSource = function (V, prefix, name, opts) {
	  if (types.isAnyArrayBuffer(V)) {
	    return webidl.converters.ArrayBuffer(V, prefix, name, { ...opts, allowShared: false })
	  }

	  if (types.isTypedArray(V)) {
	    return webidl.converters.TypedArray(V, V.constructor, prefix, name, { ...opts, allowShared: false })
	  }

	  if (types.isDataView(V)) {
	    return webidl.converters.DataView(V, prefix, name, { ...opts, allowShared: false })
	  }

	  throw webidl.errors.conversionFailed({
	    prefix,
	    argument: `${name} ("${webidl.util.Stringify(V)}")`,
	    types: ['BufferSource']
	  })
	};

	webidl.converters['sequence<ByteString>'] = webidl.sequenceConverter(
	  webidl.converters.ByteString
	);

	webidl.converters['sequence<sequence<ByteString>>'] = webidl.sequenceConverter(
	  webidl.converters['sequence<ByteString>']
	);

	webidl.converters['record<ByteString, ByteString>'] = webidl.recordConverter(
	  webidl.converters.ByteString,
	  webidl.converters.ByteString
	);

	webidl_1 = {
	  webidl
	};
	return webidl_1;
}

var util$6;
var hasRequiredUtil$6;

function requireUtil$6 () {
	if (hasRequiredUtil$6) return util$6;
	hasRequiredUtil$6 = 1;

	const { Transform } = require$$0$5;
	const zlib = require$$1;
	const { redirectStatusSet, referrerPolicySet: referrerPolicyTokens, badPortsSet } = requireConstants$2();
	const { getGlobalOrigin } = requireGlobal$1();
	const { collectASequenceOfCodePoints, collectAnHTTPQuotedString, removeChars, parseMIMEType } = requireDataUrl();
	const { performance } = require$$5;
	const { isBlobLike, ReadableStreamFrom, isValidHTTPToken, normalizedMethodRecordsBase } = requireUtil$7();
	const assert = require$$0$4;
	const { isUint8Array } = require$$8$1;
	const { webidl } = requireWebidl();

	let supportedHashes = [];

	// https://nodejs.org/api/crypto.html#determining-if-crypto-support-is-unavailable
	/** @type {import('crypto')} */
	let crypto;
	try {
	  crypto = require('node:crypto');
	  const possibleRelevantHashes = ['sha256', 'sha384', 'sha512'];
	  supportedHashes = crypto.getHashes().filter((hash) => possibleRelevantHashes.includes(hash));
	/* c8 ignore next 3 */
	} catch {

	}

	function responseURL (response) {
	  // https://fetch.spec.whatwg.org/#responses
	  // A response has an associated URL. It is a pointer to the last URL
	  // in responseâs URL list and null if responseâs URL list is empty.
	  const urlList = response.urlList;
	  const length = urlList.length;
	  return length === 0 ? null : urlList[length - 1].toString()
	}

	// https://fetch.spec.whatwg.org/#concept-response-location-url
	function responseLocationURL (response, requestFragment) {
	  // 1. If responseâs status is not a redirect status, then return null.
	  if (!redirectStatusSet.has(response.status)) {
	    return null
	  }

	  // 2. Let location be the result of extracting header list values given
	  // `Location` and responseâs header list.
	  let location = response.headersList.get('location', true);

	  // 3. If location is a header value, then set location to the result of
	  //    parsing location with responseâs URL.
	  if (location !== null && isValidHeaderValue(location)) {
	    if (!isValidEncodedURL(location)) {
	      // Some websites respond location header in UTF-8 form without encoding them as ASCII
	      // and major browsers redirect them to correctly UTF-8 encoded addresses.
	      // Here, we handle that behavior in the same way.
	      location = normalizeBinaryStringToUtf8(location);
	    }
	    location = new URL(location, responseURL(response));
	  }

	  // 4. If location is a URL whose fragment is null, then set locationâs
	  // fragment to requestFragment.
	  if (location && !location.hash) {
	    location.hash = requestFragment;
	  }

	  // 5. Return location.
	  return location
	}

	/**
	 * @see https://www.rfc-editor.org/rfc/rfc1738#section-2.2
	 * @param {string} url
	 * @returns {boolean}
	 */
	function isValidEncodedURL (url) {
	  for (let i = 0; i < url.length; ++i) {
	    const code = url.charCodeAt(i);

	    if (
	      code > 0x7E || // Non-US-ASCII + DEL
	      code < 0x20 // Control characters NUL - US
	    ) {
	      return false
	    }
	  }
	  return true
	}

	/**
	 * If string contains non-ASCII characters, assumes it's UTF-8 encoded and decodes it.
	 * Since UTF-8 is a superset of ASCII, this will work for ASCII strings as well.
	 * @param {string} value
	 * @returns {string}
	 */
	function normalizeBinaryStringToUtf8 (value) {
	  return Buffer.from(value, 'binary').toString('utf8')
	}

	/** @returns {URL} */
	function requestCurrentURL (request) {
	  return request.urlList[request.urlList.length - 1]
	}

	function requestBadPort (request) {
	  // 1. Let url be requestâs current URL.
	  const url = requestCurrentURL(request);

	  // 2. If urlâs scheme is an HTTP(S) scheme and urlâs port is a bad port,
	  // then return blocked.
	  if (urlIsHttpHttpsScheme(url) && badPortsSet.has(url.port)) {
	    return 'blocked'
	  }

	  // 3. Return allowed.
	  return 'allowed'
	}

	function isErrorLike (object) {
	  return object instanceof Error || (
	    object?.constructor?.name === 'Error' ||
	    object?.constructor?.name === 'DOMException'
	  )
	}

	// Check whether |statusText| is a ByteString and
	// matches the Reason-Phrase token production.
	// RFC 2616: https://tools.ietf.org/html/rfc2616
	// RFC 7230: https://tools.ietf.org/html/rfc7230
	// "reason-phrase = *( HTAB / SP / VCHAR / obs-text )"
	// https://github.com/chromium/chromium/blob/94.0.4604.1/third_party/blink/renderer/core/fetch/response.cc#L116
	function isValidReasonPhrase (statusText) {
	  for (let i = 0; i < statusText.length; ++i) {
	    const c = statusText.charCodeAt(i);
	    if (
	      !(
	        (
	          c === 0x09 || // HTAB
	          (c >= 0x20 && c <= 0x7e) || // SP / VCHAR
	          (c >= 0x80 && c <= 0xff)
	        ) // obs-text
	      )
	    ) {
	      return false
	    }
	  }
	  return true
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#header-name
	 * @param {string} potentialValue
	 */
	const isValidHeaderName = isValidHTTPToken;

	/**
	 * @see https://fetch.spec.whatwg.org/#header-value
	 * @param {string} potentialValue
	 */
	function isValidHeaderValue (potentialValue) {
	  // - Has no leading or trailing HTTP tab or space bytes.
	  // - Contains no 0x00 (NUL) or HTTP newline bytes.
	  return (
	    potentialValue[0] === '\t' ||
	    potentialValue[0] === ' ' ||
	    potentialValue[potentialValue.length - 1] === '\t' ||
	    potentialValue[potentialValue.length - 1] === ' ' ||
	    potentialValue.includes('\n') ||
	    potentialValue.includes('\r') ||
	    potentialValue.includes('\0')
	  ) === false
	}

	// https://w3c.github.io/webappsec-referrer-policy/#set-requests-referrer-policy-on-redirect
	function setRequestReferrerPolicyOnRedirect (request, actualResponse) {
	  //  Given a request request and a response actualResponse, this algorithm
	  //  updates requestâs referrer policy according to the Referrer-Policy
	  //  header (if any) in actualResponse.

	  // 1. Let policy be the result of executing Â§ 8.1 Parse a referrer policy
	  // from a Referrer-Policy header on actualResponse.

	  // 8.1 Parse a referrer policy from a Referrer-Policy header
	  // 1. Let policy-tokens be the result of extracting header list values given `Referrer-Policy` and responseâs header list.
	  const { headersList } = actualResponse;
	  // 2. Let policy be the empty string.
	  // 3. For each token in policy-tokens, if token is a referrer policy and token is not the empty string, then set policy to token.
	  // 4. Return policy.
	  const policyHeader = (headersList.get('referrer-policy', true) ?? '').split(',');

	  // Note: As the referrer-policy can contain multiple policies
	  // separated by comma, we need to loop through all of them
	  // and pick the first valid one.
	  // Ref: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy#specify_a_fallback_policy
	  let policy = '';
	  if (policyHeader.length > 0) {
	    // The right-most policy takes precedence.
	    // The left-most policy is the fallback.
	    for (let i = policyHeader.length; i !== 0; i--) {
	      const token = policyHeader[i - 1].trim();
	      if (referrerPolicyTokens.has(token)) {
	        policy = token;
	        break
	      }
	    }
	  }

	  // 2. If policy is not the empty string, then set requestâs referrer policy to policy.
	  if (policy !== '') {
	    request.referrerPolicy = policy;
	  }
	}

	// https://fetch.spec.whatwg.org/#cross-origin-resource-policy-check
	function crossOriginResourcePolicyCheck () {
	  // TODO
	  return 'allowed'
	}

	// https://fetch.spec.whatwg.org/#concept-cors-check
	function corsCheck () {
	  // TODO
	  return 'success'
	}

	// https://fetch.spec.whatwg.org/#concept-tao-check
	function TAOCheck () {
	  // TODO
	  return 'success'
	}

	function appendFetchMetadata (httpRequest) {
	  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-dest-header
	  //  TODO

	  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-mode-header

	  //  1. Assert: râs url is a potentially trustworthy URL.
	  //  TODO

	  //  2. Let header be a Structured Header whose value is a token.
	  let header = null;

	  //  3. Set headerâs value to râs mode.
	  header = httpRequest.mode;

	  //  4. Set a structured field value `Sec-Fetch-Mode`/header in râs header list.
	  httpRequest.headersList.set('sec-fetch-mode', header, true);

	  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-site-header
	  //  TODO

	  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-user-header
	  //  TODO
	}

	// https://fetch.spec.whatwg.org/#append-a-request-origin-header
	function appendRequestOriginHeader (request) {
	  // 1. Let serializedOrigin be the result of byte-serializing a request origin
	  //    with request.
	  // TODO: implement "byte-serializing a request origin"
	  let serializedOrigin = request.origin;

	  // "'client' is changed to an origin during fetching."
	  // This doesn't happen in undici (in most cases) because undici, by default,
	  // has no concept of origin.
	  if (serializedOrigin === 'client') {
	    return
	  }

	  // 2. If requestâs response tainting is "cors" or requestâs mode is "websocket",
	  //    then append (`Origin`, serializedOrigin) to requestâs header list.
	  // 3. Otherwise, if requestâs method is neither `GET` nor `HEAD`, then:
	  if (request.responseTainting === 'cors' || request.mode === 'websocket') {
	    request.headersList.append('origin', serializedOrigin, true);
	  } else if (request.method !== 'GET' && request.method !== 'HEAD') {
	    // 1. Switch on requestâs referrer policy:
	    switch (request.referrerPolicy) {
	      case 'no-referrer':
	        // Set serializedOrigin to `null`.
	        serializedOrigin = null;
	        break
	      case 'no-referrer-when-downgrade':
	      case 'strict-origin':
	      case 'strict-origin-when-cross-origin':
	        // If requestâs origin is a tuple origin, its scheme is "https", and
	        // requestâs current URLâs scheme is not "https", then set
	        // serializedOrigin to `null`.
	        if (request.origin && urlHasHttpsScheme(request.origin) && !urlHasHttpsScheme(requestCurrentURL(request))) {
	          serializedOrigin = null;
	        }
	        break
	      case 'same-origin':
	        // If requestâs origin is not same origin with requestâs current URLâs
	        // origin, then set serializedOrigin to `null`.
	        if (!sameOrigin(request, requestCurrentURL(request))) {
	          serializedOrigin = null;
	        }
	        break
	        // Do nothing.
	    }

	    // 2. Append (`Origin`, serializedOrigin) to requestâs header list.
	    request.headersList.append('origin', serializedOrigin, true);
	  }
	}

	// https://w3c.github.io/hr-time/#dfn-coarsen-time
	function coarsenTime (timestamp, crossOriginIsolatedCapability) {
	  // TODO
	  return timestamp
	}

	// https://fetch.spec.whatwg.org/#clamp-and-coarsen-connection-timing-info
	function clampAndCoarsenConnectionTimingInfo (connectionTimingInfo, defaultStartTime, crossOriginIsolatedCapability) {
	  if (!connectionTimingInfo?.startTime || connectionTimingInfo.startTime < defaultStartTime) {
	    return {
	      domainLookupStartTime: defaultStartTime,
	      domainLookupEndTime: defaultStartTime,
	      connectionStartTime: defaultStartTime,
	      connectionEndTime: defaultStartTime,
	      secureConnectionStartTime: defaultStartTime,
	      ALPNNegotiatedProtocol: connectionTimingInfo?.ALPNNegotiatedProtocol
	    }
	  }

	  return {
	    domainLookupStartTime: coarsenTime(connectionTimingInfo.domainLookupStartTime),
	    domainLookupEndTime: coarsenTime(connectionTimingInfo.domainLookupEndTime),
	    connectionStartTime: coarsenTime(connectionTimingInfo.connectionStartTime),
	    connectionEndTime: coarsenTime(connectionTimingInfo.connectionEndTime),
	    secureConnectionStartTime: coarsenTime(connectionTimingInfo.secureConnectionStartTime),
	    ALPNNegotiatedProtocol: connectionTimingInfo.ALPNNegotiatedProtocol
	  }
	}

	// https://w3c.github.io/hr-time/#dfn-coarsened-shared-current-time
	function coarsenedSharedCurrentTime (crossOriginIsolatedCapability) {
	  return coarsenTime(performance.now())
	}

	// https://fetch.spec.whatwg.org/#create-an-opaque-timing-info
	function createOpaqueTimingInfo (timingInfo) {
	  return {
	    startTime: timingInfo.startTime ?? 0,
	    redirectStartTime: 0,
	    redirectEndTime: 0,
	    postRedirectStartTime: timingInfo.startTime ?? 0,
	    finalServiceWorkerStartTime: 0,
	    finalNetworkResponseStartTime: 0,
	    finalNetworkRequestStartTime: 0,
	    endTime: 0,
	    encodedBodySize: 0,
	    decodedBodySize: 0,
	    finalConnectionTimingInfo: null
	  }
	}

	// https://html.spec.whatwg.org/multipage/origin.html#policy-container
	function makePolicyContainer () {
	  // Note: the fetch spec doesn't make use of embedder policy or CSP list
	  return {
	    referrerPolicy: 'strict-origin-when-cross-origin'
	  }
	}

	// https://html.spec.whatwg.org/multipage/origin.html#clone-a-policy-container
	function clonePolicyContainer (policyContainer) {
	  return {
	    referrerPolicy: policyContainer.referrerPolicy
	  }
	}

	// https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer
	function determineRequestsReferrer (request) {
	  // 1. Let policy be request's referrer policy.
	  const policy = request.referrerPolicy;

	  // Note: policy cannot (shouldn't) be null or an empty string.
	  assert(policy);

	  // 2. Let environment be requestâs client.

	  let referrerSource = null;

	  // 3. Switch on requestâs referrer:
	  if (request.referrer === 'client') {
	    // Note: node isn't a browser and doesn't implement document/iframes,
	    // so we bypass this step and replace it with our own.

	    const globalOrigin = getGlobalOrigin();

	    if (!globalOrigin || globalOrigin.origin === 'null') {
	      return 'no-referrer'
	    }

	    // note: we need to clone it as it's mutated
	    referrerSource = new URL(globalOrigin);
	  } else if (request.referrer instanceof URL) {
	    // Let referrerSource be requestâs referrer.
	    referrerSource = request.referrer;
	  }

	  // 4. Let requestâs referrerURL be the result of stripping referrerSource for
	  //    use as a referrer.
	  let referrerURL = stripURLForReferrer(referrerSource);

	  // 5. Let referrerOrigin be the result of stripping referrerSource for use as
	  //    a referrer, with the origin-only flag set to true.
	  const referrerOrigin = stripURLForReferrer(referrerSource, true);

	  // 6. If the result of serializing referrerURL is a string whose length is
	  //    greater than 4096, set referrerURL to referrerOrigin.
	  if (referrerURL.toString().length > 4096) {
	    referrerURL = referrerOrigin;
	  }

	  const areSameOrigin = sameOrigin(request, referrerURL);
	  const isNonPotentiallyTrustWorthy = isURLPotentiallyTrustworthy(referrerURL) &&
	    !isURLPotentiallyTrustworthy(request.url);

	  // 8. Execute the switch statements corresponding to the value of policy:
	  switch (policy) {
	    case 'origin': return referrerOrigin != null ? referrerOrigin : stripURLForReferrer(referrerSource, true)
	    case 'unsafe-url': return referrerURL
	    case 'same-origin':
	      return areSameOrigin ? referrerOrigin : 'no-referrer'
	    case 'origin-when-cross-origin':
	      return areSameOrigin ? referrerURL : referrerOrigin
	    case 'strict-origin-when-cross-origin': {
	      const currentURL = requestCurrentURL(request);

	      // 1. If the origin of referrerURL and the origin of requestâs current
	      //    URL are the same, then return referrerURL.
	      if (sameOrigin(referrerURL, currentURL)) {
	        return referrerURL
	      }

	      // 2. If referrerURL is a potentially trustworthy URL and requestâs
	      //    current URL is not a potentially trustworthy URL, then return no
	      //    referrer.
	      if (isURLPotentiallyTrustworthy(referrerURL) && !isURLPotentiallyTrustworthy(currentURL)) {
	        return 'no-referrer'
	      }

	      // 3. Return referrerOrigin.
	      return referrerOrigin
	    }
	    case 'strict-origin': // eslint-disable-line
	      /**
	         * 1. If referrerURL is a potentially trustworthy URL and
	         * requestâs current URL is not a potentially trustworthy URL,
	         * then return no referrer.
	         * 2. Return referrerOrigin
	        */
	    case 'no-referrer-when-downgrade': // eslint-disable-line
	      /**
	       * 1. If referrerURL is a potentially trustworthy URL and
	       * requestâs current URL is not a potentially trustworthy URL,
	       * then return no referrer.
	       * 2. Return referrerOrigin
	      */

	    default: // eslint-disable-line
	      return isNonPotentiallyTrustWorthy ? 'no-referrer' : referrerOrigin
	  }
	}

	/**
	 * @see https://w3c.github.io/webappsec-referrer-policy/#strip-url
	 * @param {URL} url
	 * @param {boolean|undefined} originOnly
	 */
	function stripURLForReferrer (url, originOnly) {
	  // 1. Assert: url is a URL.
	  assert(url instanceof URL);

	  url = new URL(url);

	  // 2. If urlâs scheme is a local scheme, then return no referrer.
	  if (url.protocol === 'file:' || url.protocol === 'about:' || url.protocol === 'blank:') {
	    return 'no-referrer'
	  }

	  // 3. Set urlâs username to the empty string.
	  url.username = '';

	  // 4. Set urlâs password to the empty string.
	  url.password = '';

	  // 5. Set urlâs fragment to null.
	  url.hash = '';

	  // 6. If the origin-only flag is true, then:
	  if (originOnly) {
	    // 1. Set urlâs path to Â« the empty string Â».
	    url.pathname = '';

	    // 2. Set urlâs query to null.
	    url.search = '';
	  }

	  // 7. Return url.
	  return url
	}

	function isURLPotentiallyTrustworthy (url) {
	  if (!(url instanceof URL)) {
	    return false
	  }

	  // If child of about, return true
	  if (url.href === 'about:blank' || url.href === 'about:srcdoc') {
	    return true
	  }

	  // If scheme is data, return true
	  if (url.protocol === 'data:') return true

	  // If file, return true
	  if (url.protocol === 'file:') return true

	  return isOriginPotentiallyTrustworthy(url.origin)

	  function isOriginPotentiallyTrustworthy (origin) {
	    // If origin is explicitly null, return false
	    if (origin == null || origin === 'null') return false

	    const originAsURL = new URL(origin);

	    // If secure, return true
	    if (originAsURL.protocol === 'https:' || originAsURL.protocol === 'wss:') {
	      return true
	    }

	    // If localhost or variants, return true
	    if (/^127(?:\.[0-9]+){0,2}\.[0-9]+$|^\[(?:0*:)*?:?0*1\]$/.test(originAsURL.hostname) ||
	     (originAsURL.hostname === 'localhost' || originAsURL.hostname.includes('localhost.')) ||
	     (originAsURL.hostname.endsWith('.localhost'))) {
	      return true
	    }

	    // If any other, return false
	    return false
	  }
	}

	/**
	 * @see https://w3c.github.io/webappsec-subresource-integrity/#does-response-match-metadatalist
	 * @param {Uint8Array} bytes
	 * @param {string} metadataList
	 */
	function bytesMatch (bytes, metadataList) {
	  // If node is not built with OpenSSL support, we cannot check
	  // a request's integrity, so allow it by default (the spec will
	  // allow requests if an invalid hash is given, as precedence).
	  /* istanbul ignore if: only if node is built with --without-ssl */
	  if (crypto === undefined) {
	    return true
	  }

	  // 1. Let parsedMetadata be the result of parsing metadataList.
	  const parsedMetadata = parseMetadata(metadataList);

	  // 2. If parsedMetadata is no metadata, return true.
	  if (parsedMetadata === 'no metadata') {
	    return true
	  }

	  // 3. If response is not eligible for integrity validation, return false.
	  // TODO

	  // 4. If parsedMetadata is the empty set, return true.
	  if (parsedMetadata.length === 0) {
	    return true
	  }

	  // 5. Let metadata be the result of getting the strongest
	  //    metadata from parsedMetadata.
	  const strongest = getStrongestMetadata(parsedMetadata);
	  const metadata = filterMetadataListByAlgorithm(parsedMetadata, strongest);

	  // 6. For each item in metadata:
	  for (const item of metadata) {
	    // 1. Let algorithm be the alg component of item.
	    const algorithm = item.algo;

	    // 2. Let expectedValue be the val component of item.
	    const expectedValue = item.hash;

	    // See https://github.com/web-platform-tests/wpt/commit/e4c5cc7a5e48093220528dfdd1c4012dc3837a0e
	    // "be liberal with padding". This is annoying, and it's not even in the spec.

	    // 3. Let actualValue be the result of applying algorithm to bytes.
	    let actualValue = crypto.createHash(algorithm).update(bytes).digest('base64');

	    if (actualValue[actualValue.length - 1] === '=') {
	      if (actualValue[actualValue.length - 2] === '=') {
	        actualValue = actualValue.slice(0, -2);
	      } else {
	        actualValue = actualValue.slice(0, -1);
	      }
	    }

	    // 4. If actualValue is a case-sensitive match for expectedValue,
	    //    return true.
	    if (compareBase64Mixed(actualValue, expectedValue)) {
	      return true
	    }
	  }

	  // 7. Return false.
	  return false
	}

	// https://w3c.github.io/webappsec-subresource-integrity/#grammardef-hash-with-options
	// https://www.w3.org/TR/CSP2/#source-list-syntax
	// https://www.rfc-editor.org/rfc/rfc5234#appendix-B.1
	const parseHashWithOptions = /(?<algo>sha256|sha384|sha512)-((?<hash>[A-Za-z0-9+/]+|[A-Za-z0-9_-]+)={0,2}(?:\s|$)( +[!-~]*)?)?/i;

	/**
	 * @see https://w3c.github.io/webappsec-subresource-integrity/#parse-metadata
	 * @param {string} metadata
	 */
	function parseMetadata (metadata) {
	  // 1. Let result be the empty set.
	  /** @type {{ algo: string, hash: string }[]} */
	  const result = [];

	  // 2. Let empty be equal to true.
	  let empty = true;

	  // 3. For each token returned by splitting metadata on spaces:
	  for (const token of metadata.split(' ')) {
	    // 1. Set empty to false.
	    empty = false;

	    // 2. Parse token as a hash-with-options.
	    const parsedToken = parseHashWithOptions.exec(token);

	    // 3. If token does not parse, continue to the next token.
	    if (
	      parsedToken === null ||
	      parsedToken.groups === undefined ||
	      parsedToken.groups.algo === undefined
	    ) {
	      // Note: Chromium blocks the request at this point, but Firefox
	      // gives a warning that an invalid integrity was given. The
	      // correct behavior is to ignore these, and subsequently not
	      // check the integrity of the resource.
	      continue
	    }

	    // 4. Let algorithm be the hash-algo component of token.
	    const algorithm = parsedToken.groups.algo.toLowerCase();

	    // 5. If algorithm is a hash function recognized by the user
	    //    agent, add the parsed token to result.
	    if (supportedHashes.includes(algorithm)) {
	      result.push(parsedToken.groups);
	    }
	  }

	  // 4. Return no metadata if empty is true, otherwise return result.
	  if (empty === true) {
	    return 'no metadata'
	  }

	  return result
	}

	/**
	 * @param {{ algo: 'sha256' | 'sha384' | 'sha512' }[]} metadataList
	 */
	function getStrongestMetadata (metadataList) {
	  // Let algorithm be the algo component of the first item in metadataList.
	  // Can be sha256
	  let algorithm = metadataList[0].algo;
	  // If the algorithm is sha512, then it is the strongest
	  // and we can return immediately
	  if (algorithm[3] === '5') {
	    return algorithm
	  }

	  for (let i = 1; i < metadataList.length; ++i) {
	    const metadata = metadataList[i];
	    // If the algorithm is sha512, then it is the strongest
	    // and we can break the loop immediately
	    if (metadata.algo[3] === '5') {
	      algorithm = 'sha512';
	      break
	    // If the algorithm is sha384, then a potential sha256 or sha384 is ignored
	    } else if (algorithm[3] === '3') {
	      continue
	    // algorithm is sha256, check if algorithm is sha384 and if so, set it as
	    // the strongest
	    } else if (metadata.algo[3] === '3') {
	      algorithm = 'sha384';
	    }
	  }
	  return algorithm
	}

	function filterMetadataListByAlgorithm (metadataList, algorithm) {
	  if (metadataList.length === 1) {
	    return metadataList
	  }

	  let pos = 0;
	  for (let i = 0; i < metadataList.length; ++i) {
	    if (metadataList[i].algo === algorithm) {
	      metadataList[pos++] = metadataList[i];
	    }
	  }

	  metadataList.length = pos;

	  return metadataList
	}

	/**
	 * Compares two base64 strings, allowing for base64url
	 * in the second string.
	 *
	* @param {string} actualValue always base64
	 * @param {string} expectedValue base64 or base64url
	 * @returns {boolean}
	 */
	function compareBase64Mixed (actualValue, expectedValue) {
	  if (actualValue.length !== expectedValue.length) {
	    return false
	  }
	  for (let i = 0; i < actualValue.length; ++i) {
	    if (actualValue[i] !== expectedValue[i]) {
	      if (
	        (actualValue[i] === '+' && expectedValue[i] === '-') ||
	        (actualValue[i] === '/' && expectedValue[i] === '_')
	      ) {
	        continue
	      }
	      return false
	    }
	  }

	  return true
	}

	// https://w3c.github.io/webappsec-upgrade-insecure-requests/#upgrade-request
	function tryUpgradeRequestToAPotentiallyTrustworthyURL (request) {
	  // TODO
	}

	/**
	 * @link {https://html.spec.whatwg.org/multipage/origin.html#same-origin}
	 * @param {URL} A
	 * @param {URL} B
	 */
	function sameOrigin (A, B) {
	  // 1. If A and B are the same opaque origin, then return true.
	  if (A.origin === B.origin && A.origin === 'null') {
	    return true
	  }

	  // 2. If A and B are both tuple origins and their schemes,
	  //    hosts, and port are identical, then return true.
	  if (A.protocol === B.protocol && A.hostname === B.hostname && A.port === B.port) {
	    return true
	  }

	  // 3. Return false.
	  return false
	}

	function createDeferredPromise () {
	  let res;
	  let rej;
	  const promise = new Promise((resolve, reject) => {
	    res = resolve;
	    rej = reject;
	  });

	  return { promise, resolve: res, reject: rej }
	}

	function isAborted (fetchParams) {
	  return fetchParams.controller.state === 'aborted'
	}

	function isCancelled (fetchParams) {
	  return fetchParams.controller.state === 'aborted' ||
	    fetchParams.controller.state === 'terminated'
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#concept-method-normalize
	 * @param {string} method
	 */
	function normalizeMethod (method) {
	  return normalizedMethodRecordsBase[method.toLowerCase()] ?? method
	}

	// https://infra.spec.whatwg.org/#serialize-a-javascript-value-to-a-json-string
	function serializeJavascriptValueToJSONString (value) {
	  // 1. Let result be ? Call(%JSON.stringify%, undefined, Â« value Â»).
	  const result = JSON.stringify(value);

	  // 2. If result is undefined, then throw a TypeError.
	  if (result === undefined) {
	    throw new TypeError('Value is not JSON serializable')
	  }

	  // 3. Assert: result is a string.
	  assert(typeof result === 'string');

	  // 4. Return result.
	  return result
	}

	// https://tc39.es/ecma262/#sec-%25iteratorprototype%25-object
	const esIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]()));

	/**
	 * @see https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object
	 * @param {string} name name of the instance
	 * @param {symbol} kInternalIterator
	 * @param {string | number} [keyIndex]
	 * @param {string | number} [valueIndex]
	 */
	function createIterator (name, kInternalIterator, keyIndex = 0, valueIndex = 1) {
	  class FastIterableIterator {
	    /** @type {any} */
	    #target
	    /** @type {'key' | 'value' | 'key+value'} */
	    #kind
	    /** @type {number} */
	    #index

	    /**
	     * @see https://webidl.spec.whatwg.org/#dfn-default-iterator-object
	     * @param {unknown} target
	     * @param {'key' | 'value' | 'key+value'} kind
	     */
	    constructor (target, kind) {
	      this.#target = target;
	      this.#kind = kind;
	      this.#index = 0;
	    }

	    next () {
	      // 1. Let interface be the interface for which the iterator prototype object exists.
	      // 2. Let thisValue be the this value.
	      // 3. Let object be ? ToObject(thisValue).
	      // 4. If object is a platform object, then perform a security
	      //    check, passing:
	      // 5. If object is not a default iterator object for interface,
	      //    then throw a TypeError.
	      if (typeof this !== 'object' || this === null || !(#target in this)) {
	        throw new TypeError(
	          `'next' called on an object that does not implement interface ${name} Iterator.`
	        )
	      }

	      // 6. Let index be objectâs index.
	      // 7. Let kind be objectâs kind.
	      // 8. Let values be objectâs target's value pairs to iterate over.
	      const index = this.#index;
	      const values = this.#target[kInternalIterator];

	      // 9. Let len be the length of values.
	      const len = values.length;

	      // 10. If index is greater than or equal to len, then return
	      //     CreateIterResultObject(undefined, true).
	      if (index >= len) {
	        return {
	          value: undefined,
	          done: true
	        }
	      }

	      // 11. Let pair be the entry in values at index index.
	      const { [keyIndex]: key, [valueIndex]: value } = values[index];

	      // 12. Set objectâs index to index + 1.
	      this.#index = index + 1;

	      // 13. Return the iterator result for pair and kind.

	      // https://webidl.spec.whatwg.org/#iterator-result

	      // 1. Let result be a value determined by the value of kind:
	      let result;
	      switch (this.#kind) {
	        case 'key':
	          // 1. Let idlKey be pairâs key.
	          // 2. Let key be the result of converting idlKey to an
	          //    ECMAScript value.
	          // 3. result is key.
	          result = key;
	          break
	        case 'value':
	          // 1. Let idlValue be pairâs value.
	          // 2. Let value be the result of converting idlValue to
	          //    an ECMAScript value.
	          // 3. result is value.
	          result = value;
	          break
	        case 'key+value':
	          // 1. Let idlKey be pairâs key.
	          // 2. Let idlValue be pairâs value.
	          // 3. Let key be the result of converting idlKey to an
	          //    ECMAScript value.
	          // 4. Let value be the result of converting idlValue to
	          //    an ECMAScript value.
	          // 5. Let array be ! ArrayCreate(2).
	          // 6. Call ! CreateDataProperty(array, "0", key).
	          // 7. Call ! CreateDataProperty(array, "1", value).
	          // 8. result is array.
	          result = [key, value];
	          break
	      }

	      // 2. Return CreateIterResultObject(result, false).
	      return {
	        value: result,
	        done: false
	      }
	    }
	  }

	  // https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object
	  // @ts-ignore
	  delete FastIterableIterator.prototype.constructor;

	  Object.setPrototypeOf(FastIterableIterator.prototype, esIteratorPrototype);

	  Object.defineProperties(FastIterableIterator.prototype, {
	    [Symbol.toStringTag]: {
	      writable: false,
	      enumerable: false,
	      configurable: true,
	      value: `${name} Iterator`
	    },
	    next: { writable: true, enumerable: true, configurable: true }
	  });

	  /**
	   * @param {unknown} target
	   * @param {'key' | 'value' | 'key+value'} kind
	   * @returns {IterableIterator<any>}
	   */
	  return function (target, kind) {
	    return new FastIterableIterator(target, kind)
	  }
	}

	/**
	 * @see https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object
	 * @param {string} name name of the instance
	 * @param {any} object class
	 * @param {symbol} kInternalIterator
	 * @param {string | number} [keyIndex]
	 * @param {string | number} [valueIndex]
	 */
	function iteratorMixin (name, object, kInternalIterator, keyIndex = 0, valueIndex = 1) {
	  const makeIterator = createIterator(name, kInternalIterator, keyIndex, valueIndex);

	  const properties = {
	    keys: {
	      writable: true,
	      enumerable: true,
	      configurable: true,
	      value: function keys () {
	        webidl.brandCheck(this, object);
	        return makeIterator(this, 'key')
	      }
	    },
	    values: {
	      writable: true,
	      enumerable: true,
	      configurable: true,
	      value: function values () {
	        webidl.brandCheck(this, object);
	        return makeIterator(this, 'value')
	      }
	    },
	    entries: {
	      writable: true,
	      enumerable: true,
	      configurable: true,
	      value: function entries () {
	        webidl.brandCheck(this, object);
	        return makeIterator(this, 'key+value')
	      }
	    },
	    forEach: {
	      writable: true,
	      enumerable: true,
	      configurable: true,
	      value: function forEach (callbackfn, thisArg = globalThis) {
	        webidl.brandCheck(this, object);
	        webidl.argumentLengthCheck(arguments, 1, `${name}.forEach`);
	        if (typeof callbackfn !== 'function') {
	          throw new TypeError(
	            `Failed to execute 'forEach' on '${name}': parameter 1 is not of type 'Function'.`
	          )
	        }
	        for (const { 0: key, 1: value } of makeIterator(this, 'key+value')) {
	          callbackfn.call(thisArg, value, key, this);
	        }
	      }
	    }
	  };

	  return Object.defineProperties(object.prototype, {
	    ...properties,
	    [Symbol.iterator]: {
	      writable: true,
	      enumerable: false,
	      configurable: true,
	      value: properties.entries.value
	    }
	  })
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#body-fully-read
	 */
	async function fullyReadBody (body, processBody, processBodyError, shouldClone) {
	  // 1. If taskDestination is null, then set taskDestination to
	  //    the result of starting a new parallel queue.

	  // 2. Let successSteps given a byte sequence bytes be to queue a
	  //    fetch task to run processBody given bytes, with taskDestination.
	  const successSteps = processBody;

	  // 3. Let errorSteps be to queue a fetch task to run processBodyError,
	  //    with taskDestination.
	  const errorSteps = processBodyError;

	  // 4. Let reader be the result of getting a reader for bodyâs stream.
	  //    If that threw an exception, then run errorSteps with that
	  //    exception and return.
	  let reader;

	  try {
	    reader = body.stream.getReader();
	  } catch (e) {
	    errorSteps(e);
	    return
	  }

	  // 5. Read all bytes from reader, given successSteps and errorSteps.
	  try {
	    successSteps(await readAllBytes(reader, shouldClone));
	  } catch (e) {
	    errorSteps(e);
	  }
	}

	function isReadableStreamLike (stream) {
	  return stream instanceof ReadableStream || (
	    stream[Symbol.toStringTag] === 'ReadableStream' &&
	    typeof stream.tee === 'function'
	  )
	}

	/**
	 * @param {ReadableStreamController<Uint8Array>} controller
	 */
	function readableStreamClose (controller) {
	  try {
	    controller.close();
	    controller.byobRequest?.respond(0);
	  } catch (err) {
	    // TODO: add comment explaining why this error occurs.
	    if (!err.message.includes('Controller is already closed') && !err.message.includes('ReadableStream is already closed')) {
	      throw err
	    }
	  }
	}

	const invalidIsomorphicEncodeValueRegex = /[^\x00-\xFF]/; // eslint-disable-line

	/**
	 * @see https://infra.spec.whatwg.org/#isomorphic-encode
	 * @param {string} input
	 */
	function isomorphicEncode (input) {
	  // 1. Assert: input contains no code points greater than U+00FF.
	  assert(!invalidIsomorphicEncodeValueRegex.test(input));

	  // 2. Return a byte sequence whose length is equal to inputâs code
	  //    point length and whose bytes have the same values as the
	  //    values of inputâs code points, in the same order
	  return input
	}

	/**
	 * @see https://streams.spec.whatwg.org/#readablestreamdefaultreader-read-all-bytes
	 * @see https://streams.spec.whatwg.org/#read-loop
	 * @param {ReadableStreamDefaultReader} reader
	 * @param {boolean} [shouldClone]
	 */
	async function readAllBytes (reader, shouldClone) {
	  const bytes = [];
	  let byteLength = 0;

	  while (true) {
	    const { done, value: chunk } = await reader.read();

	    if (done) {
	      // 1. Call successSteps with bytes.
	      if (bytes.length === 1) {
	        const { buffer, byteOffset, byteLength } = bytes[0];
	        if (shouldClone === false) {
	          return Buffer.from(buffer, byteOffset, byteLength)
	        }
	        return Buffer.from(buffer.slice(byteOffset, byteOffset + byteLength), 0, byteLength)
	      }
	      return Buffer.concat(bytes, byteLength)
	    }

	    // 1. If chunk is not a Uint8Array object, call failureSteps
	    //    with a TypeError and abort these steps.
	    if (!isUint8Array(chunk)) {
	      throw new TypeError('Received non-Uint8Array chunk')
	    }

	    // 2. Append the bytes represented by chunk to bytes.
	    bytes.push(chunk);
	    byteLength += chunk.length;

	    // 3. Read-loop given reader, bytes, successSteps, and failureSteps.
	  }
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#is-local
	 * @param {URL} url
	 */
	function urlIsLocal (url) {
	  assert('protocol' in url); // ensure it's a url object

	  const protocol = url.protocol;

	  return protocol === 'about:' || protocol === 'blob:' || protocol === 'data:'
	}

	/**
	 * @param {string|URL} url
	 * @returns {boolean}
	 */
	function urlHasHttpsScheme (url) {
	  return (
	    (
	      typeof url === 'string' &&
	      url[5] === ':' &&
	      url[0] === 'h' &&
	      url[1] === 't' &&
	      url[2] === 't' &&
	      url[3] === 'p' &&
	      url[4] === 's'
	    ) ||
	    url.protocol === 'https:'
	  )
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#http-scheme
	 * @param {URL} url
	 */
	function urlIsHttpHttpsScheme (url) {
	  assert('protocol' in url); // ensure it's a url object

	  const protocol = url.protocol;

	  return protocol === 'http:' || protocol === 'https:'
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#simple-range-header-value
	 * @param {string} value
	 * @param {boolean} allowWhitespace
	 */
	function simpleRangeHeaderValue (value, allowWhitespace) {
	  // 1. Let data be the isomorphic decoding of value.
	  // Note: isomorphic decoding takes a sequence of bytes (ie. a Uint8Array) and turns it into a string,
	  // nothing more. We obviously don't need to do that if value is a string already.
	  const data = value;

	  // 2. If data does not start with "bytes", then return failure.
	  if (!data.startsWith('bytes')) {
	    return 'failure'
	  }

	  // 3. Let position be a position variable for data, initially pointing at the 5th code point of data.
	  const position = { position: 5 };

	  // 4. If allowWhitespace is true, collect a sequence of code points that are HTTP tab or space,
	  //    from data given position.
	  if (allowWhitespace) {
	    collectASequenceOfCodePoints(
	      (char) => char === '\t' || char === ' ',
	      data,
	      position
	    );
	  }

	  // 5. If the code point at position within data is not U+003D (=), then return failure.
	  if (data.charCodeAt(position.position) !== 0x3D) {
	    return 'failure'
	  }

	  // 6. Advance position by 1.
	  position.position++;

	  // 7. If allowWhitespace is true, collect a sequence of code points that are HTTP tab or space, from
	  //    data given position.
	  if (allowWhitespace) {
	    collectASequenceOfCodePoints(
	      (char) => char === '\t' || char === ' ',
	      data,
	      position
	    );
	  }

	  // 8. Let rangeStart be the result of collecting a sequence of code points that are ASCII digits,
	  //    from data given position.
	  const rangeStart = collectASequenceOfCodePoints(
	    (char) => {
	      const code = char.charCodeAt(0);

	      return code >= 0x30 && code <= 0x39
	    },
	    data,
	    position
	  );

	  // 9. Let rangeStartValue be rangeStart, interpreted as decimal number, if rangeStart is not the
	  //    empty string; otherwise null.
	  const rangeStartValue = rangeStart.length ? Number(rangeStart) : null;

	  // 10. If allowWhitespace is true, collect a sequence of code points that are HTTP tab or space,
	  //     from data given position.
	  if (allowWhitespace) {
	    collectASequenceOfCodePoints(
	      (char) => char === '\t' || char === ' ',
	      data,
	      position
	    );
	  }

	  // 11. If the code point at position within data is not U+002D (-), then return failure.
	  if (data.charCodeAt(position.position) !== 0x2D) {
	    return 'failure'
	  }

	  // 12. Advance position by 1.
	  position.position++;

	  // 13. If allowWhitespace is true, collect a sequence of code points that are HTTP tab
	  //     or space, from data given position.
	  // Note from Khafra: its the same step as in #8 again lol
	  if (allowWhitespace) {
	    collectASequenceOfCodePoints(
	      (char) => char === '\t' || char === ' ',
	      data,
	      position
	    );
	  }

	  // 14. Let rangeEnd be the result of collecting a sequence of code points that are
	  //     ASCII digits, from data given position.
	  // Note from Khafra: you wouldn't guess it, but this is also the same step as #8
	  const rangeEnd = collectASequenceOfCodePoints(
	    (char) => {
	      const code = char.charCodeAt(0);

	      return code >= 0x30 && code <= 0x39
	    },
	    data,
	    position
	  );

	  // 15. Let rangeEndValue be rangeEnd, interpreted as decimal number, if rangeEnd
	  //     is not the empty string; otherwise null.
	  // Note from Khafra: THE SAME STEP, AGAIN!!!
	  // Note: why interpret as a decimal if we only collect ascii digits?
	  const rangeEndValue = rangeEnd.length ? Number(rangeEnd) : null;

	  // 16. If position is not past the end of data, then return failure.
	  if (position.position < data.length) {
	    return 'failure'
	  }

	  // 17. If rangeEndValue and rangeStartValue are null, then return failure.
	  if (rangeEndValue === null && rangeStartValue === null) {
	    return 'failure'
	  }

	  // 18. If rangeStartValue and rangeEndValue are numbers, and rangeStartValue is
	  //     greater than rangeEndValue, then return failure.
	  // Note: ... when can they not be numbers?
	  if (rangeStartValue > rangeEndValue) {
	    return 'failure'
	  }

	  // 19. Return (rangeStartValue, rangeEndValue).
	  return { rangeStartValue, rangeEndValue }
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#build-a-content-range
	 * @param {number} rangeStart
	 * @param {number} rangeEnd
	 * @param {number} fullLength
	 */
	function buildContentRange (rangeStart, rangeEnd, fullLength) {
	  // 1. Let contentRange be `bytes `.
	  let contentRange = 'bytes ';

	  // 2. Append rangeStart, serialized and isomorphic encoded, to contentRange.
	  contentRange += isomorphicEncode(`${rangeStart}`);

	  // 3. Append 0x2D (-) to contentRange.
	  contentRange += '-';

	  // 4. Append rangeEnd, serialized and isomorphic encoded to contentRange.
	  contentRange += isomorphicEncode(`${rangeEnd}`);

	  // 5. Append 0x2F (/) to contentRange.
	  contentRange += '/';

	  // 6. Append fullLength, serialized and isomorphic encoded to contentRange.
	  contentRange += isomorphicEncode(`${fullLength}`);

	  // 7. Return contentRange.
	  return contentRange
	}

	// A Stream, which pipes the response to zlib.createInflate() or
	// zlib.createInflateRaw() depending on the first byte of the Buffer.
	// If the lower byte of the first byte is 0x08, then the stream is
	// interpreted as a zlib stream, otherwise it's interpreted as a
	// raw deflate stream.
	class InflateStream extends Transform {
	  _transform (chunk, encoding, callback) {
	    if (!this._inflateStream) {
	      if (chunk.length === 0) {
	        callback();
	        return
	      }
	      this._inflateStream = (chunk[0] & 0x0F) === 0x08
	        ? zlib.createInflate()
	        : zlib.createInflateRaw();

	      this._inflateStream.on('data', this.push.bind(this));
	      this._inflateStream.on('end', () => this.push(null));
	      this._inflateStream.on('error', (err) => this.destroy(err));
	    }

	    this._inflateStream.write(chunk, encoding, callback);
	  }

	  _final (callback) {
	    if (this._inflateStream) {
	      this._inflateStream.end();
	      this._inflateStream = null;
	    }
	    callback();
	  }
	}

	function createInflate () {
	  return new InflateStream()
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#concept-header-extract-mime-type
	 * @param {import('./headers').HeadersList} headers
	 */
	function extractMimeType (headers) {
	  // 1. Let charset be null.
	  let charset = null;

	  // 2. Let essence be null.
	  let essence = null;

	  // 3. Let mimeType be null.
	  let mimeType = null;

	  // 4. Let values be the result of getting, decoding, and splitting `Content-Type` from headers.
	  const values = getDecodeSplit('content-type', headers);

	  // 5. If values is null, then return failure.
	  if (values === null) {
	    return 'failure'
	  }

	  // 6. For each value of values:
	  for (const value of values) {
	    // 6.1. Let temporaryMimeType be the result of parsing value.
	    const temporaryMimeType = parseMIMEType(value);

	    // 6.2. If temporaryMimeType is failure or its essence is "*/*", then continue.
	    if (temporaryMimeType === 'failure' || temporaryMimeType.essence === '*/*') {
	      continue
	    }

	    // 6.3. Set mimeType to temporaryMimeType.
	    mimeType = temporaryMimeType;

	    // 6.4. If mimeTypeâs essence is not essence, then:
	    if (mimeType.essence !== essence) {
	      // 6.4.1. Set charset to null.
	      charset = null;

	      // 6.4.2. If mimeTypeâs parameters["charset"] exists, then set charset to
	      //        mimeTypeâs parameters["charset"].
	      if (mimeType.parameters.has('charset')) {
	        charset = mimeType.parameters.get('charset');
	      }

	      // 6.4.3. Set essence to mimeTypeâs essence.
	      essence = mimeType.essence;
	    } else if (!mimeType.parameters.has('charset') && charset !== null) {
	      // 6.5. Otherwise, if mimeTypeâs parameters["charset"] does not exist, and
	      //      charset is non-null, set mimeTypeâs parameters["charset"] to charset.
	      mimeType.parameters.set('charset', charset);
	    }
	  }

	  // 7. If mimeType is null, then return failure.
	  if (mimeType == null) {
	    return 'failure'
	  }

	  // 8. Return mimeType.
	  return mimeType
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#header-value-get-decode-and-split
	 * @param {string|null} value
	 */
	function gettingDecodingSplitting (value) {
	  // 1. Let input be the result of isomorphic decoding value.
	  const input = value;

	  // 2. Let position be a position variable for input, initially pointing at the start of input.
	  const position = { position: 0 };

	  // 3. Let values be a list of strings, initially empty.
	  const values = [];

	  // 4. Let temporaryValue be the empty string.
	  let temporaryValue = '';

	  // 5. While position is not past the end of input:
	  while (position.position < input.length) {
	    // 5.1. Append the result of collecting a sequence of code points that are not U+0022 (")
	    //      or U+002C (,) from input, given position, to temporaryValue.
	    temporaryValue += collectASequenceOfCodePoints(
	      (char) => char !== '"' && char !== ',',
	      input,
	      position
	    );

	    // 5.2. If position is not past the end of input, then:
	    if (position.position < input.length) {
	      // 5.2.1. If the code point at position within input is U+0022 ("), then:
	      if (input.charCodeAt(position.position) === 0x22) {
	        // 5.2.1.1. Append the result of collecting an HTTP quoted string from input, given position, to temporaryValue.
	        temporaryValue += collectAnHTTPQuotedString(
	          input,
	          position
	        );

	        // 5.2.1.2. If position is not past the end of input, then continue.
	        if (position.position < input.length) {
	          continue
	        }
	      } else {
	        // 5.2.2. Otherwise:

	        // 5.2.2.1. Assert: the code point at position within input is U+002C (,).
	        assert(input.charCodeAt(position.position) === 0x2C);

	        // 5.2.2.2. Advance position by 1.
	        position.position++;
	      }
	    }

	    // 5.3. Remove all HTTP tab or space from the start and end of temporaryValue.
	    temporaryValue = removeChars(temporaryValue, true, true, (char) => char === 0x9 || char === 0x20);

	    // 5.4. Append temporaryValue to values.
	    values.push(temporaryValue);

	    // 5.6. Set temporaryValue to the empty string.
	    temporaryValue = '';
	  }

	  // 6. Return values.
	  return values
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#concept-header-list-get-decode-split
	 * @param {string} name lowercase header name
	 * @param {import('./headers').HeadersList} list
	 */
	function getDecodeSplit (name, list) {
	  // 1. Let value be the result of getting name from list.
	  const value = list.get(name, true);

	  // 2. If value is null, then return null.
	  if (value === null) {
	    return null
	  }

	  // 3. Return the result of getting, decoding, and splitting value.
	  return gettingDecodingSplitting(value)
	}

	const textDecoder = new TextDecoder();

	/**
	 * @see https://encoding.spec.whatwg.org/#utf-8-decode
	 * @param {Buffer} buffer
	 */
	function utf8DecodeBytes (buffer) {
	  if (buffer.length === 0) {
	    return ''
	  }

	  // 1. Let buffer be the result of peeking three bytes from
	  //    ioQueue, converted to a byte sequence.

	  // 2. If buffer is 0xEF 0xBB 0xBF, then read three
	  //    bytes from ioQueue. (Do nothing with those bytes.)
	  if (buffer[0] === 0xEF && buffer[1] === 0xBB && buffer[2] === 0xBF) {
	    buffer = buffer.subarray(3);
	  }

	  // 3. Process a queue with an instance of UTF-8âs
	  //    decoder, ioQueue, output, and "replacement".
	  const output = textDecoder.decode(buffer);

	  // 4. Return output.
	  return output
	}

	class EnvironmentSettingsObjectBase {
	  get baseUrl () {
	    return getGlobalOrigin()
	  }

	  get origin () {
	    return this.baseUrl?.origin
	  }

	  policyContainer = makePolicyContainer()
	}

	class EnvironmentSettingsObject {
	  settingsObject = new EnvironmentSettingsObjectBase()
	}

	const environmentSettingsObject = new EnvironmentSettingsObject();

	util$6 = {
	  isAborted,
	  isCancelled,
	  isValidEncodedURL,
	  createDeferredPromise,
	  ReadableStreamFrom,
	  tryUpgradeRequestToAPotentiallyTrustworthyURL,
	  clampAndCoarsenConnectionTimingInfo,
	  coarsenedSharedCurrentTime,
	  determineRequestsReferrer,
	  makePolicyContainer,
	  clonePolicyContainer,
	  appendFetchMetadata,
	  appendRequestOriginHeader,
	  TAOCheck,
	  corsCheck,
	  crossOriginResourcePolicyCheck,
	  createOpaqueTimingInfo,
	  setRequestReferrerPolicyOnRedirect,
	  isValidHTTPToken,
	  requestBadPort,
	  requestCurrentURL,
	  responseURL,
	  responseLocationURL,
	  isBlobLike,
	  isURLPotentiallyTrustworthy,
	  isValidReasonPhrase,
	  sameOrigin,
	  normalizeMethod,
	  serializeJavascriptValueToJSONString,
	  iteratorMixin,
	  createIterator,
	  isValidHeaderName,
	  isValidHeaderValue,
	  isErrorLike,
	  fullyReadBody,
	  bytesMatch,
	  isReadableStreamLike,
	  readableStreamClose,
	  isomorphicEncode,
	  urlIsLocal,
	  urlHasHttpsScheme,
	  urlIsHttpHttpsScheme,
	  readAllBytes,
	  simpleRangeHeaderValue,
	  buildContentRange,
	  parseMetadata,
	  createInflate,
	  extractMimeType,
	  getDecodeSplit,
	  utf8DecodeBytes,
	  environmentSettingsObject
	};
	return util$6;
}

var symbols$3;
var hasRequiredSymbols$3;

function requireSymbols$3 () {
	if (hasRequiredSymbols$3) return symbols$3;
	hasRequiredSymbols$3 = 1;

	symbols$3 = {
	  kUrl: Symbol('url'),
	  kHeaders: Symbol('headers'),
	  kSignal: Symbol('signal'),
	  kState: Symbol('state'),
	  kDispatcher: Symbol('dispatcher')
	};
	return symbols$3;
}

var file;
var hasRequiredFile;

function requireFile () {
	if (hasRequiredFile) return file;
	hasRequiredFile = 1;

	const { Blob, File } = require$$0$3;
	const { kState } = requireSymbols$3();
	const { webidl } = requireWebidl();

	// TODO(@KhafraDev): remove
	class FileLike {
	  constructor (blobLike, fileName, options = {}) {
	    // TODO: argument idl type check

	    // The File constructor is invoked with two or three parameters, depending
	    // on whether the optional dictionary parameter is used. When the File()
	    // constructor is invoked, user agents must run the following steps:

	    // 1. Let bytes be the result of processing blob parts given fileBits and
	    // options.

	    // 2. Let n be the fileName argument to the constructor.
	    const n = fileName;

	    // 3. Process FilePropertyBag dictionary argument by running the following
	    // substeps:

	    //    1. If the type member is provided and is not the empty string, let t
	    //    be set to the type dictionary member. If t contains any characters
	    //    outside the range U+0020 to U+007E, then set t to the empty string
	    //    and return from these substeps.
	    //    TODO
	    const t = options.type;

	    //    2. Convert every character in t to ASCII lowercase.
	    //    TODO

	    //    3. If the lastModified member is provided, let d be set to the
	    //    lastModified dictionary member. If it is not provided, set d to the
	    //    current date and time represented as the number of milliseconds since
	    //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).
	    const d = options.lastModified ?? Date.now();

	    // 4. Return a new File object F such that:
	    // F refers to the bytes byte sequence.
	    // F.size is set to the number of total bytes in bytes.
	    // F.name is set to n.
	    // F.type is set to t.
	    // F.lastModified is set to d.

	    this[kState] = {
	      blobLike,
	      name: n,
	      type: t,
	      lastModified: d
	    };
	  }

	  stream (...args) {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].blobLike.stream(...args)
	  }

	  arrayBuffer (...args) {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].blobLike.arrayBuffer(...args)
	  }

	  slice (...args) {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].blobLike.slice(...args)
	  }

	  text (...args) {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].blobLike.text(...args)
	  }

	  get size () {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].blobLike.size
	  }

	  get type () {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].blobLike.type
	  }

	  get name () {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].name
	  }

	  get lastModified () {
	    webidl.brandCheck(this, FileLike);

	    return this[kState].lastModified
	  }

	  get [Symbol.toStringTag] () {
	    return 'File'
	  }
	}

	webidl.converters.Blob = webidl.interfaceConverter(Blob);

	// If this function is moved to ./util.js, some tools (such as
	// rollup) will warn about circular dependencies. See:
	// https://github.com/nodejs/undici/issues/1629
	function isFileLike (object) {
	  return (
	    (object instanceof File) ||
	    (
	      object &&
	      (typeof object.stream === 'function' ||
	      typeof object.arrayBuffer === 'function') &&
	      object[Symbol.toStringTag] === 'File'
	    )
	  )
	}

	file = { FileLike, isFileLike };
	return file;
}

var formdata;
var hasRequiredFormdata;

function requireFormdata () {
	if (hasRequiredFormdata) return formdata;
	hasRequiredFormdata = 1;

	const { isBlobLike, iteratorMixin } = requireUtil$6();
	const { kState } = requireSymbols$3();
	const { kEnumerableProperty } = requireUtil$7();
	const { FileLike, isFileLike } = requireFile();
	const { webidl } = requireWebidl();
	const { File: NativeFile } = require$$0$3;
	const nodeUtil = require$$0$6;

	/** @type {globalThis['File']} */
	const File = globalThis.File ?? NativeFile;

	// https://xhr.spec.whatwg.org/#formdata
	class FormData {
	  constructor (form) {
	    if (form !== undefined) {
	      throw webidl.errors.conversionFailed({
	        prefix: 'FormData constructor',
	        argument: 'Argument 1',
	        types: ['undefined']
	      })
	    }

	    this[kState] = [];
	  }

	  append (name, value, filename = undefined) {
	    webidl.brandCheck(this, FormData);

	    const prefix = 'FormData.append';
	    webidl.argumentLengthCheck(arguments, 2, prefix);

	    if (arguments.length === 3 && !isBlobLike(value)) {
	      throw new TypeError(
	        "Failed to execute 'append' on 'FormData': parameter 2 is not of type 'Blob'"
	      )
	    }

	    // 1. Let value be value if given; otherwise blobValue.

	    name = webidl.converters.USVString(name, prefix, 'name');
	    value = isBlobLike(value)
	      ? webidl.converters.Blob(value, prefix, 'value', { strict: false })
	      : webidl.converters.USVString(value, prefix, 'value');
	    filename = arguments.length === 3
	      ? webidl.converters.USVString(filename, prefix, 'filename')
	      : undefined;

	    // 2. Let entry be the result of creating an entry with
	    // name, value, and filename if given.
	    const entry = makeEntry(name, value, filename);

	    // 3. Append entry to thisâs entry list.
	    this[kState].push(entry);
	  }

	  delete (name) {
	    webidl.brandCheck(this, FormData);

	    const prefix = 'FormData.delete';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    name = webidl.converters.USVString(name, prefix, 'name');

	    // The delete(name) method steps are to remove all entries whose name
	    // is name from thisâs entry list.
	    this[kState] = this[kState].filter(entry => entry.name !== name);
	  }

	  get (name) {
	    webidl.brandCheck(this, FormData);

	    const prefix = 'FormData.get';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    name = webidl.converters.USVString(name, prefix, 'name');

	    // 1. If there is no entry whose name is name in thisâs entry list,
	    // then return null.
	    const idx = this[kState].findIndex((entry) => entry.name === name);
	    if (idx === -1) {
	      return null
	    }

	    // 2. Return the value of the first entry whose name is name from
	    // thisâs entry list.
	    return this[kState][idx].value
	  }

	  getAll (name) {
	    webidl.brandCheck(this, FormData);

	    const prefix = 'FormData.getAll';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    name = webidl.converters.USVString(name, prefix, 'name');

	    // 1. If there is no entry whose name is name in thisâs entry list,
	    // then return the empty list.
	    // 2. Return the values of all entries whose name is name, in order,
	    // from thisâs entry list.
	    return this[kState]
	      .filter((entry) => entry.name === name)
	      .map((entry) => entry.value)
	  }

	  has (name) {
	    webidl.brandCheck(this, FormData);

	    const prefix = 'FormData.has';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    name = webidl.converters.USVString(name, prefix, 'name');

	    // The has(name) method steps are to return true if there is an entry
	    // whose name is name in thisâs entry list; otherwise false.
	    return this[kState].findIndex((entry) => entry.name === name) !== -1
	  }

	  set (name, value, filename = undefined) {
	    webidl.brandCheck(this, FormData);

	    const prefix = 'FormData.set';
	    webidl.argumentLengthCheck(arguments, 2, prefix);

	    if (arguments.length === 3 && !isBlobLike(value)) {
	      throw new TypeError(
	        "Failed to execute 'set' on 'FormData': parameter 2 is not of type 'Blob'"
	      )
	    }

	    // The set(name, value) and set(name, blobValue, filename) method steps
	    // are:

	    // 1. Let value be value if given; otherwise blobValue.

	    name = webidl.converters.USVString(name, prefix, 'name');
	    value = isBlobLike(value)
	      ? webidl.converters.Blob(value, prefix, 'name', { strict: false })
	      : webidl.converters.USVString(value, prefix, 'name');
	    filename = arguments.length === 3
	      ? webidl.converters.USVString(filename, prefix, 'name')
	      : undefined;

	    // 2. Let entry be the result of creating an entry with name, value, and
	    // filename if given.
	    const entry = makeEntry(name, value, filename);

	    // 3. If there are entries in thisâs entry list whose name is name, then
	    // replace the first such entry with entry and remove the others.
	    const idx = this[kState].findIndex((entry) => entry.name === name);
	    if (idx !== -1) {
	      this[kState] = [
	        ...this[kState].slice(0, idx),
	        entry,
	        ...this[kState].slice(idx + 1).filter((entry) => entry.name !== name)
	      ];
	    } else {
	      // 4. Otherwise, append entry to thisâs entry list.
	      this[kState].push(entry);
	    }
	  }

	  [nodeUtil.inspect.custom] (depth, options) {
	    const state = this[kState].reduce((a, b) => {
	      if (a[b.name]) {
	        if (Array.isArray(a[b.name])) {
	          a[b.name].push(b.value);
	        } else {
	          a[b.name] = [a[b.name], b.value];
	        }
	      } else {
	        a[b.name] = b.value;
	      }

	      return a
	    }, { __proto__: null });

	    options.depth ??= depth;
	    options.colors ??= true;

	    const output = nodeUtil.formatWithOptions(options, state);

	    // remove [Object null prototype]
	    return `FormData ${output.slice(output.indexOf(']') + 2)}`
	  }
	}

	iteratorMixin('FormData', FormData, kState, 'name', 'value');

	Object.defineProperties(FormData.prototype, {
	  append: kEnumerableProperty,
	  delete: kEnumerableProperty,
	  get: kEnumerableProperty,
	  getAll: kEnumerableProperty,
	  has: kEnumerableProperty,
	  set: kEnumerableProperty,
	  [Symbol.toStringTag]: {
	    value: 'FormData',
	    configurable: true
	  }
	});

	/**
	 * @see https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#create-an-entry
	 * @param {string} name
	 * @param {string|Blob} value
	 * @param {?string} filename
	 * @returns
	 */
	function makeEntry (name, value, filename) {
	  // 1. Set name to the result of converting name into a scalar value string.
	  // Note: This operation was done by the webidl converter USVString.

	  // 2. If value is a string, then set value to the result of converting
	  //    value into a scalar value string.
	  if (typeof value === 'string') ; else {
	    // 3. Otherwise:

	    // 1. If value is not a File object, then set value to a new File object,
	    //    representing the same bytes, whose name attribute value is "blob"
	    if (!isFileLike(value)) {
	      value = value instanceof Blob
	        ? new File([value], 'blob', { type: value.type })
	        : new FileLike(value, 'blob', { type: value.type });
	    }

	    // 2. If filename is given, then set value to a new File object,
	    //    representing the same bytes, whose name attribute is filename.
	    if (filename !== undefined) {
	      /** @type {FilePropertyBag} */
	      const options = {
	        type: value.type,
	        lastModified: value.lastModified
	      };

	      value = value instanceof NativeFile
	        ? new File([value], filename, options)
	        : new FileLike(value, filename, options);
	    }
	  }

	  // 4. Return an entry whose name is name and whose value is value.
	  return { name, value }
	}

	formdata = { FormData, makeEntry };
	return formdata;
}

var formdataParser;
var hasRequiredFormdataParser;

function requireFormdataParser () {
	if (hasRequiredFormdataParser) return formdataParser;
	hasRequiredFormdataParser = 1;

	const { isUSVString, bufferToLowerCasedHeaderName } = requireUtil$7();
	const { utf8DecodeBytes } = requireUtil$6();
	const { HTTP_TOKEN_CODEPOINTS, isomorphicDecode } = requireDataUrl();
	const { isFileLike } = requireFile();
	const { makeEntry } = requireFormdata();
	const assert = require$$0$4;
	const { File: NodeFile } = require$$0$3;

	const File = globalThis.File ?? NodeFile;

	const formDataNameBuffer = Buffer.from('form-data; name="');
	const filenameBuffer = Buffer.from('; filename');
	const dd = Buffer.from('--');
	const ddcrlf = Buffer.from('--\r\n');

	/**
	 * @param {string} chars
	 */
	function isAsciiString (chars) {
	  for (let i = 0; i < chars.length; ++i) {
	    if ((chars.charCodeAt(i) & -128) !== 0) {
	      return false
	    }
	  }
	  return true
	}

	/**
	 * @see https://andreubotella.github.io/multipart-form-data/#multipart-form-data-boundary
	 * @param {string} boundary
	 */
	function validateBoundary (boundary) {
	  const length = boundary.length;

	  // - its length is greater or equal to 27 and lesser or equal to 70, and
	  if (length < 27 || length > 70) {
	    return false
	  }

	  // - it is composed by bytes in the ranges 0x30 to 0x39, 0x41 to 0x5A, or
	  //   0x61 to 0x7A, inclusive (ASCII alphanumeric), or which are 0x27 ('),
	  //   0x2D (-) or 0x5F (_).
	  for (let i = 0; i < length; ++i) {
	    const cp = boundary.charCodeAt(i);

	    if (!(
	      (cp >= 0x30 && cp <= 0x39) ||
	      (cp >= 0x41 && cp <= 0x5a) ||
	      (cp >= 0x61 && cp <= 0x7a) ||
	      cp === 0x27 ||
	      cp === 0x2d ||
	      cp === 0x5f
	    )) {
	      return false
	    }
	  }

	  return true
	}

	/**
	 * @see https://andreubotella.github.io/multipart-form-data/#multipart-form-data-parser
	 * @param {Buffer} input
	 * @param {ReturnType<import('./data-url')['parseMIMEType']>} mimeType
	 */
	function multipartFormDataParser (input, mimeType) {
	  // 1. Assert: mimeTypeâs essence is "multipart/form-data".
	  assert(mimeType !== 'failure' && mimeType.essence === 'multipart/form-data');

	  const boundaryString = mimeType.parameters.get('boundary');

	  // 2. If mimeTypeâs parameters["boundary"] does not exist, return failure.
	  //    Otherwise, let boundary be the result of UTF-8 decoding mimeTypeâs
	  //    parameters["boundary"].
	  if (boundaryString === undefined) {
	    return 'failure'
	  }

	  const boundary = Buffer.from(`--${boundaryString}`, 'utf8');

	  // 3. Let entry list be an empty entry list.
	  const entryList = [];

	  // 4. Let position be a pointer to a byte in input, initially pointing at
	  //    the first byte.
	  const position = { position: 0 };

	  // Note: undici addition, allow \r\n before the body.
	  if (input[0] === 0x0d && input[1] === 0x0a) {
	    position.position += 2;
	  }

	  // 5. While true:
	  while (true) {
	    // 5.1. If position points to a sequence of bytes starting with 0x2D 0x2D
	    //      (`--`) followed by boundary, advance position by 2 + the length of
	    //      boundary. Otherwise, return failure.
	    // Note: boundary is padded with 2 dashes already, no need to add 2.
	    if (input.subarray(position.position, position.position + boundary.length).equals(boundary)) {
	      position.position += boundary.length;
	    } else {
	      return 'failure'
	    }

	    // 5.2. If position points to the sequence of bytes 0x2D 0x2D 0x0D 0x0A
	    //      (`--` followed by CR LF) followed by the end of input, return entry list.
	    // Note: a body does NOT need to end with CRLF. It can end with --.
	    if (
	      (position.position === input.length - 2 && bufferStartsWith(input, dd, position)) ||
	      (position.position === input.length - 4 && bufferStartsWith(input, ddcrlf, position))
	    ) {
	      return entryList
	    }

	    // 5.3. If position does not point to a sequence of bytes starting with 0x0D
	    //      0x0A (CR LF), return failure.
	    if (input[position.position] !== 0x0d || input[position.position + 1] !== 0x0a) {
	      return 'failure'
	    }

	    // 5.4. Advance position by 2. (This skips past the newline.)
	    position.position += 2;

	    // 5.5. Let name, filename and contentType be the result of parsing
	    //      multipart/form-data headers on input and position, if the result
	    //      is not failure. Otherwise, return failure.
	    const result = parseMultipartFormDataHeaders(input, position);

	    if (result === 'failure') {
	      return 'failure'
	    }

	    let { name, filename, contentType, encoding } = result;

	    // 5.6. Advance position by 2. (This skips past the empty line that marks
	    //      the end of the headers.)
	    position.position += 2;

	    // 5.7. Let body be the empty byte sequence.
	    let body;

	    // 5.8. Body loop: While position is not past the end of input:
	    // TODO: the steps here are completely wrong
	    {
	      const boundaryIndex = input.indexOf(boundary.subarray(2), position.position);

	      if (boundaryIndex === -1) {
	        return 'failure'
	      }

	      body = input.subarray(position.position, boundaryIndex - 4);

	      position.position += body.length;

	      // Note: position must be advanced by the body's length before being
	      // decoded, otherwise the parsing will fail.
	      if (encoding === 'base64') {
	        body = Buffer.from(body.toString(), 'base64');
	      }
	    }

	    // 5.9. If position does not point to a sequence of bytes starting with
	    //      0x0D 0x0A (CR LF), return failure. Otherwise, advance position by 2.
	    if (input[position.position] !== 0x0d || input[position.position + 1] !== 0x0a) {
	      return 'failure'
	    } else {
	      position.position += 2;
	    }

	    // 5.10. If filename is not null:
	    let value;

	    if (filename !== null) {
	      // 5.10.1. If contentType is null, set contentType to "text/plain".
	      contentType ??= 'text/plain';

	      // 5.10.2. If contentType is not an ASCII string, set contentType to the empty string.

	      // Note: `buffer.isAscii` can be used at zero-cost, but converting a string to a buffer is a high overhead.
	      // Content-Type is a relatively small string, so it is faster to use `String#charCodeAt`.
	      if (!isAsciiString(contentType)) {
	        contentType = '';
	      }

	      // 5.10.3. Let value be a new File object with name filename, type contentType, and body body.
	      value = new File([body], filename, { type: contentType });
	    } else {
	      // 5.11. Otherwise:

	      // 5.11.1. Let value be the UTF-8 decoding without BOM of body.
	      value = utf8DecodeBytes(Buffer.from(body));
	    }

	    // 5.12. Assert: name is a scalar value string and value is either a scalar value string or a File object.
	    assert(isUSVString(name));
	    assert((typeof value === 'string' && isUSVString(value)) || isFileLike(value));

	    // 5.13. Create an entry with name and value, and append it to entry list.
	    entryList.push(makeEntry(name, value, filename));
	  }
	}

	/**
	 * @see https://andreubotella.github.io/multipart-form-data/#parse-multipart-form-data-headers
	 * @param {Buffer} input
	 * @param {{ position: number }} position
	 */
	function parseMultipartFormDataHeaders (input, position) {
	  // 1. Let name, filename and contentType be null.
	  let name = null;
	  let filename = null;
	  let contentType = null;
	  let encoding = null;

	  // 2. While true:
	  while (true) {
	    // 2.1. If position points to a sequence of bytes starting with 0x0D 0x0A (CR LF):
	    if (input[position.position] === 0x0d && input[position.position + 1] === 0x0a) {
	      // 2.1.1. If name is null, return failure.
	      if (name === null) {
	        return 'failure'
	      }

	      // 2.1.2. Return name, filename and contentType.
	      return { name, filename, contentType, encoding }
	    }

	    // 2.2. Let header name be the result of collecting a sequence of bytes that are
	    //      not 0x0A (LF), 0x0D (CR) or 0x3A (:), given position.
	    let headerName = collectASequenceOfBytes(
	      (char) => char !== 0x0a && char !== 0x0d && char !== 0x3a,
	      input,
	      position
	    );

	    // 2.3. Remove any HTTP tab or space bytes from the start or end of header name.
	    headerName = removeChars(headerName, true, true, (char) => char === 0x9 || char === 0x20);

	    // 2.4. If header name does not match the field-name token production, return failure.
	    if (!HTTP_TOKEN_CODEPOINTS.test(headerName.toString())) {
	      return 'failure'
	    }

	    // 2.5. If the byte at position is not 0x3A (:), return failure.
	    if (input[position.position] !== 0x3a) {
	      return 'failure'
	    }

	    // 2.6. Advance position by 1.
	    position.position++;

	    // 2.7. Collect a sequence of bytes that are HTTP tab or space bytes given position.
	    //      (Do nothing with those bytes.)
	    collectASequenceOfBytes(
	      (char) => char === 0x20 || char === 0x09,
	      input,
	      position
	    );

	    // 2.8. Byte-lowercase header name and switch on the result:
	    switch (bufferToLowerCasedHeaderName(headerName)) {
	      case 'content-disposition': {
	        // 1. Set name and filename to null.
	        name = filename = null;

	        // 2. If position does not point to a sequence of bytes starting with
	        //    `form-data; name="`, return failure.
	        if (!bufferStartsWith(input, formDataNameBuffer, position)) {
	          return 'failure'
	        }

	        // 3. Advance position so it points at the byte after the next 0x22 (")
	        //    byte (the one in the sequence of bytes matched above).
	        position.position += 17;

	        // 4. Set name to the result of parsing a multipart/form-data name given
	        //    input and position, if the result is not failure. Otherwise, return
	        //    failure.
	        name = parseMultipartFormDataName(input, position);

	        if (name === null) {
	          return 'failure'
	        }

	        // 5. If position points to a sequence of bytes starting with `; filename="`:
	        if (bufferStartsWith(input, filenameBuffer, position)) {
	          // Note: undici also handles filename*
	          let check = position.position + filenameBuffer.length;

	          if (input[check] === 0x2a) {
	            position.position += 1;
	            check += 1;
	          }

	          if (input[check] !== 0x3d || input[check + 1] !== 0x22) { // ="
	            return 'failure'
	          }

	          // 1. Advance position so it points at the byte after the next 0x22 (") byte
	          //    (the one in the sequence of bytes matched above).
	          position.position += 12;

	          // 2. Set filename to the result of parsing a multipart/form-data name given
	          //    input and position, if the result is not failure. Otherwise, return failure.
	          filename = parseMultipartFormDataName(input, position);

	          if (filename === null) {
	            return 'failure'
	          }
	        }

	        break
	      }
	      case 'content-type': {
	        // 1. Let header value be the result of collecting a sequence of bytes that are
	        //    not 0x0A (LF) or 0x0D (CR), given position.
	        let headerValue = collectASequenceOfBytes(
	          (char) => char !== 0x0a && char !== 0x0d,
	          input,
	          position
	        );

	        // 2. Remove any HTTP tab or space bytes from the end of header value.
	        headerValue = removeChars(headerValue, false, true, (char) => char === 0x9 || char === 0x20);

	        // 3. Set contentType to the isomorphic decoding of header value.
	        contentType = isomorphicDecode(headerValue);

	        break
	      }
	      case 'content-transfer-encoding': {
	        let headerValue = collectASequenceOfBytes(
	          (char) => char !== 0x0a && char !== 0x0d,
	          input,
	          position
	        );

	        headerValue = removeChars(headerValue, false, true, (char) => char === 0x9 || char === 0x20);

	        encoding = isomorphicDecode(headerValue);

	        break
	      }
	      default: {
	        // Collect a sequence of bytes that are not 0x0A (LF) or 0x0D (CR), given position.
	        // (Do nothing with those bytes.)
	        collectASequenceOfBytes(
	          (char) => char !== 0x0a && char !== 0x0d,
	          input,
	          position
	        );
	      }
	    }

	    // 2.9. If position does not point to a sequence of bytes starting with 0x0D 0x0A
	    //      (CR LF), return failure. Otherwise, advance position by 2 (past the newline).
	    if (input[position.position] !== 0x0d && input[position.position + 1] !== 0x0a) {
	      return 'failure'
	    } else {
	      position.position += 2;
	    }
	  }
	}

	/**
	 * @see https://andreubotella.github.io/multipart-form-data/#parse-a-multipart-form-data-name
	 * @param {Buffer} input
	 * @param {{ position: number }} position
	 */
	function parseMultipartFormDataName (input, position) {
	  // 1. Assert: The byte at (position - 1) is 0x22 (").
	  assert(input[position.position - 1] === 0x22);

	  // 2. Let name be the result of collecting a sequence of bytes that are not 0x0A (LF), 0x0D (CR) or 0x22 ("), given position.
	  /** @type {string | Buffer} */
	  let name = collectASequenceOfBytes(
	    (char) => char !== 0x0a && char !== 0x0d && char !== 0x22,
	    input,
	    position
	  );

	  // 3. If the byte at position is not 0x22 ("), return failure. Otherwise, advance position by 1.
	  if (input[position.position] !== 0x22) {
	    return null // name could be 'failure'
	  } else {
	    position.position++;
	  }

	  // 4. Replace any occurrence of the following subsequences in name with the given byte:
	  // - `%0A`: 0x0A (LF)
	  // - `%0D`: 0x0D (CR)
	  // - `%22`: 0x22 (")
	  name = new TextDecoder().decode(name)
	    .replace(/%0A/ig, '\n')
	    .replace(/%0D/ig, '\r')
	    .replace(/%22/g, '"');

	  // 5. Return the UTF-8 decoding without BOM of name.
	  return name
	}

	/**
	 * @param {(char: number) => boolean} condition
	 * @param {Buffer} input
	 * @param {{ position: number }} position
	 */
	function collectASequenceOfBytes (condition, input, position) {
	  let start = position.position;

	  while (start < input.length && condition(input[start])) {
	    ++start;
	  }

	  return input.subarray(position.position, (position.position = start))
	}

	/**
	 * @param {Buffer} buf
	 * @param {boolean} leading
	 * @param {boolean} trailing
	 * @param {(charCode: number) => boolean} predicate
	 * @returns {Buffer}
	 */
	function removeChars (buf, leading, trailing, predicate) {
	  let lead = 0;
	  let trail = buf.length - 1;

	  if (leading) {
	    while (lead < buf.length && predicate(buf[lead])) lead++;
	  }

	  {
	    while (trail > 0 && predicate(buf[trail])) trail--;
	  }

	  return lead === 0 && trail === buf.length - 1 ? buf : buf.subarray(lead, trail + 1)
	}

	/**
	 * Checks if {@param buffer} starts with {@param start}
	 * @param {Buffer} buffer
	 * @param {Buffer} start
	 * @param {{ position: number }} position
	 */
	function bufferStartsWith (buffer, start, position) {
	  if (buffer.length < start.length) {
	    return false
	  }

	  for (let i = 0; i < start.length; i++) {
	    if (start[i] !== buffer[position.position + i]) {
	      return false
	    }
	  }

	  return true
	}

	formdataParser = {
	  multipartFormDataParser,
	  validateBoundary
	};
	return formdataParser;
}

var body;
var hasRequiredBody;

function requireBody () {
	if (hasRequiredBody) return body;
	hasRequiredBody = 1;

	const util = requireUtil$7();
	const {
	  ReadableStreamFrom,
	  isBlobLike,
	  isReadableStreamLike,
	  readableStreamClose,
	  createDeferredPromise,
	  fullyReadBody,
	  extractMimeType,
	  utf8DecodeBytes
	} = requireUtil$6();
	const { FormData } = requireFormdata();
	const { kState } = requireSymbols$3();
	const { webidl } = requireWebidl();
	const { Blob } = require$$0$3;
	const assert = require$$0$4;
	const { isErrored } = requireUtil$7();
	const { isArrayBuffer } = require$$8$1;
	const { serializeAMimeType } = requireDataUrl();
	const { multipartFormDataParser } = requireFormdataParser();

	const textEncoder = new TextEncoder();

	// https://fetch.spec.whatwg.org/#concept-bodyinit-extract
	function extractBody (object, keepalive = false) {
	  // 1. Let stream be null.
	  let stream = null;

	  // 2. If object is a ReadableStream object, then set stream to object.
	  if (object instanceof ReadableStream) {
	    stream = object;
	  } else if (isBlobLike(object)) {
	    // 3. Otherwise, if object is a Blob object, set stream to the
	    //    result of running objectâs get stream.
	    stream = object.stream();
	  } else {
	    // 4. Otherwise, set stream to a new ReadableStream object, and set
	    //    up stream with byte reading support.
	    stream = new ReadableStream({
	      async pull (controller) {
	        const buffer = typeof source === 'string' ? textEncoder.encode(source) : source;

	        if (buffer.byteLength) {
	          controller.enqueue(buffer);
	        }

	        queueMicrotask(() => readableStreamClose(controller));
	      },
	      start () {},
	      type: 'bytes'
	    });
	  }

	  // 5. Assert: stream is a ReadableStream object.
	  assert(isReadableStreamLike(stream));

	  // 6. Let action be null.
	  let action = null;

	  // 7. Let source be null.
	  let source = null;

	  // 8. Let length be null.
	  let length = null;

	  // 9. Let type be null.
	  let type = null;

	  // 10. Switch on object:
	  if (typeof object === 'string') {
	    // Set source to the UTF-8 encoding of object.
	    // Note: setting source to a Uint8Array here breaks some mocking assumptions.
	    source = object;

	    // Set type to `text/plain;charset=UTF-8`.
	    type = 'text/plain;charset=UTF-8';
	  } else if (object instanceof URLSearchParams) {
	    // URLSearchParams

	    // spec says to run application/x-www-form-urlencoded on body.list
	    // this is implemented in Node.js as apart of an URLSearchParams instance toString method
	    // See: https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L490
	    // and https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L1100

	    // Set source to the result of running the application/x-www-form-urlencoded serializer with objectâs list.
	    source = object.toString();

	    // Set type to `application/x-www-form-urlencoded;charset=UTF-8`.
	    type = 'application/x-www-form-urlencoded;charset=UTF-8';
	  } else if (isArrayBuffer(object)) {
	    // BufferSource/ArrayBuffer

	    // Set source to a copy of the bytes held by object.
	    source = new Uint8Array(object.slice());
	  } else if (ArrayBuffer.isView(object)) {
	    // BufferSource/ArrayBufferView

	    // Set source to a copy of the bytes held by object.
	    source = new Uint8Array(object.buffer.slice(object.byteOffset, object.byteOffset + object.byteLength));
	  } else if (util.isFormDataLike(object)) {
	    const boundary = `----formdata-undici-0${`${Math.floor(Math.random() * 1e11)}`.padStart(11, '0')}`;
	    const prefix = `--${boundary}\r\nContent-Disposition: form-data`;

	    /*! formdata-polyfill. MIT License. Jimmy WÃ¤rting <https://jimmy.warting.se/opensource> */
	    const escape = (str) =>
	      str.replace(/\n/g, '%0A').replace(/\r/g, '%0D').replace(/"/g, '%22');
	    const normalizeLinefeeds = (value) => value.replace(/\r?\n|\r/g, '\r\n');

	    // Set action to this step: run the multipart/form-data
	    // encoding algorithm, with objectâs entry list and UTF-8.
	    // - This ensures that the body is immutable and can't be changed afterwords
	    // - That the content-length is calculated in advance.
	    // - And that all parts are pre-encoded and ready to be sent.

	    const blobParts = [];
	    const rn = new Uint8Array([13, 10]); // '\r\n'
	    length = 0;
	    let hasUnknownSizeValue = false;

	    for (const [name, value] of object) {
	      if (typeof value === 'string') {
	        const chunk = textEncoder.encode(prefix +
	          `; name="${escape(normalizeLinefeeds(name))}"` +
	          `\r\n\r\n${normalizeLinefeeds(value)}\r\n`);
	        blobParts.push(chunk);
	        length += chunk.byteLength;
	      } else {
	        const chunk = textEncoder.encode(`${prefix}; name="${escape(normalizeLinefeeds(name))}"` +
	          (value.name ? `; filename="${escape(value.name)}"` : '') + '\r\n' +
	          `Content-Type: ${
	            value.type || 'application/octet-stream'
	          }\r\n\r\n`);
	        blobParts.push(chunk, value, rn);
	        if (typeof value.size === 'number') {
	          length += chunk.byteLength + value.size + rn.byteLength;
	        } else {
	          hasUnknownSizeValue = true;
	        }
	      }
	    }

	    const chunk = textEncoder.encode(`--${boundary}--`);
	    blobParts.push(chunk);
	    length += chunk.byteLength;
	    if (hasUnknownSizeValue) {
	      length = null;
	    }

	    // Set source to object.
	    source = object;

	    action = async function * () {
	      for (const part of blobParts) {
	        if (part.stream) {
	          yield * part.stream();
	        } else {
	          yield part;
	        }
	      }
	    };

	    // Set type to `multipart/form-data; boundary=`,
	    // followed by the multipart/form-data boundary string generated
	    // by the multipart/form-data encoding algorithm.
	    type = `multipart/form-data; boundary=${boundary}`;
	  } else if (isBlobLike(object)) {
	    // Blob

	    // Set source to object.
	    source = object;

	    // Set length to objectâs size.
	    length = object.size;

	    // If objectâs type attribute is not the empty byte sequence, set
	    // type to its value.
	    if (object.type) {
	      type = object.type;
	    }
	  } else if (typeof object[Symbol.asyncIterator] === 'function') {
	    // If keepalive is true, then throw a TypeError.
	    if (keepalive) {
	      throw new TypeError('keepalive')
	    }

	    // If object is disturbed or locked, then throw a TypeError.
	    if (util.isDisturbed(object) || object.locked) {
	      throw new TypeError(
	        'Response body object should not be disturbed or locked'
	      )
	    }

	    stream =
	      object instanceof ReadableStream ? object : ReadableStreamFrom(object);
	  }

	  // 11. If source is a byte sequence, then set action to a
	  // step that returns source and length to sourceâs length.
	  if (typeof source === 'string' || util.isBuffer(source)) {
	    length = Buffer.byteLength(source);
	  }

	  // 12. If action is non-null, then run these steps in in parallel:
	  if (action != null) {
	    // Run action.
	    let iterator;
	    stream = new ReadableStream({
	      async start () {
	        iterator = action(object)[Symbol.asyncIterator]();
	      },
	      async pull (controller) {
	        const { value, done } = await iterator.next();
	        if (done) {
	          // When running action is done, close stream.
	          queueMicrotask(() => {
	            controller.close();
	            controller.byobRequest?.respond(0);
	          });
	        } else {
	          // Whenever one or more bytes are available and stream is not errored,
	          // enqueue a Uint8Array wrapping an ArrayBuffer containing the available
	          // bytes into stream.
	          if (!isErrored(stream)) {
	            const buffer = new Uint8Array(value);
	            if (buffer.byteLength) {
	              controller.enqueue(buffer);
	            }
	          }
	        }
	        return controller.desiredSize > 0
	      },
	      async cancel (reason) {
	        await iterator.return();
	      },
	      type: 'bytes'
	    });
	  }

	  // 13. Let body be a body whose stream is stream, source is source,
	  // and length is length.
	  const body = { stream, source, length };

	  // 14. Return (body, type).
	  return [body, type]
	}

	// https://fetch.spec.whatwg.org/#bodyinit-safely-extract
	function safelyExtractBody (object, keepalive = false) {
	  // To safely extract a body and a `Content-Type` value from
	  // a byte sequence or BodyInit object object, run these steps:

	  // 1. If object is a ReadableStream object, then:
	  if (object instanceof ReadableStream) {
	    // Assert: object is neither disturbed nor locked.
	    // istanbul ignore next
	    assert(!util.isDisturbed(object), 'The body has already been consumed.');
	    // istanbul ignore next
	    assert(!object.locked, 'The stream is locked.');
	  }

	  // 2. Return the results of extracting object.
	  return extractBody(object, keepalive)
	}

	function cloneBody (body) {
	  // To clone a body body, run these steps:

	  // https://fetch.spec.whatwg.org/#concept-body-clone

	  // 1. Let Â« out1, out2 Â» be the result of teeing bodyâs stream.
	  const [out1, out2] = body.stream.tee();

	  // 2. Set bodyâs stream to out1.
	  body.stream = out1;

	  // 3. Return a body whose stream is out2 and other members are copied from body.
	  return {
	    stream: out2,
	    length: body.length,
	    source: body.source
	  }
	}

	function throwIfAborted (state) {
	  if (state.aborted) {
	    throw new DOMException('The operation was aborted.', 'AbortError')
	  }
	}

	function bodyMixinMethods (instance) {
	  const methods = {
	    blob () {
	      // The blob() method steps are to return the result of
	      // running consume body with this and the following step
	      // given a byte sequence bytes: return a Blob whose
	      // contents are bytes and whose type attribute is thisâs
	      // MIME type.
	      return consumeBody(this, (bytes) => {
	        let mimeType = bodyMimeType(this);

	        if (mimeType === null) {
	          mimeType = '';
	        } else if (mimeType) {
	          mimeType = serializeAMimeType(mimeType);
	        }

	        // Return a Blob whose contents are bytes and type attribute
	        // is mimeType.
	        return new Blob([bytes], { type: mimeType })
	      }, instance, false)
	    },

	    arrayBuffer () {
	      // The arrayBuffer() method steps are to return the result
	      // of running consume body with this and the following step
	      // given a byte sequence bytes: return a new ArrayBuffer
	      // whose contents are bytes.
	      return consumeBody(this, (bytes) => {
	        // Note: arrayBuffer already cloned.
	        return bytes.buffer
	      }, instance, true)
	    },

	    text () {
	      // The text() method steps are to return the result of running
	      // consume body with this and UTF-8 decode.
	      return consumeBody(this, utf8DecodeBytes, instance, false)
	    },

	    json () {
	      // The json() method steps are to return the result of running
	      // consume body with this and parse JSON from bytes.
	      return consumeBody(this, parseJSONFromBytes, instance, false)
	    },

	    formData () {
	      // The formData() method steps are to return the result of running
	      // consume body with this and the following step given a byte sequence bytes:
	      return consumeBody(this, (value) => {
	        // 1. Let mimeType be the result of get the MIME type with this.
	        const mimeType = bodyMimeType(this);

	        // 2. If mimeType is non-null, then switch on mimeTypeâs essence and run
	        //    the corresponding steps:
	        if (mimeType !== null) {
	          switch (mimeType.essence) {
	            case 'multipart/form-data': {
	              // 1. ... [long step]
	              const parsed = multipartFormDataParser(value, mimeType);

	              // 2. If that fails for some reason, then throw a TypeError.
	              if (parsed === 'failure') {
	                throw new TypeError('Failed to parse body as FormData.')
	              }

	              // 3. Return a new FormData object, appending each entry,
	              //    resulting from the parsing operation, to its entry list.
	              const fd = new FormData();
	              fd[kState] = parsed;

	              return fd
	            }
	            case 'application/x-www-form-urlencoded': {
	              // 1. Let entries be the result of parsing bytes.
	              const entries = new URLSearchParams(value.toString());

	              // 2. If entries is failure, then throw a TypeError.

	              // 3. Return a new FormData object whose entry list is entries.
	              const fd = new FormData();

	              for (const [name, value] of entries) {
	                fd.append(name, value);
	              }

	              return fd
	            }
	          }
	        }

	        // 3. Throw a TypeError.
	        throw new TypeError(
	          'Content-Type was not one of "multipart/form-data" or "application/x-www-form-urlencoded".'
	        )
	      }, instance, false)
	    },

	    bytes () {
	      // The bytes() method steps are to return the result of running consume body
	      // with this and the following step given a byte sequence bytes: return the
	      // result of creating a Uint8Array from bytes in thisâs relevant realm.
	      return consumeBody(this, (bytes) => {
	        return new Uint8Array(bytes.buffer, 0, bytes.byteLength)
	      }, instance, true)
	    }
	  };

	  return methods
	}

	function mixinBody (prototype) {
	  Object.assign(prototype.prototype, bodyMixinMethods(prototype));
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#concept-body-consume-body
	 * @param {Response|Request} object
	 * @param {(value: unknown) => unknown} convertBytesToJSValue
	 * @param {Response|Request} instance
	 * @param {boolean} [shouldClone]
	 */
	async function consumeBody (object, convertBytesToJSValue, instance, shouldClone) {
	  webidl.brandCheck(object, instance);

	  // 1. If object is unusable, then return a promise rejected
	  //    with a TypeError.
	  if (bodyUnusable(object[kState].body)) {
	    throw new TypeError('Body is unusable: Body has already been read')
	  }

	  throwIfAborted(object[kState]);

	  // 2. Let promise be a new promise.
	  const promise = createDeferredPromise();

	  // 3. Let errorSteps given error be to reject promise with error.
	  const errorSteps = (error) => promise.reject(error);

	  // 4. Let successSteps given a byte sequence data be to resolve
	  //    promise with the result of running convertBytesToJSValue
	  //    with data. If that threw an exception, then run errorSteps
	  //    with that exception.
	  const successSteps = (data) => {
	    try {
	      promise.resolve(convertBytesToJSValue(data));
	    } catch (e) {
	      errorSteps(e);
	    }
	  };

	  // 5. If objectâs body is null, then run successSteps with an
	  //    empty byte sequence.
	  if (object[kState].body == null) {
	    successSteps(Buffer.allocUnsafe(0));
	    return promise.promise
	  }

	  // 6. Otherwise, fully read objectâs body given successSteps,
	  //    errorSteps, and objectâs relevant global object.
	  await fullyReadBody(object[kState].body, successSteps, errorSteps, shouldClone);

	  // 7. Return promise.
	  return promise.promise
	}

	// https://fetch.spec.whatwg.org/#body-unusable
	function bodyUnusable (body) {
	  // An object including the Body interface mixin is
	  // said to be unusable if its body is non-null and
	  // its bodyâs stream is disturbed or locked.
	  return body != null && (body.stream.locked || util.isDisturbed(body.stream))
	}

	/**
	 * @see https://infra.spec.whatwg.org/#parse-json-bytes-to-a-javascript-value
	 * @param {Uint8Array} bytes
	 */
	function parseJSONFromBytes (bytes) {
	  return JSON.parse(utf8DecodeBytes(bytes))
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#concept-body-mime-type
	 * @param {import('./response').Response|import('./request').Request} requestOrResponse
	 */
	function bodyMimeType (requestOrResponse) {
	  // 1. Let headers be null.
	  // 2. If requestOrResponse is a Request object, then set headers to requestOrResponseâs requestâs header list.
	  // 3. Otherwise, set headers to requestOrResponseâs responseâs header list.
	  /** @type {import('./headers').HeadersList} */
	  const headers = requestOrResponse[kState].headersList;

	  // 4. Let mimeType be the result of extracting a MIME type from headers.
	  const mimeType = extractMimeType(headers);

	  // 5. If mimeType is failure, then return null.
	  if (mimeType === 'failure') {
	    return null
	  }

	  // 6. Return mimeType.
	  return mimeType
	}

	body = {
	  extractBody,
	  safelyExtractBody,
	  cloneBody,
	  mixinBody
	};
	return body;
}

var clientH1;
var hasRequiredClientH1;

function requireClientH1 () {
	if (hasRequiredClientH1) return clientH1;
	hasRequiredClientH1 = 1;

	/* global WebAssembly */

	const assert = require$$0$4;
	const util = requireUtil$7();
	const { channels } = requireDiagnostics();
	const timers = requireTimers();
	const {
	  RequestContentLengthMismatchError,
	  ResponseContentLengthMismatchError,
	  RequestAbortedError,
	  HeadersTimeoutError,
	  HeadersOverflowError,
	  SocketError,
	  InformationalError,
	  BodyTimeoutError,
	  HTTPParserError,
	  ResponseExceededMaxSizeError
	} = requireErrors();
	const {
	  kUrl,
	  kReset,
	  kClient,
	  kParser,
	  kBlocking,
	  kRunning,
	  kPending,
	  kSize,
	  kWriting,
	  kQueue,
	  kNoRef,
	  kKeepAliveDefaultTimeout,
	  kHostHeader,
	  kPendingIdx,
	  kRunningIdx,
	  kError,
	  kPipelining,
	  kSocket,
	  kKeepAliveTimeoutValue,
	  kMaxHeadersSize,
	  kKeepAliveMaxTimeout,
	  kKeepAliveTimeoutThreshold,
	  kHeadersTimeout,
	  kBodyTimeout,
	  kStrictContentLength,
	  kMaxRequests,
	  kCounter,
	  kMaxResponseSize,
	  kOnError,
	  kResume,
	  kHTTPContext
	} = requireSymbols$4();

	const constants = requireConstants$3();
	const EMPTY_BUF = Buffer.alloc(0);
	const FastBuffer = Buffer[Symbol.species];
	const addListener = util.addListener;
	const removeAllListeners = util.removeAllListeners;

	let extractBody;

	async function lazyllhttp () {
	  const llhttpWasmData = process.env.JEST_WORKER_ID ? requireLlhttpWasm() : undefined;

	  let mod;
	  try {
	    mod = await WebAssembly.compile(requireLlhttp_simdWasm());
	  } catch (e) {
	    /* istanbul ignore next */

	    // We could check if the error was caused by the simd option not
	    // being enabled, but the occurring of this other error
	    // * https://github.com/emscripten-core/emscripten/issues/11495
	    // got me to remove that check to avoid breaking Node 12.
	    mod = await WebAssembly.compile(llhttpWasmData || requireLlhttpWasm());
	  }

	  return await WebAssembly.instantiate(mod, {
	    env: {
	      /* eslint-disable camelcase */

	      wasm_on_url: (p, at, len) => {
	        /* istanbul ignore next */
	        return 0
	      },
	      wasm_on_status: (p, at, len) => {
	        assert.strictEqual(currentParser.ptr, p);
	        const start = at - currentBufferPtr + currentBufferRef.byteOffset;
	        return currentParser.onStatus(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
	      },
	      wasm_on_message_begin: (p) => {
	        assert.strictEqual(currentParser.ptr, p);
	        return currentParser.onMessageBegin() || 0
	      },
	      wasm_on_header_field: (p, at, len) => {
	        assert.strictEqual(currentParser.ptr, p);
	        const start = at - currentBufferPtr + currentBufferRef.byteOffset;
	        return currentParser.onHeaderField(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
	      },
	      wasm_on_header_value: (p, at, len) => {
	        assert.strictEqual(currentParser.ptr, p);
	        const start = at - currentBufferPtr + currentBufferRef.byteOffset;
	        return currentParser.onHeaderValue(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
	      },
	      wasm_on_headers_complete: (p, statusCode, upgrade, shouldKeepAlive) => {
	        assert.strictEqual(currentParser.ptr, p);
	        return currentParser.onHeadersComplete(statusCode, Boolean(upgrade), Boolean(shouldKeepAlive)) || 0
	      },
	      wasm_on_body: (p, at, len) => {
	        assert.strictEqual(currentParser.ptr, p);
	        const start = at - currentBufferPtr + currentBufferRef.byteOffset;
	        return currentParser.onBody(new FastBuffer(currentBufferRef.buffer, start, len)) || 0
	      },
	      wasm_on_message_complete: (p) => {
	        assert.strictEqual(currentParser.ptr, p);
	        return currentParser.onMessageComplete() || 0
	      }

	      /* eslint-enable camelcase */
	    }
	  })
	}

	let llhttpInstance = null;
	let llhttpPromise = lazyllhttp();
	llhttpPromise.catch();

	let currentParser = null;
	let currentBufferRef = null;
	let currentBufferSize = 0;
	let currentBufferPtr = null;

	const TIMEOUT_HEADERS = 1;
	const TIMEOUT_BODY = 2;
	const TIMEOUT_IDLE = 3;

	class Parser {
	  constructor (client, socket, { exports }) {
	    assert(Number.isFinite(client[kMaxHeadersSize]) && client[kMaxHeadersSize] > 0);

	    this.llhttp = exports;
	    this.ptr = this.llhttp.llhttp_alloc(constants.TYPE.RESPONSE);
	    this.client = client;
	    this.socket = socket;
	    this.timeout = null;
	    this.timeoutValue = null;
	    this.timeoutType = null;
	    this.statusCode = null;
	    this.statusText = '';
	    this.upgrade = false;
	    this.headers = [];
	    this.headersSize = 0;
	    this.headersMaxSize = client[kMaxHeadersSize];
	    this.shouldKeepAlive = false;
	    this.paused = false;
	    this.resume = this.resume.bind(this);

	    this.bytesRead = 0;

	    this.keepAlive = '';
	    this.contentLength = '';
	    this.connection = '';
	    this.maxResponseSize = client[kMaxResponseSize];
	  }

	  setTimeout (value, type) {
	    this.timeoutType = type;
	    if (value !== this.timeoutValue) {
	      timers.clearTimeout(this.timeout);
	      if (value) {
	        this.timeout = timers.setTimeout(onParserTimeout, value, this);
	        // istanbul ignore else: only for jest
	        if (this.timeout.unref) {
	          this.timeout.unref();
	        }
	      } else {
	        this.timeout = null;
	      }
	      this.timeoutValue = value;
	    } else if (this.timeout) {
	      // istanbul ignore else: only for jest
	      if (this.timeout.refresh) {
	        this.timeout.refresh();
	      }
	    }
	  }

	  resume () {
	    if (this.socket.destroyed || !this.paused) {
	      return
	    }

	    assert(this.ptr != null);
	    assert(currentParser == null);

	    this.llhttp.llhttp_resume(this.ptr);

	    assert(this.timeoutType === TIMEOUT_BODY);
	    if (this.timeout) {
	      // istanbul ignore else: only for jest
	      if (this.timeout.refresh) {
	        this.timeout.refresh();
	      }
	    }

	    this.paused = false;
	    this.execute(this.socket.read() || EMPTY_BUF); // Flush parser.
	    this.readMore();
	  }

	  readMore () {
	    while (!this.paused && this.ptr) {
	      const chunk = this.socket.read();
	      if (chunk === null) {
	        break
	      }
	      this.execute(chunk);
	    }
	  }

	  execute (data) {
	    assert(this.ptr != null);
	    assert(currentParser == null);
	    assert(!this.paused);

	    const { socket, llhttp } = this;

	    if (data.length > currentBufferSize) {
	      if (currentBufferPtr) {
	        llhttp.free(currentBufferPtr);
	      }
	      currentBufferSize = Math.ceil(data.length / 4096) * 4096;
	      currentBufferPtr = llhttp.malloc(currentBufferSize);
	    }

	    new Uint8Array(llhttp.memory.buffer, currentBufferPtr, currentBufferSize).set(data);

	    // Call `execute` on the wasm parser.
	    // We pass the `llhttp_parser` pointer address, the pointer address of buffer view data,
	    // and finally the length of bytes to parse.
	    // The return value is an error code or `constants.ERROR.OK`.
	    try {
	      let ret;

	      try {
	        currentBufferRef = data;
	        currentParser = this;
	        ret = llhttp.llhttp_execute(this.ptr, currentBufferPtr, data.length);
	        /* eslint-disable-next-line no-useless-catch */
	      } catch (err) {
	        /* istanbul ignore next: difficult to make a test case for */
	        throw err
	      } finally {
	        currentParser = null;
	        currentBufferRef = null;
	      }

	      const offset = llhttp.llhttp_get_error_pos(this.ptr) - currentBufferPtr;

	      if (ret === constants.ERROR.PAUSED_UPGRADE) {
	        this.onUpgrade(data.slice(offset));
	      } else if (ret === constants.ERROR.PAUSED) {
	        this.paused = true;
	        socket.unshift(data.slice(offset));
	      } else if (ret !== constants.ERROR.OK) {
	        const ptr = llhttp.llhttp_get_error_reason(this.ptr);
	        let message = '';
	        /* istanbul ignore else: difficult to make a test case for */
	        if (ptr) {
	          const len = new Uint8Array(llhttp.memory.buffer, ptr).indexOf(0);
	          message =
	            'Response does not match the HTTP/1.1 protocol (' +
	            Buffer.from(llhttp.memory.buffer, ptr, len).toString() +
	            ')';
	        }
	        throw new HTTPParserError(message, constants.ERROR[ret], data.slice(offset))
	      }
	    } catch (err) {
	      util.destroy(socket, err);
	    }
	  }

	  destroy () {
	    assert(this.ptr != null);
	    assert(currentParser == null);

	    this.llhttp.llhttp_free(this.ptr);
	    this.ptr = null;

	    timers.clearTimeout(this.timeout);
	    this.timeout = null;
	    this.timeoutValue = null;
	    this.timeoutType = null;

	    this.paused = false;
	  }

	  onStatus (buf) {
	    this.statusText = buf.toString();
	  }

	  onMessageBegin () {
	    const { socket, client } = this;

	    /* istanbul ignore next: difficult to make a test case for */
	    if (socket.destroyed) {
	      return -1
	    }

	    const request = client[kQueue][client[kRunningIdx]];
	    if (!request) {
	      return -1
	    }
	    request.onResponseStarted();
	  }

	  onHeaderField (buf) {
	    const len = this.headers.length;

	    if ((len & 1) === 0) {
	      this.headers.push(buf);
	    } else {
	      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf]);
	    }

	    this.trackHeader(buf.length);
	  }

	  onHeaderValue (buf) {
	    let len = this.headers.length;

	    if ((len & 1) === 1) {
	      this.headers.push(buf);
	      len += 1;
	    } else {
	      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf]);
	    }

	    const key = this.headers[len - 2];
	    if (key.length === 10) {
	      const headerName = util.bufferToLowerCasedHeaderName(key);
	      if (headerName === 'keep-alive') {
	        this.keepAlive += buf.toString();
	      } else if (headerName === 'connection') {
	        this.connection += buf.toString();
	      }
	    } else if (key.length === 14 && util.bufferToLowerCasedHeaderName(key) === 'content-length') {
	      this.contentLength += buf.toString();
	    }

	    this.trackHeader(buf.length);
	  }

	  trackHeader (len) {
	    this.headersSize += len;
	    if (this.headersSize >= this.headersMaxSize) {
	      util.destroy(this.socket, new HeadersOverflowError());
	    }
	  }

	  onUpgrade (head) {
	    const { upgrade, client, socket, headers, statusCode } = this;

	    assert(upgrade);

	    const request = client[kQueue][client[kRunningIdx]];
	    assert(request);

	    assert(!socket.destroyed);
	    assert(socket === client[kSocket]);
	    assert(!this.paused);
	    assert(request.upgrade || request.method === 'CONNECT');

	    this.statusCode = null;
	    this.statusText = '';
	    this.shouldKeepAlive = null;

	    assert(this.headers.length % 2 === 0);
	    this.headers = [];
	    this.headersSize = 0;

	    socket.unshift(head);

	    socket[kParser].destroy();
	    socket[kParser] = null;

	    socket[kClient] = null;
	    socket[kError] = null;

	    removeAllListeners(socket);

	    client[kSocket] = null;
	    client[kHTTPContext] = null; // TODO (fix): This is hacky...
	    client[kQueue][client[kRunningIdx]++] = null;
	    client.emit('disconnect', client[kUrl], [client], new InformationalError('upgrade'));

	    try {
	      request.onUpgrade(statusCode, headers, socket);
	    } catch (err) {
	      util.destroy(socket, err);
	    }

	    client[kResume]();
	  }

	  onHeadersComplete (statusCode, upgrade, shouldKeepAlive) {
	    const { client, socket, headers, statusText } = this;

	    /* istanbul ignore next: difficult to make a test case for */
	    if (socket.destroyed) {
	      return -1
	    }

	    const request = client[kQueue][client[kRunningIdx]];

	    /* istanbul ignore next: difficult to make a test case for */
	    if (!request) {
	      return -1
	    }

	    assert(!this.upgrade);
	    assert(this.statusCode < 200);

	    if (statusCode === 100) {
	      util.destroy(socket, new SocketError('bad response', util.getSocketInfo(socket)));
	      return -1
	    }

	    /* this can only happen if server is misbehaving */
	    if (upgrade && !request.upgrade) {
	      util.destroy(socket, new SocketError('bad upgrade', util.getSocketInfo(socket)));
	      return -1
	    }

	    assert.strictEqual(this.timeoutType, TIMEOUT_HEADERS);

	    this.statusCode = statusCode;
	    this.shouldKeepAlive = (
	      shouldKeepAlive ||
	      // Override llhttp value which does not allow keepAlive for HEAD.
	      (request.method === 'HEAD' && !socket[kReset] && this.connection.toLowerCase() === 'keep-alive')
	    );

	    if (this.statusCode >= 200) {
	      const bodyTimeout = request.bodyTimeout != null
	        ? request.bodyTimeout
	        : client[kBodyTimeout];
	      this.setTimeout(bodyTimeout, TIMEOUT_BODY);
	    } else if (this.timeout) {
	      // istanbul ignore else: only for jest
	      if (this.timeout.refresh) {
	        this.timeout.refresh();
	      }
	    }

	    if (request.method === 'CONNECT') {
	      assert(client[kRunning] === 1);
	      this.upgrade = true;
	      return 2
	    }

	    if (upgrade) {
	      assert(client[kRunning] === 1);
	      this.upgrade = true;
	      return 2
	    }

	    assert(this.headers.length % 2 === 0);
	    this.headers = [];
	    this.headersSize = 0;

	    if (this.shouldKeepAlive && client[kPipelining]) {
	      const keepAliveTimeout = this.keepAlive ? util.parseKeepAliveTimeout(this.keepAlive) : null;

	      if (keepAliveTimeout != null) {
	        const timeout = Math.min(
	          keepAliveTimeout - client[kKeepAliveTimeoutThreshold],
	          client[kKeepAliveMaxTimeout]
	        );
	        if (timeout <= 0) {
	          socket[kReset] = true;
	        } else {
	          client[kKeepAliveTimeoutValue] = timeout;
	        }
	      } else {
	        client[kKeepAliveTimeoutValue] = client[kKeepAliveDefaultTimeout];
	      }
	    } else {
	      // Stop more requests from being dispatched.
	      socket[kReset] = true;
	    }

	    const pause = request.onHeaders(statusCode, headers, this.resume, statusText) === false;

	    if (request.aborted) {
	      return -1
	    }

	    if (request.method === 'HEAD') {
	      return 1
	    }

	    if (statusCode < 200) {
	      return 1
	    }

	    if (socket[kBlocking]) {
	      socket[kBlocking] = false;
	      client[kResume]();
	    }

	    return pause ? constants.ERROR.PAUSED : 0
	  }

	  onBody (buf) {
	    const { client, socket, statusCode, maxResponseSize } = this;

	    if (socket.destroyed) {
	      return -1
	    }

	    const request = client[kQueue][client[kRunningIdx]];
	    assert(request);

	    assert.strictEqual(this.timeoutType, TIMEOUT_BODY);
	    if (this.timeout) {
	      // istanbul ignore else: only for jest
	      if (this.timeout.refresh) {
	        this.timeout.refresh();
	      }
	    }

	    assert(statusCode >= 200);

	    if (maxResponseSize > -1 && this.bytesRead + buf.length > maxResponseSize) {
	      util.destroy(socket, new ResponseExceededMaxSizeError());
	      return -1
	    }

	    this.bytesRead += buf.length;

	    if (request.onData(buf) === false) {
	      return constants.ERROR.PAUSED
	    }
	  }

	  onMessageComplete () {
	    const { client, socket, statusCode, upgrade, headers, contentLength, bytesRead, shouldKeepAlive } = this;

	    if (socket.destroyed && (!statusCode || shouldKeepAlive)) {
	      return -1
	    }

	    if (upgrade) {
	      return
	    }

	    const request = client[kQueue][client[kRunningIdx]];
	    assert(request);

	    assert(statusCode >= 100);

	    this.statusCode = null;
	    this.statusText = '';
	    this.bytesRead = 0;
	    this.contentLength = '';
	    this.keepAlive = '';
	    this.connection = '';

	    assert(this.headers.length % 2 === 0);
	    this.headers = [];
	    this.headersSize = 0;

	    if (statusCode < 200) {
	      return
	    }

	    /* istanbul ignore next: should be handled by llhttp? */
	    if (request.method !== 'HEAD' && contentLength && bytesRead !== parseInt(contentLength, 10)) {
	      util.destroy(socket, new ResponseContentLengthMismatchError());
	      return -1
	    }

	    request.onComplete(headers);

	    client[kQueue][client[kRunningIdx]++] = null;

	    if (socket[kWriting]) {
	      assert.strictEqual(client[kRunning], 0);
	      // Response completed before request.
	      util.destroy(socket, new InformationalError('reset'));
	      return constants.ERROR.PAUSED
	    } else if (!shouldKeepAlive) {
	      util.destroy(socket, new InformationalError('reset'));
	      return constants.ERROR.PAUSED
	    } else if (socket[kReset] && client[kRunning] === 0) {
	      // Destroy socket once all requests have completed.
	      // The request at the tail of the pipeline is the one
	      // that requested reset and no further requests should
	      // have been queued since then.
	      util.destroy(socket, new InformationalError('reset'));
	      return constants.ERROR.PAUSED
	    } else if (client[kPipelining] == null || client[kPipelining] === 1) {
	      // We must wait a full event loop cycle to reuse this socket to make sure
	      // that non-spec compliant servers are not closing the connection even if they
	      // said they won't.
	      setImmediate(() => client[kResume]());
	    } else {
	      client[kResume]();
	    }
	  }
	}

	function onParserTimeout (parser) {
	  const { socket, timeoutType, client } = parser;

	  /* istanbul ignore else */
	  if (timeoutType === TIMEOUT_HEADERS) {
	    if (!socket[kWriting] || socket.writableNeedDrain || client[kRunning] > 1) {
	      assert(!parser.paused, 'cannot be paused while waiting for headers');
	      util.destroy(socket, new HeadersTimeoutError());
	    }
	  } else if (timeoutType === TIMEOUT_BODY) {
	    if (!parser.paused) {
	      util.destroy(socket, new BodyTimeoutError());
	    }
	  } else if (timeoutType === TIMEOUT_IDLE) {
	    assert(client[kRunning] === 0 && client[kKeepAliveTimeoutValue]);
	    util.destroy(socket, new InformationalError('socket idle timeout'));
	  }
	}

	async function connectH1 (client, socket) {
	  client[kSocket] = socket;

	  if (!llhttpInstance) {
	    llhttpInstance = await llhttpPromise;
	    llhttpPromise = null;
	  }

	  socket[kNoRef] = false;
	  socket[kWriting] = false;
	  socket[kReset] = false;
	  socket[kBlocking] = false;
	  socket[kParser] = new Parser(client, socket, llhttpInstance);

	  addListener(socket, 'error', function (err) {
	    const parser = this[kParser];

	    assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID');

	    // On Mac OS, we get an ECONNRESET even if there is a full body to be forwarded
	    // to the user.
	    if (err.code === 'ECONNRESET' && parser.statusCode && !parser.shouldKeepAlive) {
	      // We treat all incoming data so for as a valid response.
	      parser.onMessageComplete();
	      return
	    }

	    this[kError] = err;

	    this[kClient][kOnError](err);
	  });
	  addListener(socket, 'readable', function () {
	    const parser = this[kParser];

	    if (parser) {
	      parser.readMore();
	    }
	  });
	  addListener(socket, 'end', function () {
	    const parser = this[kParser];

	    if (parser.statusCode && !parser.shouldKeepAlive) {
	      // We treat all incoming data so far as a valid response.
	      parser.onMessageComplete();
	      return
	    }

	    util.destroy(this, new SocketError('other side closed', util.getSocketInfo(this)));
	  });
	  addListener(socket, 'close', function () {
	    const client = this[kClient];
	    const parser = this[kParser];

	    if (parser) {
	      if (!this[kError] && parser.statusCode && !parser.shouldKeepAlive) {
	        // We treat all incoming data so far as a valid response.
	        parser.onMessageComplete();
	      }

	      this[kParser].destroy();
	      this[kParser] = null;
	    }

	    const err = this[kError] || new SocketError('closed', util.getSocketInfo(this));

	    client[kSocket] = null;
	    client[kHTTPContext] = null; // TODO (fix): This is hacky...

	    if (client.destroyed) {
	      assert(client[kPending] === 0);

	      // Fail entire queue.
	      const requests = client[kQueue].splice(client[kRunningIdx]);
	      for (let i = 0; i < requests.length; i++) {
	        const request = requests[i];
	        util.errorRequest(client, request, err);
	      }
	    } else if (client[kRunning] > 0 && err.code !== 'UND_ERR_INFO') {
	      // Fail head of pipeline.
	      const request = client[kQueue][client[kRunningIdx]];
	      client[kQueue][client[kRunningIdx]++] = null;

	      util.errorRequest(client, request, err);
	    }

	    client[kPendingIdx] = client[kRunningIdx];

	    assert(client[kRunning] === 0);

	    client.emit('disconnect', client[kUrl], [client], err);

	    client[kResume]();
	  });

	  let closed = false;
	  socket.on('close', () => {
	    closed = true;
	  });

	  return {
	    version: 'h1',
	    defaultPipelining: 1,
	    write (...args) {
	      return writeH1(client, ...args)
	    },
	    resume () {
	      resumeH1(client);
	    },
	    destroy (err, callback) {
	      if (closed) {
	        queueMicrotask(callback);
	      } else {
	        socket.destroy(err).on('close', callback);
	      }
	    },
	    get destroyed () {
	      return socket.destroyed
	    },
	    busy (request) {
	      if (socket[kWriting] || socket[kReset] || socket[kBlocking]) {
	        return true
	      }

	      if (request) {
	        if (client[kRunning] > 0 && !request.idempotent) {
	          // Non-idempotent request cannot be retried.
	          // Ensure that no other requests are inflight and
	          // could cause failure.
	          return true
	        }

	        if (client[kRunning] > 0 && (request.upgrade || request.method === 'CONNECT')) {
	          // Don't dispatch an upgrade until all preceding requests have completed.
	          // A misbehaving server might upgrade the connection before all pipelined
	          // request has completed.
	          return true
	        }

	        if (client[kRunning] > 0 && util.bodyLength(request.body) !== 0 &&
	          (util.isStream(request.body) || util.isAsyncIterable(request.body) || util.isFormDataLike(request.body))) {
	          // Request with stream or iterator body can error while other requests
	          // are inflight and indirectly error those as well.
	          // Ensure this doesn't happen by waiting for inflight
	          // to complete before dispatching.

	          // Request with stream or iterator body cannot be retried.
	          // Ensure that no other requests are inflight and
	          // could cause failure.
	          return true
	        }
	      }

	      return false
	    }
	  }
	}

	function resumeH1 (client) {
	  const socket = client[kSocket];

	  if (socket && !socket.destroyed) {
	    if (client[kSize] === 0) {
	      if (!socket[kNoRef] && socket.unref) {
	        socket.unref();
	        socket[kNoRef] = true;
	      }
	    } else if (socket[kNoRef] && socket.ref) {
	      socket.ref();
	      socket[kNoRef] = false;
	    }

	    if (client[kSize] === 0) {
	      if (socket[kParser].timeoutType !== TIMEOUT_IDLE) {
	        socket[kParser].setTimeout(client[kKeepAliveTimeoutValue], TIMEOUT_IDLE);
	      }
	    } else if (client[kRunning] > 0 && socket[kParser].statusCode < 200) {
	      if (socket[kParser].timeoutType !== TIMEOUT_HEADERS) {
	        const request = client[kQueue][client[kRunningIdx]];
	        const headersTimeout = request.headersTimeout != null
	          ? request.headersTimeout
	          : client[kHeadersTimeout];
	        socket[kParser].setTimeout(headersTimeout, TIMEOUT_HEADERS);
	      }
	    }
	  }
	}

	// https://www.rfc-editor.org/rfc/rfc7230#section-3.3.2
	function shouldSendContentLength (method) {
	  return method !== 'GET' && method !== 'HEAD' && method !== 'OPTIONS' && method !== 'TRACE' && method !== 'CONNECT'
	}

	function writeH1 (client, request) {
	  const { method, path, host, upgrade, blocking, reset } = request;

	  let { body, headers, contentLength } = request;

	  // https://tools.ietf.org/html/rfc7231#section-4.3.1
	  // https://tools.ietf.org/html/rfc7231#section-4.3.2
	  // https://tools.ietf.org/html/rfc7231#section-4.3.5

	  // Sending a payload body on a request that does not
	  // expect it can cause undefined behavior on some
	  // servers and corrupt connection state. Do not
	  // re-use the connection for further requests.

	  const expectsPayload = (
	    method === 'PUT' ||
	    method === 'POST' ||
	    method === 'PATCH'
	  );

	  if (util.isFormDataLike(body)) {
	    if (!extractBody) {
	      extractBody = requireBody().extractBody;
	    }

	    const [bodyStream, contentType] = extractBody(body);
	    if (request.contentType == null) {
	      headers.push('content-type', contentType);
	    }
	    body = bodyStream.stream;
	    contentLength = bodyStream.length;
	  } else if (util.isBlobLike(body) && request.contentType == null && body.type) {
	    headers.push('content-type', body.type);
	  }

	  if (body && typeof body.read === 'function') {
	    // Try to read EOF in order to get length.
	    body.read(0);
	  }

	  const bodyLength = util.bodyLength(body);

	  contentLength = bodyLength ?? contentLength;

	  if (contentLength === null) {
	    contentLength = request.contentLength;
	  }

	  if (contentLength === 0 && !expectsPayload) {
	    // https://tools.ietf.org/html/rfc7230#section-3.3.2
	    // A user agent SHOULD NOT send a Content-Length header field when
	    // the request message does not contain a payload body and the method
	    // semantics do not anticipate such a body.

	    contentLength = null;
	  }

	  // https://github.com/nodejs/undici/issues/2046
	  // A user agent may send a Content-Length header with 0 value, this should be allowed.
	  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength !== null && request.contentLength !== contentLength) {
	    if (client[kStrictContentLength]) {
	      util.errorRequest(client, request, new RequestContentLengthMismatchError());
	      return false
	    }

	    process.emitWarning(new RequestContentLengthMismatchError());
	  }

	  const socket = client[kSocket];

	  const abort = (err) => {
	    if (request.aborted || request.completed) {
	      return
	    }

	    util.errorRequest(client, request, err || new RequestAbortedError());

	    util.destroy(body);
	    util.destroy(socket, new InformationalError('aborted'));
	  };

	  try {
	    request.onConnect(abort);
	  } catch (err) {
	    util.errorRequest(client, request, err);
	  }

	  if (request.aborted) {
	    return false
	  }

	  if (method === 'HEAD') {
	    // https://github.com/mcollina/undici/issues/258
	    // Close after a HEAD request to interop with misbehaving servers
	    // that may send a body in the response.

	    socket[kReset] = true;
	  }

	  if (upgrade || method === 'CONNECT') {
	    // On CONNECT or upgrade, block pipeline from dispatching further
	    // requests on this connection.

	    socket[kReset] = true;
	  }

	  if (reset != null) {
	    socket[kReset] = reset;
	  }

	  if (client[kMaxRequests] && socket[kCounter]++ >= client[kMaxRequests]) {
	    socket[kReset] = true;
	  }

	  if (blocking) {
	    socket[kBlocking] = true;
	  }

	  let header = `${method} ${path} HTTP/1.1\r\n`;

	  if (typeof host === 'string') {
	    header += `host: ${host}\r\n`;
	  } else {
	    header += client[kHostHeader];
	  }

	  if (upgrade) {
	    header += `connection: upgrade\r\nupgrade: ${upgrade}\r\n`;
	  } else if (client[kPipelining] && !socket[kReset]) {
	    header += 'connection: keep-alive\r\n';
	  } else {
	    header += 'connection: close\r\n';
	  }

	  if (Array.isArray(headers)) {
	    for (let n = 0; n < headers.length; n += 2) {
	      const key = headers[n + 0];
	      const val = headers[n + 1];

	      if (Array.isArray(val)) {
	        for (let i = 0; i < val.length; i++) {
	          header += `${key}: ${val[i]}\r\n`;
	        }
	      } else {
	        header += `${key}: ${val}\r\n`;
	      }
	    }
	  }

	  if (channels.sendHeaders.hasSubscribers) {
	    channels.sendHeaders.publish({ request, headers: header, socket });
	  }

	  /* istanbul ignore else: assertion */
	  if (!body || bodyLength === 0) {
	    writeBuffer(abort, null, client, request, socket, contentLength, header, expectsPayload);
	  } else if (util.isBuffer(body)) {
	    writeBuffer(abort, body, client, request, socket, contentLength, header, expectsPayload);
	  } else if (util.isBlobLike(body)) {
	    if (typeof body.stream === 'function') {
	      writeIterable(abort, body.stream(), client, request, socket, contentLength, header, expectsPayload);
	    } else {
	      writeBlob(abort, body, client, request, socket, contentLength, header, expectsPayload);
	    }
	  } else if (util.isStream(body)) {
	    writeStream(abort, body, client, request, socket, contentLength, header, expectsPayload);
	  } else if (util.isIterable(body)) {
	    writeIterable(abort, body, client, request, socket, contentLength, header, expectsPayload);
	  } else {
	    assert(false);
	  }

	  return true
	}

	function writeStream (abort, body, client, request, socket, contentLength, header, expectsPayload) {
	  assert(contentLength !== 0 || client[kRunning] === 0, 'stream body cannot be pipelined');

	  let finished = false;

	  const writer = new AsyncWriter({ abort, socket, request, contentLength, client, expectsPayload, header });

	  const onData = function (chunk) {
	    if (finished) {
	      return
	    }

	    try {
	      if (!writer.write(chunk) && this.pause) {
	        this.pause();
	      }
	    } catch (err) {
	      util.destroy(this, err);
	    }
	  };
	  const onDrain = function () {
	    if (finished) {
	      return
	    }

	    if (body.resume) {
	      body.resume();
	    }
	  };
	  const onClose = function () {
	    // 'close' might be emitted *before* 'error' for
	    // broken streams. Wait a tick to avoid this case.
	    queueMicrotask(() => {
	      // It's only safe to remove 'error' listener after
	      // 'close'.
	      body.removeListener('error', onFinished);
	    });

	    if (!finished) {
	      const err = new RequestAbortedError();
	      queueMicrotask(() => onFinished(err));
	    }
	  };
	  const onFinished = function (err) {
	    if (finished) {
	      return
	    }

	    finished = true;

	    assert(socket.destroyed || (socket[kWriting] && client[kRunning] <= 1));

	    socket
	      .off('drain', onDrain)
	      .off('error', onFinished);

	    body
	      .removeListener('data', onData)
	      .removeListener('end', onFinished)
	      .removeListener('close', onClose);

	    if (!err) {
	      try {
	        writer.end();
	      } catch (er) {
	        err = er;
	      }
	    }

	    writer.destroy(err);

	    if (err && (err.code !== 'UND_ERR_INFO' || err.message !== 'reset')) {
	      util.destroy(body, err);
	    } else {
	      util.destroy(body);
	    }
	  };

	  body
	    .on('data', onData)
	    .on('end', onFinished)
	    .on('error', onFinished)
	    .on('close', onClose);

	  if (body.resume) {
	    body.resume();
	  }

	  socket
	    .on('drain', onDrain)
	    .on('error', onFinished);

	  if (body.errorEmitted ?? body.errored) {
	    setImmediate(() => onFinished(body.errored));
	  } else if (body.endEmitted ?? body.readableEnded) {
	    setImmediate(() => onFinished(null));
	  }

	  if (body.closeEmitted ?? body.closed) {
	    setImmediate(onClose);
	  }
	}

	function writeBuffer (abort, body, client, request, socket, contentLength, header, expectsPayload) {
	  try {
	    if (!body) {
	      if (contentLength === 0) {
	        socket.write(`${header}content-length: 0\r\n\r\n`, 'latin1');
	      } else {
	        assert(contentLength === null, 'no body must not have content length');
	        socket.write(`${header}\r\n`, 'latin1');
	      }
	    } else if (util.isBuffer(body)) {
	      assert(contentLength === body.byteLength, 'buffer body must have content length');

	      socket.cork();
	      socket.write(`${header}content-length: ${contentLength}\r\n\r\n`, 'latin1');
	      socket.write(body);
	      socket.uncork();
	      request.onBodySent(body);

	      if (!expectsPayload) {
	        socket[kReset] = true;
	      }
	    }
	    request.onRequestSent();

	    client[kResume]();
	  } catch (err) {
	    abort(err);
	  }
	}

	async function writeBlob (abort, body, client, request, socket, contentLength, header, expectsPayload) {
	  assert(contentLength === body.size, 'blob body must have content length');

	  try {
	    if (contentLength != null && contentLength !== body.size) {
	      throw new RequestContentLengthMismatchError()
	    }

	    const buffer = Buffer.from(await body.arrayBuffer());

	    socket.cork();
	    socket.write(`${header}content-length: ${contentLength}\r\n\r\n`, 'latin1');
	    socket.write(buffer);
	    socket.uncork();

	    request.onBodySent(buffer);
	    request.onRequestSent();

	    if (!expectsPayload) {
	      socket[kReset] = true;
	    }

	    client[kResume]();
	  } catch (err) {
	    abort(err);
	  }
	}

	async function writeIterable (abort, body, client, request, socket, contentLength, header, expectsPayload) {
	  assert(contentLength !== 0 || client[kRunning] === 0, 'iterator body cannot be pipelined');

	  let callback = null;
	  function onDrain () {
	    if (callback) {
	      const cb = callback;
	      callback = null;
	      cb();
	    }
	  }

	  const waitForDrain = () => new Promise((resolve, reject) => {
	    assert(callback === null);

	    if (socket[kError]) {
	      reject(socket[kError]);
	    } else {
	      callback = resolve;
	    }
	  });

	  socket
	    .on('close', onDrain)
	    .on('drain', onDrain);

	  const writer = new AsyncWriter({ abort, socket, request, contentLength, client, expectsPayload, header });
	  try {
	    // It's up to the user to somehow abort the async iterable.
	    for await (const chunk of body) {
	      if (socket[kError]) {
	        throw socket[kError]
	      }

	      if (!writer.write(chunk)) {
	        await waitForDrain();
	      }
	    }

	    writer.end();
	  } catch (err) {
	    writer.destroy(err);
	  } finally {
	    socket
	      .off('close', onDrain)
	      .off('drain', onDrain);
	  }
	}

	class AsyncWriter {
	  constructor ({ abort, socket, request, contentLength, client, expectsPayload, header }) {
	    this.socket = socket;
	    this.request = request;
	    this.contentLength = contentLength;
	    this.client = client;
	    this.bytesWritten = 0;
	    this.expectsPayload = expectsPayload;
	    this.header = header;
	    this.abort = abort;

	    socket[kWriting] = true;
	  }

	  write (chunk) {
	    const { socket, request, contentLength, client, bytesWritten, expectsPayload, header } = this;

	    if (socket[kError]) {
	      throw socket[kError]
	    }

	    if (socket.destroyed) {
	      return false
	    }

	    const len = Buffer.byteLength(chunk);
	    if (!len) {
	      return true
	    }

	    // We should defer writing chunks.
	    if (contentLength !== null && bytesWritten + len > contentLength) {
	      if (client[kStrictContentLength]) {
	        throw new RequestContentLengthMismatchError()
	      }

	      process.emitWarning(new RequestContentLengthMismatchError());
	    }

	    socket.cork();

	    if (bytesWritten === 0) {
	      if (!expectsPayload) {
	        socket[kReset] = true;
	      }

	      if (contentLength === null) {
	        socket.write(`${header}transfer-encoding: chunked\r\n`, 'latin1');
	      } else {
	        socket.write(`${header}content-length: ${contentLength}\r\n\r\n`, 'latin1');
	      }
	    }

	    if (contentLength === null) {
	      socket.write(`\r\n${len.toString(16)}\r\n`, 'latin1');
	    }

	    this.bytesWritten += len;

	    const ret = socket.write(chunk);

	    socket.uncork();

	    request.onBodySent(chunk);

	    if (!ret) {
	      if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {
	        // istanbul ignore else: only for jest
	        if (socket[kParser].timeout.refresh) {
	          socket[kParser].timeout.refresh();
	        }
	      }
	    }

	    return ret
	  }

	  end () {
	    const { socket, contentLength, client, bytesWritten, expectsPayload, header, request } = this;
	    request.onRequestSent();

	    socket[kWriting] = false;

	    if (socket[kError]) {
	      throw socket[kError]
	    }

	    if (socket.destroyed) {
	      return
	    }

	    if (bytesWritten === 0) {
	      if (expectsPayload) {
	        // https://tools.ietf.org/html/rfc7230#section-3.3.2
	        // A user agent SHOULD send a Content-Length in a request message when
	        // no Transfer-Encoding is sent and the request method defines a meaning
	        // for an enclosed payload body.

	        socket.write(`${header}content-length: 0\r\n\r\n`, 'latin1');
	      } else {
	        socket.write(`${header}\r\n`, 'latin1');
	      }
	    } else if (contentLength === null) {
	      socket.write('\r\n0\r\n\r\n', 'latin1');
	    }

	    if (contentLength !== null && bytesWritten !== contentLength) {
	      if (client[kStrictContentLength]) {
	        throw new RequestContentLengthMismatchError()
	      } else {
	        process.emitWarning(new RequestContentLengthMismatchError());
	      }
	    }

	    if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {
	      // istanbul ignore else: only for jest
	      if (socket[kParser].timeout.refresh) {
	        socket[kParser].timeout.refresh();
	      }
	    }

	    client[kResume]();
	  }

	  destroy (err) {
	    const { socket, client, abort } = this;

	    socket[kWriting] = false;

	    if (err) {
	      assert(client[kRunning] <= 1, 'pipeline should only contain this request');
	      abort(err);
	    }
	  }
	}

	clientH1 = connectH1;
	return clientH1;
}

var clientH2;
var hasRequiredClientH2;

function requireClientH2 () {
	if (hasRequiredClientH2) return clientH2;
	hasRequiredClientH2 = 1;

	const assert = require$$0$4;
	const { pipeline } = require$$0$5;
	const util = requireUtil$7();
	const {
	  RequestContentLengthMismatchError,
	  RequestAbortedError,
	  SocketError,
	  InformationalError
	} = requireErrors();
	const {
	  kUrl,
	  kReset,
	  kClient,
	  kRunning,
	  kPending,
	  kQueue,
	  kPendingIdx,
	  kRunningIdx,
	  kError,
	  kSocket,
	  kStrictContentLength,
	  kOnError,
	  kMaxConcurrentStreams,
	  kHTTP2Session,
	  kResume
	} = requireSymbols$4();

	const kOpenStreams = Symbol('open streams');

	// Experimental
	let h2ExperimentalWarned = false;

	/** @type {import('http2')} */
	let http2;
	try {
	  http2 = require('node:http2');
	} catch {
	  // @ts-ignore
	  http2 = { constants: {} };
	}

	const {
	  constants: {
	    HTTP2_HEADER_AUTHORITY,
	    HTTP2_HEADER_METHOD,
	    HTTP2_HEADER_PATH,
	    HTTP2_HEADER_SCHEME,
	    HTTP2_HEADER_CONTENT_LENGTH,
	    HTTP2_HEADER_EXPECT,
	    HTTP2_HEADER_STATUS
	  }
	} = http2;

	function parseH2Headers (headers) {
	  const result = [];

	  for (const [name, value] of Object.entries(headers)) {
	    // h2 may concat the header value by array
	    // e.g. Set-Cookie
	    if (Array.isArray(value)) {
	      for (const subvalue of value) {
	        // we need to provide each header value of header name
	        // because the headers handler expect name-value pair
	        result.push(Buffer.from(name), Buffer.from(subvalue));
	      }
	    } else {
	      result.push(Buffer.from(name), Buffer.from(value));
	    }
	  }

	  return result
	}

	async function connectH2 (client, socket) {
	  client[kSocket] = socket;

	  if (!h2ExperimentalWarned) {
	    h2ExperimentalWarned = true;
	    process.emitWarning('H2 support is experimental, expect them to change at any time.', {
	      code: 'UNDICI-H2'
	    });
	  }

	  const session = http2.connect(client[kUrl], {
	    createConnection: () => socket,
	    peerMaxConcurrentStreams: client[kMaxConcurrentStreams]
	  });

	  session[kOpenStreams] = 0;
	  session[kClient] = client;
	  session[kSocket] = socket;

	  util.addListener(session, 'error', onHttp2SessionError);
	  util.addListener(session, 'frameError', onHttp2FrameError);
	  util.addListener(session, 'end', onHttp2SessionEnd);
	  util.addListener(session, 'goaway', onHTTP2GoAway);
	  util.addListener(session, 'close', function () {
	    const { [kClient]: client } = this;
	    const { [kSocket]: socket } = client;

	    const err = this[kSocket][kError] || this[kError] || new SocketError('closed', util.getSocketInfo(socket));

	    client[kHTTP2Session] = null;

	    if (client.destroyed) {
	      assert(client[kPending] === 0);

	      // Fail entire queue.
	      const requests = client[kQueue].splice(client[kRunningIdx]);
	      for (let i = 0; i < requests.length; i++) {
	        const request = requests[i];
	        util.errorRequest(client, request, err);
	      }
	    }
	  });

	  session.unref();

	  client[kHTTP2Session] = session;
	  socket[kHTTP2Session] = session;

	  util.addListener(socket, 'error', function (err) {
	    assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID');

	    this[kError] = err;

	    this[kClient][kOnError](err);
	  });

	  util.addListener(socket, 'end', function () {
	    util.destroy(this, new SocketError('other side closed', util.getSocketInfo(this)));
	  });

	  util.addListener(socket, 'close', function () {
	    const err = this[kError] || new SocketError('closed', util.getSocketInfo(this));

	    client[kSocket] = null;

	    if (this[kHTTP2Session] != null) {
	      this[kHTTP2Session].destroy(err);
	    }

	    client[kPendingIdx] = client[kRunningIdx];

	    assert(client[kRunning] === 0);

	    client.emit('disconnect', client[kUrl], [client], err);

	    client[kResume]();
	  });

	  let closed = false;
	  socket.on('close', () => {
	    closed = true;
	  });

	  return {
	    version: 'h2',
	    defaultPipelining: Infinity,
	    write (...args) {
	      // TODO (fix): return
	      writeH2(client, ...args);
	    },
	    resume () {

	    },
	    destroy (err, callback) {
	      if (closed) {
	        queueMicrotask(callback);
	      } else {
	        // Destroying the socket will trigger the session close
	        socket.destroy(err).on('close', callback);
	      }
	    },
	    get destroyed () {
	      return socket.destroyed
	    },
	    busy () {
	      return false
	    }
	  }
	}

	function onHttp2SessionError (err) {
	  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID');

	  this[kSocket][kError] = err;
	  this[kClient][kOnError](err);
	}

	function onHttp2FrameError (type, code, id) {
	  if (id === 0) {
	    const err = new InformationalError(`HTTP/2: "frameError" received - type ${type}, code ${code}`);
	    this[kSocket][kError] = err;
	    this[kClient][kOnError](err);
	  }
	}

	function onHttp2SessionEnd () {
	  const err = new SocketError('other side closed', util.getSocketInfo(this[kSocket]));
	  this.destroy(err);
	  util.destroy(this[kSocket], err);
	}

	/**
	 * This is the root cause of #3011
	 * We need to handle GOAWAY frames properly, and trigger the session close
	 * along with the socket right away
	 */
	function onHTTP2GoAway (code) {
	  const err = new RequestAbortedError(`HTTP/2: "GOAWAY" frame received with code ${code}`);

	  // We need to trigger the close cycle right away
	  // We need to destroy the session and the socket
	  // Requests should be failed with the error after the current one is handled
	  this[kSocket][kError] = err;
	  this[kClient][kOnError](err);

	  this.unref();

	  util.destroy(this[kSocket], err);
	}

	// https://www.rfc-editor.org/rfc/rfc7230#section-3.3.2
	function shouldSendContentLength (method) {
	  return method !== 'GET' && method !== 'HEAD' && method !== 'OPTIONS' && method !== 'TRACE' && method !== 'CONNECT'
	}

	function writeH2 (client, request) {
	  const session = client[kHTTP2Session];
	  const { body, method, path, host, upgrade, expectContinue, signal, headers: reqHeaders } = request;

	  if (upgrade) {
	    util.errorRequest(client, request, new Error('Upgrade not supported for H2'));
	    return false
	  }

	  if (request.aborted) {
	    return false
	  }

	  const headers = {};
	  for (let n = 0; n < reqHeaders.length; n += 2) {
	    const key = reqHeaders[n + 0];
	    const val = reqHeaders[n + 1];

	    if (Array.isArray(val)) {
	      for (let i = 0; i < val.length; i++) {
	        if (headers[key]) {
	          headers[key] += `,${val[i]}`;
	        } else {
	          headers[key] = val[i];
	        }
	      }
	    } else {
	      headers[key] = val;
	    }
	  }

	  /** @type {import('node:http2').ClientHttp2Stream} */
	  let stream;

	  const { hostname, port } = client[kUrl];

	  headers[HTTP2_HEADER_AUTHORITY] = host || `${hostname}${port ? `:${port}` : ''}`;
	  headers[HTTP2_HEADER_METHOD] = method;

	  const abort = (err) => {
	    if (request.aborted || request.completed) {
	      return
	    }

	    err = err || new RequestAbortedError();

	    util.errorRequest(client, request, err);

	    if (stream != null) {
	      util.destroy(stream, err);
	    }

	    // We do not destroy the socket as we can continue using the session
	    // the stream get's destroyed and the session remains to create new streams
	    util.destroy(body, err);
	  };

	  try {
	    // We are already connected, streams are pending.
	    // We can call on connect, and wait for abort
	    request.onConnect(abort);
	  } catch (err) {
	    util.errorRequest(client, request, err);
	  }

	  if (method === 'CONNECT') {
	    session.ref();
	    // We are already connected, streams are pending, first request
	    // will create a new stream. We trigger a request to create the stream and wait until
	    // `ready` event is triggered
	    // We disabled endStream to allow the user to write to the stream
	    stream = session.request(headers, { endStream: false, signal });

	    if (stream.id && !stream.pending) {
	      request.onUpgrade(null, null, stream);
	      ++session[kOpenStreams];
	    } else {
	      stream.once('ready', () => {
	        request.onUpgrade(null, null, stream);
	        ++session[kOpenStreams];
	      });
	    }

	    stream.once('close', () => {
	      session[kOpenStreams] -= 1;
	      if (session[kOpenStreams] === 0) session.unref();
	    });

	    return true
	  }

	  // https://tools.ietf.org/html/rfc7540#section-8.3
	  // :path and :scheme headers must be omitted when sending CONNECT

	  headers[HTTP2_HEADER_PATH] = path;
	  headers[HTTP2_HEADER_SCHEME] = 'https';

	  // https://tools.ietf.org/html/rfc7231#section-4.3.1
	  // https://tools.ietf.org/html/rfc7231#section-4.3.2
	  // https://tools.ietf.org/html/rfc7231#section-4.3.5

	  // Sending a payload body on a request that does not
	  // expect it can cause undefined behavior on some
	  // servers and corrupt connection state. Do not
	  // re-use the connection for further requests.

	  const expectsPayload = (
	    method === 'PUT' ||
	    method === 'POST' ||
	    method === 'PATCH'
	  );

	  if (body && typeof body.read === 'function') {
	    // Try to read EOF in order to get length.
	    body.read(0);
	  }

	  let contentLength = util.bodyLength(body);

	  if (contentLength == null) {
	    contentLength = request.contentLength;
	  }

	  if (contentLength === 0 || !expectsPayload) {
	    // https://tools.ietf.org/html/rfc7230#section-3.3.2
	    // A user agent SHOULD NOT send a Content-Length header field when
	    // the request message does not contain a payload body and the method
	    // semantics do not anticipate such a body.

	    contentLength = null;
	  }

	  // https://github.com/nodejs/undici/issues/2046
	  // A user agent may send a Content-Length header with 0 value, this should be allowed.
	  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength != null && request.contentLength !== contentLength) {
	    if (client[kStrictContentLength]) {
	      util.errorRequest(client, request, new RequestContentLengthMismatchError());
	      return false
	    }

	    process.emitWarning(new RequestContentLengthMismatchError());
	  }

	  if (contentLength != null) {
	    assert(body, 'no body must not have content length');
	    headers[HTTP2_HEADER_CONTENT_LENGTH] = `${contentLength}`;
	  }

	  session.ref();

	  const shouldEndStream = method === 'GET' || method === 'HEAD' || body === null;
	  if (expectContinue) {
	    headers[HTTP2_HEADER_EXPECT] = '100-continue';
	    stream = session.request(headers, { endStream: shouldEndStream, signal });

	    stream.once('continue', writeBodyH2);
	  } else {
	    stream = session.request(headers, {
	      endStream: shouldEndStream,
	      signal
	    });
	    writeBodyH2();
	  }

	  // Increment counter as we have new streams open
	  ++session[kOpenStreams];

	  stream.once('response', headers => {
	    const { [HTTP2_HEADER_STATUS]: statusCode, ...realHeaders } = headers;
	    request.onResponseStarted();

	    // Due to the stream nature, it is possible we face a race condition
	    // where the stream has been assigned, but the request has been aborted
	    // the request remains in-flight and headers hasn't been received yet
	    // for those scenarios, best effort is to destroy the stream immediately
	    // as there's no value to keep it open.
	    if (request.aborted) {
	      const err = new RequestAbortedError();
	      util.errorRequest(client, request, err);
	      util.destroy(stream, err);
	      return
	    }

	    if (request.onHeaders(Number(statusCode), parseH2Headers(realHeaders), stream.resume.bind(stream), '') === false) {
	      stream.pause();
	    }

	    stream.on('data', (chunk) => {
	      if (request.onData(chunk) === false) {
	        stream.pause();
	      }
	    });
	  });

	  stream.once('end', () => {
	    // When state is null, it means we haven't consumed body and the stream still do not have
	    // a state.
	    // Present specially when using pipeline or stream
	    if (stream.state?.state == null || stream.state.state < 6) {
	      request.onComplete([]);
	      return
	    }

	    // Stream is closed or half-closed-remote (6), decrement counter and cleanup
	    // It does not have sense to continue working with the stream as we do not
	    // have yet RST_STREAM support on client-side
	    if (session[kOpenStreams] === 0) {
	      session.unref();
	    }

	    abort(new InformationalError('HTTP/2: stream half-closed (remote)'));
	  });

	  stream.once('close', () => {
	    session[kOpenStreams] -= 1;
	    if (session[kOpenStreams] === 0) {
	      session.unref();
	    }
	  });

	  stream.once('error', function (err) {
	    abort(err);
	  });

	  stream.once('frameError', (type, code) => {
	    abort(new InformationalError(`HTTP/2: "frameError" received - type ${type}, code ${code}`));
	  });

	  // stream.on('aborted', () => {
	  //   // TODO(HTTP/2): Support aborted
	  // })

	  // stream.on('timeout', () => {
	  //   // TODO(HTTP/2): Support timeout
	  // })

	  // stream.on('push', headers => {
	  //   // TODO(HTTP/2): Support push
	  // })

	  // stream.on('trailers', headers => {
	  //   // TODO(HTTP/2): Support trailers
	  // })

	  return true

	  function writeBodyH2 () {
	    /* istanbul ignore else: assertion */
	    if (!body || contentLength === 0) {
	      writeBuffer(
	        abort,
	        stream,
	        null,
	        client,
	        request,
	        client[kSocket],
	        contentLength,
	        expectsPayload
	      );
	    } else if (util.isBuffer(body)) {
	      writeBuffer(
	        abort,
	        stream,
	        body,
	        client,
	        request,
	        client[kSocket],
	        contentLength,
	        expectsPayload
	      );
	    } else if (util.isBlobLike(body)) {
	      if (typeof body.stream === 'function') {
	        writeIterable(
	          abort,
	          stream,
	          body.stream(),
	          client,
	          request,
	          client[kSocket],
	          contentLength,
	          expectsPayload
	        );
	      } else {
	        writeBlob(
	          abort,
	          stream,
	          body,
	          client,
	          request,
	          client[kSocket],
	          contentLength,
	          expectsPayload
	        );
	      }
	    } else if (util.isStream(body)) {
	      writeStream(
	        abort,
	        client[kSocket],
	        expectsPayload,
	        stream,
	        body,
	        client,
	        request,
	        contentLength
	      );
	    } else if (util.isIterable(body)) {
	      writeIterable(
	        abort,
	        stream,
	        body,
	        client,
	        request,
	        client[kSocket],
	        contentLength,
	        expectsPayload
	      );
	    } else {
	      assert(false);
	    }
	  }
	}

	function writeBuffer (abort, h2stream, body, client, request, socket, contentLength, expectsPayload) {
	  try {
	    if (body != null && util.isBuffer(body)) {
	      assert(contentLength === body.byteLength, 'buffer body must have content length');
	      h2stream.cork();
	      h2stream.write(body);
	      h2stream.uncork();
	      h2stream.end();

	      request.onBodySent(body);
	    }

	    if (!expectsPayload) {
	      socket[kReset] = true;
	    }

	    request.onRequestSent();
	    client[kResume]();
	  } catch (error) {
	    abort(error);
	  }
	}

	function writeStream (abort, socket, expectsPayload, h2stream, body, client, request, contentLength) {
	  assert(contentLength !== 0 || client[kRunning] === 0, 'stream body cannot be pipelined');

	  // For HTTP/2, is enough to pipe the stream
	  const pipe = pipeline(
	    body,
	    h2stream,
	    (err) => {
	      if (err) {
	        util.destroy(pipe, err);
	        abort(err);
	      } else {
	        util.removeAllListeners(pipe);
	        request.onRequestSent();

	        if (!expectsPayload) {
	          socket[kReset] = true;
	        }

	        client[kResume]();
	      }
	    }
	  );

	  util.addListener(pipe, 'data', onPipeData);

	  function onPipeData (chunk) {
	    request.onBodySent(chunk);
	  }
	}

	async function writeBlob (abort, h2stream, body, client, request, socket, contentLength, expectsPayload) {
	  assert(contentLength === body.size, 'blob body must have content length');

	  try {
	    if (contentLength != null && contentLength !== body.size) {
	      throw new RequestContentLengthMismatchError()
	    }

	    const buffer = Buffer.from(await body.arrayBuffer());

	    h2stream.cork();
	    h2stream.write(buffer);
	    h2stream.uncork();
	    h2stream.end();

	    request.onBodySent(buffer);
	    request.onRequestSent();

	    if (!expectsPayload) {
	      socket[kReset] = true;
	    }

	    client[kResume]();
	  } catch (err) {
	    abort(err);
	  }
	}

	async function writeIterable (abort, h2stream, body, client, request, socket, contentLength, expectsPayload) {
	  assert(contentLength !== 0 || client[kRunning] === 0, 'iterator body cannot be pipelined');

	  let callback = null;
	  function onDrain () {
	    if (callback) {
	      const cb = callback;
	      callback = null;
	      cb();
	    }
	  }

	  const waitForDrain = () => new Promise((resolve, reject) => {
	    assert(callback === null);

	    if (socket[kError]) {
	      reject(socket[kError]);
	    } else {
	      callback = resolve;
	    }
	  });

	  h2stream
	    .on('close', onDrain)
	    .on('drain', onDrain);

	  try {
	    // It's up to the user to somehow abort the async iterable.
	    for await (const chunk of body) {
	      if (socket[kError]) {
	        throw socket[kError]
	      }

	      const res = h2stream.write(chunk);
	      request.onBodySent(chunk);
	      if (!res) {
	        await waitForDrain();
	      }
	    }

	    h2stream.end();

	    request.onRequestSent();

	    if (!expectsPayload) {
	      socket[kReset] = true;
	    }

	    client[kResume]();
	  } catch (err) {
	    abort(err);
	  } finally {
	    h2stream
	      .off('close', onDrain)
	      .off('drain', onDrain);
	  }
	}

	clientH2 = connectH2;
	return clientH2;
}

var redirectHandler;
var hasRequiredRedirectHandler;

function requireRedirectHandler () {
	if (hasRequiredRedirectHandler) return redirectHandler;
	hasRequiredRedirectHandler = 1;

	const util = requireUtil$7();
	const { kBodyUsed } = requireSymbols$4();
	const assert = require$$0$4;
	const { InvalidArgumentError } = requireErrors();
	const EE = require$$8;

	const redirectableStatusCodes = [300, 301, 302, 303, 307, 308];

	const kBody = Symbol('body');

	class BodyAsyncIterable {
	  constructor (body) {
	    this[kBody] = body;
	    this[kBodyUsed] = false;
	  }

	  async * [Symbol.asyncIterator] () {
	    assert(!this[kBodyUsed], 'disturbed');
	    this[kBodyUsed] = true;
	    yield * this[kBody];
	  }
	}

	class RedirectHandler {
	  constructor (dispatch, maxRedirections, opts, handler) {
	    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {
	      throw new InvalidArgumentError('maxRedirections must be a positive number')
	    }

	    util.validateHandler(handler, opts.method, opts.upgrade);

	    this.dispatch = dispatch;
	    this.location = null;
	    this.abort = null;
	    this.opts = { ...opts, maxRedirections: 0 }; // opts must be a copy
	    this.maxRedirections = maxRedirections;
	    this.handler = handler;
	    this.history = [];
	    this.redirectionLimitReached = false;

	    if (util.isStream(this.opts.body)) {
	      // TODO (fix): Provide some way for the user to cache the file to e.g. /tmp
	      // so that it can be dispatched again?
	      // TODO (fix): Do we need 100-expect support to provide a way to do this properly?
	      if (util.bodyLength(this.opts.body) === 0) {
	        this.opts.body
	          .on('data', function () {
	            assert(false);
	          });
	      }

	      if (typeof this.opts.body.readableDidRead !== 'boolean') {
	        this.opts.body[kBodyUsed] = false;
	        EE.prototype.on.call(this.opts.body, 'data', function () {
	          this[kBodyUsed] = true;
	        });
	      }
	    } else if (this.opts.body && typeof this.opts.body.pipeTo === 'function') {
	      // TODO (fix): We can't access ReadableStream internal state
	      // to determine whether or not it has been disturbed. This is just
	      // a workaround.
	      this.opts.body = new BodyAsyncIterable(this.opts.body);
	    } else if (
	      this.opts.body &&
	      typeof this.opts.body !== 'string' &&
	      !ArrayBuffer.isView(this.opts.body) &&
	      util.isIterable(this.opts.body)
	    ) {
	      // TODO: Should we allow re-using iterable if !this.opts.idempotent
	      // or through some other flag?
	      this.opts.body = new BodyAsyncIterable(this.opts.body);
	    }
	  }

	  onConnect (abort) {
	    this.abort = abort;
	    this.handler.onConnect(abort, { history: this.history });
	  }

	  onUpgrade (statusCode, headers, socket) {
	    this.handler.onUpgrade(statusCode, headers, socket);
	  }

	  onError (error) {
	    this.handler.onError(error);
	  }

	  onHeaders (statusCode, headers, resume, statusText) {
	    this.location = this.history.length >= this.maxRedirections || util.isDisturbed(this.opts.body)
	      ? null
	      : parseLocation(statusCode, headers);

	    if (this.opts.throwOnMaxRedirect && this.history.length >= this.maxRedirections) {
	      if (this.request) {
	        this.request.abort(new Error('max redirects'));
	      }

	      this.redirectionLimitReached = true;
	      this.abort(new Error('max redirects'));
	      return
	    }

	    if (this.opts.origin) {
	      this.history.push(new URL(this.opts.path, this.opts.origin));
	    }

	    if (!this.location) {
	      return this.handler.onHeaders(statusCode, headers, resume, statusText)
	    }

	    const { origin, pathname, search } = util.parseURL(new URL(this.location, this.opts.origin && new URL(this.opts.path, this.opts.origin)));
	    const path = search ? `${pathname}${search}` : pathname;

	    // Remove headers referring to the original URL.
	    // By default it is Host only, unless it's a 303 (see below), which removes also all Content-* headers.
	    // https://tools.ietf.org/html/rfc7231#section-6.4
	    this.opts.headers = cleanRequestHeaders(this.opts.headers, statusCode === 303, this.opts.origin !== origin);
	    this.opts.path = path;
	    this.opts.origin = origin;
	    this.opts.maxRedirections = 0;
	    this.opts.query = null;

	    // https://tools.ietf.org/html/rfc7231#section-6.4.4
	    // In case of HTTP 303, always replace method to be either HEAD or GET
	    if (statusCode === 303 && this.opts.method !== 'HEAD') {
	      this.opts.method = 'GET';
	      this.opts.body = null;
	    }
	  }

	  onData (chunk) {
	    if (this.location) ; else {
	      return this.handler.onData(chunk)
	    }
	  }

	  onComplete (trailers) {
	    if (this.location) {
	      /*
	        https://tools.ietf.org/html/rfc7231#section-6.4

	        TLDR: undici always ignores 3xx response trailers as they are not expected in case of redirections
	        and neither are useful if present.

	        See comment on onData method above for more detailed information.
	      */

	      this.location = null;
	      this.abort = null;

	      this.dispatch(this.opts, this);
	    } else {
	      this.handler.onComplete(trailers);
	    }
	  }

	  onBodySent (chunk) {
	    if (this.handler.onBodySent) {
	      this.handler.onBodySent(chunk);
	    }
	  }
	}

	function parseLocation (statusCode, headers) {
	  if (redirectableStatusCodes.indexOf(statusCode) === -1) {
	    return null
	  }

	  for (let i = 0; i < headers.length; i += 2) {
	    if (headers[i].length === 8 && util.headerNameToString(headers[i]) === 'location') {
	      return headers[i + 1]
	    }
	  }
	}

	// https://tools.ietf.org/html/rfc7231#section-6.4.4
	function shouldRemoveHeader (header, removeContent, unknownOrigin) {
	  if (header.length === 4) {
	    return util.headerNameToString(header) === 'host'
	  }
	  if (removeContent && util.headerNameToString(header).startsWith('content-')) {
	    return true
	  }
	  if (unknownOrigin && (header.length === 13 || header.length === 6 || header.length === 19)) {
	    const name = util.headerNameToString(header);
	    return name === 'authorization' || name === 'cookie' || name === 'proxy-authorization'
	  }
	  return false
	}

	// https://tools.ietf.org/html/rfc7231#section-6.4
	function cleanRequestHeaders (headers, removeContent, unknownOrigin) {
	  const ret = [];
	  if (Array.isArray(headers)) {
	    for (let i = 0; i < headers.length; i += 2) {
	      if (!shouldRemoveHeader(headers[i], removeContent, unknownOrigin)) {
	        ret.push(headers[i], headers[i + 1]);
	      }
	    }
	  } else if (headers && typeof headers === 'object') {
	    for (const key of Object.keys(headers)) {
	      if (!shouldRemoveHeader(key, removeContent, unknownOrigin)) {
	        ret.push(key, headers[key]);
	      }
	    }
	  } else {
	    assert(headers == null, 'headers must be an object or an array');
	  }
	  return ret
	}

	redirectHandler = RedirectHandler;
	return redirectHandler;
}

var redirectInterceptor;
var hasRequiredRedirectInterceptor;

function requireRedirectInterceptor () {
	if (hasRequiredRedirectInterceptor) return redirectInterceptor;
	hasRequiredRedirectInterceptor = 1;

	const RedirectHandler = requireRedirectHandler();

	function createRedirectInterceptor ({ maxRedirections: defaultMaxRedirections }) {
	  return (dispatch) => {
	    return function Intercept (opts, handler) {
	      const { maxRedirections = defaultMaxRedirections } = opts;

	      if (!maxRedirections) {
	        return dispatch(opts, handler)
	      }

	      const redirectHandler = new RedirectHandler(dispatch, maxRedirections, opts, handler);
	      opts = { ...opts, maxRedirections: 0 }; // Stop sub dispatcher from also redirecting.
	      return dispatch(opts, redirectHandler)
	    }
	  }
	}

	redirectInterceptor = createRedirectInterceptor;
	return redirectInterceptor;
}

var client;
var hasRequiredClient;

function requireClient () {
	if (hasRequiredClient) return client;
	hasRequiredClient = 1;

	const assert = require$$0$4;
	const net = require$$4;
	const http = require$$2;
	const util = requireUtil$7();
	const { channels } = requireDiagnostics();
	const Request = requireRequest$1();
	const DispatcherBase = requireDispatcherBase();
	const {
	  InvalidArgumentError,
	  InformationalError,
	  ClientDestroyedError
	} = requireErrors();
	const buildConnector = requireConnect();
	const {
	  kUrl,
	  kServerName,
	  kClient,
	  kBusy,
	  kConnect,
	  kResuming,
	  kRunning,
	  kPending,
	  kSize,
	  kQueue,
	  kConnected,
	  kConnecting,
	  kNeedDrain,
	  kKeepAliveDefaultTimeout,
	  kHostHeader,
	  kPendingIdx,
	  kRunningIdx,
	  kError,
	  kPipelining,
	  kKeepAliveTimeoutValue,
	  kMaxHeadersSize,
	  kKeepAliveMaxTimeout,
	  kKeepAliveTimeoutThreshold,
	  kHeadersTimeout,
	  kBodyTimeout,
	  kStrictContentLength,
	  kConnector,
	  kMaxRedirections,
	  kMaxRequests,
	  kCounter,
	  kClose,
	  kDestroy,
	  kDispatch,
	  kInterceptors,
	  kLocalAddress,
	  kMaxResponseSize,
	  kOnError,
	  kHTTPContext,
	  kMaxConcurrentStreams,
	  kResume
	} = requireSymbols$4();
	const connectH1 = requireClientH1();
	const connectH2 = requireClientH2();
	let deprecatedInterceptorWarned = false;

	const kClosedResolve = Symbol('kClosedResolve');

	function getPipelining (client) {
	  return client[kPipelining] ?? client[kHTTPContext]?.defaultPipelining ?? 1
	}

	/**
	 * @type {import('../../types/client.js').default}
	 */
	class Client extends DispatcherBase {
	  /**
	   *
	   * @param {string|URL} url
	   * @param {import('../../types/client.js').Client.Options} options
	   */
	  constructor (url, {
	    interceptors,
	    maxHeaderSize,
	    headersTimeout,
	    socketTimeout,
	    requestTimeout,
	    connectTimeout,
	    bodyTimeout,
	    idleTimeout,
	    keepAlive,
	    keepAliveTimeout,
	    maxKeepAliveTimeout,
	    keepAliveMaxTimeout,
	    keepAliveTimeoutThreshold,
	    socketPath,
	    pipelining,
	    tls,
	    strictContentLength,
	    maxCachedSessions,
	    maxRedirections,
	    connect,
	    maxRequestsPerClient,
	    localAddress,
	    maxResponseSize,
	    autoSelectFamily,
	    autoSelectFamilyAttemptTimeout,
	    // h2
	    maxConcurrentStreams,
	    allowH2
	  } = {}) {
	    super();

	    if (keepAlive !== undefined) {
	      throw new InvalidArgumentError('unsupported keepAlive, use pipelining=0 instead')
	    }

	    if (socketTimeout !== undefined) {
	      throw new InvalidArgumentError('unsupported socketTimeout, use headersTimeout & bodyTimeout instead')
	    }

	    if (requestTimeout !== undefined) {
	      throw new InvalidArgumentError('unsupported requestTimeout, use headersTimeout & bodyTimeout instead')
	    }

	    if (idleTimeout !== undefined) {
	      throw new InvalidArgumentError('unsupported idleTimeout, use keepAliveTimeout instead')
	    }

	    if (maxKeepAliveTimeout !== undefined) {
	      throw new InvalidArgumentError('unsupported maxKeepAliveTimeout, use keepAliveMaxTimeout instead')
	    }

	    if (maxHeaderSize != null && !Number.isFinite(maxHeaderSize)) {
	      throw new InvalidArgumentError('invalid maxHeaderSize')
	    }

	    if (socketPath != null && typeof socketPath !== 'string') {
	      throw new InvalidArgumentError('invalid socketPath')
	    }

	    if (connectTimeout != null && (!Number.isFinite(connectTimeout) || connectTimeout < 0)) {
	      throw new InvalidArgumentError('invalid connectTimeout')
	    }

	    if (keepAliveTimeout != null && (!Number.isFinite(keepAliveTimeout) || keepAliveTimeout <= 0)) {
	      throw new InvalidArgumentError('invalid keepAliveTimeout')
	    }

	    if (keepAliveMaxTimeout != null && (!Number.isFinite(keepAliveMaxTimeout) || keepAliveMaxTimeout <= 0)) {
	      throw new InvalidArgumentError('invalid keepAliveMaxTimeout')
	    }

	    if (keepAliveTimeoutThreshold != null && !Number.isFinite(keepAliveTimeoutThreshold)) {
	      throw new InvalidArgumentError('invalid keepAliveTimeoutThreshold')
	    }

	    if (headersTimeout != null && (!Number.isInteger(headersTimeout) || headersTimeout < 0)) {
	      throw new InvalidArgumentError('headersTimeout must be a positive integer or zero')
	    }

	    if (bodyTimeout != null && (!Number.isInteger(bodyTimeout) || bodyTimeout < 0)) {
	      throw new InvalidArgumentError('bodyTimeout must be a positive integer or zero')
	    }

	    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {
	      throw new InvalidArgumentError('connect must be a function or an object')
	    }

	    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {
	      throw new InvalidArgumentError('maxRedirections must be a positive number')
	    }

	    if (maxRequestsPerClient != null && (!Number.isInteger(maxRequestsPerClient) || maxRequestsPerClient < 0)) {
	      throw new InvalidArgumentError('maxRequestsPerClient must be a positive number')
	    }

	    if (localAddress != null && (typeof localAddress !== 'string' || net.isIP(localAddress) === 0)) {
	      throw new InvalidArgumentError('localAddress must be valid string IP address')
	    }

	    if (maxResponseSize != null && (!Number.isInteger(maxResponseSize) || maxResponseSize < -1)) {
	      throw new InvalidArgumentError('maxResponseSize must be a positive number')
	    }

	    if (
	      autoSelectFamilyAttemptTimeout != null &&
	      (!Number.isInteger(autoSelectFamilyAttemptTimeout) || autoSelectFamilyAttemptTimeout < -1)
	    ) {
	      throw new InvalidArgumentError('autoSelectFamilyAttemptTimeout must be a positive number')
	    }

	    // h2
	    if (allowH2 != null && typeof allowH2 !== 'boolean') {
	      throw new InvalidArgumentError('allowH2 must be a valid boolean value')
	    }

	    if (maxConcurrentStreams != null && (typeof maxConcurrentStreams !== 'number' || maxConcurrentStreams < 1)) {
	      throw new InvalidArgumentError('maxConcurrentStreams must be a positive integer, greater than 0')
	    }

	    if (typeof connect !== 'function') {
	      connect = buildConnector({
	        ...tls,
	        maxCachedSessions,
	        allowH2,
	        socketPath,
	        timeout: connectTimeout,
	        ...(autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),
	        ...connect
	      });
	    }

	    if (interceptors?.Client && Array.isArray(interceptors.Client)) {
	      this[kInterceptors] = interceptors.Client;
	      if (!deprecatedInterceptorWarned) {
	        deprecatedInterceptorWarned = true;
	        process.emitWarning('Client.Options#interceptor is deprecated. Use Dispatcher#compose instead.', {
	          code: 'UNDICI-CLIENT-INTERCEPTOR-DEPRECATED'
	        });
	      }
	    } else {
	      this[kInterceptors] = [createRedirectInterceptor({ maxRedirections })];
	    }

	    this[kUrl] = util.parseOrigin(url);
	    this[kConnector] = connect;
	    this[kPipelining] = pipelining != null ? pipelining : 1;
	    this[kMaxHeadersSize] = maxHeaderSize || http.maxHeaderSize;
	    this[kKeepAliveDefaultTimeout] = keepAliveTimeout == null ? 4e3 : keepAliveTimeout;
	    this[kKeepAliveMaxTimeout] = keepAliveMaxTimeout == null ? 600e3 : keepAliveMaxTimeout;
	    this[kKeepAliveTimeoutThreshold] = keepAliveTimeoutThreshold == null ? 2e3 : keepAliveTimeoutThreshold;
	    this[kKeepAliveTimeoutValue] = this[kKeepAliveDefaultTimeout];
	    this[kServerName] = null;
	    this[kLocalAddress] = localAddress != null ? localAddress : null;
	    this[kResuming] = 0; // 0, idle, 1, scheduled, 2 resuming
	    this[kNeedDrain] = 0; // 0, idle, 1, scheduled, 2 resuming
	    this[kHostHeader] = `host: ${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}\r\n`;
	    this[kBodyTimeout] = bodyTimeout != null ? bodyTimeout : 300e3;
	    this[kHeadersTimeout] = headersTimeout != null ? headersTimeout : 300e3;
	    this[kStrictContentLength] = strictContentLength == null ? true : strictContentLength;
	    this[kMaxRedirections] = maxRedirections;
	    this[kMaxRequests] = maxRequestsPerClient;
	    this[kClosedResolve] = null;
	    this[kMaxResponseSize] = maxResponseSize > -1 ? maxResponseSize : -1;
	    this[kMaxConcurrentStreams] = maxConcurrentStreams != null ? maxConcurrentStreams : 100; // Max peerConcurrentStreams for a Node h2 server
	    this[kHTTPContext] = null;

	    // kQueue is built up of 3 sections separated by
	    // the kRunningIdx and kPendingIdx indices.
	    // |   complete   |   running   |   pending   |
	    //                ^ kRunningIdx ^ kPendingIdx ^ kQueue.length
	    // kRunningIdx points to the first running element.
	    // kPendingIdx points to the first pending element.
	    // This implements a fast queue with an amortized
	    // time of O(1).

	    this[kQueue] = [];
	    this[kRunningIdx] = 0;
	    this[kPendingIdx] = 0;

	    this[kResume] = (sync) => resume(this, sync);
	    this[kOnError] = (err) => onError(this, err);
	  }

	  get pipelining () {
	    return this[kPipelining]
	  }

	  set pipelining (value) {
	    this[kPipelining] = value;
	    this[kResume](true);
	  }

	  get [kPending] () {
	    return this[kQueue].length - this[kPendingIdx]
	  }

	  get [kRunning] () {
	    return this[kPendingIdx] - this[kRunningIdx]
	  }

	  get [kSize] () {
	    return this[kQueue].length - this[kRunningIdx]
	  }

	  get [kConnected] () {
	    return !!this[kHTTPContext] && !this[kConnecting] && !this[kHTTPContext].destroyed
	  }

	  get [kBusy] () {
	    return Boolean(
	      this[kHTTPContext]?.busy(null) ||
	      (this[kSize] >= (getPipelining(this) || 1)) ||
	      this[kPending] > 0
	    )
	  }

	  /* istanbul ignore: only used for test */
	  [kConnect] (cb) {
	    connect(this);
	    this.once('connect', cb);
	  }

	  [kDispatch] (opts, handler) {
	    const origin = opts.origin || this[kUrl].origin;
	    const request = new Request(origin, opts, handler);

	    this[kQueue].push(request);
	    if (this[kResuming]) ; else if (util.bodyLength(request.body) == null && util.isIterable(request.body)) {
	      // Wait a tick in case stream/iterator is ended in the same tick.
	      this[kResuming] = 1;
	      queueMicrotask(() => resume(this));
	    } else {
	      this[kResume](true);
	    }

	    if (this[kResuming] && this[kNeedDrain] !== 2 && this[kBusy]) {
	      this[kNeedDrain] = 2;
	    }

	    return this[kNeedDrain] < 2
	  }

	  async [kClose] () {
	    // TODO: for H2 we need to gracefully flush the remaining enqueued
	    // request and close each stream.
	    return new Promise((resolve) => {
	      if (this[kSize]) {
	        this[kClosedResolve] = resolve;
	      } else {
	        resolve(null);
	      }
	    })
	  }

	  async [kDestroy] (err) {
	    return new Promise((resolve) => {
	      const requests = this[kQueue].splice(this[kPendingIdx]);
	      for (let i = 0; i < requests.length; i++) {
	        const request = requests[i];
	        util.errorRequest(this, request, err);
	      }

	      const callback = () => {
	        if (this[kClosedResolve]) {
	          // TODO (fix): Should we error here with ClientDestroyedError?
	          this[kClosedResolve]();
	          this[kClosedResolve] = null;
	        }
	        resolve(null);
	      };

	      if (this[kHTTPContext]) {
	        this[kHTTPContext].destroy(err, callback);
	        this[kHTTPContext] = null;
	      } else {
	        queueMicrotask(callback);
	      }

	      this[kResume]();
	    })
	  }
	}

	const createRedirectInterceptor = requireRedirectInterceptor();

	function onError (client, err) {
	  if (
	    client[kRunning] === 0 &&
	    err.code !== 'UND_ERR_INFO' &&
	    err.code !== 'UND_ERR_SOCKET'
	  ) {
	    // Error is not caused by running request and not a recoverable
	    // socket error.

	    assert(client[kPendingIdx] === client[kRunningIdx]);

	    const requests = client[kQueue].splice(client[kRunningIdx]);

	    for (let i = 0; i < requests.length; i++) {
	      const request = requests[i];
	      util.errorRequest(client, request, err);
	    }
	    assert(client[kSize] === 0);
	  }
	}

	async function connect (client) {
	  assert(!client[kConnecting]);
	  assert(!client[kHTTPContext]);

	  let { host, hostname, protocol, port } = client[kUrl];

	  // Resolve ipv6
	  if (hostname[0] === '[') {
	    const idx = hostname.indexOf(']');

	    assert(idx !== -1);
	    const ip = hostname.substring(1, idx);

	    assert(net.isIP(ip));
	    hostname = ip;
	  }

	  client[kConnecting] = true;

	  if (channels.beforeConnect.hasSubscribers) {
	    channels.beforeConnect.publish({
	      connectParams: {
	        host,
	        hostname,
	        protocol,
	        port,
	        version: client[kHTTPContext]?.version,
	        servername: client[kServerName],
	        localAddress: client[kLocalAddress]
	      },
	      connector: client[kConnector]
	    });
	  }

	  try {
	    const socket = await new Promise((resolve, reject) => {
	      client[kConnector]({
	        host,
	        hostname,
	        protocol,
	        port,
	        servername: client[kServerName],
	        localAddress: client[kLocalAddress]
	      }, (err, socket) => {
	        if (err) {
	          reject(err);
	        } else {
	          resolve(socket);
	        }
	      });
	    });

	    if (client.destroyed) {
	      util.destroy(socket.on('error', () => {}), new ClientDestroyedError());
	      return
	    }

	    assert(socket);

	    try {
	      client[kHTTPContext] = socket.alpnProtocol === 'h2'
	        ? await connectH2(client, socket)
	        : await connectH1(client, socket);
	    } catch (err) {
	      socket.destroy().on('error', () => {});
	      throw err
	    }

	    client[kConnecting] = false;

	    socket[kCounter] = 0;
	    socket[kMaxRequests] = client[kMaxRequests];
	    socket[kClient] = client;
	    socket[kError] = null;

	    if (channels.connected.hasSubscribers) {
	      channels.connected.publish({
	        connectParams: {
	          host,
	          hostname,
	          protocol,
	          port,
	          version: client[kHTTPContext]?.version,
	          servername: client[kServerName],
	          localAddress: client[kLocalAddress]
	        },
	        connector: client[kConnector],
	        socket
	      });
	    }
	    client.emit('connect', client[kUrl], [client]);
	  } catch (err) {
	    if (client.destroyed) {
	      return
	    }

	    client[kConnecting] = false;

	    if (channels.connectError.hasSubscribers) {
	      channels.connectError.publish({
	        connectParams: {
	          host,
	          hostname,
	          protocol,
	          port,
	          version: client[kHTTPContext]?.version,
	          servername: client[kServerName],
	          localAddress: client[kLocalAddress]
	        },
	        connector: client[kConnector],
	        error: err
	      });
	    }

	    if (err.code === 'ERR_TLS_CERT_ALTNAME_INVALID') {
	      assert(client[kRunning] === 0);
	      while (client[kPending] > 0 && client[kQueue][client[kPendingIdx]].servername === client[kServerName]) {
	        const request = client[kQueue][client[kPendingIdx]++];
	        util.errorRequest(client, request, err);
	      }
	    } else {
	      onError(client, err);
	    }

	    client.emit('connectionError', client[kUrl], [client], err);
	  }

	  client[kResume]();
	}

	function emitDrain (client) {
	  client[kNeedDrain] = 0;
	  client.emit('drain', client[kUrl], [client]);
	}

	function resume (client, sync) {
	  if (client[kResuming] === 2) {
	    return
	  }

	  client[kResuming] = 2;

	  _resume(client, sync);
	  client[kResuming] = 0;

	  if (client[kRunningIdx] > 256) {
	    client[kQueue].splice(0, client[kRunningIdx]);
	    client[kPendingIdx] -= client[kRunningIdx];
	    client[kRunningIdx] = 0;
	  }
	}

	function _resume (client, sync) {
	  while (true) {
	    if (client.destroyed) {
	      assert(client[kPending] === 0);
	      return
	    }

	    if (client[kClosedResolve] && !client[kSize]) {
	      client[kClosedResolve]();
	      client[kClosedResolve] = null;
	      return
	    }

	    if (client[kHTTPContext]) {
	      client[kHTTPContext].resume();
	    }

	    if (client[kBusy]) {
	      client[kNeedDrain] = 2;
	    } else if (client[kNeedDrain] === 2) {
	      if (sync) {
	        client[kNeedDrain] = 1;
	        queueMicrotask(() => emitDrain(client));
	      } else {
	        emitDrain(client);
	      }
	      continue
	    }

	    if (client[kPending] === 0) {
	      return
	    }

	    if (client[kRunning] >= (getPipelining(client) || 1)) {
	      return
	    }

	    const request = client[kQueue][client[kPendingIdx]];

	    if (client[kUrl].protocol === 'https:' && client[kServerName] !== request.servername) {
	      if (client[kRunning] > 0) {
	        return
	      }

	      client[kServerName] = request.servername;
	      client[kHTTPContext]?.destroy(new InformationalError('servername changed'), () => {
	        client[kHTTPContext] = null;
	        resume(client);
	      });
	    }

	    if (client[kConnecting]) {
	      return
	    }

	    if (!client[kHTTPContext]) {
	      connect(client);
	      return
	    }

	    if (client[kHTTPContext].destroyed) {
	      return
	    }

	    if (client[kHTTPContext].busy(request)) {
	      return
	    }

	    if (!request.aborted && client[kHTTPContext].write(request)) {
	      client[kPendingIdx]++;
	    } else {
	      client[kQueue].splice(client[kPendingIdx], 1);
	    }
	  }
	}

	client = Client;
	return client;
}

/* eslint-disable */

var fixedQueue;
var hasRequiredFixedQueue;

function requireFixedQueue () {
	if (hasRequiredFixedQueue) return fixedQueue;
	hasRequiredFixedQueue = 1;

	// Extracted from node/lib/internal/fixed_queue.js

	// Currently optimal queue size, tested on V8 6.0 - 6.6. Must be power of two.
	const kSize = 2048;
	const kMask = kSize - 1;

	// The FixedQueue is implemented as a singly-linked list of fixed-size
	// circular buffers. It looks something like this:
	//
	//  head                                                       tail
	//    |                                                          |
	//    v                                                          v
	// +-----------+ <-----\       +-----------+ <------\         +-----------+
	// |  [null]   |        \----- |   next    |         \------- |   next    |
	// +-----------+               +-----------+                  +-----------+
	// |   item    | <-- bottom    |   item    | <-- bottom       |  [empty]  |
	// |   item    |               |   item    |                  |  [empty]  |
	// |   item    |               |   item    |                  |  [empty]  |
	// |   item    |               |   item    |                  |  [empty]  |
	// |   item    |               |   item    |       bottom --> |   item    |
	// |   item    |               |   item    |                  |   item    |
	// |    ...    |               |    ...    |                  |    ...    |
	// |   item    |               |   item    |                  |   item    |
	// |   item    |               |   item    |                  |   item    |
	// |  [empty]  | <-- top       |   item    |                  |   item    |
	// |  [empty]  |               |   item    |                  |   item    |
	// |  [empty]  |               |  [empty]  | <-- top  top --> |  [empty]  |
	// +-----------+               +-----------+                  +-----------+
	//
	// Or, if there is only one circular buffer, it looks something
	// like either of these:
	//
	//  head   tail                                 head   tail
	//    |     |                                     |     |
	//    v     v                                     v     v
	// +-----------+                               +-----------+
	// |  [null]   |                               |  [null]   |
	// +-----------+                               +-----------+
	// |  [empty]  |                               |   item    |
	// |  [empty]  |                               |   item    |
	// |   item    | <-- bottom            top --> |  [empty]  |
	// |   item    |                               |  [empty]  |
	// |  [empty]  | <-- top            bottom --> |   item    |
	// |  [empty]  |                               |   item    |
	// +-----------+                               +-----------+
	//
	// Adding a value means moving `top` forward by one, removing means
	// moving `bottom` forward by one. After reaching the end, the queue
	// wraps around.
	//
	// When `top === bottom` the current queue is empty and when
	// `top + 1 === bottom` it's full. This wastes a single space of storage
	// but allows much quicker checks.

	class FixedCircularBuffer {
	  constructor() {
	    this.bottom = 0;
	    this.top = 0;
	    this.list = new Array(kSize);
	    this.next = null;
	  }

	  isEmpty() {
	    return this.top === this.bottom;
	  }

	  isFull() {
	    return ((this.top + 1) & kMask) === this.bottom;
	  }

	  push(data) {
	    this.list[this.top] = data;
	    this.top = (this.top + 1) & kMask;
	  }

	  shift() {
	    const nextItem = this.list[this.bottom];
	    if (nextItem === undefined)
	      return null;
	    this.list[this.bottom] = undefined;
	    this.bottom = (this.bottom + 1) & kMask;
	    return nextItem;
	  }
	}

	fixedQueue = class FixedQueue {
	  constructor() {
	    this.head = this.tail = new FixedCircularBuffer();
	  }

	  isEmpty() {
	    return this.head.isEmpty();
	  }

	  push(data) {
	    if (this.head.isFull()) {
	      // Head is full: Creates a new queue, sets the old queue's `.next` to it,
	      // and sets it as the new main queue.
	      this.head = this.head.next = new FixedCircularBuffer();
	    }
	    this.head.push(data);
	  }

	  shift() {
	    const tail = this.tail;
	    const next = tail.shift();
	    if (tail.isEmpty() && tail.next !== null) {
	      // If there is another queue, it forms the new tail.
	      this.tail = tail.next;
	    }
	    return next;
	  }
	};
	return fixedQueue;
}

var poolStats;
var hasRequiredPoolStats;

function requirePoolStats () {
	if (hasRequiredPoolStats) return poolStats;
	hasRequiredPoolStats = 1;
	const { kFree, kConnected, kPending, kQueued, kRunning, kSize } = requireSymbols$4();
	const kPool = Symbol('pool');

	class PoolStats {
	  constructor (pool) {
	    this[kPool] = pool;
	  }

	  get connected () {
	    return this[kPool][kConnected]
	  }

	  get free () {
	    return this[kPool][kFree]
	  }

	  get pending () {
	    return this[kPool][kPending]
	  }

	  get queued () {
	    return this[kPool][kQueued]
	  }

	  get running () {
	    return this[kPool][kRunning]
	  }

	  get size () {
	    return this[kPool][kSize]
	  }
	}

	poolStats = PoolStats;
	return poolStats;
}

var poolBase;
var hasRequiredPoolBase;

function requirePoolBase () {
	if (hasRequiredPoolBase) return poolBase;
	hasRequiredPoolBase = 1;

	const DispatcherBase = requireDispatcherBase();
	const FixedQueue = requireFixedQueue();
	const { kConnected, kSize, kRunning, kPending, kQueued, kBusy, kFree, kUrl, kClose, kDestroy, kDispatch } = requireSymbols$4();
	const PoolStats = requirePoolStats();

	const kClients = Symbol('clients');
	const kNeedDrain = Symbol('needDrain');
	const kQueue = Symbol('queue');
	const kClosedResolve = Symbol('closed resolve');
	const kOnDrain = Symbol('onDrain');
	const kOnConnect = Symbol('onConnect');
	const kOnDisconnect = Symbol('onDisconnect');
	const kOnConnectionError = Symbol('onConnectionError');
	const kGetDispatcher = Symbol('get dispatcher');
	const kAddClient = Symbol('add client');
	const kRemoveClient = Symbol('remove client');
	const kStats = Symbol('stats');

	class PoolBase extends DispatcherBase {
	  constructor () {
	    super();

	    this[kQueue] = new FixedQueue();
	    this[kClients] = [];
	    this[kQueued] = 0;

	    const pool = this;

	    this[kOnDrain] = function onDrain (origin, targets) {
	      const queue = pool[kQueue];

	      let needDrain = false;

	      while (!needDrain) {
	        const item = queue.shift();
	        if (!item) {
	          break
	        }
	        pool[kQueued]--;
	        needDrain = !this.dispatch(item.opts, item.handler);
	      }

	      this[kNeedDrain] = needDrain;

	      if (!this[kNeedDrain] && pool[kNeedDrain]) {
	        pool[kNeedDrain] = false;
	        pool.emit('drain', origin, [pool, ...targets]);
	      }

	      if (pool[kClosedResolve] && queue.isEmpty()) {
	        Promise
	          .all(pool[kClients].map(c => c.close()))
	          .then(pool[kClosedResolve]);
	      }
	    };

	    this[kOnConnect] = (origin, targets) => {
	      pool.emit('connect', origin, [pool, ...targets]);
	    };

	    this[kOnDisconnect] = (origin, targets, err) => {
	      pool.emit('disconnect', origin, [pool, ...targets], err);
	    };

	    this[kOnConnectionError] = (origin, targets, err) => {
	      pool.emit('connectionError', origin, [pool, ...targets], err);
	    };

	    this[kStats] = new PoolStats(this);
	  }

	  get [kBusy] () {
	    return this[kNeedDrain]
	  }

	  get [kConnected] () {
	    return this[kClients].filter(client => client[kConnected]).length
	  }

	  get [kFree] () {
	    return this[kClients].filter(client => client[kConnected] && !client[kNeedDrain]).length
	  }

	  get [kPending] () {
	    let ret = this[kQueued];
	    for (const { [kPending]: pending } of this[kClients]) {
	      ret += pending;
	    }
	    return ret
	  }

	  get [kRunning] () {
	    let ret = 0;
	    for (const { [kRunning]: running } of this[kClients]) {
	      ret += running;
	    }
	    return ret
	  }

	  get [kSize] () {
	    let ret = this[kQueued];
	    for (const { [kSize]: size } of this[kClients]) {
	      ret += size;
	    }
	    return ret
	  }

	  get stats () {
	    return this[kStats]
	  }

	  async [kClose] () {
	    if (this[kQueue].isEmpty()) {
	      return Promise.all(this[kClients].map(c => c.close()))
	    } else {
	      return new Promise((resolve) => {
	        this[kClosedResolve] = resolve;
	      })
	    }
	  }

	  async [kDestroy] (err) {
	    while (true) {
	      const item = this[kQueue].shift();
	      if (!item) {
	        break
	      }
	      item.handler.onError(err);
	    }

	    return Promise.all(this[kClients].map(c => c.destroy(err)))
	  }

	  [kDispatch] (opts, handler) {
	    const dispatcher = this[kGetDispatcher]();

	    if (!dispatcher) {
	      this[kNeedDrain] = true;
	      this[kQueue].push({ opts, handler });
	      this[kQueued]++;
	    } else if (!dispatcher.dispatch(opts, handler)) {
	      dispatcher[kNeedDrain] = true;
	      this[kNeedDrain] = !this[kGetDispatcher]();
	    }

	    return !this[kNeedDrain]
	  }

	  [kAddClient] (client) {
	    client
	      .on('drain', this[kOnDrain])
	      .on('connect', this[kOnConnect])
	      .on('disconnect', this[kOnDisconnect])
	      .on('connectionError', this[kOnConnectionError]);

	    this[kClients].push(client);

	    if (this[kNeedDrain]) {
	      queueMicrotask(() => {
	        if (this[kNeedDrain]) {
	          this[kOnDrain](client[kUrl], [this, client]);
	        }
	      });
	    }

	    return this
	  }

	  [kRemoveClient] (client) {
	    client.close(() => {
	      const idx = this[kClients].indexOf(client);
	      if (idx !== -1) {
	        this[kClients].splice(idx, 1);
	      }
	    });

	    this[kNeedDrain] = this[kClients].some(dispatcher => (
	      !dispatcher[kNeedDrain] &&
	      dispatcher.closed !== true &&
	      dispatcher.destroyed !== true
	    ));
	  }
	}

	poolBase = {
	  PoolBase,
	  kClients,
	  kNeedDrain,
	  kAddClient,
	  kRemoveClient,
	  kGetDispatcher
	};
	return poolBase;
}

var pool;
var hasRequiredPool;

function requirePool () {
	if (hasRequiredPool) return pool;
	hasRequiredPool = 1;

	const {
	  PoolBase,
	  kClients,
	  kNeedDrain,
	  kAddClient,
	  kGetDispatcher
	} = requirePoolBase();
	const Client = requireClient();
	const {
	  InvalidArgumentError
	} = requireErrors();
	const util = requireUtil$7();
	const { kUrl, kInterceptors } = requireSymbols$4();
	const buildConnector = requireConnect();

	const kOptions = Symbol('options');
	const kConnections = Symbol('connections');
	const kFactory = Symbol('factory');

	function defaultFactory (origin, opts) {
	  return new Client(origin, opts)
	}

	class Pool extends PoolBase {
	  constructor (origin, {
	    connections,
	    factory = defaultFactory,
	    connect,
	    connectTimeout,
	    tls,
	    maxCachedSessions,
	    socketPath,
	    autoSelectFamily,
	    autoSelectFamilyAttemptTimeout,
	    allowH2,
	    ...options
	  } = {}) {
	    super();

	    if (connections != null && (!Number.isFinite(connections) || connections < 0)) {
	      throw new InvalidArgumentError('invalid connections')
	    }

	    if (typeof factory !== 'function') {
	      throw new InvalidArgumentError('factory must be a function.')
	    }

	    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {
	      throw new InvalidArgumentError('connect must be a function or an object')
	    }

	    if (typeof connect !== 'function') {
	      connect = buildConnector({
	        ...tls,
	        maxCachedSessions,
	        allowH2,
	        socketPath,
	        timeout: connectTimeout,
	        ...(autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),
	        ...connect
	      });
	    }

	    this[kInterceptors] = options.interceptors?.Pool && Array.isArray(options.interceptors.Pool)
	      ? options.interceptors.Pool
	      : [];
	    this[kConnections] = connections || null;
	    this[kUrl] = util.parseOrigin(origin);
	    this[kOptions] = { ...util.deepClone(options), connect, allowH2 };
	    this[kOptions].interceptors = options.interceptors
	      ? { ...options.interceptors }
	      : undefined;
	    this[kFactory] = factory;
	  }

	  [kGetDispatcher] () {
	    for (const client of this[kClients]) {
	      if (!client[kNeedDrain]) {
	        return client
	      }
	    }

	    if (!this[kConnections] || this[kClients].length < this[kConnections]) {
	      const dispatcher = this[kFactory](this[kUrl], this[kOptions]);
	      this[kAddClient](dispatcher);
	      return dispatcher
	    }
	  }
	}

	pool = Pool;
	return pool;
}

var balancedPool;
var hasRequiredBalancedPool;

function requireBalancedPool () {
	if (hasRequiredBalancedPool) return balancedPool;
	hasRequiredBalancedPool = 1;

	const {
	  BalancedPoolMissingUpstreamError,
	  InvalidArgumentError
	} = requireErrors();
	const {
	  PoolBase,
	  kClients,
	  kNeedDrain,
	  kAddClient,
	  kRemoveClient,
	  kGetDispatcher
	} = requirePoolBase();
	const Pool = requirePool();
	const { kUrl, kInterceptors } = requireSymbols$4();
	const { parseOrigin } = requireUtil$7();
	const kFactory = Symbol('factory');

	const kOptions = Symbol('options');
	const kGreatestCommonDivisor = Symbol('kGreatestCommonDivisor');
	const kCurrentWeight = Symbol('kCurrentWeight');
	const kIndex = Symbol('kIndex');
	const kWeight = Symbol('kWeight');
	const kMaxWeightPerServer = Symbol('kMaxWeightPerServer');
	const kErrorPenalty = Symbol('kErrorPenalty');

	function getGreatestCommonDivisor (a, b) {
	  if (b === 0) return a
	  return getGreatestCommonDivisor(b, a % b)
	}

	function defaultFactory (origin, opts) {
	  return new Pool(origin, opts)
	}

	class BalancedPool extends PoolBase {
	  constructor (upstreams = [], { factory = defaultFactory, ...opts } = {}) {
	    super();

	    this[kOptions] = opts;
	    this[kIndex] = -1;
	    this[kCurrentWeight] = 0;

	    this[kMaxWeightPerServer] = this[kOptions].maxWeightPerServer || 100;
	    this[kErrorPenalty] = this[kOptions].errorPenalty || 15;

	    if (!Array.isArray(upstreams)) {
	      upstreams = [upstreams];
	    }

	    if (typeof factory !== 'function') {
	      throw new InvalidArgumentError('factory must be a function.')
	    }

	    this[kInterceptors] = opts.interceptors?.BalancedPool && Array.isArray(opts.interceptors.BalancedPool)
	      ? opts.interceptors.BalancedPool
	      : [];
	    this[kFactory] = factory;

	    for (const upstream of upstreams) {
	      this.addUpstream(upstream);
	    }
	    this._updateBalancedPoolStats();
	  }

	  addUpstream (upstream) {
	    const upstreamOrigin = parseOrigin(upstream).origin;

	    if (this[kClients].find((pool) => (
	      pool[kUrl].origin === upstreamOrigin &&
	      pool.closed !== true &&
	      pool.destroyed !== true
	    ))) {
	      return this
	    }
	    const pool = this[kFactory](upstreamOrigin, Object.assign({}, this[kOptions]));

	    this[kAddClient](pool);
	    pool.on('connect', () => {
	      pool[kWeight] = Math.min(this[kMaxWeightPerServer], pool[kWeight] + this[kErrorPenalty]);
	    });

	    pool.on('connectionError', () => {
	      pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty]);
	      this._updateBalancedPoolStats();
	    });

	    pool.on('disconnect', (...args) => {
	      const err = args[2];
	      if (err && err.code === 'UND_ERR_SOCKET') {
	        // decrease the weight of the pool.
	        pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty]);
	        this._updateBalancedPoolStats();
	      }
	    });

	    for (const client of this[kClients]) {
	      client[kWeight] = this[kMaxWeightPerServer];
	    }

	    this._updateBalancedPoolStats();

	    return this
	  }

	  _updateBalancedPoolStats () {
	    this[kGreatestCommonDivisor] = this[kClients].map(p => p[kWeight]).reduce(getGreatestCommonDivisor, 0);
	  }

	  removeUpstream (upstream) {
	    const upstreamOrigin = parseOrigin(upstream).origin;

	    const pool = this[kClients].find((pool) => (
	      pool[kUrl].origin === upstreamOrigin &&
	      pool.closed !== true &&
	      pool.destroyed !== true
	    ));

	    if (pool) {
	      this[kRemoveClient](pool);
	    }

	    return this
	  }

	  get upstreams () {
	    return this[kClients]
	      .filter(dispatcher => dispatcher.closed !== true && dispatcher.destroyed !== true)
	      .map((p) => p[kUrl].origin)
	  }

	  [kGetDispatcher] () {
	    // We validate that pools is greater than 0,
	    // otherwise we would have to wait until an upstream
	    // is added, which might never happen.
	    if (this[kClients].length === 0) {
	      throw new BalancedPoolMissingUpstreamError()
	    }

	    const dispatcher = this[kClients].find(dispatcher => (
	      !dispatcher[kNeedDrain] &&
	      dispatcher.closed !== true &&
	      dispatcher.destroyed !== true
	    ));

	    if (!dispatcher) {
	      return
	    }

	    const allClientsBusy = this[kClients].map(pool => pool[kNeedDrain]).reduce((a, b) => a && b, true);

	    if (allClientsBusy) {
	      return
	    }

	    let counter = 0;

	    let maxWeightIndex = this[kClients].findIndex(pool => !pool[kNeedDrain]);

	    while (counter++ < this[kClients].length) {
	      this[kIndex] = (this[kIndex] + 1) % this[kClients].length;
	      const pool = this[kClients][this[kIndex]];

	      // find pool index with the largest weight
	      if (pool[kWeight] > this[kClients][maxWeightIndex][kWeight] && !pool[kNeedDrain]) {
	        maxWeightIndex = this[kIndex];
	      }

	      // decrease the current weight every `this[kClients].length`.
	      if (this[kIndex] === 0) {
	        // Set the current weight to the next lower weight.
	        this[kCurrentWeight] = this[kCurrentWeight] - this[kGreatestCommonDivisor];

	        if (this[kCurrentWeight] <= 0) {
	          this[kCurrentWeight] = this[kMaxWeightPerServer];
	        }
	      }
	      if (pool[kWeight] >= this[kCurrentWeight] && (!pool[kNeedDrain])) {
	        return pool
	      }
	    }

	    this[kCurrentWeight] = this[kClients][maxWeightIndex][kWeight];
	    this[kIndex] = maxWeightIndex;
	    return this[kClients][maxWeightIndex]
	  }
	}

	balancedPool = BalancedPool;
	return balancedPool;
}

var agent;
var hasRequiredAgent;

function requireAgent () {
	if (hasRequiredAgent) return agent;
	hasRequiredAgent = 1;

	const { InvalidArgumentError } = requireErrors();
	const { kClients, kRunning, kClose, kDestroy, kDispatch, kInterceptors } = requireSymbols$4();
	const DispatcherBase = requireDispatcherBase();
	const Pool = requirePool();
	const Client = requireClient();
	const util = requireUtil$7();
	const createRedirectInterceptor = requireRedirectInterceptor();

	const kOnConnect = Symbol('onConnect');
	const kOnDisconnect = Symbol('onDisconnect');
	const kOnConnectionError = Symbol('onConnectionError');
	const kMaxRedirections = Symbol('maxRedirections');
	const kOnDrain = Symbol('onDrain');
	const kFactory = Symbol('factory');
	const kOptions = Symbol('options');

	function defaultFactory (origin, opts) {
	  return opts && opts.connections === 1
	    ? new Client(origin, opts)
	    : new Pool(origin, opts)
	}

	class Agent extends DispatcherBase {
	  constructor ({ factory = defaultFactory, maxRedirections = 0, connect, ...options } = {}) {
	    super();

	    if (typeof factory !== 'function') {
	      throw new InvalidArgumentError('factory must be a function.')
	    }

	    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {
	      throw new InvalidArgumentError('connect must be a function or an object')
	    }

	    if (!Number.isInteger(maxRedirections) || maxRedirections < 0) {
	      throw new InvalidArgumentError('maxRedirections must be a positive number')
	    }

	    if (connect && typeof connect !== 'function') {
	      connect = { ...connect };
	    }

	    this[kInterceptors] = options.interceptors?.Agent && Array.isArray(options.interceptors.Agent)
	      ? options.interceptors.Agent
	      : [createRedirectInterceptor({ maxRedirections })];

	    this[kOptions] = { ...util.deepClone(options), connect };
	    this[kOptions].interceptors = options.interceptors
	      ? { ...options.interceptors }
	      : undefined;
	    this[kMaxRedirections] = maxRedirections;
	    this[kFactory] = factory;
	    this[kClients] = new Map();

	    this[kOnDrain] = (origin, targets) => {
	      this.emit('drain', origin, [this, ...targets]);
	    };

	    this[kOnConnect] = (origin, targets) => {
	      this.emit('connect', origin, [this, ...targets]);
	    };

	    this[kOnDisconnect] = (origin, targets, err) => {
	      this.emit('disconnect', origin, [this, ...targets], err);
	    };

	    this[kOnConnectionError] = (origin, targets, err) => {
	      this.emit('connectionError', origin, [this, ...targets], err);
	    };
	  }

	  get [kRunning] () {
	    let ret = 0;
	    for (const client of this[kClients].values()) {
	      ret += client[kRunning];
	    }
	    return ret
	  }

	  [kDispatch] (opts, handler) {
	    let key;
	    if (opts.origin && (typeof opts.origin === 'string' || opts.origin instanceof URL)) {
	      key = String(opts.origin);
	    } else {
	      throw new InvalidArgumentError('opts.origin must be a non-empty string or URL.')
	    }

	    let dispatcher = this[kClients].get(key);

	    if (!dispatcher) {
	      dispatcher = this[kFactory](opts.origin, this[kOptions])
	        .on('drain', this[kOnDrain])
	        .on('connect', this[kOnConnect])
	        .on('disconnect', this[kOnDisconnect])
	        .on('connectionError', this[kOnConnectionError]);

	      // This introduces a tiny memory leak, as dispatchers are never removed from the map.
	      // TODO(mcollina): remove te timer when the client/pool do not have any more
	      // active connections.
	      this[kClients].set(key, dispatcher);
	    }

	    return dispatcher.dispatch(opts, handler)
	  }

	  async [kClose] () {
	    const closePromises = [];
	    for (const client of this[kClients].values()) {
	      closePromises.push(client.close());
	    }
	    this[kClients].clear();

	    await Promise.all(closePromises);
	  }

	  async [kDestroy] (err) {
	    const destroyPromises = [];
	    for (const client of this[kClients].values()) {
	      destroyPromises.push(client.destroy(err));
	    }
	    this[kClients].clear();

	    await Promise.all(destroyPromises);
	  }
	}

	agent = Agent;
	return agent;
}

var proxyAgent;
var hasRequiredProxyAgent;

function requireProxyAgent () {
	if (hasRequiredProxyAgent) return proxyAgent;
	hasRequiredProxyAgent = 1;

	const { kProxy, kClose, kDestroy, kInterceptors } = requireSymbols$4();
	const { URL } = url;
	const Agent = requireAgent();
	const Pool = requirePool();
	const DispatcherBase = requireDispatcherBase();
	const { InvalidArgumentError, RequestAbortedError, SecureProxyConnectionError } = requireErrors();
	const buildConnector = requireConnect();

	const kAgent = Symbol('proxy agent');
	const kClient = Symbol('proxy client');
	const kProxyHeaders = Symbol('proxy headers');
	const kRequestTls = Symbol('request tls settings');
	const kProxyTls = Symbol('proxy tls settings');
	const kConnectEndpoint = Symbol('connect endpoint function');

	function defaultProtocolPort (protocol) {
	  return protocol === 'https:' ? 443 : 80
	}

	function defaultFactory (origin, opts) {
	  return new Pool(origin, opts)
	}

	class ProxyAgent extends DispatcherBase {
	  constructor (opts) {
	    super();

	    if (!opts || (typeof opts === 'object' && !(opts instanceof URL) && !opts.uri)) {
	      throw new InvalidArgumentError('Proxy uri is mandatory')
	    }

	    const { clientFactory = defaultFactory } = opts;
	    if (typeof clientFactory !== 'function') {
	      throw new InvalidArgumentError('Proxy opts.clientFactory must be a function.')
	    }

	    const url = this.#getUrl(opts);
	    const { href, origin, port, protocol, username, password, hostname: proxyHostname } = url;

	    this[kProxy] = { uri: href, protocol };
	    this[kInterceptors] = opts.interceptors?.ProxyAgent && Array.isArray(opts.interceptors.ProxyAgent)
	      ? opts.interceptors.ProxyAgent
	      : [];
	    this[kRequestTls] = opts.requestTls;
	    this[kProxyTls] = opts.proxyTls;
	    this[kProxyHeaders] = opts.headers || {};

	    if (opts.auth && opts.token) {
	      throw new InvalidArgumentError('opts.auth cannot be used in combination with opts.token')
	    } else if (opts.auth) {
	      /* @deprecated in favour of opts.token */
	      this[kProxyHeaders]['proxy-authorization'] = `Basic ${opts.auth}`;
	    } else if (opts.token) {
	      this[kProxyHeaders]['proxy-authorization'] = opts.token;
	    } else if (username && password) {
	      this[kProxyHeaders]['proxy-authorization'] = `Basic ${Buffer.from(`${decodeURIComponent(username)}:${decodeURIComponent(password)}`).toString('base64')}`;
	    }

	    const connect = buildConnector({ ...opts.proxyTls });
	    this[kConnectEndpoint] = buildConnector({ ...opts.requestTls });
	    this[kClient] = clientFactory(url, { connect });
	    this[kAgent] = new Agent({
	      ...opts,
	      connect: async (opts, callback) => {
	        let requestedPath = opts.host;
	        if (!opts.port) {
	          requestedPath += `:${defaultProtocolPort(opts.protocol)}`;
	        }
	        try {
	          const { socket, statusCode } = await this[kClient].connect({
	            origin,
	            port,
	            path: requestedPath,
	            signal: opts.signal,
	            headers: {
	              ...this[kProxyHeaders],
	              host: opts.host
	            },
	            servername: this[kProxyTls]?.servername || proxyHostname
	          });
	          if (statusCode !== 200) {
	            socket.on('error', () => {}).destroy();
	            callback(new RequestAbortedError(`Proxy response (${statusCode}) !== 200 when HTTP Tunneling`));
	          }
	          if (opts.protocol !== 'https:') {
	            callback(null, socket);
	            return
	          }
	          let servername;
	          if (this[kRequestTls]) {
	            servername = this[kRequestTls].servername;
	          } else {
	            servername = opts.servername;
	          }
	          this[kConnectEndpoint]({ ...opts, servername, httpSocket: socket }, callback);
	        } catch (err) {
	          if (err.code === 'ERR_TLS_CERT_ALTNAME_INVALID') {
	            // Throw a custom error to avoid loop in client.js#connect
	            callback(new SecureProxyConnectionError(err));
	          } else {
	            callback(err);
	          }
	        }
	      }
	    });
	  }

	  dispatch (opts, handler) {
	    const headers = buildHeaders(opts.headers);
	    throwIfProxyAuthIsSent(headers);

	    if (headers && !('host' in headers) && !('Host' in headers)) {
	      const { host } = new URL(opts.origin);
	      headers.host = host;
	    }

	    return this[kAgent].dispatch(
	      {
	        ...opts,
	        headers
	      },
	      handler
	    )
	  }

	  /**
	   * @param {import('../types/proxy-agent').ProxyAgent.Options | string | URL} opts
	   * @returns {URL}
	   */
	  #getUrl (opts) {
	    if (typeof opts === 'string') {
	      return new URL(opts)
	    } else if (opts instanceof URL) {
	      return opts
	    } else {
	      return new URL(opts.uri)
	    }
	  }

	  async [kClose] () {
	    await this[kAgent].close();
	    await this[kClient].close();
	  }

	  async [kDestroy] () {
	    await this[kAgent].destroy();
	    await this[kClient].destroy();
	  }
	}

	/**
	 * @param {string[] | Record<string, string>} headers
	 * @returns {Record<string, string>}
	 */
	function buildHeaders (headers) {
	  // When using undici.fetch, the headers list is stored
	  // as an array.
	  if (Array.isArray(headers)) {
	    /** @type {Record<string, string>} */
	    const headersPair = {};

	    for (let i = 0; i < headers.length; i += 2) {
	      headersPair[headers[i]] = headers[i + 1];
	    }

	    return headersPair
	  }

	  return headers
	}

	/**
	 * @param {Record<string, string>} headers
	 *
	 * Previous versions of ProxyAgent suggests the Proxy-Authorization in request headers
	 * Nevertheless, it was changed and to avoid a security vulnerability by end users
	 * this check was created.
	 * It should be removed in the next major version for performance reasons
	 */
	function throwIfProxyAuthIsSent (headers) {
	  const existProxyAuth = headers && Object.keys(headers)
	    .find((key) => key.toLowerCase() === 'proxy-authorization');
	  if (existProxyAuth) {
	    throw new InvalidArgumentError('Proxy-Authorization should be sent in ProxyAgent constructor')
	  }
	}

	proxyAgent = ProxyAgent;
	return proxyAgent;
}

var envHttpProxyAgent;
var hasRequiredEnvHttpProxyAgent;

function requireEnvHttpProxyAgent () {
	if (hasRequiredEnvHttpProxyAgent) return envHttpProxyAgent;
	hasRequiredEnvHttpProxyAgent = 1;

	const DispatcherBase = requireDispatcherBase();
	const { kClose, kDestroy, kClosed, kDestroyed, kDispatch, kNoProxyAgent, kHttpProxyAgent, kHttpsProxyAgent } = requireSymbols$4();
	const ProxyAgent = requireProxyAgent();
	const Agent = requireAgent();

	const DEFAULT_PORTS = {
	  'http:': 80,
	  'https:': 443
	};

	let experimentalWarned = false;

	class EnvHttpProxyAgent extends DispatcherBase {
	  #noProxyValue = null
	  #noProxyEntries = null
	  #opts = null

	  constructor (opts = {}) {
	    super();
	    this.#opts = opts;

	    if (!experimentalWarned) {
	      experimentalWarned = true;
	      process.emitWarning('EnvHttpProxyAgent is experimental, expect them to change at any time.', {
	        code: 'UNDICI-EHPA'
	      });
	    }

	    const { httpProxy, httpsProxy, noProxy, ...agentOpts } = opts;

	    this[kNoProxyAgent] = new Agent(agentOpts);

	    const HTTP_PROXY = httpProxy ?? process.env.http_proxy ?? process.env.HTTP_PROXY;
	    if (HTTP_PROXY) {
	      this[kHttpProxyAgent] = new ProxyAgent({ ...agentOpts, uri: HTTP_PROXY });
	    } else {
	      this[kHttpProxyAgent] = this[kNoProxyAgent];
	    }

	    const HTTPS_PROXY = httpsProxy ?? process.env.https_proxy ?? process.env.HTTPS_PROXY;
	    if (HTTPS_PROXY) {
	      this[kHttpsProxyAgent] = new ProxyAgent({ ...agentOpts, uri: HTTPS_PROXY });
	    } else {
	      this[kHttpsProxyAgent] = this[kHttpProxyAgent];
	    }

	    this.#parseNoProxy();
	  }

	  [kDispatch] (opts, handler) {
	    const url = new URL(opts.origin);
	    const agent = this.#getProxyAgentForUrl(url);
	    return agent.dispatch(opts, handler)
	  }

	  async [kClose] () {
	    await this[kNoProxyAgent].close();
	    if (!this[kHttpProxyAgent][kClosed]) {
	      await this[kHttpProxyAgent].close();
	    }
	    if (!this[kHttpsProxyAgent][kClosed]) {
	      await this[kHttpsProxyAgent].close();
	    }
	  }

	  async [kDestroy] (err) {
	    await this[kNoProxyAgent].destroy(err);
	    if (!this[kHttpProxyAgent][kDestroyed]) {
	      await this[kHttpProxyAgent].destroy(err);
	    }
	    if (!this[kHttpsProxyAgent][kDestroyed]) {
	      await this[kHttpsProxyAgent].destroy(err);
	    }
	  }

	  #getProxyAgentForUrl (url) {
	    let { protocol, host: hostname, port } = url;

	    // Stripping ports in this way instead of using parsedUrl.hostname to make
	    // sure that the brackets around IPv6 addresses are kept.
	    hostname = hostname.replace(/:\d*$/, '').toLowerCase();
	    port = Number.parseInt(port, 10) || DEFAULT_PORTS[protocol] || 0;
	    if (!this.#shouldProxy(hostname, port)) {
	      return this[kNoProxyAgent]
	    }
	    if (protocol === 'https:') {
	      return this[kHttpsProxyAgent]
	    }
	    return this[kHttpProxyAgent]
	  }

	  #shouldProxy (hostname, port) {
	    if (this.#noProxyChanged) {
	      this.#parseNoProxy();
	    }

	    if (this.#noProxyEntries.length === 0) {
	      return true // Always proxy if NO_PROXY is not set or empty.
	    }
	    if (this.#noProxyValue === '*') {
	      return false // Never proxy if wildcard is set.
	    }

	    for (let i = 0; i < this.#noProxyEntries.length; i++) {
	      const entry = this.#noProxyEntries[i];
	      if (entry.port && entry.port !== port) {
	        continue // Skip if ports don't match.
	      }
	      if (!/^[.*]/.test(entry.hostname)) {
	        // No wildcards, so don't proxy only if there is not an exact match.
	        if (hostname === entry.hostname) {
	          return false
	        }
	      } else {
	        // Don't proxy if the hostname ends with the no_proxy host.
	        if (hostname.endsWith(entry.hostname.replace(/^\*/, ''))) {
	          return false
	        }
	      }
	    }

	    return true
	  }

	  #parseNoProxy () {
	    const noProxyValue = this.#opts.noProxy ?? this.#noProxyEnv;
	    const noProxySplit = noProxyValue.split(/[,\s]/);
	    const noProxyEntries = [];

	    for (let i = 0; i < noProxySplit.length; i++) {
	      const entry = noProxySplit[i];
	      if (!entry) {
	        continue
	      }
	      const parsed = entry.match(/^(.+):(\d+)$/);
	      noProxyEntries.push({
	        hostname: (parsed ? parsed[1] : entry).toLowerCase(),
	        port: parsed ? Number.parseInt(parsed[2], 10) : 0
	      });
	    }

	    this.#noProxyValue = noProxyValue;
	    this.#noProxyEntries = noProxyEntries;
	  }

	  get #noProxyChanged () {
	    if (this.#opts.noProxy !== undefined) {
	      return false
	    }
	    return this.#noProxyValue !== this.#noProxyEnv
	  }

	  get #noProxyEnv () {
	    return process.env.no_proxy ?? process.env.NO_PROXY ?? ''
	  }
	}

	envHttpProxyAgent = EnvHttpProxyAgent;
	return envHttpProxyAgent;
}

var retryHandler;
var hasRequiredRetryHandler;

function requireRetryHandler () {
	if (hasRequiredRetryHandler) return retryHandler;
	hasRequiredRetryHandler = 1;
	const assert = require$$0$4;

	const { kRetryHandlerDefaultRetry } = requireSymbols$4();
	const { RequestRetryError } = requireErrors();
	const {
	  isDisturbed,
	  parseHeaders,
	  parseRangeHeader,
	  wrapRequestBody
	} = requireUtil$7();

	function calculateRetryAfterHeader (retryAfter) {
	  const current = Date.now();
	  return new Date(retryAfter).getTime() - current
	}

	class RetryHandler {
	  constructor (opts, handlers) {
	    const { retryOptions, ...dispatchOpts } = opts;
	    const {
	      // Retry scoped
	      retry: retryFn,
	      maxRetries,
	      maxTimeout,
	      minTimeout,
	      timeoutFactor,
	      // Response scoped
	      methods,
	      errorCodes,
	      retryAfter,
	      statusCodes
	    } = retryOptions ?? {};

	    this.dispatch = handlers.dispatch;
	    this.handler = handlers.handler;
	    this.opts = { ...dispatchOpts, body: wrapRequestBody(opts.body) };
	    this.abort = null;
	    this.aborted = false;
	    this.retryOpts = {
	      retry: retryFn ?? RetryHandler[kRetryHandlerDefaultRetry],
	      retryAfter: retryAfter ?? true,
	      maxTimeout: maxTimeout ?? 30 * 1000, // 30s,
	      minTimeout: minTimeout ?? 500, // .5s
	      timeoutFactor: timeoutFactor ?? 2,
	      maxRetries: maxRetries ?? 5,
	      // What errors we should retry
	      methods: methods ?? ['GET', 'HEAD', 'OPTIONS', 'PUT', 'DELETE', 'TRACE'],
	      // Indicates which errors to retry
	      statusCodes: statusCodes ?? [500, 502, 503, 504, 429],
	      // List of errors to retry
	      errorCodes: errorCodes ?? [
	        'ECONNRESET',
	        'ECONNREFUSED',
	        'ENOTFOUND',
	        'ENETDOWN',
	        'ENETUNREACH',
	        'EHOSTDOWN',
	        'EHOSTUNREACH',
	        'EPIPE',
	        'UND_ERR_SOCKET'
	      ]
	    };

	    this.retryCount = 0;
	    this.retryCountCheckpoint = 0;
	    this.start = 0;
	    this.end = null;
	    this.etag = null;
	    this.resume = null;

	    // Handle possible onConnect duplication
	    this.handler.onConnect(reason => {
	      this.aborted = true;
	      if (this.abort) {
	        this.abort(reason);
	      } else {
	        this.reason = reason;
	      }
	    });
	  }

	  onRequestSent () {
	    if (this.handler.onRequestSent) {
	      this.handler.onRequestSent();
	    }
	  }

	  onUpgrade (statusCode, headers, socket) {
	    if (this.handler.onUpgrade) {
	      this.handler.onUpgrade(statusCode, headers, socket);
	    }
	  }

	  onConnect (abort) {
	    if (this.aborted) {
	      abort(this.reason);
	    } else {
	      this.abort = abort;
	    }
	  }

	  onBodySent (chunk) {
	    if (this.handler.onBodySent) return this.handler.onBodySent(chunk)
	  }

	  static [kRetryHandlerDefaultRetry] (err, { state, opts }, cb) {
	    const { statusCode, code, headers } = err;
	    const { method, retryOptions } = opts;
	    const {
	      maxRetries,
	      minTimeout,
	      maxTimeout,
	      timeoutFactor,
	      statusCodes,
	      errorCodes,
	      methods
	    } = retryOptions;
	    const { counter } = state;

	    // Any code that is not a Undici's originated and allowed to retry
	    if (code && code !== 'UND_ERR_REQ_RETRY' && !errorCodes.includes(code)) {
	      cb(err);
	      return
	    }

	    // If a set of method are provided and the current method is not in the list
	    if (Array.isArray(methods) && !methods.includes(method)) {
	      cb(err);
	      return
	    }

	    // If a set of status code are provided and the current status code is not in the list
	    if (
	      statusCode != null &&
	      Array.isArray(statusCodes) &&
	      !statusCodes.includes(statusCode)
	    ) {
	      cb(err);
	      return
	    }

	    // If we reached the max number of retries
	    if (counter > maxRetries) {
	      cb(err);
	      return
	    }

	    let retryAfterHeader = headers?.['retry-after'];
	    if (retryAfterHeader) {
	      retryAfterHeader = Number(retryAfterHeader);
	      retryAfterHeader = Number.isNaN(retryAfterHeader)
	        ? calculateRetryAfterHeader(retryAfterHeader)
	        : retryAfterHeader * 1e3; // Retry-After is in seconds
	    }

	    const retryTimeout =
	      retryAfterHeader > 0
	        ? Math.min(retryAfterHeader, maxTimeout)
	        : Math.min(minTimeout * timeoutFactor ** (counter - 1), maxTimeout);

	    setTimeout(() => cb(null), retryTimeout);
	  }

	  onHeaders (statusCode, rawHeaders, resume, statusMessage) {
	    const headers = parseHeaders(rawHeaders);

	    this.retryCount += 1;

	    if (statusCode >= 300) {
	      if (this.retryOpts.statusCodes.includes(statusCode) === false) {
	        return this.handler.onHeaders(
	          statusCode,
	          rawHeaders,
	          resume,
	          statusMessage
	        )
	      } else {
	        this.abort(
	          new RequestRetryError('Request failed', statusCode, {
	            headers,
	            data: {
	              count: this.retryCount
	            }
	          })
	        );
	        return false
	      }
	    }

	    // Checkpoint for resume from where we left it
	    if (this.resume != null) {
	      this.resume = null;

	      if (statusCode !== 206) {
	        return true
	      }

	      const contentRange = parseRangeHeader(headers['content-range']);
	      // If no content range
	      if (!contentRange) {
	        this.abort(
	          new RequestRetryError('Content-Range mismatch', statusCode, {
	            headers,
	            data: { count: this.retryCount }
	          })
	        );
	        return false
	      }

	      // Let's start with a weak etag check
	      if (this.etag != null && this.etag !== headers.etag) {
	        this.abort(
	          new RequestRetryError('ETag mismatch', statusCode, {
	            headers,
	            data: { count: this.retryCount }
	          })
	        );
	        return false
	      }

	      const { start, size, end = size } = contentRange;

	      assert(this.start === start, 'content-range mismatch');
	      assert(this.end == null || this.end === end, 'content-range mismatch');

	      this.resume = resume;
	      return true
	    }

	    if (this.end == null) {
	      if (statusCode === 206) {
	        // First time we receive 206
	        const range = parseRangeHeader(headers['content-range']);

	        if (range == null) {
	          return this.handler.onHeaders(
	            statusCode,
	            rawHeaders,
	            resume,
	            statusMessage
	          )
	        }

	        const { start, size, end = size } = range;
	        assert(
	          start != null && Number.isFinite(start),
	          'content-range mismatch'
	        );
	        assert(end != null && Number.isFinite(end), 'invalid content-length');

	        this.start = start;
	        this.end = end;
	      }

	      // We make our best to checkpoint the body for further range headers
	      if (this.end == null) {
	        const contentLength = headers['content-length'];
	        this.end = contentLength != null ? Number(contentLength) : null;
	      }

	      assert(Number.isFinite(this.start));
	      assert(
	        this.end == null || Number.isFinite(this.end),
	        'invalid content-length'
	      );

	      this.resume = resume;
	      this.etag = headers.etag != null ? headers.etag : null;

	      // Weak etags are not useful for comparison nor cache
	      // for instance not safe to assume if the response is byte-per-byte
	      // equal
	      if (this.etag != null && this.etag.startsWith('W/')) {
	        this.etag = null;
	      }

	      return this.handler.onHeaders(
	        statusCode,
	        rawHeaders,
	        resume,
	        statusMessage
	      )
	    }

	    const err = new RequestRetryError('Request failed', statusCode, {
	      headers,
	      data: { count: this.retryCount }
	    });

	    this.abort(err);

	    return false
	  }

	  onData (chunk) {
	    this.start += chunk.length;

	    return this.handler.onData(chunk)
	  }

	  onComplete (rawTrailers) {
	    this.retryCount = 0;
	    return this.handler.onComplete(rawTrailers)
	  }

	  onError (err) {
	    if (this.aborted || isDisturbed(this.opts.body)) {
	      return this.handler.onError(err)
	    }

	    // We reconcile in case of a mix between network errors
	    // and server error response
	    if (this.retryCount - this.retryCountCheckpoint > 0) {
	      // We count the difference between the last checkpoint and the current retry count
	      this.retryCount =
	        this.retryCountCheckpoint +
	        (this.retryCount - this.retryCountCheckpoint);
	    } else {
	      this.retryCount += 1;
	    }

	    this.retryOpts.retry(
	      err,
	      {
	        state: { counter: this.retryCount },
	        opts: { retryOptions: this.retryOpts, ...this.opts }
	      },
	      onRetry.bind(this)
	    );

	    function onRetry (err) {
	      if (err != null || this.aborted || isDisturbed(this.opts.body)) {
	        return this.handler.onError(err)
	      }

	      if (this.start !== 0) {
	        const headers = { range: `bytes=${this.start}-${this.end ?? ''}` };

	        // Weak etag check - weak etags will make comparison algorithms never match
	        if (this.etag != null) {
	          headers['if-match'] = this.etag;
	        }

	        this.opts = {
	          ...this.opts,
	          headers: {
	            ...this.opts.headers,
	            ...headers
	          }
	        };
	      }

	      try {
	        this.retryCountCheckpoint = this.retryCount;
	        this.dispatch(this.opts, this);
	      } catch (err) {
	        this.handler.onError(err);
	      }
	    }
	  }
	}

	retryHandler = RetryHandler;
	return retryHandler;
}

var retryAgent;
var hasRequiredRetryAgent;

function requireRetryAgent () {
	if (hasRequiredRetryAgent) return retryAgent;
	hasRequiredRetryAgent = 1;

	const Dispatcher = requireDispatcher();
	const RetryHandler = requireRetryHandler();

	class RetryAgent extends Dispatcher {
	  #agent = null
	  #options = null
	  constructor (agent, options = {}) {
	    super(options);
	    this.#agent = agent;
	    this.#options = options;
	  }

	  dispatch (opts, handler) {
	    const retry = new RetryHandler({
	      ...opts,
	      retryOptions: this.#options
	    }, {
	      dispatch: this.#agent.dispatch.bind(this.#agent),
	      handler
	    });
	    return this.#agent.dispatch(opts, retry)
	  }

	  close () {
	    return this.#agent.close()
	  }

	  destroy () {
	    return this.#agent.destroy()
	  }
	}

	retryAgent = RetryAgent;
	return retryAgent;
}

var api = {};

var apiRequest = {exports: {}};

var readable;
var hasRequiredReadable;

function requireReadable () {
	if (hasRequiredReadable) return readable;
	hasRequiredReadable = 1;

	const assert = require$$0$4;
	const { Readable } = require$$0$5;
	const { RequestAbortedError, NotSupportedError, InvalidArgumentError, AbortError } = requireErrors();
	const util = requireUtil$7();
	const { ReadableStreamFrom } = requireUtil$7();

	const kConsume = Symbol('kConsume');
	const kReading = Symbol('kReading');
	const kBody = Symbol('kBody');
	const kAbort = Symbol('kAbort');
	const kContentType = Symbol('kContentType');
	const kContentLength = Symbol('kContentLength');

	const noop = () => {};

	class BodyReadable extends Readable {
	  constructor ({
	    resume,
	    abort,
	    contentType = '',
	    contentLength,
	    highWaterMark = 64 * 1024 // Same as nodejs fs streams.
	  }) {
	    super({
	      autoDestroy: true,
	      read: resume,
	      highWaterMark
	    });

	    this._readableState.dataEmitted = false;

	    this[kAbort] = abort;
	    this[kConsume] = null;
	    this[kBody] = null;
	    this[kContentType] = contentType;
	    this[kContentLength] = contentLength;

	    // Is stream being consumed through Readable API?
	    // This is an optimization so that we avoid checking
	    // for 'data' and 'readable' listeners in the hot path
	    // inside push().
	    this[kReading] = false;
	  }

	  destroy (err) {
	    if (!err && !this._readableState.endEmitted) {
	      err = new RequestAbortedError();
	    }

	    if (err) {
	      this[kAbort]();
	    }

	    return super.destroy(err)
	  }

	  _destroy (err, callback) {
	    // Workaround for Node "bug". If the stream is destroyed in same
	    // tick as it is created, then a user who is waiting for a
	    // promise (i.e micro tick) for installing a 'error' listener will
	    // never get a chance and will always encounter an unhandled exception.
	    if (!this[kReading]) {
	      setImmediate(() => {
	        callback(err);
	      });
	    } else {
	      callback(err);
	    }
	  }

	  on (ev, ...args) {
	    if (ev === 'data' || ev === 'readable') {
	      this[kReading] = true;
	    }
	    return super.on(ev, ...args)
	  }

	  addListener (ev, ...args) {
	    return this.on(ev, ...args)
	  }

	  off (ev, ...args) {
	    const ret = super.off(ev, ...args);
	    if (ev === 'data' || ev === 'readable') {
	      this[kReading] = (
	        this.listenerCount('data') > 0 ||
	        this.listenerCount('readable') > 0
	      );
	    }
	    return ret
	  }

	  removeListener (ev, ...args) {
	    return this.off(ev, ...args)
	  }

	  push (chunk) {
	    if (this[kConsume] && chunk !== null) {
	      consumePush(this[kConsume], chunk);
	      return this[kReading] ? super.push(chunk) : true
	    }
	    return super.push(chunk)
	  }

	  // https://fetch.spec.whatwg.org/#dom-body-text
	  async text () {
	    return consume(this, 'text')
	  }

	  // https://fetch.spec.whatwg.org/#dom-body-json
	  async json () {
	    return consume(this, 'json')
	  }

	  // https://fetch.spec.whatwg.org/#dom-body-blob
	  async blob () {
	    return consume(this, 'blob')
	  }

	  // https://fetch.spec.whatwg.org/#dom-body-arraybuffer
	  async arrayBuffer () {
	    return consume(this, 'arrayBuffer')
	  }

	  // https://fetch.spec.whatwg.org/#dom-body-formdata
	  async formData () {
	    // TODO: Implement.
	    throw new NotSupportedError()
	  }

	  // https://fetch.spec.whatwg.org/#dom-body-bodyused
	  get bodyUsed () {
	    return util.isDisturbed(this)
	  }

	  // https://fetch.spec.whatwg.org/#dom-body-body
	  get body () {
	    if (!this[kBody]) {
	      this[kBody] = ReadableStreamFrom(this);
	      if (this[kConsume]) {
	        // TODO: Is this the best way to force a lock?
	        this[kBody].getReader(); // Ensure stream is locked.
	        assert(this[kBody].locked);
	      }
	    }
	    return this[kBody]
	  }

	  async dump (opts) {
	    let limit = Number.isFinite(opts?.limit) ? opts.limit : 128 * 1024;
	    const signal = opts?.signal;

	    if (signal != null && (typeof signal !== 'object' || !('aborted' in signal))) {
	      throw new InvalidArgumentError('signal must be an AbortSignal')
	    }

	    signal?.throwIfAborted();

	    if (this._readableState.closeEmitted) {
	      return null
	    }

	    return await new Promise((resolve, reject) => {
	      if (this[kContentLength] > limit) {
	        this.destroy(new AbortError());
	      }

	      const onAbort = () => {
	        this.destroy(signal.reason ?? new AbortError());
	      };
	      signal?.addEventListener('abort', onAbort);

	      this
	        .on('close', function () {
	          signal?.removeEventListener('abort', onAbort);
	          if (signal?.aborted) {
	            reject(signal.reason ?? new AbortError());
	          } else {
	            resolve(null);
	          }
	        })
	        .on('error', noop)
	        .on('data', function (chunk) {
	          limit -= chunk.length;
	          if (limit <= 0) {
	            this.destroy();
	          }
	        })
	        .resume();
	    })
	  }
	}

	// https://streams.spec.whatwg.org/#readablestream-locked
	function isLocked (self) {
	  // Consume is an implicit lock.
	  return (self[kBody] && self[kBody].locked === true) || self[kConsume]
	}

	// https://fetch.spec.whatwg.org/#body-unusable
	function isUnusable (self) {
	  return util.isDisturbed(self) || isLocked(self)
	}

	async function consume (stream, type) {
	  assert(!stream[kConsume]);

	  return new Promise((resolve, reject) => {
	    if (isUnusable(stream)) {
	      const rState = stream._readableState;
	      if (rState.destroyed && rState.closeEmitted === false) {
	        stream
	          .on('error', err => {
	            reject(err);
	          })
	          .on('close', () => {
	            reject(new TypeError('unusable'));
	          });
	      } else {
	        reject(rState.errored ?? new TypeError('unusable'));
	      }
	    } else {
	      queueMicrotask(() => {
	        stream[kConsume] = {
	          type,
	          stream,
	          resolve,
	          reject,
	          length: 0,
	          body: []
	        };

	        stream
	          .on('error', function (err) {
	            consumeFinish(this[kConsume], err);
	          })
	          .on('close', function () {
	            if (this[kConsume].body !== null) {
	              consumeFinish(this[kConsume], new RequestAbortedError());
	            }
	          });

	        consumeStart(stream[kConsume]);
	      });
	    }
	  })
	}

	function consumeStart (consume) {
	  if (consume.body === null) {
	    return
	  }

	  const { _readableState: state } = consume.stream;

	  if (state.bufferIndex) {
	    const start = state.bufferIndex;
	    const end = state.buffer.length;
	    for (let n = start; n < end; n++) {
	      consumePush(consume, state.buffer[n]);
	    }
	  } else {
	    for (const chunk of state.buffer) {
	      consumePush(consume, chunk);
	    }
	  }

	  if (state.endEmitted) {
	    consumeEnd(this[kConsume]);
	  } else {
	    consume.stream.on('end', function () {
	      consumeEnd(this[kConsume]);
	    });
	  }

	  consume.stream.resume();

	  while (consume.stream.read() != null) {
	    // Loop
	  }
	}

	/**
	 * @param {Buffer[]} chunks
	 * @param {number} length
	 */
	function chunksDecode (chunks, length) {
	  if (chunks.length === 0 || length === 0) {
	    return ''
	  }
	  const buffer = chunks.length === 1 ? chunks[0] : Buffer.concat(chunks, length);
	  const bufferLength = buffer.length;

	  // Skip BOM.
	  const start =
	    bufferLength > 2 &&
	    buffer[0] === 0xef &&
	    buffer[1] === 0xbb &&
	    buffer[2] === 0xbf
	      ? 3
	      : 0;
	  return buffer.utf8Slice(start, bufferLength)
	}

	function consumeEnd (consume) {
	  const { type, body, resolve, stream, length } = consume;

	  try {
	    if (type === 'text') {
	      resolve(chunksDecode(body, length));
	    } else if (type === 'json') {
	      resolve(JSON.parse(chunksDecode(body, length)));
	    } else if (type === 'arrayBuffer') {
	      const dst = new Uint8Array(length);

	      let pos = 0;
	      for (const buf of body) {
	        dst.set(buf, pos);
	        pos += buf.byteLength;
	      }

	      resolve(dst.buffer);
	    } else if (type === 'blob') {
	      resolve(new Blob(body, { type: stream[kContentType] }));
	    }

	    consumeFinish(consume);
	  } catch (err) {
	    stream.destroy(err);
	  }
	}

	function consumePush (consume, chunk) {
	  consume.length += chunk.length;
	  consume.body.push(chunk);
	}

	function consumeFinish (consume, err) {
	  if (consume.body === null) {
	    return
	  }

	  if (err) {
	    consume.reject(err);
	  } else {
	    consume.resolve();
	  }

	  consume.type = null;
	  consume.stream = null;
	  consume.resolve = null;
	  consume.reject = null;
	  consume.length = 0;
	  consume.body = null;
	}

	readable = { Readable: BodyReadable, chunksDecode };
	return readable;
}

var util$5;
var hasRequiredUtil$5;

function requireUtil$5 () {
	if (hasRequiredUtil$5) return util$5;
	hasRequiredUtil$5 = 1;
	const assert = require$$0$4;
	const {
	  ResponseStatusCodeError
	} = requireErrors();

	const { chunksDecode } = requireReadable();
	const CHUNK_LIMIT = 128 * 1024;

	async function getResolveErrorBodyCallback ({ callback, body, contentType, statusCode, statusMessage, headers }) {
	  assert(body);

	  let chunks = [];
	  let length = 0;

	  try {
	    for await (const chunk of body) {
	      chunks.push(chunk);
	      length += chunk.length;
	      if (length > CHUNK_LIMIT) {
	        chunks = [];
	        length = 0;
	        break
	      }
	    }
	  } catch {
	    chunks = [];
	    length = 0;
	    // Do nothing....
	  }

	  const message = `Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`;

	  if (statusCode === 204 || !contentType || !length) {
	    queueMicrotask(() => callback(new ResponseStatusCodeError(message, statusCode, headers)));
	    return
	  }

	  const stackTraceLimit = Error.stackTraceLimit;
	  Error.stackTraceLimit = 0;
	  let payload;

	  try {
	    if (isContentTypeApplicationJson(contentType)) {
	      payload = JSON.parse(chunksDecode(chunks, length));
	    } else if (isContentTypeText(contentType)) {
	      payload = chunksDecode(chunks, length);
	    }
	  } catch {
	    // process in a callback to avoid throwing in the microtask queue
	  } finally {
	    Error.stackTraceLimit = stackTraceLimit;
	  }
	  queueMicrotask(() => callback(new ResponseStatusCodeError(message, statusCode, headers, payload)));
	}

	const isContentTypeApplicationJson = (contentType) => {
	  return (
	    contentType.length > 15 &&
	    contentType[11] === '/' &&
	    contentType[0] === 'a' &&
	    contentType[1] === 'p' &&
	    contentType[2] === 'p' &&
	    contentType[3] === 'l' &&
	    contentType[4] === 'i' &&
	    contentType[5] === 'c' &&
	    contentType[6] === 'a' &&
	    contentType[7] === 't' &&
	    contentType[8] === 'i' &&
	    contentType[9] === 'o' &&
	    contentType[10] === 'n' &&
	    contentType[12] === 'j' &&
	    contentType[13] === 's' &&
	    contentType[14] === 'o' &&
	    contentType[15] === 'n'
	  )
	};

	const isContentTypeText = (contentType) => {
	  return (
	    contentType.length > 4 &&
	    contentType[4] === '/' &&
	    contentType[0] === 't' &&
	    contentType[1] === 'e' &&
	    contentType[2] === 'x' &&
	    contentType[3] === 't'
	  )
	};

	util$5 = {
	  getResolveErrorBodyCallback,
	  isContentTypeApplicationJson,
	  isContentTypeText
	};
	return util$5;
}

var hasRequiredApiRequest;

function requireApiRequest () {
	if (hasRequiredApiRequest) return apiRequest.exports;
	hasRequiredApiRequest = 1;

	const assert = require$$0$4;
	const { Readable } = requireReadable();
	const { InvalidArgumentError, RequestAbortedError } = requireErrors();
	const util = requireUtil$7();
	const { getResolveErrorBodyCallback } = requireUtil$5();
	const { AsyncResource } = require$$5$1;

	class RequestHandler extends AsyncResource {
	  constructor (opts, callback) {
	    if (!opts || typeof opts !== 'object') {
	      throw new InvalidArgumentError('invalid opts')
	    }

	    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError, highWaterMark } = opts;

	    try {
	      if (typeof callback !== 'function') {
	        throw new InvalidArgumentError('invalid callback')
	      }

	      if (highWaterMark && (typeof highWaterMark !== 'number' || highWaterMark < 0)) {
	        throw new InvalidArgumentError('invalid highWaterMark')
	      }

	      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
	        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
	      }

	      if (method === 'CONNECT') {
	        throw new InvalidArgumentError('invalid method')
	      }

	      if (onInfo && typeof onInfo !== 'function') {
	        throw new InvalidArgumentError('invalid onInfo callback')
	      }

	      super('UNDICI_REQUEST');
	    } catch (err) {
	      if (util.isStream(body)) {
	        util.destroy(body.on('error', util.nop), err);
	      }
	      throw err
	    }

	    this.method = method;
	    this.responseHeaders = responseHeaders || null;
	    this.opaque = opaque || null;
	    this.callback = callback;
	    this.res = null;
	    this.abort = null;
	    this.body = body;
	    this.trailers = {};
	    this.context = null;
	    this.onInfo = onInfo || null;
	    this.throwOnError = throwOnError;
	    this.highWaterMark = highWaterMark;
	    this.signal = signal;
	    this.reason = null;
	    this.removeAbortListener = null;

	    if (util.isStream(body)) {
	      body.on('error', (err) => {
	        this.onError(err);
	      });
	    }

	    if (this.signal) {
	      if (this.signal.aborted) {
	        this.reason = this.signal.reason ?? new RequestAbortedError();
	      } else {
	        this.removeAbortListener = util.addAbortListener(this.signal, () => {
	          this.reason = this.signal.reason ?? new RequestAbortedError();
	          if (this.res) {
	            util.destroy(this.res, this.reason);
	          } else if (this.abort) {
	            this.abort(this.reason);
	          }

	          if (this.removeAbortListener) {
	            this.res?.off('close', this.removeAbortListener);
	            this.removeAbortListener();
	            this.removeAbortListener = null;
	          }
	        });
	      }
	    }
	  }

	  onConnect (abort, context) {
	    if (this.reason) {
	      abort(this.reason);
	      return
	    }

	    assert(this.callback);

	    this.abort = abort;
	    this.context = context;
	  }

	  onHeaders (statusCode, rawHeaders, resume, statusMessage) {
	    const { callback, opaque, abort, context, responseHeaders, highWaterMark } = this;

	    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders);

	    if (statusCode < 200) {
	      if (this.onInfo) {
	        this.onInfo({ statusCode, headers });
	      }
	      return
	    }

	    const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers;
	    const contentType = parsedHeaders['content-type'];
	    const contentLength = parsedHeaders['content-length'];
	    const res = new Readable({
	      resume,
	      abort,
	      contentType,
	      contentLength: this.method !== 'HEAD' && contentLength
	        ? Number(contentLength)
	        : null,
	      highWaterMark
	    });

	    if (this.removeAbortListener) {
	      res.on('close', this.removeAbortListener);
	    }

	    this.callback = null;
	    this.res = res;
	    if (callback !== null) {
	      if (this.throwOnError && statusCode >= 400) {
	        this.runInAsyncScope(getResolveErrorBodyCallback, null,
	          { callback, body: res, contentType, statusCode, statusMessage, headers }
	        );
	      } else {
	        this.runInAsyncScope(callback, null, null, {
	          statusCode,
	          headers,
	          trailers: this.trailers,
	          opaque,
	          body: res,
	          context
	        });
	      }
	    }
	  }

	  onData (chunk) {
	    return this.res.push(chunk)
	  }

	  onComplete (trailers) {
	    util.parseHeaders(trailers, this.trailers);
	    this.res.push(null);
	  }

	  onError (err) {
	    const { res, callback, body, opaque } = this;

	    if (callback) {
	      // TODO: Does this need queueMicrotask?
	      this.callback = null;
	      queueMicrotask(() => {
	        this.runInAsyncScope(callback, null, err, { opaque });
	      });
	    }

	    if (res) {
	      this.res = null;
	      // Ensure all queued handlers are invoked before destroying res.
	      queueMicrotask(() => {
	        util.destroy(res, err);
	      });
	    }

	    if (body) {
	      this.body = null;
	      util.destroy(body, err);
	    }

	    if (this.removeAbortListener) {
	      res?.off('close', this.removeAbortListener);
	      this.removeAbortListener();
	      this.removeAbortListener = null;
	    }
	  }
	}

	function request (opts, callback) {
	  if (callback === undefined) {
	    return new Promise((resolve, reject) => {
	      request.call(this, opts, (err, data) => {
	        return err ? reject(err) : resolve(data)
	      });
	    })
	  }

	  try {
	    this.dispatch(opts, new RequestHandler(opts, callback));
	  } catch (err) {
	    if (typeof callback !== 'function') {
	      throw err
	    }
	    const opaque = opts?.opaque;
	    queueMicrotask(() => callback(err, { opaque }));
	  }
	}

	apiRequest.exports = request;
	apiRequest.exports.RequestHandler = RequestHandler;
	return apiRequest.exports;
}

var abortSignal;
var hasRequiredAbortSignal;

function requireAbortSignal () {
	if (hasRequiredAbortSignal) return abortSignal;
	hasRequiredAbortSignal = 1;
	const { addAbortListener } = requireUtil$7();
	const { RequestAbortedError } = requireErrors();

	const kListener = Symbol('kListener');
	const kSignal = Symbol('kSignal');

	function abort (self) {
	  if (self.abort) {
	    self.abort(self[kSignal]?.reason);
	  } else {
	    self.reason = self[kSignal]?.reason ?? new RequestAbortedError();
	  }
	  removeSignal(self);
	}

	function addSignal (self, signal) {
	  self.reason = null;

	  self[kSignal] = null;
	  self[kListener] = null;

	  if (!signal) {
	    return
	  }

	  if (signal.aborted) {
	    abort(self);
	    return
	  }

	  self[kSignal] = signal;
	  self[kListener] = () => {
	    abort(self);
	  };

	  addAbortListener(self[kSignal], self[kListener]);
	}

	function removeSignal (self) {
	  if (!self[kSignal]) {
	    return
	  }

	  if ('removeEventListener' in self[kSignal]) {
	    self[kSignal].removeEventListener('abort', self[kListener]);
	  } else {
	    self[kSignal].removeListener('abort', self[kListener]);
	  }

	  self[kSignal] = null;
	  self[kListener] = null;
	}

	abortSignal = {
	  addSignal,
	  removeSignal
	};
	return abortSignal;
}

var apiStream;
var hasRequiredApiStream;

function requireApiStream () {
	if (hasRequiredApiStream) return apiStream;
	hasRequiredApiStream = 1;

	const assert = require$$0$4;
	const { finished, PassThrough } = require$$0$5;
	const { InvalidArgumentError, InvalidReturnValueError } = requireErrors();
	const util = requireUtil$7();
	const { getResolveErrorBodyCallback } = requireUtil$5();
	const { AsyncResource } = require$$5$1;
	const { addSignal, removeSignal } = requireAbortSignal();

	class StreamHandler extends AsyncResource {
	  constructor (opts, factory, callback) {
	    if (!opts || typeof opts !== 'object') {
	      throw new InvalidArgumentError('invalid opts')
	    }

	    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError } = opts;

	    try {
	      if (typeof callback !== 'function') {
	        throw new InvalidArgumentError('invalid callback')
	      }

	      if (typeof factory !== 'function') {
	        throw new InvalidArgumentError('invalid factory')
	      }

	      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
	        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
	      }

	      if (method === 'CONNECT') {
	        throw new InvalidArgumentError('invalid method')
	      }

	      if (onInfo && typeof onInfo !== 'function') {
	        throw new InvalidArgumentError('invalid onInfo callback')
	      }

	      super('UNDICI_STREAM');
	    } catch (err) {
	      if (util.isStream(body)) {
	        util.destroy(body.on('error', util.nop), err);
	      }
	      throw err
	    }

	    this.responseHeaders = responseHeaders || null;
	    this.opaque = opaque || null;
	    this.factory = factory;
	    this.callback = callback;
	    this.res = null;
	    this.abort = null;
	    this.context = null;
	    this.trailers = null;
	    this.body = body;
	    this.onInfo = onInfo || null;
	    this.throwOnError = throwOnError || false;

	    if (util.isStream(body)) {
	      body.on('error', (err) => {
	        this.onError(err);
	      });
	    }

	    addSignal(this, signal);
	  }

	  onConnect (abort, context) {
	    if (this.reason) {
	      abort(this.reason);
	      return
	    }

	    assert(this.callback);

	    this.abort = abort;
	    this.context = context;
	  }

	  onHeaders (statusCode, rawHeaders, resume, statusMessage) {
	    const { factory, opaque, context, callback, responseHeaders } = this;

	    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders);

	    if (statusCode < 200) {
	      if (this.onInfo) {
	        this.onInfo({ statusCode, headers });
	      }
	      return
	    }

	    this.factory = null;

	    let res;

	    if (this.throwOnError && statusCode >= 400) {
	      const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers;
	      const contentType = parsedHeaders['content-type'];
	      res = new PassThrough();

	      this.callback = null;
	      this.runInAsyncScope(getResolveErrorBodyCallback, null,
	        { callback, body: res, contentType, statusCode, statusMessage, headers }
	      );
	    } else {
	      if (factory === null) {
	        return
	      }

	      res = this.runInAsyncScope(factory, null, {
	        statusCode,
	        headers,
	        opaque,
	        context
	      });

	      if (
	        !res ||
	        typeof res.write !== 'function' ||
	        typeof res.end !== 'function' ||
	        typeof res.on !== 'function'
	      ) {
	        throw new InvalidReturnValueError('expected Writable')
	      }

	      // TODO: Avoid finished. It registers an unnecessary amount of listeners.
	      finished(res, { readable: false }, (err) => {
	        const { callback, res, opaque, trailers, abort } = this;

	        this.res = null;
	        if (err || !res.readable) {
	          util.destroy(res, err);
	        }

	        this.callback = null;
	        this.runInAsyncScope(callback, null, err || null, { opaque, trailers });

	        if (err) {
	          abort();
	        }
	      });
	    }

	    res.on('drain', resume);

	    this.res = res;

	    const needDrain = res.writableNeedDrain !== undefined
	      ? res.writableNeedDrain
	      : res._writableState?.needDrain;

	    return needDrain !== true
	  }

	  onData (chunk) {
	    const { res } = this;

	    return res ? res.write(chunk) : true
	  }

	  onComplete (trailers) {
	    const { res } = this;

	    removeSignal(this);

	    if (!res) {
	      return
	    }

	    this.trailers = util.parseHeaders(trailers);

	    res.end();
	  }

	  onError (err) {
	    const { res, callback, opaque, body } = this;

	    removeSignal(this);

	    this.factory = null;

	    if (res) {
	      this.res = null;
	      util.destroy(res, err);
	    } else if (callback) {
	      this.callback = null;
	      queueMicrotask(() => {
	        this.runInAsyncScope(callback, null, err, { opaque });
	      });
	    }

	    if (body) {
	      this.body = null;
	      util.destroy(body, err);
	    }
	  }
	}

	function stream (opts, factory, callback) {
	  if (callback === undefined) {
	    return new Promise((resolve, reject) => {
	      stream.call(this, opts, factory, (err, data) => {
	        return err ? reject(err) : resolve(data)
	      });
	    })
	  }

	  try {
	    this.dispatch(opts, new StreamHandler(opts, factory, callback));
	  } catch (err) {
	    if (typeof callback !== 'function') {
	      throw err
	    }
	    const opaque = opts?.opaque;
	    queueMicrotask(() => callback(err, { opaque }));
	  }
	}

	apiStream = stream;
	return apiStream;
}

var apiPipeline;
var hasRequiredApiPipeline;

function requireApiPipeline () {
	if (hasRequiredApiPipeline) return apiPipeline;
	hasRequiredApiPipeline = 1;

	const {
	  Readable,
	  Duplex,
	  PassThrough
	} = require$$0$5;
	const {
	  InvalidArgumentError,
	  InvalidReturnValueError,
	  RequestAbortedError
	} = requireErrors();
	const util = requireUtil$7();
	const { AsyncResource } = require$$5$1;
	const { addSignal, removeSignal } = requireAbortSignal();
	const assert = require$$0$4;

	const kResume = Symbol('resume');

	class PipelineRequest extends Readable {
	  constructor () {
	    super({ autoDestroy: true });

	    this[kResume] = null;
	  }

	  _read () {
	    const { [kResume]: resume } = this;

	    if (resume) {
	      this[kResume] = null;
	      resume();
	    }
	  }

	  _destroy (err, callback) {
	    this._read();

	    callback(err);
	  }
	}

	class PipelineResponse extends Readable {
	  constructor (resume) {
	    super({ autoDestroy: true });
	    this[kResume] = resume;
	  }

	  _read () {
	    this[kResume]();
	  }

	  _destroy (err, callback) {
	    if (!err && !this._readableState.endEmitted) {
	      err = new RequestAbortedError();
	    }

	    callback(err);
	  }
	}

	class PipelineHandler extends AsyncResource {
	  constructor (opts, handler) {
	    if (!opts || typeof opts !== 'object') {
	      throw new InvalidArgumentError('invalid opts')
	    }

	    if (typeof handler !== 'function') {
	      throw new InvalidArgumentError('invalid handler')
	    }

	    const { signal, method, opaque, onInfo, responseHeaders } = opts;

	    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
	      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
	    }

	    if (method === 'CONNECT') {
	      throw new InvalidArgumentError('invalid method')
	    }

	    if (onInfo && typeof onInfo !== 'function') {
	      throw new InvalidArgumentError('invalid onInfo callback')
	    }

	    super('UNDICI_PIPELINE');

	    this.opaque = opaque || null;
	    this.responseHeaders = responseHeaders || null;
	    this.handler = handler;
	    this.abort = null;
	    this.context = null;
	    this.onInfo = onInfo || null;

	    this.req = new PipelineRequest().on('error', util.nop);

	    this.ret = new Duplex({
	      readableObjectMode: opts.objectMode,
	      autoDestroy: true,
	      read: () => {
	        const { body } = this;

	        if (body?.resume) {
	          body.resume();
	        }
	      },
	      write: (chunk, encoding, callback) => {
	        const { req } = this;

	        if (req.push(chunk, encoding) || req._readableState.destroyed) {
	          callback();
	        } else {
	          req[kResume] = callback;
	        }
	      },
	      destroy: (err, callback) => {
	        const { body, req, res, ret, abort } = this;

	        if (!err && !ret._readableState.endEmitted) {
	          err = new RequestAbortedError();
	        }

	        if (abort && err) {
	          abort();
	        }

	        util.destroy(body, err);
	        util.destroy(req, err);
	        util.destroy(res, err);

	        removeSignal(this);

	        callback(err);
	      }
	    }).on('prefinish', () => {
	      const { req } = this;

	      // Node < 15 does not call _final in same tick.
	      req.push(null);
	    });

	    this.res = null;

	    addSignal(this, signal);
	  }

	  onConnect (abort, context) {
	    const { ret, res } = this;

	    if (this.reason) {
	      abort(this.reason);
	      return
	    }

	    assert(!res, 'pipeline cannot be retried');
	    assert(!ret.destroyed);

	    this.abort = abort;
	    this.context = context;
	  }

	  onHeaders (statusCode, rawHeaders, resume) {
	    const { opaque, handler, context } = this;

	    if (statusCode < 200) {
	      if (this.onInfo) {
	        const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders);
	        this.onInfo({ statusCode, headers });
	      }
	      return
	    }

	    this.res = new PipelineResponse(resume);

	    let body;
	    try {
	      this.handler = null;
	      const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders);
	      body = this.runInAsyncScope(handler, null, {
	        statusCode,
	        headers,
	        opaque,
	        body: this.res,
	        context
	      });
	    } catch (err) {
	      this.res.on('error', util.nop);
	      throw err
	    }

	    if (!body || typeof body.on !== 'function') {
	      throw new InvalidReturnValueError('expected Readable')
	    }

	    body
	      .on('data', (chunk) => {
	        const { ret, body } = this;

	        if (!ret.push(chunk) && body.pause) {
	          body.pause();
	        }
	      })
	      .on('error', (err) => {
	        const { ret } = this;

	        util.destroy(ret, err);
	      })
	      .on('end', () => {
	        const { ret } = this;

	        ret.push(null);
	      })
	      .on('close', () => {
	        const { ret } = this;

	        if (!ret._readableState.ended) {
	          util.destroy(ret, new RequestAbortedError());
	        }
	      });

	    this.body = body;
	  }

	  onData (chunk) {
	    const { res } = this;
	    return res.push(chunk)
	  }

	  onComplete (trailers) {
	    const { res } = this;
	    res.push(null);
	  }

	  onError (err) {
	    const { ret } = this;
	    this.handler = null;
	    util.destroy(ret, err);
	  }
	}

	function pipeline (opts, handler) {
	  try {
	    const pipelineHandler = new PipelineHandler(opts, handler);
	    this.dispatch({ ...opts, body: pipelineHandler.req }, pipelineHandler);
	    return pipelineHandler.ret
	  } catch (err) {
	    return new PassThrough().destroy(err)
	  }
	}

	apiPipeline = pipeline;
	return apiPipeline;
}

var apiUpgrade;
var hasRequiredApiUpgrade;

function requireApiUpgrade () {
	if (hasRequiredApiUpgrade) return apiUpgrade;
	hasRequiredApiUpgrade = 1;

	const { InvalidArgumentError, SocketError } = requireErrors();
	const { AsyncResource } = require$$5$1;
	const util = requireUtil$7();
	const { addSignal, removeSignal } = requireAbortSignal();
	const assert = require$$0$4;

	class UpgradeHandler extends AsyncResource {
	  constructor (opts, callback) {
	    if (!opts || typeof opts !== 'object') {
	      throw new InvalidArgumentError('invalid opts')
	    }

	    if (typeof callback !== 'function') {
	      throw new InvalidArgumentError('invalid callback')
	    }

	    const { signal, opaque, responseHeaders } = opts;

	    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
	      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
	    }

	    super('UNDICI_UPGRADE');

	    this.responseHeaders = responseHeaders || null;
	    this.opaque = opaque || null;
	    this.callback = callback;
	    this.abort = null;
	    this.context = null;

	    addSignal(this, signal);
	  }

	  onConnect (abort, context) {
	    if (this.reason) {
	      abort(this.reason);
	      return
	    }

	    assert(this.callback);

	    this.abort = abort;
	    this.context = null;
	  }

	  onHeaders () {
	    throw new SocketError('bad upgrade', null)
	  }

	  onUpgrade (statusCode, rawHeaders, socket) {
	    const { callback, opaque, context } = this;

	    assert.strictEqual(statusCode, 101);

	    removeSignal(this);

	    this.callback = null;
	    const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders);
	    this.runInAsyncScope(callback, null, null, {
	      headers,
	      socket,
	      opaque,
	      context
	    });
	  }

	  onError (err) {
	    const { callback, opaque } = this;

	    removeSignal(this);

	    if (callback) {
	      this.callback = null;
	      queueMicrotask(() => {
	        this.runInAsyncScope(callback, null, err, { opaque });
	      });
	    }
	  }
	}

	function upgrade (opts, callback) {
	  if (callback === undefined) {
	    return new Promise((resolve, reject) => {
	      upgrade.call(this, opts, (err, data) => {
	        return err ? reject(err) : resolve(data)
	      });
	    })
	  }

	  try {
	    const upgradeHandler = new UpgradeHandler(opts, callback);
	    this.dispatch({
	      ...opts,
	      method: opts.method || 'GET',
	      upgrade: opts.protocol || 'Websocket'
	    }, upgradeHandler);
	  } catch (err) {
	    if (typeof callback !== 'function') {
	      throw err
	    }
	    const opaque = opts?.opaque;
	    queueMicrotask(() => callback(err, { opaque }));
	  }
	}

	apiUpgrade = upgrade;
	return apiUpgrade;
}

var apiConnect;
var hasRequiredApiConnect;

function requireApiConnect () {
	if (hasRequiredApiConnect) return apiConnect;
	hasRequiredApiConnect = 1;

	const assert = require$$0$4;
	const { AsyncResource } = require$$5$1;
	const { InvalidArgumentError, SocketError } = requireErrors();
	const util = requireUtil$7();
	const { addSignal, removeSignal } = requireAbortSignal();

	class ConnectHandler extends AsyncResource {
	  constructor (opts, callback) {
	    if (!opts || typeof opts !== 'object') {
	      throw new InvalidArgumentError('invalid opts')
	    }

	    if (typeof callback !== 'function') {
	      throw new InvalidArgumentError('invalid callback')
	    }

	    const { signal, opaque, responseHeaders } = opts;

	    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {
	      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')
	    }

	    super('UNDICI_CONNECT');

	    this.opaque = opaque || null;
	    this.responseHeaders = responseHeaders || null;
	    this.callback = callback;
	    this.abort = null;

	    addSignal(this, signal);
	  }

	  onConnect (abort, context) {
	    if (this.reason) {
	      abort(this.reason);
	      return
	    }

	    assert(this.callback);

	    this.abort = abort;
	    this.context = context;
	  }

	  onHeaders () {
	    throw new SocketError('bad connect', null)
	  }

	  onUpgrade (statusCode, rawHeaders, socket) {
	    const { callback, opaque, context } = this;

	    removeSignal(this);

	    this.callback = null;

	    let headers = rawHeaders;
	    // Indicates is an HTTP2Session
	    if (headers != null) {
	      headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders);
	    }

	    this.runInAsyncScope(callback, null, null, {
	      statusCode,
	      headers,
	      socket,
	      opaque,
	      context
	    });
	  }

	  onError (err) {
	    const { callback, opaque } = this;

	    removeSignal(this);

	    if (callback) {
	      this.callback = null;
	      queueMicrotask(() => {
	        this.runInAsyncScope(callback, null, err, { opaque });
	      });
	    }
	  }
	}

	function connect (opts, callback) {
	  if (callback === undefined) {
	    return new Promise((resolve, reject) => {
	      connect.call(this, opts, (err, data) => {
	        return err ? reject(err) : resolve(data)
	      });
	    })
	  }

	  try {
	    const connectHandler = new ConnectHandler(opts, callback);
	    this.dispatch({ ...opts, method: 'CONNECT' }, connectHandler);
	  } catch (err) {
	    if (typeof callback !== 'function') {
	      throw err
	    }
	    const opaque = opts?.opaque;
	    queueMicrotask(() => callback(err, { opaque }));
	  }
	}

	apiConnect = connect;
	return apiConnect;
}

var hasRequiredApi;

function requireApi () {
	if (hasRequiredApi) return api;
	hasRequiredApi = 1;

	api.request = requireApiRequest();
	api.stream = requireApiStream();
	api.pipeline = requireApiPipeline();
	api.upgrade = requireApiUpgrade();
	api.connect = requireApiConnect();
	return api;
}

var mockErrors;
var hasRequiredMockErrors;

function requireMockErrors () {
	if (hasRequiredMockErrors) return mockErrors;
	hasRequiredMockErrors = 1;

	const { UndiciError } = requireErrors();

	class MockNotMatchedError extends UndiciError {
	  constructor (message) {
	    super(message);
	    Error.captureStackTrace(this, MockNotMatchedError);
	    this.name = 'MockNotMatchedError';
	    this.message = message || 'The request does not match any registered mock dispatches';
	    this.code = 'UND_MOCK_ERR_MOCK_NOT_MATCHED';
	  }
	}

	mockErrors = {
	  MockNotMatchedError
	};
	return mockErrors;
}

var mockSymbols;
var hasRequiredMockSymbols;

function requireMockSymbols () {
	if (hasRequiredMockSymbols) return mockSymbols;
	hasRequiredMockSymbols = 1;

	mockSymbols = {
	  kAgent: Symbol('agent'),
	  kOptions: Symbol('options'),
	  kFactory: Symbol('factory'),
	  kDispatches: Symbol('dispatches'),
	  kDispatchKey: Symbol('dispatch key'),
	  kDefaultHeaders: Symbol('default headers'),
	  kDefaultTrailers: Symbol('default trailers'),
	  kContentLength: Symbol('content length'),
	  kMockAgent: Symbol('mock agent'),
	  kMockAgentSet: Symbol('mock agent set'),
	  kMockAgentGet: Symbol('mock agent get'),
	  kMockDispatch: Symbol('mock dispatch'),
	  kClose: Symbol('close'),
	  kOriginalClose: Symbol('original agent close'),
	  kOrigin: Symbol('origin'),
	  kIsMockActive: Symbol('is mock active'),
	  kNetConnect: Symbol('net connect'),
	  kGetNetConnect: Symbol('get net connect'),
	  kConnected: Symbol('connected')
	};
	return mockSymbols;
}

var mockUtils;
var hasRequiredMockUtils;

function requireMockUtils () {
	if (hasRequiredMockUtils) return mockUtils;
	hasRequiredMockUtils = 1;

	const { MockNotMatchedError } = requireMockErrors();
	const {
	  kDispatches,
	  kMockAgent,
	  kOriginalDispatch,
	  kOrigin,
	  kGetNetConnect
	} = requireMockSymbols();
	const { buildURL } = requireUtil$7();
	const { STATUS_CODES } = require$$2;
	const {
	  types: {
	    isPromise
	  }
	} = require$$0$6;

	function matchValue (match, value) {
	  if (typeof match === 'string') {
	    return match === value
	  }
	  if (match instanceof RegExp) {
	    return match.test(value)
	  }
	  if (typeof match === 'function') {
	    return match(value) === true
	  }
	  return false
	}

	function lowerCaseEntries (headers) {
	  return Object.fromEntries(
	    Object.entries(headers).map(([headerName, headerValue]) => {
	      return [headerName.toLocaleLowerCase(), headerValue]
	    })
	  )
	}

	/**
	 * @param {import('../../index').Headers|string[]|Record<string, string>} headers
	 * @param {string} key
	 */
	function getHeaderByName (headers, key) {
	  if (Array.isArray(headers)) {
	    for (let i = 0; i < headers.length; i += 2) {
	      if (headers[i].toLocaleLowerCase() === key.toLocaleLowerCase()) {
	        return headers[i + 1]
	      }
	    }

	    return undefined
	  } else if (typeof headers.get === 'function') {
	    return headers.get(key)
	  } else {
	    return lowerCaseEntries(headers)[key.toLocaleLowerCase()]
	  }
	}

	/** @param {string[]} headers */
	function buildHeadersFromArray (headers) { // fetch HeadersList
	  const clone = headers.slice();
	  const entries = [];
	  for (let index = 0; index < clone.length; index += 2) {
	    entries.push([clone[index], clone[index + 1]]);
	  }
	  return Object.fromEntries(entries)
	}

	function matchHeaders (mockDispatch, headers) {
	  if (typeof mockDispatch.headers === 'function') {
	    if (Array.isArray(headers)) { // fetch HeadersList
	      headers = buildHeadersFromArray(headers);
	    }
	    return mockDispatch.headers(headers ? lowerCaseEntries(headers) : {})
	  }
	  if (typeof mockDispatch.headers === 'undefined') {
	    return true
	  }
	  if (typeof headers !== 'object' || typeof mockDispatch.headers !== 'object') {
	    return false
	  }

	  for (const [matchHeaderName, matchHeaderValue] of Object.entries(mockDispatch.headers)) {
	    const headerValue = getHeaderByName(headers, matchHeaderName);

	    if (!matchValue(matchHeaderValue, headerValue)) {
	      return false
	    }
	  }
	  return true
	}

	function safeUrl (path) {
	  if (typeof path !== 'string') {
	    return path
	  }

	  const pathSegments = path.split('?');

	  if (pathSegments.length !== 2) {
	    return path
	  }

	  const qp = new URLSearchParams(pathSegments.pop());
	  qp.sort();
	  return [...pathSegments, qp.toString()].join('?')
	}

	function matchKey (mockDispatch, { path, method, body, headers }) {
	  const pathMatch = matchValue(mockDispatch.path, path);
	  const methodMatch = matchValue(mockDispatch.method, method);
	  const bodyMatch = typeof mockDispatch.body !== 'undefined' ? matchValue(mockDispatch.body, body) : true;
	  const headersMatch = matchHeaders(mockDispatch, headers);
	  return pathMatch && methodMatch && bodyMatch && headersMatch
	}

	function getResponseData (data) {
	  if (Buffer.isBuffer(data)) {
	    return data
	  } else if (typeof data === 'object') {
	    return JSON.stringify(data)
	  } else {
	    return data.toString()
	  }
	}

	function getMockDispatch (mockDispatches, key) {
	  const basePath = key.query ? buildURL(key.path, key.query) : key.path;
	  const resolvedPath = typeof basePath === 'string' ? safeUrl(basePath) : basePath;

	  // Match path
	  let matchedMockDispatches = mockDispatches.filter(({ consumed }) => !consumed).filter(({ path }) => matchValue(safeUrl(path), resolvedPath));
	  if (matchedMockDispatches.length === 0) {
	    throw new MockNotMatchedError(`Mock dispatch not matched for path '${resolvedPath}'`)
	  }

	  // Match method
	  matchedMockDispatches = matchedMockDispatches.filter(({ method }) => matchValue(method, key.method));
	  if (matchedMockDispatches.length === 0) {
	    throw new MockNotMatchedError(`Mock dispatch not matched for method '${key.method}' on path '${resolvedPath}'`)
	  }

	  // Match body
	  matchedMockDispatches = matchedMockDispatches.filter(({ body }) => typeof body !== 'undefined' ? matchValue(body, key.body) : true);
	  if (matchedMockDispatches.length === 0) {
	    throw new MockNotMatchedError(`Mock dispatch not matched for body '${key.body}' on path '${resolvedPath}'`)
	  }

	  // Match headers
	  matchedMockDispatches = matchedMockDispatches.filter((mockDispatch) => matchHeaders(mockDispatch, key.headers));
	  if (matchedMockDispatches.length === 0) {
	    const headers = typeof key.headers === 'object' ? JSON.stringify(key.headers) : key.headers;
	    throw new MockNotMatchedError(`Mock dispatch not matched for headers '${headers}' on path '${resolvedPath}'`)
	  }

	  return matchedMockDispatches[0]
	}

	function addMockDispatch (mockDispatches, key, data) {
	  const baseData = { timesInvoked: 0, times: 1, persist: false, consumed: false };
	  const replyData = typeof data === 'function' ? { callback: data } : { ...data };
	  const newMockDispatch = { ...baseData, ...key, pending: true, data: { error: null, ...replyData } };
	  mockDispatches.push(newMockDispatch);
	  return newMockDispatch
	}

	function deleteMockDispatch (mockDispatches, key) {
	  const index = mockDispatches.findIndex(dispatch => {
	    if (!dispatch.consumed) {
	      return false
	    }
	    return matchKey(dispatch, key)
	  });
	  if (index !== -1) {
	    mockDispatches.splice(index, 1);
	  }
	}

	function buildKey (opts) {
	  const { path, method, body, headers, query } = opts;
	  return {
	    path,
	    method,
	    body,
	    headers,
	    query
	  }
	}

	function generateKeyValues (data) {
	  const keys = Object.keys(data);
	  const result = [];
	  for (let i = 0; i < keys.length; ++i) {
	    const key = keys[i];
	    const value = data[key];
	    const name = Buffer.from(`${key}`);
	    if (Array.isArray(value)) {
	      for (let j = 0; j < value.length; ++j) {
	        result.push(name, Buffer.from(`${value[j]}`));
	      }
	    } else {
	      result.push(name, Buffer.from(`${value}`));
	    }
	  }
	  return result
	}

	/**
	 * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Status
	 * @param {number} statusCode
	 */
	function getStatusText (statusCode) {
	  return STATUS_CODES[statusCode] || 'unknown'
	}

	async function getResponse (body) {
	  const buffers = [];
	  for await (const data of body) {
	    buffers.push(data);
	  }
	  return Buffer.concat(buffers).toString('utf8')
	}

	/**
	 * Mock dispatch function used to simulate undici dispatches
	 */
	function mockDispatch (opts, handler) {
	  // Get mock dispatch from built key
	  const key = buildKey(opts);
	  const mockDispatch = getMockDispatch(this[kDispatches], key);

	  mockDispatch.timesInvoked++;

	  // Here's where we resolve a callback if a callback is present for the dispatch data.
	  if (mockDispatch.data.callback) {
	    mockDispatch.data = { ...mockDispatch.data, ...mockDispatch.data.callback(opts) };
	  }

	  // Parse mockDispatch data
	  const { data: { statusCode, data, headers, trailers, error }, delay, persist } = mockDispatch;
	  const { timesInvoked, times } = mockDispatch;

	  // If it's used up and not persistent, mark as consumed
	  mockDispatch.consumed = !persist && timesInvoked >= times;
	  mockDispatch.pending = timesInvoked < times;

	  // If specified, trigger dispatch error
	  if (error !== null) {
	    deleteMockDispatch(this[kDispatches], key);
	    handler.onError(error);
	    return true
	  }

	  // Handle the request with a delay if necessary
	  if (typeof delay === 'number' && delay > 0) {
	    setTimeout(() => {
	      handleReply(this[kDispatches]);
	    }, delay);
	  } else {
	    handleReply(this[kDispatches]);
	  }

	  function handleReply (mockDispatches, _data = data) {
	    // fetch's HeadersList is a 1D string array
	    const optsHeaders = Array.isArray(opts.headers)
	      ? buildHeadersFromArray(opts.headers)
	      : opts.headers;
	    const body = typeof _data === 'function'
	      ? _data({ ...opts, headers: optsHeaders })
	      : _data;

	    // util.types.isPromise is likely needed for jest.
	    if (isPromise(body)) {
	      // If handleReply is asynchronous, throwing an error
	      // in the callback will reject the promise, rather than
	      // synchronously throw the error, which breaks some tests.
	      // Rather, we wait for the callback to resolve if it is a
	      // promise, and then re-run handleReply with the new body.
	      body.then((newData) => handleReply(mockDispatches, newData));
	      return
	    }

	    const responseData = getResponseData(body);
	    const responseHeaders = generateKeyValues(headers);
	    const responseTrailers = generateKeyValues(trailers);

	    handler.onConnect?.(err => handler.onError(err), null);
	    handler.onHeaders?.(statusCode, responseHeaders, resume, getStatusText(statusCode));
	    handler.onData?.(Buffer.from(responseData));
	    handler.onComplete?.(responseTrailers);
	    deleteMockDispatch(mockDispatches, key);
	  }

	  function resume () {}

	  return true
	}

	function buildMockDispatch () {
	  const agent = this[kMockAgent];
	  const origin = this[kOrigin];
	  const originalDispatch = this[kOriginalDispatch];

	  return function dispatch (opts, handler) {
	    if (agent.isMockActive) {
	      try {
	        mockDispatch.call(this, opts, handler);
	      } catch (error) {
	        if (error instanceof MockNotMatchedError) {
	          const netConnect = agent[kGetNetConnect]();
	          if (netConnect === false) {
	            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect disabled)`)
	          }
	          if (checkNetConnect(netConnect, origin)) {
	            originalDispatch.call(this, opts, handler);
	          } else {
	            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect is not enabled for this origin)`)
	          }
	        } else {
	          throw error
	        }
	      }
	    } else {
	      originalDispatch.call(this, opts, handler);
	    }
	  }
	}

	function checkNetConnect (netConnect, origin) {
	  const url = new URL(origin);
	  if (netConnect === true) {
	    return true
	  } else if (Array.isArray(netConnect) && netConnect.some((matcher) => matchValue(matcher, url.host))) {
	    return true
	  }
	  return false
	}

	function buildMockOptions (opts) {
	  if (opts) {
	    const { agent, ...mockOptions } = opts;
	    return mockOptions
	  }
	}

	mockUtils = {
	  getResponseData,
	  getMockDispatch,
	  addMockDispatch,
	  deleteMockDispatch,
	  buildKey,
	  generateKeyValues,
	  matchValue,
	  getResponse,
	  getStatusText,
	  mockDispatch,
	  buildMockDispatch,
	  checkNetConnect,
	  buildMockOptions,
	  getHeaderByName,
	  buildHeadersFromArray
	};
	return mockUtils;
}

var mockInterceptor = {};

var hasRequiredMockInterceptor;

function requireMockInterceptor () {
	if (hasRequiredMockInterceptor) return mockInterceptor;
	hasRequiredMockInterceptor = 1;

	const { getResponseData, buildKey, addMockDispatch } = requireMockUtils();
	const {
	  kDispatches,
	  kDispatchKey,
	  kDefaultHeaders,
	  kDefaultTrailers,
	  kContentLength,
	  kMockDispatch
	} = requireMockSymbols();
	const { InvalidArgumentError } = requireErrors();
	const { buildURL } = requireUtil$7();

	/**
	 * Defines the scope API for an interceptor reply
	 */
	class MockScope {
	  constructor (mockDispatch) {
	    this[kMockDispatch] = mockDispatch;
	  }

	  /**
	   * Delay a reply by a set amount in ms.
	   */
	  delay (waitInMs) {
	    if (typeof waitInMs !== 'number' || !Number.isInteger(waitInMs) || waitInMs <= 0) {
	      throw new InvalidArgumentError('waitInMs must be a valid integer > 0')
	    }

	    this[kMockDispatch].delay = waitInMs;
	    return this
	  }

	  /**
	   * For a defined reply, never mark as consumed.
	   */
	  persist () {
	    this[kMockDispatch].persist = true;
	    return this
	  }

	  /**
	   * Allow one to define a reply for a set amount of matching requests.
	   */
	  times (repeatTimes) {
	    if (typeof repeatTimes !== 'number' || !Number.isInteger(repeatTimes) || repeatTimes <= 0) {
	      throw new InvalidArgumentError('repeatTimes must be a valid integer > 0')
	    }

	    this[kMockDispatch].times = repeatTimes;
	    return this
	  }
	}

	/**
	 * Defines an interceptor for a Mock
	 */
	class MockInterceptor {
	  constructor (opts, mockDispatches) {
	    if (typeof opts !== 'object') {
	      throw new InvalidArgumentError('opts must be an object')
	    }
	    if (typeof opts.path === 'undefined') {
	      throw new InvalidArgumentError('opts.path must be defined')
	    }
	    if (typeof opts.method === 'undefined') {
	      opts.method = 'GET';
	    }
	    // See https://github.com/nodejs/undici/issues/1245
	    // As per RFC 3986, clients are not supposed to send URI
	    // fragments to servers when they retrieve a document,
	    if (typeof opts.path === 'string') {
	      if (opts.query) {
	        opts.path = buildURL(opts.path, opts.query);
	      } else {
	        // Matches https://github.com/nodejs/undici/blob/main/lib/web/fetch/index.js#L1811
	        const parsedURL = new URL(opts.path, 'data://');
	        opts.path = parsedURL.pathname + parsedURL.search;
	      }
	    }
	    if (typeof opts.method === 'string') {
	      opts.method = opts.method.toUpperCase();
	    }

	    this[kDispatchKey] = buildKey(opts);
	    this[kDispatches] = mockDispatches;
	    this[kDefaultHeaders] = {};
	    this[kDefaultTrailers] = {};
	    this[kContentLength] = false;
	  }

	  createMockScopeDispatchData ({ statusCode, data, responseOptions }) {
	    const responseData = getResponseData(data);
	    const contentLength = this[kContentLength] ? { 'content-length': responseData.length } : {};
	    const headers = { ...this[kDefaultHeaders], ...contentLength, ...responseOptions.headers };
	    const trailers = { ...this[kDefaultTrailers], ...responseOptions.trailers };

	    return { statusCode, data, headers, trailers }
	  }

	  validateReplyParameters (replyParameters) {
	    if (typeof replyParameters.statusCode === 'undefined') {
	      throw new InvalidArgumentError('statusCode must be defined')
	    }
	    if (typeof replyParameters.responseOptions !== 'object' || replyParameters.responseOptions === null) {
	      throw new InvalidArgumentError('responseOptions must be an object')
	    }
	  }

	  /**
	   * Mock an undici request with a defined reply.
	   */
	  reply (replyOptionsCallbackOrStatusCode) {
	    // Values of reply aren't available right now as they
	    // can only be available when the reply callback is invoked.
	    if (typeof replyOptionsCallbackOrStatusCode === 'function') {
	      // We'll first wrap the provided callback in another function,
	      // this function will properly resolve the data from the callback
	      // when invoked.
	      const wrappedDefaultsCallback = (opts) => {
	        // Our reply options callback contains the parameter for statusCode, data and options.
	        const resolvedData = replyOptionsCallbackOrStatusCode(opts);

	        // Check if it is in the right format
	        if (typeof resolvedData !== 'object' || resolvedData === null) {
	          throw new InvalidArgumentError('reply options callback must return an object')
	        }

	        const replyParameters = { data: '', responseOptions: {}, ...resolvedData };
	        this.validateReplyParameters(replyParameters);
	        // Since the values can be obtained immediately we return them
	        // from this higher order function that will be resolved later.
	        return {
	          ...this.createMockScopeDispatchData(replyParameters)
	        }
	      };

	      // Add usual dispatch data, but this time set the data parameter to function that will eventually provide data.
	      const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], wrappedDefaultsCallback);
	      return new MockScope(newMockDispatch)
	    }

	    // We can have either one or three parameters, if we get here,
	    // we should have 1-3 parameters. So we spread the arguments of
	    // this function to obtain the parameters, since replyData will always
	    // just be the statusCode.
	    const replyParameters = {
	      statusCode: replyOptionsCallbackOrStatusCode,
	      data: arguments[1] === undefined ? '' : arguments[1],
	      responseOptions: arguments[2] === undefined ? {} : arguments[2]
	    };
	    this.validateReplyParameters(replyParameters);

	    // Send in-already provided data like usual
	    const dispatchData = this.createMockScopeDispatchData(replyParameters);
	    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], dispatchData);
	    return new MockScope(newMockDispatch)
	  }

	  /**
	   * Mock an undici request with a defined error.
	   */
	  replyWithError (error) {
	    if (typeof error === 'undefined') {
	      throw new InvalidArgumentError('error must be defined')
	    }

	    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], { error });
	    return new MockScope(newMockDispatch)
	  }

	  /**
	   * Set default reply headers on the interceptor for subsequent replies
	   */
	  defaultReplyHeaders (headers) {
	    if (typeof headers === 'undefined') {
	      throw new InvalidArgumentError('headers must be defined')
	    }

	    this[kDefaultHeaders] = headers;
	    return this
	  }

	  /**
	   * Set default reply trailers on the interceptor for subsequent replies
	   */
	  defaultReplyTrailers (trailers) {
	    if (typeof trailers === 'undefined') {
	      throw new InvalidArgumentError('trailers must be defined')
	    }

	    this[kDefaultTrailers] = trailers;
	    return this
	  }

	  /**
	   * Set reply content length header for replies on the interceptor
	   */
	  replyContentLength () {
	    this[kContentLength] = true;
	    return this
	  }
	}

	mockInterceptor.MockInterceptor = MockInterceptor;
	mockInterceptor.MockScope = MockScope;
	return mockInterceptor;
}

var mockClient;
var hasRequiredMockClient;

function requireMockClient () {
	if (hasRequiredMockClient) return mockClient;
	hasRequiredMockClient = 1;

	const { promisify } = require$$0$6;
	const Client = requireClient();
	const { buildMockDispatch } = requireMockUtils();
	const {
	  kDispatches,
	  kMockAgent,
	  kClose,
	  kOriginalClose,
	  kOrigin,
	  kOriginalDispatch,
	  kConnected
	} = requireMockSymbols();
	const { MockInterceptor } = requireMockInterceptor();
	const Symbols = requireSymbols$4();
	const { InvalidArgumentError } = requireErrors();

	/**
	 * MockClient provides an API that extends the Client to influence the mockDispatches.
	 */
	class MockClient extends Client {
	  constructor (origin, opts) {
	    super(origin, opts);

	    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {
	      throw new InvalidArgumentError('Argument opts.agent must implement Agent')
	    }

	    this[kMockAgent] = opts.agent;
	    this[kOrigin] = origin;
	    this[kDispatches] = [];
	    this[kConnected] = 1;
	    this[kOriginalDispatch] = this.dispatch;
	    this[kOriginalClose] = this.close.bind(this);

	    this.dispatch = buildMockDispatch.call(this);
	    this.close = this[kClose];
	  }

	  get [Symbols.kConnected] () {
	    return this[kConnected]
	  }

	  /**
	   * Sets up the base interceptor for mocking replies from undici.
	   */
	  intercept (opts) {
	    return new MockInterceptor(opts, this[kDispatches])
	  }

	  async [kClose] () {
	    await promisify(this[kOriginalClose])();
	    this[kConnected] = 0;
	    this[kMockAgent][Symbols.kClients].delete(this[kOrigin]);
	  }
	}

	mockClient = MockClient;
	return mockClient;
}

var mockPool;
var hasRequiredMockPool;

function requireMockPool () {
	if (hasRequiredMockPool) return mockPool;
	hasRequiredMockPool = 1;

	const { promisify } = require$$0$6;
	const Pool = requirePool();
	const { buildMockDispatch } = requireMockUtils();
	const {
	  kDispatches,
	  kMockAgent,
	  kClose,
	  kOriginalClose,
	  kOrigin,
	  kOriginalDispatch,
	  kConnected
	} = requireMockSymbols();
	const { MockInterceptor } = requireMockInterceptor();
	const Symbols = requireSymbols$4();
	const { InvalidArgumentError } = requireErrors();

	/**
	 * MockPool provides an API that extends the Pool to influence the mockDispatches.
	 */
	class MockPool extends Pool {
	  constructor (origin, opts) {
	    super(origin, opts);

	    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {
	      throw new InvalidArgumentError('Argument opts.agent must implement Agent')
	    }

	    this[kMockAgent] = opts.agent;
	    this[kOrigin] = origin;
	    this[kDispatches] = [];
	    this[kConnected] = 1;
	    this[kOriginalDispatch] = this.dispatch;
	    this[kOriginalClose] = this.close.bind(this);

	    this.dispatch = buildMockDispatch.call(this);
	    this.close = this[kClose];
	  }

	  get [Symbols.kConnected] () {
	    return this[kConnected]
	  }

	  /**
	   * Sets up the base interceptor for mocking replies from undici.
	   */
	  intercept (opts) {
	    return new MockInterceptor(opts, this[kDispatches])
	  }

	  async [kClose] () {
	    await promisify(this[kOriginalClose])();
	    this[kConnected] = 0;
	    this[kMockAgent][Symbols.kClients].delete(this[kOrigin]);
	  }
	}

	mockPool = MockPool;
	return mockPool;
}

var pluralizer;
var hasRequiredPluralizer;

function requirePluralizer () {
	if (hasRequiredPluralizer) return pluralizer;
	hasRequiredPluralizer = 1;

	const singulars = {
	  pronoun: 'it',
	  is: 'is',
	  was: 'was',
	  this: 'this'
	};

	const plurals = {
	  pronoun: 'they',
	  is: 'are',
	  was: 'were',
	  this: 'these'
	};

	pluralizer = class Pluralizer {
	  constructor (singular, plural) {
	    this.singular = singular;
	    this.plural = plural;
	  }

	  pluralize (count) {
	    const one = count === 1;
	    const keys = one ? singulars : plurals;
	    const noun = one ? this.singular : this.plural;
	    return { ...keys, count, noun }
	  }
	};
	return pluralizer;
}

var pendingInterceptorsFormatter;
var hasRequiredPendingInterceptorsFormatter;

function requirePendingInterceptorsFormatter () {
	if (hasRequiredPendingInterceptorsFormatter) return pendingInterceptorsFormatter;
	hasRequiredPendingInterceptorsFormatter = 1;

	const { Transform } = require$$0$5;
	const { Console } = require$$1$1;

	const PERSISTENT = process.versions.icu ? 'â' : 'Y ';
	const NOT_PERSISTENT = process.versions.icu ? 'â' : 'N ';

	/**
	 * Gets the output of `console.table(â¦)` as a string.
	 */
	pendingInterceptorsFormatter = class PendingInterceptorsFormatter {
	  constructor ({ disableColors } = {}) {
	    this.transform = new Transform({
	      transform (chunk, _enc, cb) {
	        cb(null, chunk);
	      }
	    });

	    this.logger = new Console({
	      stdout: this.transform,
	      inspectOptions: {
	        colors: !disableColors && !process.env.CI
	      }
	    });
	  }

	  format (pendingInterceptors) {
	    const withPrettyHeaders = pendingInterceptors.map(
	      ({ method, path, data: { statusCode }, persist, times, timesInvoked, origin }) => ({
	        Method: method,
	        Origin: origin,
	        Path: path,
	        'Status code': statusCode,
	        Persistent: persist ? PERSISTENT : NOT_PERSISTENT,
	        Invocations: timesInvoked,
	        Remaining: persist ? Infinity : times - timesInvoked
	      }));

	    this.logger.table(withPrettyHeaders);
	    return this.transform.read().toString()
	  }
	};
	return pendingInterceptorsFormatter;
}

var mockAgent;
var hasRequiredMockAgent;

function requireMockAgent () {
	if (hasRequiredMockAgent) return mockAgent;
	hasRequiredMockAgent = 1;

	const { kClients } = requireSymbols$4();
	const Agent = requireAgent();
	const {
	  kAgent,
	  kMockAgentSet,
	  kMockAgentGet,
	  kDispatches,
	  kIsMockActive,
	  kNetConnect,
	  kGetNetConnect,
	  kOptions,
	  kFactory
	} = requireMockSymbols();
	const MockClient = requireMockClient();
	const MockPool = requireMockPool();
	const { matchValue, buildMockOptions } = requireMockUtils();
	const { InvalidArgumentError, UndiciError } = requireErrors();
	const Dispatcher = requireDispatcher();
	const Pluralizer = requirePluralizer();
	const PendingInterceptorsFormatter = requirePendingInterceptorsFormatter();

	class MockAgent extends Dispatcher {
	  constructor (opts) {
	    super(opts);

	    this[kNetConnect] = true;
	    this[kIsMockActive] = true;

	    // Instantiate Agent and encapsulate
	    if ((opts?.agent && typeof opts.agent.dispatch !== 'function')) {
	      throw new InvalidArgumentError('Argument opts.agent must implement Agent')
	    }
	    const agent = opts?.agent ? opts.agent : new Agent(opts);
	    this[kAgent] = agent;

	    this[kClients] = agent[kClients];
	    this[kOptions] = buildMockOptions(opts);
	  }

	  get (origin) {
	    let dispatcher = this[kMockAgentGet](origin);

	    if (!dispatcher) {
	      dispatcher = this[kFactory](origin);
	      this[kMockAgentSet](origin, dispatcher);
	    }
	    return dispatcher
	  }

	  dispatch (opts, handler) {
	    // Call MockAgent.get to perform additional setup before dispatching as normal
	    this.get(opts.origin);
	    return this[kAgent].dispatch(opts, handler)
	  }

	  async close () {
	    await this[kAgent].close();
	    this[kClients].clear();
	  }

	  deactivate () {
	    this[kIsMockActive] = false;
	  }

	  activate () {
	    this[kIsMockActive] = true;
	  }

	  enableNetConnect (matcher) {
	    if (typeof matcher === 'string' || typeof matcher === 'function' || matcher instanceof RegExp) {
	      if (Array.isArray(this[kNetConnect])) {
	        this[kNetConnect].push(matcher);
	      } else {
	        this[kNetConnect] = [matcher];
	      }
	    } else if (typeof matcher === 'undefined') {
	      this[kNetConnect] = true;
	    } else {
	      throw new InvalidArgumentError('Unsupported matcher. Must be one of String|Function|RegExp.')
	    }
	  }

	  disableNetConnect () {
	    this[kNetConnect] = false;
	  }

	  // This is required to bypass issues caused by using global symbols - see:
	  // https://github.com/nodejs/undici/issues/1447
	  get isMockActive () {
	    return this[kIsMockActive]
	  }

	  [kMockAgentSet] (origin, dispatcher) {
	    this[kClients].set(origin, dispatcher);
	  }

	  [kFactory] (origin) {
	    const mockOptions = Object.assign({ agent: this }, this[kOptions]);
	    return this[kOptions] && this[kOptions].connections === 1
	      ? new MockClient(origin, mockOptions)
	      : new MockPool(origin, mockOptions)
	  }

	  [kMockAgentGet] (origin) {
	    // First check if we can immediately find it
	    const client = this[kClients].get(origin);
	    if (client) {
	      return client
	    }

	    // If the origin is not a string create a dummy parent pool and return to user
	    if (typeof origin !== 'string') {
	      const dispatcher = this[kFactory]('http://localhost:9999');
	      this[kMockAgentSet](origin, dispatcher);
	      return dispatcher
	    }

	    // If we match, create a pool and assign the same dispatches
	    for (const [keyMatcher, nonExplicitDispatcher] of Array.from(this[kClients])) {
	      if (nonExplicitDispatcher && typeof keyMatcher !== 'string' && matchValue(keyMatcher, origin)) {
	        const dispatcher = this[kFactory](origin);
	        this[kMockAgentSet](origin, dispatcher);
	        dispatcher[kDispatches] = nonExplicitDispatcher[kDispatches];
	        return dispatcher
	      }
	    }
	  }

	  [kGetNetConnect] () {
	    return this[kNetConnect]
	  }

	  pendingInterceptors () {
	    const mockAgentClients = this[kClients];

	    return Array.from(mockAgentClients.entries())
	      .flatMap(([origin, scope]) => scope[kDispatches].map(dispatch => ({ ...dispatch, origin })))
	      .filter(({ pending }) => pending)
	  }

	  assertNoPendingInterceptors ({ pendingInterceptorsFormatter = new PendingInterceptorsFormatter() } = {}) {
	    const pending = this.pendingInterceptors();

	    if (pending.length === 0) {
	      return
	    }

	    const pluralizer = new Pluralizer('interceptor', 'interceptors').pluralize(pending.length);

	    throw new UndiciError(`
${pluralizer.count} ${pluralizer.noun} ${pluralizer.is} pending:

${pendingInterceptorsFormatter.format(pending)}
`.trim())
	  }
	}

	mockAgent = MockAgent;
	return mockAgent;
}

var global$1;
var hasRequiredGlobal;

function requireGlobal () {
	if (hasRequiredGlobal) return global$1;
	hasRequiredGlobal = 1;

	// We include a version number for the Dispatcher API. In case of breaking changes,
	// this version number must be increased to avoid conflicts.
	const globalDispatcher = Symbol.for('undici.globalDispatcher.1');
	const { InvalidArgumentError } = requireErrors();
	const Agent = requireAgent();

	if (getGlobalDispatcher() === undefined) {
	  setGlobalDispatcher(new Agent());
	}

	function setGlobalDispatcher (agent) {
	  if (!agent || typeof agent.dispatch !== 'function') {
	    throw new InvalidArgumentError('Argument agent must implement Agent')
	  }
	  Object.defineProperty(globalThis, globalDispatcher, {
	    value: agent,
	    writable: true,
	    enumerable: false,
	    configurable: false
	  });
	}

	function getGlobalDispatcher () {
	  return globalThis[globalDispatcher]
	}

	global$1 = {
	  setGlobalDispatcher,
	  getGlobalDispatcher
	};
	return global$1;
}

var decoratorHandler;
var hasRequiredDecoratorHandler;

function requireDecoratorHandler () {
	if (hasRequiredDecoratorHandler) return decoratorHandler;
	hasRequiredDecoratorHandler = 1;

	decoratorHandler = class DecoratorHandler {
	  #handler

	  constructor (handler) {
	    if (typeof handler !== 'object' || handler === null) {
	      throw new TypeError('handler must be an object')
	    }
	    this.#handler = handler;
	  }

	  onConnect (...args) {
	    return this.#handler.onConnect?.(...args)
	  }

	  onError (...args) {
	    return this.#handler.onError?.(...args)
	  }

	  onUpgrade (...args) {
	    return this.#handler.onUpgrade?.(...args)
	  }

	  onResponseStarted (...args) {
	    return this.#handler.onResponseStarted?.(...args)
	  }

	  onHeaders (...args) {
	    return this.#handler.onHeaders?.(...args)
	  }

	  onData (...args) {
	    return this.#handler.onData?.(...args)
	  }

	  onComplete (...args) {
	    return this.#handler.onComplete?.(...args)
	  }

	  onBodySent (...args) {
	    return this.#handler.onBodySent?.(...args)
	  }
	};
	return decoratorHandler;
}

var redirect;
var hasRequiredRedirect;

function requireRedirect () {
	if (hasRequiredRedirect) return redirect;
	hasRequiredRedirect = 1;
	const RedirectHandler = requireRedirectHandler();

	redirect = opts => {
	  const globalMaxRedirections = opts?.maxRedirections;
	  return dispatch => {
	    return function redirectInterceptor (opts, handler) {
	      const { maxRedirections = globalMaxRedirections, ...baseOpts } = opts;

	      if (!maxRedirections) {
	        return dispatch(opts, handler)
	      }

	      const redirectHandler = new RedirectHandler(
	        dispatch,
	        maxRedirections,
	        opts,
	        handler
	      );

	      return dispatch(baseOpts, redirectHandler)
	    }
	  }
	};
	return redirect;
}

var retry;
var hasRequiredRetry;

function requireRetry () {
	if (hasRequiredRetry) return retry;
	hasRequiredRetry = 1;
	const RetryHandler = requireRetryHandler();

	retry = globalOpts => {
	  return dispatch => {
	    return function retryInterceptor (opts, handler) {
	      return dispatch(
	        opts,
	        new RetryHandler(
	          { ...opts, retryOptions: { ...globalOpts, ...opts.retryOptions } },
	          {
	            handler,
	            dispatch
	          }
	        )
	      )
	    }
	  }
	};
	return retry;
}

var dump;
var hasRequiredDump;

function requireDump () {
	if (hasRequiredDump) return dump;
	hasRequiredDump = 1;

	const util = requireUtil$7();
	const { InvalidArgumentError, RequestAbortedError } = requireErrors();
	const DecoratorHandler = requireDecoratorHandler();

	class DumpHandler extends DecoratorHandler {
	  #maxSize = 1024 * 1024
	  #abort = null
	  #dumped = false
	  #aborted = false
	  #size = 0
	  #reason = null
	  #handler = null

	  constructor ({ maxSize }, handler) {
	    super(handler);

	    if (maxSize != null && (!Number.isFinite(maxSize) || maxSize < 1)) {
	      throw new InvalidArgumentError('maxSize must be a number greater than 0')
	    }

	    this.#maxSize = maxSize ?? this.#maxSize;
	    this.#handler = handler;
	  }

	  onConnect (abort) {
	    this.#abort = abort;

	    this.#handler.onConnect(this.#customAbort.bind(this));
	  }

	  #customAbort (reason) {
	    this.#aborted = true;
	    this.#reason = reason;
	  }

	  // TODO: will require adjustment after new hooks are out
	  onHeaders (statusCode, rawHeaders, resume, statusMessage) {
	    const headers = util.parseHeaders(rawHeaders);
	    const contentLength = headers['content-length'];

	    if (contentLength != null && contentLength > this.#maxSize) {
	      throw new RequestAbortedError(
	        `Response size (${contentLength}) larger than maxSize (${
	          this.#maxSize
	        })`
	      )
	    }

	    if (this.#aborted) {
	      return true
	    }

	    return this.#handler.onHeaders(
	      statusCode,
	      rawHeaders,
	      resume,
	      statusMessage
	    )
	  }

	  onError (err) {
	    if (this.#dumped) {
	      return
	    }

	    err = this.#reason ?? err;

	    this.#handler.onError(err);
	  }

	  onData (chunk) {
	    this.#size = this.#size + chunk.length;

	    if (this.#size >= this.#maxSize) {
	      this.#dumped = true;

	      if (this.#aborted) {
	        this.#handler.onError(this.#reason);
	      } else {
	        this.#handler.onComplete([]);
	      }
	    }

	    return true
	  }

	  onComplete (trailers) {
	    if (this.#dumped) {
	      return
	    }

	    if (this.#aborted) {
	      this.#handler.onError(this.reason);
	      return
	    }

	    this.#handler.onComplete(trailers);
	  }
	}

	function createDumpInterceptor (
	  { maxSize: defaultMaxSize } = {
	    maxSize: 1024 * 1024
	  }
	) {
	  return dispatch => {
	    return function Intercept (opts, handler) {
	      const { dumpMaxSize = defaultMaxSize } =
	        opts;

	      const dumpHandler = new DumpHandler(
	        { maxSize: dumpMaxSize },
	        handler
	      );

	      return dispatch(opts, dumpHandler)
	    }
	  }
	}

	dump = createDumpInterceptor;
	return dump;
}

var headers;
var hasRequiredHeaders;

function requireHeaders () {
	if (hasRequiredHeaders) return headers;
	hasRequiredHeaders = 1;

	const { kConstruct } = requireSymbols$4();
	const { kEnumerableProperty } = requireUtil$7();
	const {
	  iteratorMixin,
	  isValidHeaderName,
	  isValidHeaderValue
	} = requireUtil$6();
	const { webidl } = requireWebidl();
	const assert = require$$0$4;
	const util = require$$0$6;

	const kHeadersMap = Symbol('headers map');
	const kHeadersSortedMap = Symbol('headers map sorted');

	/**
	 * @param {number} code
	 */
	function isHTTPWhiteSpaceCharCode (code) {
	  return code === 0x00a || code === 0x00d || code === 0x009 || code === 0x020
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#concept-header-value-normalize
	 * @param {string} potentialValue
	 */
	function headerValueNormalize (potentialValue) {
	  //  To normalize a byte sequence potentialValue, remove
	  //  any leading and trailing HTTP whitespace bytes from
	  //  potentialValue.
	  let i = 0; let j = potentialValue.length;

	  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(j - 1))) --j;
	  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(i))) ++i;

	  return i === 0 && j === potentialValue.length ? potentialValue : potentialValue.substring(i, j)
	}

	function fill (headers, object) {
	  // To fill a Headers object headers with a given object object, run these steps:

	  // 1. If object is a sequence, then for each header in object:
	  // Note: webidl conversion to array has already been done.
	  if (Array.isArray(object)) {
	    for (let i = 0; i < object.length; ++i) {
	      const header = object[i];
	      // 1. If header does not contain exactly two items, then throw a TypeError.
	      if (header.length !== 2) {
	        throw webidl.errors.exception({
	          header: 'Headers constructor',
	          message: `expected name/value pair to be length 2, found ${header.length}.`
	        })
	      }

	      // 2. Append (headerâs first item, headerâs second item) to headers.
	      appendHeader(headers, header[0], header[1]);
	    }
	  } else if (typeof object === 'object' && object !== null) {
	    // Note: null should throw

	    // 2. Otherwise, object is a record, then for each key â value in object,
	    //    append (key, value) to headers
	    const keys = Object.keys(object);
	    for (let i = 0; i < keys.length; ++i) {
	      appendHeader(headers, keys[i], object[keys[i]]);
	    }
	  } else {
	    throw webidl.errors.conversionFailed({
	      prefix: 'Headers constructor',
	      argument: 'Argument 1',
	      types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']
	    })
	  }
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#concept-headers-append
	 */
	function appendHeader (headers, name, value) {
	  // 1. Normalize value.
	  value = headerValueNormalize(value);

	  // 2. If name is not a header name or value is not a
	  //    header value, then throw a TypeError.
	  if (!isValidHeaderName(name)) {
	    throw webidl.errors.invalidArgument({
	      prefix: 'Headers.append',
	      value: name,
	      type: 'header name'
	    })
	  } else if (!isValidHeaderValue(value)) {
	    throw webidl.errors.invalidArgument({
	      prefix: 'Headers.append',
	      value,
	      type: 'header value'
	    })
	  }

	  // 3. If headersâs guard is "immutable", then throw a TypeError.
	  // 4. Otherwise, if headersâs guard is "request" and name is a
	  //    forbidden header name, return.
	  // 5. Otherwise, if headersâs guard is "request-no-cors":
	  //    TODO
	  // Note: undici does not implement forbidden header names
	  if (getHeadersGuard(headers) === 'immutable') {
	    throw new TypeError('immutable')
	  }

	  // 6. Otherwise, if headersâs guard is "response" and name is a
	  //    forbidden response-header name, return.

	  // 7. Append (name, value) to headersâs header list.
	  return getHeadersList(headers).append(name, value, false)

	  // 8. If headersâs guard is "request-no-cors", then remove
	  //    privileged no-CORS request headers from headers
	}

	function compareHeaderName (a, b) {
	  return a[0] < b[0] ? -1 : 1
	}

	class HeadersList {
	  /** @type {[string, string][]|null} */
	  cookies = null

	  constructor (init) {
	    if (init instanceof HeadersList) {
	      this[kHeadersMap] = new Map(init[kHeadersMap]);
	      this[kHeadersSortedMap] = init[kHeadersSortedMap];
	      this.cookies = init.cookies === null ? null : [...init.cookies];
	    } else {
	      this[kHeadersMap] = new Map(init);
	      this[kHeadersSortedMap] = null;
	    }
	  }

	  /**
	   * @see https://fetch.spec.whatwg.org/#header-list-contains
	   * @param {string} name
	   * @param {boolean} isLowerCase
	   */
	  contains (name, isLowerCase) {
	    // A header list list contains a header name name if list
	    // contains a header whose name is a byte-case-insensitive
	    // match for name.

	    return this[kHeadersMap].has(isLowerCase ? name : name.toLowerCase())
	  }

	  clear () {
	    this[kHeadersMap].clear();
	    this[kHeadersSortedMap] = null;
	    this.cookies = null;
	  }

	  /**
	   * @see https://fetch.spec.whatwg.org/#concept-header-list-append
	   * @param {string} name
	   * @param {string} value
	   * @param {boolean} isLowerCase
	   */
	  append (name, value, isLowerCase) {
	    this[kHeadersSortedMap] = null;

	    // 1. If list contains name, then set name to the first such
	    //    headerâs name.
	    const lowercaseName = isLowerCase ? name : name.toLowerCase();
	    const exists = this[kHeadersMap].get(lowercaseName);

	    // 2. Append (name, value) to list.
	    if (exists) {
	      const delimiter = lowercaseName === 'cookie' ? '; ' : ', ';
	      this[kHeadersMap].set(lowercaseName, {
	        name: exists.name,
	        value: `${exists.value}${delimiter}${value}`
	      });
	    } else {
	      this[kHeadersMap].set(lowercaseName, { name, value });
	    }

	    if (lowercaseName === 'set-cookie') {
	      (this.cookies ??= []).push(value);
	    }
	  }

	  /**
	   * @see https://fetch.spec.whatwg.org/#concept-header-list-set
	   * @param {string} name
	   * @param {string} value
	   * @param {boolean} isLowerCase
	   */
	  set (name, value, isLowerCase) {
	    this[kHeadersSortedMap] = null;
	    const lowercaseName = isLowerCase ? name : name.toLowerCase();

	    if (lowercaseName === 'set-cookie') {
	      this.cookies = [value];
	    }

	    // 1. If list contains name, then set the value of
	    //    the first such header to value and remove the
	    //    others.
	    // 2. Otherwise, append header (name, value) to list.
	    this[kHeadersMap].set(lowercaseName, { name, value });
	  }

	  /**
	   * @see https://fetch.spec.whatwg.org/#concept-header-list-delete
	   * @param {string} name
	   * @param {boolean} isLowerCase
	   */
	  delete (name, isLowerCase) {
	    this[kHeadersSortedMap] = null;
	    if (!isLowerCase) name = name.toLowerCase();

	    if (name === 'set-cookie') {
	      this.cookies = null;
	    }

	    this[kHeadersMap].delete(name);
	  }

	  /**
	   * @see https://fetch.spec.whatwg.org/#concept-header-list-get
	   * @param {string} name
	   * @param {boolean} isLowerCase
	   * @returns {string | null}
	   */
	  get (name, isLowerCase) {
	    // 1. If list does not contain name, then return null.
	    // 2. Return the values of all headers in list whose name
	    //    is a byte-case-insensitive match for name,
	    //    separated from each other by 0x2C 0x20, in order.
	    return this[kHeadersMap].get(isLowerCase ? name : name.toLowerCase())?.value ?? null
	  }

	  * [Symbol.iterator] () {
	    // use the lowercased name
	    for (const { 0: name, 1: { value } } of this[kHeadersMap]) {
	      yield [name, value];
	    }
	  }

	  get entries () {
	    const headers = {};

	    if (this[kHeadersMap].size !== 0) {
	      for (const { name, value } of this[kHeadersMap].values()) {
	        headers[name] = value;
	      }
	    }

	    return headers
	  }

	  rawValues () {
	    return this[kHeadersMap].values()
	  }

	  get entriesList () {
	    const headers = [];

	    if (this[kHeadersMap].size !== 0) {
	      for (const { 0: lowerName, 1: { name, value } } of this[kHeadersMap]) {
	        if (lowerName === 'set-cookie') {
	          for (const cookie of this.cookies) {
	            headers.push([name, cookie]);
	          }
	        } else {
	          headers.push([name, value]);
	        }
	      }
	    }

	    return headers
	  }

	  // https://fetch.spec.whatwg.org/#convert-header-names-to-a-sorted-lowercase-set
	  toSortedArray () {
	    const size = this[kHeadersMap].size;
	    const array = new Array(size);
	    // In most cases, you will use the fast-path.
	    // fast-path: Use binary insertion sort for small arrays.
	    if (size <= 32) {
	      if (size === 0) {
	        // If empty, it is an empty array. To avoid the first index assignment.
	        return array
	      }
	      // Improve performance by unrolling loop and avoiding double-loop.
	      // Double-loop-less version of the binary insertion sort.
	      const iterator = this[kHeadersMap][Symbol.iterator]();
	      const firstValue = iterator.next().value;
	      // set [name, value] to first index.
	      array[0] = [firstValue[0], firstValue[1].value];
	      // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine
	      // 3.2.2. Assert: value is non-null.
	      assert(firstValue[1].value !== null);
	      for (
	        let i = 1, j = 0, right = 0, left = 0, pivot = 0, x, value;
	        i < size;
	        ++i
	      ) {
	        // get next value
	        value = iterator.next().value;
	        // set [name, value] to current index.
	        x = array[i] = [value[0], value[1].value];
	        // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine
	        // 3.2.2. Assert: value is non-null.
	        assert(x[1] !== null);
	        left = 0;
	        right = i;
	        // binary search
	        while (left < right) {
	          // middle index
	          pivot = left + ((right - left) >> 1);
	          // compare header name
	          if (array[pivot][0] <= x[0]) {
	            left = pivot + 1;
	          } else {
	            right = pivot;
	          }
	        }
	        if (i !== pivot) {
	          j = i;
	          while (j > left) {
	            array[j] = array[--j];
	          }
	          array[left] = x;
	        }
	      }
	      /* c8 ignore next 4 */
	      if (!iterator.next().done) {
	        // This is for debugging and will never be called.
	        throw new TypeError('Unreachable')
	      }
	      return array
	    } else {
	      // This case would be a rare occurrence.
	      // slow-path: fallback
	      let i = 0;
	      for (const { 0: name, 1: { value } } of this[kHeadersMap]) {
	        array[i++] = [name, value];
	        // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine
	        // 3.2.2. Assert: value is non-null.
	        assert(value !== null);
	      }
	      return array.sort(compareHeaderName)
	    }
	  }
	}

	// https://fetch.spec.whatwg.org/#headers-class
	class Headers {
	  #guard
	  #headersList

	  constructor (init = undefined) {
	    if (init === kConstruct) {
	      return
	    }

	    this.#headersList = new HeadersList();

	    // The new Headers(init) constructor steps are:

	    // 1. Set thisâs guard to "none".
	    this.#guard = 'none';

	    // 2. If init is given, then fill this with init.
	    if (init !== undefined) {
	      init = webidl.converters.HeadersInit(init, 'Headers contructor', 'init');
	      fill(this, init);
	    }
	  }

	  // https://fetch.spec.whatwg.org/#dom-headers-append
	  append (name, value) {
	    webidl.brandCheck(this, Headers);

	    webidl.argumentLengthCheck(arguments, 2, 'Headers.append');

	    const prefix = 'Headers.append';
	    name = webidl.converters.ByteString(name, prefix, 'name');
	    value = webidl.converters.ByteString(value, prefix, 'value');

	    return appendHeader(this, name, value)
	  }

	  // https://fetch.spec.whatwg.org/#dom-headers-delete
	  delete (name) {
	    webidl.brandCheck(this, Headers);

	    webidl.argumentLengthCheck(arguments, 1, 'Headers.delete');

	    const prefix = 'Headers.delete';
	    name = webidl.converters.ByteString(name, prefix, 'name');

	    // 1. If name is not a header name, then throw a TypeError.
	    if (!isValidHeaderName(name)) {
	      throw webidl.errors.invalidArgument({
	        prefix: 'Headers.delete',
	        value: name,
	        type: 'header name'
	      })
	    }

	    // 2. If thisâs guard is "immutable", then throw a TypeError.
	    // 3. Otherwise, if thisâs guard is "request" and name is a
	    //    forbidden header name, return.
	    // 4. Otherwise, if thisâs guard is "request-no-cors", name
	    //    is not a no-CORS-safelisted request-header name, and
	    //    name is not a privileged no-CORS request-header name,
	    //    return.
	    // 5. Otherwise, if thisâs guard is "response" and name is
	    //    a forbidden response-header name, return.
	    // Note: undici does not implement forbidden header names
	    if (this.#guard === 'immutable') {
	      throw new TypeError('immutable')
	    }

	    // 6. If thisâs header list does not contain name, then
	    //    return.
	    if (!this.#headersList.contains(name, false)) {
	      return
	    }

	    // 7. Delete name from thisâs header list.
	    // 8. If thisâs guard is "request-no-cors", then remove
	    //    privileged no-CORS request headers from this.
	    this.#headersList.delete(name, false);
	  }

	  // https://fetch.spec.whatwg.org/#dom-headers-get
	  get (name) {
	    webidl.brandCheck(this, Headers);

	    webidl.argumentLengthCheck(arguments, 1, 'Headers.get');

	    const prefix = 'Headers.get';
	    name = webidl.converters.ByteString(name, prefix, 'name');

	    // 1. If name is not a header name, then throw a TypeError.
	    if (!isValidHeaderName(name)) {
	      throw webidl.errors.invalidArgument({
	        prefix,
	        value: name,
	        type: 'header name'
	      })
	    }

	    // 2. Return the result of getting name from thisâs header
	    //    list.
	    return this.#headersList.get(name, false)
	  }

	  // https://fetch.spec.whatwg.org/#dom-headers-has
	  has (name) {
	    webidl.brandCheck(this, Headers);

	    webidl.argumentLengthCheck(arguments, 1, 'Headers.has');

	    const prefix = 'Headers.has';
	    name = webidl.converters.ByteString(name, prefix, 'name');

	    // 1. If name is not a header name, then throw a TypeError.
	    if (!isValidHeaderName(name)) {
	      throw webidl.errors.invalidArgument({
	        prefix,
	        value: name,
	        type: 'header name'
	      })
	    }

	    // 2. Return true if thisâs header list contains name;
	    //    otherwise false.
	    return this.#headersList.contains(name, false)
	  }

	  // https://fetch.spec.whatwg.org/#dom-headers-set
	  set (name, value) {
	    webidl.brandCheck(this, Headers);

	    webidl.argumentLengthCheck(arguments, 2, 'Headers.set');

	    const prefix = 'Headers.set';
	    name = webidl.converters.ByteString(name, prefix, 'name');
	    value = webidl.converters.ByteString(value, prefix, 'value');

	    // 1. Normalize value.
	    value = headerValueNormalize(value);

	    // 2. If name is not a header name or value is not a
	    //    header value, then throw a TypeError.
	    if (!isValidHeaderName(name)) {
	      throw webidl.errors.invalidArgument({
	        prefix,
	        value: name,
	        type: 'header name'
	      })
	    } else if (!isValidHeaderValue(value)) {
	      throw webidl.errors.invalidArgument({
	        prefix,
	        value,
	        type: 'header value'
	      })
	    }

	    // 3. If thisâs guard is "immutable", then throw a TypeError.
	    // 4. Otherwise, if thisâs guard is "request" and name is a
	    //    forbidden header name, return.
	    // 5. Otherwise, if thisâs guard is "request-no-cors" and
	    //    name/value is not a no-CORS-safelisted request-header,
	    //    return.
	    // 6. Otherwise, if thisâs guard is "response" and name is a
	    //    forbidden response-header name, return.
	    // Note: undici does not implement forbidden header names
	    if (this.#guard === 'immutable') {
	      throw new TypeError('immutable')
	    }

	    // 7. Set (name, value) in thisâs header list.
	    // 8. If thisâs guard is "request-no-cors", then remove
	    //    privileged no-CORS request headers from this
	    this.#headersList.set(name, value, false);
	  }

	  // https://fetch.spec.whatwg.org/#dom-headers-getsetcookie
	  getSetCookie () {
	    webidl.brandCheck(this, Headers);

	    // 1. If thisâs header list does not contain `Set-Cookie`, then return Â« Â».
	    // 2. Return the values of all headers in thisâs header list whose name is
	    //    a byte-case-insensitive match for `Set-Cookie`, in order.

	    const list = this.#headersList.cookies;

	    if (list) {
	      return [...list]
	    }

	    return []
	  }

	  // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine
	  get [kHeadersSortedMap] () {
	    if (this.#headersList[kHeadersSortedMap]) {
	      return this.#headersList[kHeadersSortedMap]
	    }

	    // 1. Let headers be an empty list of headers with the key being the name
	    //    and value the value.
	    const headers = [];

	    // 2. Let names be the result of convert header names to a sorted-lowercase
	    //    set with all the names of the headers in list.
	    const names = this.#headersList.toSortedArray();

	    const cookies = this.#headersList.cookies;

	    // fast-path
	    if (cookies === null || cookies.length === 1) {
	      // Note: The non-null assertion of value has already been done by `HeadersList#toSortedArray`
	      return (this.#headersList[kHeadersSortedMap] = names)
	    }

	    // 3. For each name of names:
	    for (let i = 0; i < names.length; ++i) {
	      const { 0: name, 1: value } = names[i];
	      // 1. If name is `set-cookie`, then:
	      if (name === 'set-cookie') {
	        // 1. Let values be a list of all values of headers in list whose name
	        //    is a byte-case-insensitive match for name, in order.

	        // 2. For each value of values:
	        // 1. Append (name, value) to headers.
	        for (let j = 0; j < cookies.length; ++j) {
	          headers.push([name, cookies[j]]);
	        }
	      } else {
	        // 2. Otherwise:

	        // 1. Let value be the result of getting name from list.

	        // 2. Assert: value is non-null.
	        // Note: This operation was done by `HeadersList#toSortedArray`.

	        // 3. Append (name, value) to headers.
	        headers.push([name, value]);
	      }
	    }

	    // 4. Return headers.
	    return (this.#headersList[kHeadersSortedMap] = headers)
	  }

	  [util.inspect.custom] (depth, options) {
	    options.depth ??= depth;

	    return `Headers ${util.formatWithOptions(options, this.#headersList.entries)}`
	  }

	  static getHeadersGuard (o) {
	    return o.#guard
	  }

	  static setHeadersGuard (o, guard) {
	    o.#guard = guard;
	  }

	  static getHeadersList (o) {
	    return o.#headersList
	  }

	  static setHeadersList (o, list) {
	    o.#headersList = list;
	  }
	}

	const { getHeadersGuard, setHeadersGuard, getHeadersList, setHeadersList } = Headers;
	Reflect.deleteProperty(Headers, 'getHeadersGuard');
	Reflect.deleteProperty(Headers, 'setHeadersGuard');
	Reflect.deleteProperty(Headers, 'getHeadersList');
	Reflect.deleteProperty(Headers, 'setHeadersList');

	iteratorMixin('Headers', Headers, kHeadersSortedMap, 0, 1);

	Object.defineProperties(Headers.prototype, {
	  append: kEnumerableProperty,
	  delete: kEnumerableProperty,
	  get: kEnumerableProperty,
	  has: kEnumerableProperty,
	  set: kEnumerableProperty,
	  getSetCookie: kEnumerableProperty,
	  [Symbol.toStringTag]: {
	    value: 'Headers',
	    configurable: true
	  },
	  [util.inspect.custom]: {
	    enumerable: false
	  }
	});

	webidl.converters.HeadersInit = function (V, prefix, argument) {
	  if (webidl.util.Type(V) === 'Object') {
	    const iterator = Reflect.get(V, Symbol.iterator);

	    // A work-around to ensure we send the properly-cased Headers when V is a Headers object.
	    // Read https://github.com/nodejs/undici/pull/3159#issuecomment-2075537226 before touching, please.
	    if (!util.types.isProxy(V) && iterator === Headers.prototype.entries) { // Headers object
	      try {
	        return getHeadersList(V).entriesList
	      } catch {
	        // fall-through
	      }
	    }

	    if (typeof iterator === 'function') {
	      return webidl.converters['sequence<sequence<ByteString>>'](V, prefix, argument, iterator.bind(V))
	    }

	    return webidl.converters['record<ByteString, ByteString>'](V, prefix, argument)
	  }

	  throw webidl.errors.conversionFailed({
	    prefix: 'Headers constructor',
	    argument: 'Argument 1',
	    types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']
	  })
	};

	headers = {
	  fill,
	  // for test.
	  compareHeaderName,
	  Headers,
	  HeadersList,
	  getHeadersGuard,
	  setHeadersGuard,
	  setHeadersList,
	  getHeadersList
	};
	return headers;
}

var response;
var hasRequiredResponse;

function requireResponse () {
	if (hasRequiredResponse) return response;
	hasRequiredResponse = 1;

	const { Headers, HeadersList, fill, getHeadersGuard, setHeadersGuard, setHeadersList } = requireHeaders();
	const { extractBody, cloneBody, mixinBody } = requireBody();
	const util = requireUtil$7();
	const nodeUtil = require$$0$6;
	const { kEnumerableProperty } = util;
	const {
	  isValidReasonPhrase,
	  isCancelled,
	  isAborted,
	  isBlobLike,
	  serializeJavascriptValueToJSONString,
	  isErrorLike,
	  isomorphicEncode,
	  environmentSettingsObject: relevantRealm
	} = requireUtil$6();
	const {
	  redirectStatusSet,
	  nullBodyStatus
	} = requireConstants$2();
	const { kState, kHeaders } = requireSymbols$3();
	const { webidl } = requireWebidl();
	const { FormData } = requireFormdata();
	const { URLSerializer } = requireDataUrl();
	const { kConstruct } = requireSymbols$4();
	const assert = require$$0$4;
	const { types } = require$$0$6;
	const { isDisturbed, isErrored } = require$$0$5;

	const textEncoder = new TextEncoder('utf-8');

	const hasFinalizationRegistry = globalThis.FinalizationRegistry && process.version.indexOf('v18') !== 0;
	let registry;

	if (hasFinalizationRegistry) {
	  registry = new FinalizationRegistry((stream) => {
	    if (!stream.locked && !isDisturbed(stream) && !isErrored(stream)) {
	      stream.cancel('Response object has been garbage collected').catch(noop);
	    }
	  });
	}

	function noop () {}

	// https://fetch.spec.whatwg.org/#response-class
	class Response {
	  // Creates network error Response.
	  static error () {
	    // The static error() method steps are to return the result of creating a
	    // Response object, given a new network error, "immutable", and thisâs
	    // relevant Realm.
	    const responseObject = fromInnerResponse(makeNetworkError(), 'immutable');

	    return responseObject
	  }

	  // https://fetch.spec.whatwg.org/#dom-response-json
	  static json (data, init = {}) {
	    webidl.argumentLengthCheck(arguments, 1, 'Response.json');

	    if (init !== null) {
	      init = webidl.converters.ResponseInit(init);
	    }

	    // 1. Let bytes the result of running serialize a JavaScript value to JSON bytes on data.
	    const bytes = textEncoder.encode(
	      serializeJavascriptValueToJSONString(data)
	    );

	    // 2. Let body be the result of extracting bytes.
	    const body = extractBody(bytes);

	    // 3. Let responseObject be the result of creating a Response object, given a new response,
	    //    "response", and thisâs relevant Realm.
	    const responseObject = fromInnerResponse(makeResponse({}), 'response');

	    // 4. Perform initialize a response given responseObject, init, and (body, "application/json").
	    initializeResponse(responseObject, init, { body: body[0], type: 'application/json' });

	    // 5. Return responseObject.
	    return responseObject
	  }

	  // Creates a redirect Response that redirects to url with status status.
	  static redirect (url, status = 302) {
	    webidl.argumentLengthCheck(arguments, 1, 'Response.redirect');

	    url = webidl.converters.USVString(url);
	    status = webidl.converters['unsigned short'](status);

	    // 1. Let parsedURL be the result of parsing url with current settings
	    // objectâs API base URL.
	    // 2. If parsedURL is failure, then throw a TypeError.
	    // TODO: base-URL?
	    let parsedURL;
	    try {
	      parsedURL = new URL(url, relevantRealm.settingsObject.baseUrl);
	    } catch (err) {
	      throw new TypeError(`Failed to parse URL from ${url}`, { cause: err })
	    }

	    // 3. If status is not a redirect status, then throw a RangeError.
	    if (!redirectStatusSet.has(status)) {
	      throw new RangeError(`Invalid status code ${status}`)
	    }

	    // 4. Let responseObject be the result of creating a Response object,
	    // given a new response, "immutable", and thisâs relevant Realm.
	    const responseObject = fromInnerResponse(makeResponse({}), 'immutable');

	    // 5. Set responseObjectâs responseâs status to status.
	    responseObject[kState].status = status;

	    // 6. Let value be parsedURL, serialized and isomorphic encoded.
	    const value = isomorphicEncode(URLSerializer(parsedURL));

	    // 7. Append `Location`/value to responseObjectâs responseâs header list.
	    responseObject[kState].headersList.append('location', value, true);

	    // 8. Return responseObject.
	    return responseObject
	  }

	  // https://fetch.spec.whatwg.org/#dom-response
	  constructor (body = null, init = {}) {
	    if (body === kConstruct) {
	      return
	    }

	    if (body !== null) {
	      body = webidl.converters.BodyInit(body);
	    }

	    init = webidl.converters.ResponseInit(init);

	    // 1. Set thisâs response to a new response.
	    this[kState] = makeResponse({});

	    // 2. Set thisâs headers to a new Headers object with thisâs relevant
	    // Realm, whose header list is thisâs responseâs header list and guard
	    // is "response".
	    this[kHeaders] = new Headers(kConstruct);
	    setHeadersGuard(this[kHeaders], 'response');
	    setHeadersList(this[kHeaders], this[kState].headersList);

	    // 3. Let bodyWithType be null.
	    let bodyWithType = null;

	    // 4. If body is non-null, then set bodyWithType to the result of extracting body.
	    if (body != null) {
	      const [extractedBody, type] = extractBody(body);
	      bodyWithType = { body: extractedBody, type };
	    }

	    // 5. Perform initialize a response given this, init, and bodyWithType.
	    initializeResponse(this, init, bodyWithType);
	  }

	  // Returns responseâs type, e.g., "cors".
	  get type () {
	    webidl.brandCheck(this, Response);

	    // The type getter steps are to return thisâs responseâs type.
	    return this[kState].type
	  }

	  // Returns responseâs URL, if it has one; otherwise the empty string.
	  get url () {
	    webidl.brandCheck(this, Response);

	    const urlList = this[kState].urlList;

	    // The url getter steps are to return the empty string if thisâs
	    // responseâs URL is null; otherwise thisâs responseâs URL,
	    // serialized with exclude fragment set to true.
	    const url = urlList[urlList.length - 1] ?? null;

	    if (url === null) {
	      return ''
	    }

	    return URLSerializer(url, true)
	  }

	  // Returns whether response was obtained through a redirect.
	  get redirected () {
	    webidl.brandCheck(this, Response);

	    // The redirected getter steps are to return true if thisâs responseâs URL
	    // list has more than one item; otherwise false.
	    return this[kState].urlList.length > 1
	  }

	  // Returns responseâs status.
	  get status () {
	    webidl.brandCheck(this, Response);

	    // The status getter steps are to return thisâs responseâs status.
	    return this[kState].status
	  }

	  // Returns whether responseâs status is an ok status.
	  get ok () {
	    webidl.brandCheck(this, Response);

	    // The ok getter steps are to return true if thisâs responseâs status is an
	    // ok status; otherwise false.
	    return this[kState].status >= 200 && this[kState].status <= 299
	  }

	  // Returns responseâs status message.
	  get statusText () {
	    webidl.brandCheck(this, Response);

	    // The statusText getter steps are to return thisâs responseâs status
	    // message.
	    return this[kState].statusText
	  }

	  // Returns responseâs headers as Headers.
	  get headers () {
	    webidl.brandCheck(this, Response);

	    // The headers getter steps are to return thisâs headers.
	    return this[kHeaders]
	  }

	  get body () {
	    webidl.brandCheck(this, Response);

	    return this[kState].body ? this[kState].body.stream : null
	  }

	  get bodyUsed () {
	    webidl.brandCheck(this, Response);

	    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)
	  }

	  // Returns a clone of response.
	  clone () {
	    webidl.brandCheck(this, Response);

	    // 1. If this is unusable, then throw a TypeError.
	    if (this.bodyUsed || this.body?.locked) {
	      throw webidl.errors.exception({
	        header: 'Response.clone',
	        message: 'Body has already been consumed.'
	      })
	    }

	    // 2. Let clonedResponse be the result of cloning thisâs response.
	    const clonedResponse = cloneResponse(this[kState]);

	    // 3. Return the result of creating a Response object, given
	    // clonedResponse, thisâs headersâs guard, and thisâs relevant Realm.
	    return fromInnerResponse(clonedResponse, getHeadersGuard(this[kHeaders]))
	  }

	  [nodeUtil.inspect.custom] (depth, options) {
	    if (options.depth === null) {
	      options.depth = 2;
	    }

	    options.colors ??= true;

	    const properties = {
	      status: this.status,
	      statusText: this.statusText,
	      headers: this.headers,
	      body: this.body,
	      bodyUsed: this.bodyUsed,
	      ok: this.ok,
	      redirected: this.redirected,
	      type: this.type,
	      url: this.url
	    };

	    return `Response ${nodeUtil.formatWithOptions(options, properties)}`
	  }
	}

	mixinBody(Response);

	Object.defineProperties(Response.prototype, {
	  type: kEnumerableProperty,
	  url: kEnumerableProperty,
	  status: kEnumerableProperty,
	  ok: kEnumerableProperty,
	  redirected: kEnumerableProperty,
	  statusText: kEnumerableProperty,
	  headers: kEnumerableProperty,
	  clone: kEnumerableProperty,
	  body: kEnumerableProperty,
	  bodyUsed: kEnumerableProperty,
	  [Symbol.toStringTag]: {
	    value: 'Response',
	    configurable: true
	  }
	});

	Object.defineProperties(Response, {
	  json: kEnumerableProperty,
	  redirect: kEnumerableProperty,
	  error: kEnumerableProperty
	});

	// https://fetch.spec.whatwg.org/#concept-response-clone
	function cloneResponse (response) {
	  // To clone a response response, run these steps:

	  // 1. If response is a filtered response, then return a new identical
	  // filtered response whose internal response is a clone of responseâs
	  // internal response.
	  if (response.internalResponse) {
	    return filterResponse(
	      cloneResponse(response.internalResponse),
	      response.type
	    )
	  }

	  // 2. Let newResponse be a copy of response, except for its body.
	  const newResponse = makeResponse({ ...response, body: null });

	  // 3. If responseâs body is non-null, then set newResponseâs body to the
	  // result of cloning responseâs body.
	  if (response.body != null) {
	    newResponse.body = cloneBody(response.body);
	  }

	  // 4. Return newResponse.
	  return newResponse
	}

	function makeResponse (init) {
	  return {
	    aborted: false,
	    rangeRequested: false,
	    timingAllowPassed: false,
	    requestIncludesCredentials: false,
	    type: 'default',
	    status: 200,
	    timingInfo: null,
	    cacheState: '',
	    statusText: '',
	    ...init,
	    headersList: init?.headersList
	      ? new HeadersList(init?.headersList)
	      : new HeadersList(),
	    urlList: init?.urlList ? [...init.urlList] : []
	  }
	}

	function makeNetworkError (reason) {
	  const isError = isErrorLike(reason);
	  return makeResponse({
	    type: 'error',
	    status: 0,
	    error: isError
	      ? reason
	      : new Error(reason ? String(reason) : reason),
	    aborted: reason && reason.name === 'AbortError'
	  })
	}

	// @see https://fetch.spec.whatwg.org/#concept-network-error
	function isNetworkError (response) {
	  return (
	    // A network error is a response whose type is "error",
	    response.type === 'error' &&
	    // status is 0
	    response.status === 0
	  )
	}

	function makeFilteredResponse (response, state) {
	  state = {
	    internalResponse: response,
	    ...state
	  };

	  return new Proxy(response, {
	    get (target, p) {
	      return p in state ? state[p] : target[p]
	    },
	    set (target, p, value) {
	      assert(!(p in state));
	      target[p] = value;
	      return true
	    }
	  })
	}

	// https://fetch.spec.whatwg.org/#concept-filtered-response
	function filterResponse (response, type) {
	  // Set response to the following filtered response with response as its
	  // internal response, depending on requestâs response tainting:
	  if (type === 'basic') {
	    // A basic filtered response is a filtered response whose type is "basic"
	    // and header list excludes any headers in internal responseâs header list
	    // whose name is a forbidden response-header name.

	    // Note: undici does not implement forbidden response-header names
	    return makeFilteredResponse(response, {
	      type: 'basic',
	      headersList: response.headersList
	    })
	  } else if (type === 'cors') {
	    // A CORS filtered response is a filtered response whose type is "cors"
	    // and header list excludes any headers in internal responseâs header
	    // list whose name is not a CORS-safelisted response-header name, given
	    // internal responseâs CORS-exposed header-name list.

	    // Note: undici does not implement CORS-safelisted response-header names
	    return makeFilteredResponse(response, {
	      type: 'cors',
	      headersList: response.headersList
	    })
	  } else if (type === 'opaque') {
	    // An opaque filtered response is a filtered response whose type is
	    // "opaque", URL list is the empty list, status is 0, status message
	    // is the empty byte sequence, header list is empty, and body is null.

	    return makeFilteredResponse(response, {
	      type: 'opaque',
	      urlList: Object.freeze([]),
	      status: 0,
	      statusText: '',
	      body: null
	    })
	  } else if (type === 'opaqueredirect') {
	    // An opaque-redirect filtered response is a filtered response whose type
	    // is "opaqueredirect", status is 0, status message is the empty byte
	    // sequence, header list is empty, and body is null.

	    return makeFilteredResponse(response, {
	      type: 'opaqueredirect',
	      status: 0,
	      statusText: '',
	      headersList: [],
	      body: null
	    })
	  } else {
	    assert(false);
	  }
	}

	// https://fetch.spec.whatwg.org/#appropriate-network-error
	function makeAppropriateNetworkError (fetchParams, err = null) {
	  // 1. Assert: fetchParams is canceled.
	  assert(isCancelled(fetchParams));

	  // 2. Return an aborted network error if fetchParams is aborted;
	  // otherwise return a network error.
	  return isAborted(fetchParams)
	    ? makeNetworkError(Object.assign(new DOMException('The operation was aborted.', 'AbortError'), { cause: err }))
	    : makeNetworkError(Object.assign(new DOMException('Request was cancelled.'), { cause: err }))
	}

	// https://whatpr.org/fetch/1392.html#initialize-a-response
	function initializeResponse (response, init, body) {
	  // 1. If init["status"] is not in the range 200 to 599, inclusive, then
	  //    throw a RangeError.
	  if (init.status !== null && (init.status < 200 || init.status > 599)) {
	    throw new RangeError('init["status"] must be in the range of 200 to 599, inclusive.')
	  }

	  // 2. If init["statusText"] does not match the reason-phrase token production,
	  //    then throw a TypeError.
	  if ('statusText' in init && init.statusText != null) {
	    // See, https://datatracker.ietf.org/doc/html/rfc7230#section-3.1.2:
	    //   reason-phrase  = *( HTAB / SP / VCHAR / obs-text )
	    if (!isValidReasonPhrase(String(init.statusText))) {
	      throw new TypeError('Invalid statusText')
	    }
	  }

	  // 3. Set responseâs responseâs status to init["status"].
	  if ('status' in init && init.status != null) {
	    response[kState].status = init.status;
	  }

	  // 4. Set responseâs responseâs status message to init["statusText"].
	  if ('statusText' in init && init.statusText != null) {
	    response[kState].statusText = init.statusText;
	  }

	  // 5. If init["headers"] exists, then fill responseâs headers with init["headers"].
	  if ('headers' in init && init.headers != null) {
	    fill(response[kHeaders], init.headers);
	  }

	  // 6. If body was given, then:
	  if (body) {
	    // 1. If response's status is a null body status, then throw a TypeError.
	    if (nullBodyStatus.includes(response.status)) {
	      throw webidl.errors.exception({
	        header: 'Response constructor',
	        message: `Invalid response status code ${response.status}`
	      })
	    }

	    // 2. Set response's body to body's body.
	    response[kState].body = body.body;

	    // 3. If body's type is non-null and response's header list does not contain
	    //    `Content-Type`, then append (`Content-Type`, body's type) to response's header list.
	    if (body.type != null && !response[kState].headersList.contains('content-type', true)) {
	      response[kState].headersList.append('content-type', body.type, true);
	    }
	  }
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#response-create
	 * @param {any} innerResponse
	 * @param {'request' | 'immutable' | 'request-no-cors' | 'response' | 'none'} guard
	 * @returns {Response}
	 */
	function fromInnerResponse (innerResponse, guard) {
	  const response = new Response(kConstruct);
	  response[kState] = innerResponse;
	  response[kHeaders] = new Headers(kConstruct);
	  setHeadersList(response[kHeaders], innerResponse.headersList);
	  setHeadersGuard(response[kHeaders], guard);

	  if (hasFinalizationRegistry && innerResponse.body?.stream) {
	    registry.register(response, innerResponse.body.stream);
	  }

	  return response
	}

	webidl.converters.ReadableStream = webidl.interfaceConverter(
	  ReadableStream
	);

	webidl.converters.FormData = webidl.interfaceConverter(
	  FormData
	);

	webidl.converters.URLSearchParams = webidl.interfaceConverter(
	  URLSearchParams
	);

	// https://fetch.spec.whatwg.org/#typedefdef-xmlhttprequestbodyinit
	webidl.converters.XMLHttpRequestBodyInit = function (V, prefix, name) {
	  if (typeof V === 'string') {
	    return webidl.converters.USVString(V, prefix, name)
	  }

	  if (isBlobLike(V)) {
	    return webidl.converters.Blob(V, prefix, name, { strict: false })
	  }

	  if (ArrayBuffer.isView(V) || types.isArrayBuffer(V)) {
	    return webidl.converters.BufferSource(V, prefix, name)
	  }

	  if (util.isFormDataLike(V)) {
	    return webidl.converters.FormData(V, prefix, name, { strict: false })
	  }

	  if (V instanceof URLSearchParams) {
	    return webidl.converters.URLSearchParams(V, prefix, name)
	  }

	  return webidl.converters.DOMString(V, prefix, name)
	};

	// https://fetch.spec.whatwg.org/#bodyinit
	webidl.converters.BodyInit = function (V, prefix, argument) {
	  if (V instanceof ReadableStream) {
	    return webidl.converters.ReadableStream(V, prefix, argument)
	  }

	  // Note: the spec doesn't include async iterables,
	  // this is an undici extension.
	  if (V?.[Symbol.asyncIterator]) {
	    return V
	  }

	  return webidl.converters.XMLHttpRequestBodyInit(V, prefix, argument)
	};

	webidl.converters.ResponseInit = webidl.dictionaryConverter([
	  {
	    key: 'status',
	    converter: webidl.converters['unsigned short'],
	    defaultValue: () => 200
	  },
	  {
	    key: 'statusText',
	    converter: webidl.converters.ByteString,
	    defaultValue: () => ''
	  },
	  {
	    key: 'headers',
	    converter: webidl.converters.HeadersInit
	  }
	]);

	response = {
	  isNetworkError,
	  makeNetworkError,
	  makeResponse,
	  makeAppropriateNetworkError,
	  filterResponse,
	  Response,
	  cloneResponse,
	  fromInnerResponse
	};
	return response;
}

var dispatcherWeakref;
var hasRequiredDispatcherWeakref;

function requireDispatcherWeakref () {
	if (hasRequiredDispatcherWeakref) return dispatcherWeakref;
	hasRequiredDispatcherWeakref = 1;

	const { kConnected, kSize } = requireSymbols$4();

	class CompatWeakRef {
	  constructor (value) {
	    this.value = value;
	  }

	  deref () {
	    return this.value[kConnected] === 0 && this.value[kSize] === 0
	      ? undefined
	      : this.value
	  }
	}

	class CompatFinalizer {
	  constructor (finalizer) {
	    this.finalizer = finalizer;
	  }

	  register (dispatcher, key) {
	    if (dispatcher.on) {
	      dispatcher.on('disconnect', () => {
	        if (dispatcher[kConnected] === 0 && dispatcher[kSize] === 0) {
	          this.finalizer(key);
	        }
	      });
	    }
	  }

	  unregister (key) {}
	}

	dispatcherWeakref = function () {
	  // FIXME: remove workaround when the Node bug is backported to v18
	  // https://github.com/nodejs/node/issues/49344#issuecomment-1741776308
	  if (process.env.NODE_V8_COVERAGE && process.version.startsWith('v18')) {
	    process._rawDebug('Using compatibility WeakRef and FinalizationRegistry');
	    return {
	      WeakRef: CompatWeakRef,
	      FinalizationRegistry: CompatFinalizer
	    }
	  }
	  return { WeakRef, FinalizationRegistry }
	};
	return dispatcherWeakref;
}

/* globals AbortController */

var request;
var hasRequiredRequest;

function requireRequest () {
	if (hasRequiredRequest) return request;
	hasRequiredRequest = 1;

	const { extractBody, mixinBody, cloneBody } = requireBody();
	const { Headers, fill: fillHeaders, HeadersList, setHeadersGuard, getHeadersGuard, setHeadersList, getHeadersList } = requireHeaders();
	const { FinalizationRegistry } = requireDispatcherWeakref()();
	const util = requireUtil$7();
	const nodeUtil = require$$0$6;
	const {
	  isValidHTTPToken,
	  sameOrigin,
	  environmentSettingsObject
	} = requireUtil$6();
	const {
	  forbiddenMethodsSet,
	  corsSafeListedMethodsSet,
	  referrerPolicy,
	  requestRedirect,
	  requestMode,
	  requestCredentials,
	  requestCache,
	  requestDuplex
	} = requireConstants$2();
	const { kEnumerableProperty, normalizedMethodRecordsBase, normalizedMethodRecords } = util;
	const { kHeaders, kSignal, kState, kDispatcher } = requireSymbols$3();
	const { webidl } = requireWebidl();
	const { URLSerializer } = requireDataUrl();
	const { kConstruct } = requireSymbols$4();
	const assert = require$$0$4;
	const { getMaxListeners, setMaxListeners, getEventListeners, defaultMaxListeners } = require$$8;

	const kAbortController = Symbol('abortController');

	const requestFinalizer = new FinalizationRegistry(({ signal, abort }) => {
	  signal.removeEventListener('abort', abort);
	});

	const dependentControllerMap = new WeakMap();

	function buildAbort (acRef) {
	  return abort

	  function abort () {
	    const ac = acRef.deref();
	    if (ac !== undefined) {
	      // Currently, there is a problem with FinalizationRegistry.
	      // https://github.com/nodejs/node/issues/49344
	      // https://github.com/nodejs/node/issues/47748
	      // In the case of abort, the first step is to unregister from it.
	      // If the controller can refer to it, it is still registered.
	      // It will be removed in the future.
	      requestFinalizer.unregister(abort);

	      // Unsubscribe a listener.
	      // FinalizationRegistry will no longer be called, so this must be done.
	      this.removeEventListener('abort', abort);

	      ac.abort(this.reason);

	      const controllerList = dependentControllerMap.get(ac.signal);

	      if (controllerList !== undefined) {
	        if (controllerList.size !== 0) {
	          for (const ref of controllerList) {
	            const ctrl = ref.deref();
	            if (ctrl !== undefined) {
	              ctrl.abort(this.reason);
	            }
	          }
	          controllerList.clear();
	        }
	        dependentControllerMap.delete(ac.signal);
	      }
	    }
	  }
	}

	let patchMethodWarning = false;

	// https://fetch.spec.whatwg.org/#request-class
	class Request {
	  // https://fetch.spec.whatwg.org/#dom-request
	  constructor (input, init = {}) {
	    if (input === kConstruct) {
	      return
	    }

	    const prefix = 'Request constructor';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    input = webidl.converters.RequestInfo(input, prefix, 'input');
	    init = webidl.converters.RequestInit(init, prefix, 'init');

	    // 1. Let request be null.
	    let request = null;

	    // 2. Let fallbackMode be null.
	    let fallbackMode = null;

	    // 3. Let baseURL be thisâs relevant settings objectâs API base URL.
	    const baseUrl = environmentSettingsObject.settingsObject.baseUrl;

	    // 4. Let signal be null.
	    let signal = null;

	    // 5. If input is a string, then:
	    if (typeof input === 'string') {
	      this[kDispatcher] = init.dispatcher;

	      // 1. Let parsedURL be the result of parsing input with baseURL.
	      // 2. If parsedURL is failure, then throw a TypeError.
	      let parsedURL;
	      try {
	        parsedURL = new URL(input, baseUrl);
	      } catch (err) {
	        throw new TypeError('Failed to parse URL from ' + input, { cause: err })
	      }

	      // 3. If parsedURL includes credentials, then throw a TypeError.
	      if (parsedURL.username || parsedURL.password) {
	        throw new TypeError(
	          'Request cannot be constructed from a URL that includes credentials: ' +
	            input
	        )
	      }

	      // 4. Set request to a new request whose URL is parsedURL.
	      request = makeRequest({ urlList: [parsedURL] });

	      // 5. Set fallbackMode to "cors".
	      fallbackMode = 'cors';
	    } else {
	      this[kDispatcher] = init.dispatcher || input[kDispatcher];

	      // 6. Otherwise:

	      // 7. Assert: input is a Request object.
	      assert(input instanceof Request);

	      // 8. Set request to inputâs request.
	      request = input[kState];

	      // 9. Set signal to inputâs signal.
	      signal = input[kSignal];
	    }

	    // 7. Let origin be thisâs relevant settings objectâs origin.
	    const origin = environmentSettingsObject.settingsObject.origin;

	    // 8. Let window be "client".
	    let window = 'client';

	    // 9. If requestâs window is an environment settings object and its origin
	    // is same origin with origin, then set window to requestâs window.
	    if (
	      request.window?.constructor?.name === 'EnvironmentSettingsObject' &&
	      sameOrigin(request.window, origin)
	    ) {
	      window = request.window;
	    }

	    // 10. If init["window"] exists and is non-null, then throw a TypeError.
	    if (init.window != null) {
	      throw new TypeError(`'window' option '${window}' must be null`)
	    }

	    // 11. If init["window"] exists, then set window to "no-window".
	    if ('window' in init) {
	      window = 'no-window';
	    }

	    // 12. Set request to a new request with the following properties:
	    request = makeRequest({
	      // URL requestâs URL.
	      // undici implementation note: this is set as the first item in request's urlList in makeRequest
	      // method requestâs method.
	      method: request.method,
	      // header list A copy of requestâs header list.
	      // undici implementation note: headersList is cloned in makeRequest
	      headersList: request.headersList,
	      // unsafe-request flag Set.
	      unsafeRequest: request.unsafeRequest,
	      // client Thisâs relevant settings object.
	      client: environmentSettingsObject.settingsObject,
	      // window window.
	      window,
	      // priority requestâs priority.
	      priority: request.priority,
	      // origin requestâs origin. The propagation of the origin is only significant for navigation requests
	      // being handled by a service worker. In this scenario a request can have an origin that is different
	      // from the current client.
	      origin: request.origin,
	      // referrer requestâs referrer.
	      referrer: request.referrer,
	      // referrer policy requestâs referrer policy.
	      referrerPolicy: request.referrerPolicy,
	      // mode requestâs mode.
	      mode: request.mode,
	      // credentials mode requestâs credentials mode.
	      credentials: request.credentials,
	      // cache mode requestâs cache mode.
	      cache: request.cache,
	      // redirect mode requestâs redirect mode.
	      redirect: request.redirect,
	      // integrity metadata requestâs integrity metadata.
	      integrity: request.integrity,
	      // keepalive requestâs keepalive.
	      keepalive: request.keepalive,
	      // reload-navigation flag requestâs reload-navigation flag.
	      reloadNavigation: request.reloadNavigation,
	      // history-navigation flag requestâs history-navigation flag.
	      historyNavigation: request.historyNavigation,
	      // URL list A clone of requestâs URL list.
	      urlList: [...request.urlList]
	    });

	    const initHasKey = Object.keys(init).length !== 0;

	    // 13. If init is not empty, then:
	    if (initHasKey) {
	      // 1. If requestâs mode is "navigate", then set it to "same-origin".
	      if (request.mode === 'navigate') {
	        request.mode = 'same-origin';
	      }

	      // 2. Unset requestâs reload-navigation flag.
	      request.reloadNavigation = false;

	      // 3. Unset requestâs history-navigation flag.
	      request.historyNavigation = false;

	      // 4. Set requestâs origin to "client".
	      request.origin = 'client';

	      // 5. Set requestâs referrer to "client"
	      request.referrer = 'client';

	      // 6. Set requestâs referrer policy to the empty string.
	      request.referrerPolicy = '';

	      // 7. Set requestâs URL to requestâs current URL.
	      request.url = request.urlList[request.urlList.length - 1];

	      // 8. Set requestâs URL list to Â« requestâs URL Â».
	      request.urlList = [request.url];
	    }

	    // 14. If init["referrer"] exists, then:
	    if (init.referrer !== undefined) {
	      // 1. Let referrer be init["referrer"].
	      const referrer = init.referrer;

	      // 2. If referrer is the empty string, then set requestâs referrer to "no-referrer".
	      if (referrer === '') {
	        request.referrer = 'no-referrer';
	      } else {
	        // 1. Let parsedReferrer be the result of parsing referrer with
	        // baseURL.
	        // 2. If parsedReferrer is failure, then throw a TypeError.
	        let parsedReferrer;
	        try {
	          parsedReferrer = new URL(referrer, baseUrl);
	        } catch (err) {
	          throw new TypeError(`Referrer "${referrer}" is not a valid URL.`, { cause: err })
	        }

	        // 3. If one of the following is true
	        // - parsedReferrerâs scheme is "about" and path is the string "client"
	        // - parsedReferrerâs origin is not same origin with origin
	        // then set requestâs referrer to "client".
	        if (
	          (parsedReferrer.protocol === 'about:' && parsedReferrer.hostname === 'client') ||
	          (origin && !sameOrigin(parsedReferrer, environmentSettingsObject.settingsObject.baseUrl))
	        ) {
	          request.referrer = 'client';
	        } else {
	          // 4. Otherwise, set requestâs referrer to parsedReferrer.
	          request.referrer = parsedReferrer;
	        }
	      }
	    }

	    // 15. If init["referrerPolicy"] exists, then set requestâs referrer policy
	    // to it.
	    if (init.referrerPolicy !== undefined) {
	      request.referrerPolicy = init.referrerPolicy;
	    }

	    // 16. Let mode be init["mode"] if it exists, and fallbackMode otherwise.
	    let mode;
	    if (init.mode !== undefined) {
	      mode = init.mode;
	    } else {
	      mode = fallbackMode;
	    }

	    // 17. If mode is "navigate", then throw a TypeError.
	    if (mode === 'navigate') {
	      throw webidl.errors.exception({
	        header: 'Request constructor',
	        message: 'invalid request mode navigate.'
	      })
	    }

	    // 18. If mode is non-null, set requestâs mode to mode.
	    if (mode != null) {
	      request.mode = mode;
	    }

	    // 19. If init["credentials"] exists, then set requestâs credentials mode
	    // to it.
	    if (init.credentials !== undefined) {
	      request.credentials = init.credentials;
	    }

	    // 18. If init["cache"] exists, then set requestâs cache mode to it.
	    if (init.cache !== undefined) {
	      request.cache = init.cache;
	    }

	    // 21. If requestâs cache mode is "only-if-cached" and requestâs mode is
	    // not "same-origin", then throw a TypeError.
	    if (request.cache === 'only-if-cached' && request.mode !== 'same-origin') {
	      throw new TypeError(
	        "'only-if-cached' can be set only with 'same-origin' mode"
	      )
	    }

	    // 22. If init["redirect"] exists, then set requestâs redirect mode to it.
	    if (init.redirect !== undefined) {
	      request.redirect = init.redirect;
	    }

	    // 23. If init["integrity"] exists, then set requestâs integrity metadata to it.
	    if (init.integrity != null) {
	      request.integrity = String(init.integrity);
	    }

	    // 24. If init["keepalive"] exists, then set requestâs keepalive to it.
	    if (init.keepalive !== undefined) {
	      request.keepalive = Boolean(init.keepalive);
	    }

	    // 25. If init["method"] exists, then:
	    if (init.method !== undefined) {
	      // 1. Let method be init["method"].
	      let method = init.method;

	      const mayBeNormalized = normalizedMethodRecords[method];

	      if (mayBeNormalized !== undefined) {
	        // Note: Bypass validation DELETE, GET, HEAD, OPTIONS, POST, PUT, PATCH and these lowercase ones
	        request.method = mayBeNormalized;
	      } else {
	        // 2. If method is not a method or method is a forbidden method, then
	        // throw a TypeError.
	        if (!isValidHTTPToken(method)) {
	          throw new TypeError(`'${method}' is not a valid HTTP method.`)
	        }

	        const upperCase = method.toUpperCase();

	        if (forbiddenMethodsSet.has(upperCase)) {
	          throw new TypeError(`'${method}' HTTP method is unsupported.`)
	        }

	        // 3. Normalize method.
	        // https://fetch.spec.whatwg.org/#concept-method-normalize
	        // Note: must be in uppercase
	        method = normalizedMethodRecordsBase[upperCase] ?? method;

	        // 4. Set requestâs method to method.
	        request.method = method;
	      }

	      if (!patchMethodWarning && request.method === 'patch') {
	        process.emitWarning('Using `patch` is highly likely to result in a `405 Method Not Allowed`. `PATCH` is much more likely to succeed.', {
	          code: 'UNDICI-FETCH-patch'
	        });

	        patchMethodWarning = true;
	      }
	    }

	    // 26. If init["signal"] exists, then set signal to it.
	    if (init.signal !== undefined) {
	      signal = init.signal;
	    }

	    // 27. Set thisâs request to request.
	    this[kState] = request;

	    // 28. Set thisâs signal to a new AbortSignal object with thisâs relevant
	    // Realm.
	    // TODO: could this be simplified with AbortSignal.any
	    // (https://dom.spec.whatwg.org/#dom-abortsignal-any)
	    const ac = new AbortController();
	    this[kSignal] = ac.signal;

	    // 29. If signal is not null, then make thisâs signal follow signal.
	    if (signal != null) {
	      if (
	        !signal ||
	        typeof signal.aborted !== 'boolean' ||
	        typeof signal.addEventListener !== 'function'
	      ) {
	        throw new TypeError(
	          "Failed to construct 'Request': member signal is not of type AbortSignal."
	        )
	      }

	      if (signal.aborted) {
	        ac.abort(signal.reason);
	      } else {
	        // Keep a strong ref to ac while request object
	        // is alive. This is needed to prevent AbortController
	        // from being prematurely garbage collected.
	        // See, https://github.com/nodejs/undici/issues/1926.
	        this[kAbortController] = ac;

	        const acRef = new WeakRef(ac);
	        const abort = buildAbort(acRef);

	        // Third-party AbortControllers may not work with these.
	        // See, https://github.com/nodejs/undici/pull/1910#issuecomment-1464495619.
	        try {
	          // If the max amount of listeners is equal to the default, increase it
	          // This is only available in node >= v19.9.0
	          if (typeof getMaxListeners === 'function' && getMaxListeners(signal) === defaultMaxListeners) {
	            setMaxListeners(1500, signal);
	          } else if (getEventListeners(signal, 'abort').length >= defaultMaxListeners) {
	            setMaxListeners(1500, signal);
	          }
	        } catch {}

	        util.addAbortListener(signal, abort);
	        // The third argument must be a registry key to be unregistered.
	        // Without it, you cannot unregister.
	        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry
	        // abort is used as the unregister key. (because it is unique)
	        requestFinalizer.register(ac, { signal, abort }, abort);
	      }
	    }

	    // 30. Set thisâs headers to a new Headers object with thisâs relevant
	    // Realm, whose header list is requestâs header list and guard is
	    // "request".
	    this[kHeaders] = new Headers(kConstruct);
	    setHeadersList(this[kHeaders], request.headersList);
	    setHeadersGuard(this[kHeaders], 'request');

	    // 31. If thisâs requestâs mode is "no-cors", then:
	    if (mode === 'no-cors') {
	      // 1. If thisâs requestâs method is not a CORS-safelisted method,
	      // then throw a TypeError.
	      if (!corsSafeListedMethodsSet.has(request.method)) {
	        throw new TypeError(
	          `'${request.method} is unsupported in no-cors mode.`
	        )
	      }

	      // 2. Set thisâs headersâs guard to "request-no-cors".
	      setHeadersGuard(this[kHeaders], 'request-no-cors');
	    }

	    // 32. If init is not empty, then:
	    if (initHasKey) {
	      /** @type {HeadersList} */
	      const headersList = getHeadersList(this[kHeaders]);
	      // 1. Let headers be a copy of thisâs headers and its associated header
	      // list.
	      // 2. If init["headers"] exists, then set headers to init["headers"].
	      const headers = init.headers !== undefined ? init.headers : new HeadersList(headersList);

	      // 3. Empty thisâs headersâs header list.
	      headersList.clear();

	      // 4. If headers is a Headers object, then for each header in its header
	      // list, append headerâs name/headerâs value to thisâs headers.
	      if (headers instanceof HeadersList) {
	        for (const { name, value } of headers.rawValues()) {
	          headersList.append(name, value, false);
	        }
	        // Note: Copy the `set-cookie` meta-data.
	        headersList.cookies = headers.cookies;
	      } else {
	        // 5. Otherwise, fill thisâs headers with headers.
	        fillHeaders(this[kHeaders], headers);
	      }
	    }

	    // 33. Let inputBody be inputâs requestâs body if input is a Request
	    // object; otherwise null.
	    const inputBody = input instanceof Request ? input[kState].body : null;

	    // 34. If either init["body"] exists and is non-null or inputBody is
	    // non-null, and requestâs method is `GET` or `HEAD`, then throw a
	    // TypeError.
	    if (
	      (init.body != null || inputBody != null) &&
	      (request.method === 'GET' || request.method === 'HEAD')
	    ) {
	      throw new TypeError('Request with GET/HEAD method cannot have body.')
	    }

	    // 35. Let initBody be null.
	    let initBody = null;

	    // 36. If init["body"] exists and is non-null, then:
	    if (init.body != null) {
	      // 1. Let Content-Type be null.
	      // 2. Set initBody and Content-Type to the result of extracting
	      // init["body"], with keepalive set to requestâs keepalive.
	      const [extractedBody, contentType] = extractBody(
	        init.body,
	        request.keepalive
	      );
	      initBody = extractedBody;

	      // 3, If Content-Type is non-null and thisâs headersâs header list does
	      // not contain `Content-Type`, then append `Content-Type`/Content-Type to
	      // thisâs headers.
	      if (contentType && !getHeadersList(this[kHeaders]).contains('content-type', true)) {
	        this[kHeaders].append('content-type', contentType);
	      }
	    }

	    // 37. Let inputOrInitBody be initBody if it is non-null; otherwise
	    // inputBody.
	    const inputOrInitBody = initBody ?? inputBody;

	    // 38. If inputOrInitBody is non-null and inputOrInitBodyâs source is
	    // null, then:
	    if (inputOrInitBody != null && inputOrInitBody.source == null) {
	      // 1. If initBody is non-null and init["duplex"] does not exist,
	      //    then throw a TypeError.
	      if (initBody != null && init.duplex == null) {
	        throw new TypeError('RequestInit: duplex option is required when sending a body.')
	      }

	      // 2. If thisâs requestâs mode is neither "same-origin" nor "cors",
	      // then throw a TypeError.
	      if (request.mode !== 'same-origin' && request.mode !== 'cors') {
	        throw new TypeError(
	          'If request is made from ReadableStream, mode should be "same-origin" or "cors"'
	        )
	      }

	      // 3. Set thisâs requestâs use-CORS-preflight flag.
	      request.useCORSPreflightFlag = true;
	    }

	    // 39. Let finalBody be inputOrInitBody.
	    let finalBody = inputOrInitBody;

	    // 40. If initBody is null and inputBody is non-null, then:
	    if (initBody == null && inputBody != null) {
	      // 1. If input is unusable, then throw a TypeError.
	      if (util.isDisturbed(inputBody.stream) || inputBody.stream.locked) {
	        throw new TypeError(
	          'Cannot construct a Request with a Request object that has already been used.'
	        )
	      }

	      // 2. Set finalBody to the result of creating a proxy for inputBody.
	      // https://streams.spec.whatwg.org/#readablestream-create-a-proxy
	      const identityTransform = new TransformStream();
	      inputBody.stream.pipeThrough(identityTransform);
	      finalBody = {
	        source: inputBody.source,
	        length: inputBody.length,
	        stream: identityTransform.readable
	      };
	    }

	    // 41. Set thisâs requestâs body to finalBody.
	    this[kState].body = finalBody;
	  }

	  // Returns requestâs HTTP method, which is "GET" by default.
	  get method () {
	    webidl.brandCheck(this, Request);

	    // The method getter steps are to return thisâs requestâs method.
	    return this[kState].method
	  }

	  // Returns the URL of request as a string.
	  get url () {
	    webidl.brandCheck(this, Request);

	    // The url getter steps are to return thisâs requestâs URL, serialized.
	    return URLSerializer(this[kState].url)
	  }

	  // Returns a Headers object consisting of the headers associated with request.
	  // Note that headers added in the network layer by the user agent will not
	  // be accounted for in this object, e.g., the "Host" header.
	  get headers () {
	    webidl.brandCheck(this, Request);

	    // The headers getter steps are to return thisâs headers.
	    return this[kHeaders]
	  }

	  // Returns the kind of resource requested by request, e.g., "document"
	  // or "script".
	  get destination () {
	    webidl.brandCheck(this, Request);

	    // The destination getter are to return thisâs requestâs destination.
	    return this[kState].destination
	  }

	  // Returns the referrer of request. Its value can be a same-origin URL if
	  // explicitly set in init, the empty string to indicate no referrer, and
	  // "about:client" when defaulting to the globalâs default. This is used
	  // during fetching to determine the value of the `Referer` header of the
	  // request being made.
	  get referrer () {
	    webidl.brandCheck(this, Request);

	    // 1. If thisâs requestâs referrer is "no-referrer", then return the
	    // empty string.
	    if (this[kState].referrer === 'no-referrer') {
	      return ''
	    }

	    // 2. If thisâs requestâs referrer is "client", then return
	    // "about:client".
	    if (this[kState].referrer === 'client') {
	      return 'about:client'
	    }

	    // Return thisâs requestâs referrer, serialized.
	    return this[kState].referrer.toString()
	  }

	  // Returns the referrer policy associated with request.
	  // This is used during fetching to compute the value of the requestâs
	  // referrer.
	  get referrerPolicy () {
	    webidl.brandCheck(this, Request);

	    // The referrerPolicy getter steps are to return thisâs requestâs referrer policy.
	    return this[kState].referrerPolicy
	  }

	  // Returns the mode associated with request, which is a string indicating
	  // whether the request will use CORS, or will be restricted to same-origin
	  // URLs.
	  get mode () {
	    webidl.brandCheck(this, Request);

	    // The mode getter steps are to return thisâs requestâs mode.
	    return this[kState].mode
	  }

	  // Returns the credentials mode associated with request,
	  // which is a string indicating whether credentials will be sent with the
	  // request always, never, or only when sent to a same-origin URL.
	  get credentials () {
	    // The credentials getter steps are to return thisâs requestâs credentials mode.
	    return this[kState].credentials
	  }

	  // Returns the cache mode associated with request,
	  // which is a string indicating how the request will
	  // interact with the browserâs cache when fetching.
	  get cache () {
	    webidl.brandCheck(this, Request);

	    // The cache getter steps are to return thisâs requestâs cache mode.
	    return this[kState].cache
	  }

	  // Returns the redirect mode associated with request,
	  // which is a string indicating how redirects for the
	  // request will be handled during fetching. A request
	  // will follow redirects by default.
	  get redirect () {
	    webidl.brandCheck(this, Request);

	    // The redirect getter steps are to return thisâs requestâs redirect mode.
	    return this[kState].redirect
	  }

	  // Returns requestâs subresource integrity metadata, which is a
	  // cryptographic hash of the resource being fetched. Its value
	  // consists of multiple hashes separated by whitespace. [SRI]
	  get integrity () {
	    webidl.brandCheck(this, Request);

	    // The integrity getter steps are to return thisâs requestâs integrity
	    // metadata.
	    return this[kState].integrity
	  }

	  // Returns a boolean indicating whether or not request can outlive the
	  // global in which it was created.
	  get keepalive () {
	    webidl.brandCheck(this, Request);

	    // The keepalive getter steps are to return thisâs requestâs keepalive.
	    return this[kState].keepalive
	  }

	  // Returns a boolean indicating whether or not request is for a reload
	  // navigation.
	  get isReloadNavigation () {
	    webidl.brandCheck(this, Request);

	    // The isReloadNavigation getter steps are to return true if thisâs
	    // requestâs reload-navigation flag is set; otherwise false.
	    return this[kState].reloadNavigation
	  }

	  // Returns a boolean indicating whether or not request is for a history
	  // navigation (a.k.a. back-forward navigation).
	  get isHistoryNavigation () {
	    webidl.brandCheck(this, Request);

	    // The isHistoryNavigation getter steps are to return true if thisâs requestâs
	    // history-navigation flag is set; otherwise false.
	    return this[kState].historyNavigation
	  }

	  // Returns the signal associated with request, which is an AbortSignal
	  // object indicating whether or not request has been aborted, and its
	  // abort event handler.
	  get signal () {
	    webidl.brandCheck(this, Request);

	    // The signal getter steps are to return thisâs signal.
	    return this[kSignal]
	  }

	  get body () {
	    webidl.brandCheck(this, Request);

	    return this[kState].body ? this[kState].body.stream : null
	  }

	  get bodyUsed () {
	    webidl.brandCheck(this, Request);

	    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)
	  }

	  get duplex () {
	    webidl.brandCheck(this, Request);

	    return 'half'
	  }

	  // Returns a clone of request.
	  clone () {
	    webidl.brandCheck(this, Request);

	    // 1. If this is unusable, then throw a TypeError.
	    if (this.bodyUsed || this.body?.locked) {
	      throw new TypeError('unusable')
	    }

	    // 2. Let clonedRequest be the result of cloning thisâs request.
	    const clonedRequest = cloneRequest(this[kState]);

	    // 3. Let clonedRequestObject be the result of creating a Request object,
	    // given clonedRequest, thisâs headersâs guard, and thisâs relevant Realm.
	    // 4. Make clonedRequestObjectâs signal follow thisâs signal.
	    const ac = new AbortController();
	    if (this.signal.aborted) {
	      ac.abort(this.signal.reason);
	    } else {
	      let list = dependentControllerMap.get(this.signal);
	      if (list === undefined) {
	        list = new Set();
	        dependentControllerMap.set(this.signal, list);
	      }
	      const acRef = new WeakRef(ac);
	      list.add(acRef);
	      util.addAbortListener(
	        ac.signal,
	        buildAbort(acRef)
	      );
	    }

	    // 4. Return clonedRequestObject.
	    return fromInnerRequest(clonedRequest, ac.signal, getHeadersGuard(this[kHeaders]))
	  }

	  [nodeUtil.inspect.custom] (depth, options) {
	    if (options.depth === null) {
	      options.depth = 2;
	    }

	    options.colors ??= true;

	    const properties = {
	      method: this.method,
	      url: this.url,
	      headers: this.headers,
	      destination: this.destination,
	      referrer: this.referrer,
	      referrerPolicy: this.referrerPolicy,
	      mode: this.mode,
	      credentials: this.credentials,
	      cache: this.cache,
	      redirect: this.redirect,
	      integrity: this.integrity,
	      keepalive: this.keepalive,
	      isReloadNavigation: this.isReloadNavigation,
	      isHistoryNavigation: this.isHistoryNavigation,
	      signal: this.signal
	    };

	    return `Request ${nodeUtil.formatWithOptions(options, properties)}`
	  }
	}

	mixinBody(Request);

	// https://fetch.spec.whatwg.org/#requests
	function makeRequest (init) {
	  return {
	    method: init.method ?? 'GET',
	    localURLsOnly: init.localURLsOnly ?? false,
	    unsafeRequest: init.unsafeRequest ?? false,
	    body: init.body ?? null,
	    client: init.client ?? null,
	    reservedClient: init.reservedClient ?? null,
	    replacesClientId: init.replacesClientId ?? '',
	    window: init.window ?? 'client',
	    keepalive: init.keepalive ?? false,
	    serviceWorkers: init.serviceWorkers ?? 'all',
	    initiator: init.initiator ?? '',
	    destination: init.destination ?? '',
	    priority: init.priority ?? null,
	    origin: init.origin ?? 'client',
	    policyContainer: init.policyContainer ?? 'client',
	    referrer: init.referrer ?? 'client',
	    referrerPolicy: init.referrerPolicy ?? '',
	    mode: init.mode ?? 'no-cors',
	    useCORSPreflightFlag: init.useCORSPreflightFlag ?? false,
	    credentials: init.credentials ?? 'same-origin',
	    useCredentials: init.useCredentials ?? false,
	    cache: init.cache ?? 'default',
	    redirect: init.redirect ?? 'follow',
	    integrity: init.integrity ?? '',
	    cryptoGraphicsNonceMetadata: init.cryptoGraphicsNonceMetadata ?? '',
	    parserMetadata: init.parserMetadata ?? '',
	    reloadNavigation: init.reloadNavigation ?? false,
	    historyNavigation: init.historyNavigation ?? false,
	    userActivation: init.userActivation ?? false,
	    taintedOrigin: init.taintedOrigin ?? false,
	    redirectCount: init.redirectCount ?? 0,
	    responseTainting: init.responseTainting ?? 'basic',
	    preventNoCacheCacheControlHeaderModification: init.preventNoCacheCacheControlHeaderModification ?? false,
	    done: init.done ?? false,
	    timingAllowFailed: init.timingAllowFailed ?? false,
	    urlList: init.urlList,
	    url: init.urlList[0],
	    headersList: init.headersList
	      ? new HeadersList(init.headersList)
	      : new HeadersList()
	  }
	}

	// https://fetch.spec.whatwg.org/#concept-request-clone
	function cloneRequest (request) {
	  // To clone a request request, run these steps:

	  // 1. Let newRequest be a copy of request, except for its body.
	  const newRequest = makeRequest({ ...request, body: null });

	  // 2. If requestâs body is non-null, set newRequestâs body to the
	  // result of cloning requestâs body.
	  if (request.body != null) {
	    newRequest.body = cloneBody(request.body);
	  }

	  // 3. Return newRequest.
	  return newRequest
	}

	/**
	 * @see https://fetch.spec.whatwg.org/#request-create
	 * @param {any} innerRequest
	 * @param {AbortSignal} signal
	 * @param {'request' | 'immutable' | 'request-no-cors' | 'response' | 'none'} guard
	 * @returns {Request}
	 */
	function fromInnerRequest (innerRequest, signal, guard) {
	  const request = new Request(kConstruct);
	  request[kState] = innerRequest;
	  request[kSignal] = signal;
	  request[kHeaders] = new Headers(kConstruct);
	  setHeadersList(request[kHeaders], innerRequest.headersList);
	  setHeadersGuard(request[kHeaders], guard);
	  return request
	}

	Object.defineProperties(Request.prototype, {
	  method: kEnumerableProperty,
	  url: kEnumerableProperty,
	  headers: kEnumerableProperty,
	  redirect: kEnumerableProperty,
	  clone: kEnumerableProperty,
	  signal: kEnumerableProperty,
	  duplex: kEnumerableProperty,
	  destination: kEnumerableProperty,
	  body: kEnumerableProperty,
	  bodyUsed: kEnumerableProperty,
	  isHistoryNavigation: kEnumerableProperty,
	  isReloadNavigation: kEnumerableProperty,
	  keepalive: kEnumerableProperty,
	  integrity: kEnumerableProperty,
	  cache: kEnumerableProperty,
	  credentials: kEnumerableProperty,
	  attribute: kEnumerableProperty,
	  referrerPolicy: kEnumerableProperty,
	  referrer: kEnumerableProperty,
	  mode: kEnumerableProperty,
	  [Symbol.toStringTag]: {
	    value: 'Request',
	    configurable: true
	  }
	});

	webidl.converters.Request = webidl.interfaceConverter(
	  Request
	);

	// https://fetch.spec.whatwg.org/#requestinfo
	webidl.converters.RequestInfo = function (V, prefix, argument) {
	  if (typeof V === 'string') {
	    return webidl.converters.USVString(V, prefix, argument)
	  }

	  if (V instanceof Request) {
	    return webidl.converters.Request(V, prefix, argument)
	  }

	  return webidl.converters.USVString(V, prefix, argument)
	};

	webidl.converters.AbortSignal = webidl.interfaceConverter(
	  AbortSignal
	);

	// https://fetch.spec.whatwg.org/#requestinit
	webidl.converters.RequestInit = webidl.dictionaryConverter([
	  {
	    key: 'method',
	    converter: webidl.converters.ByteString
	  },
	  {
	    key: 'headers',
	    converter: webidl.converters.HeadersInit
	  },
	  {
	    key: 'body',
	    converter: webidl.nullableConverter(
	      webidl.converters.BodyInit
	    )
	  },
	  {
	    key: 'referrer',
	    converter: webidl.converters.USVString
	  },
	  {
	    key: 'referrerPolicy',
	    converter: webidl.converters.DOMString,
	    // https://w3c.github.io/webappsec-referrer-policy/#referrer-policy
	    allowedValues: referrerPolicy
	  },
	  {
	    key: 'mode',
	    converter: webidl.converters.DOMString,
	    // https://fetch.spec.whatwg.org/#concept-request-mode
	    allowedValues: requestMode
	  },
	  {
	    key: 'credentials',
	    converter: webidl.converters.DOMString,
	    // https://fetch.spec.whatwg.org/#requestcredentials
	    allowedValues: requestCredentials
	  },
	  {
	    key: 'cache',
	    converter: webidl.converters.DOMString,
	    // https://fetch.spec.whatwg.org/#requestcache
	    allowedValues: requestCache
	  },
	  {
	    key: 'redirect',
	    converter: webidl.converters.DOMString,
	    // https://fetch.spec.whatwg.org/#requestredirect
	    allowedValues: requestRedirect
	  },
	  {
	    key: 'integrity',
	    converter: webidl.converters.DOMString
	  },
	  {
	    key: 'keepalive',
	    converter: webidl.converters.boolean
	  },
	  {
	    key: 'signal',
	    converter: webidl.nullableConverter(
	      (signal) => webidl.converters.AbortSignal(
	        signal,
	        'RequestInit',
	        'signal',
	        { strict: false }
	      )
	    )
	  },
	  {
	    key: 'window',
	    converter: webidl.converters.any
	  },
	  {
	    key: 'duplex',
	    converter: webidl.converters.DOMString,
	    allowedValues: requestDuplex
	  },
	  {
	    key: 'dispatcher', // undici specific option
	    converter: webidl.converters.any
	  }
	]);

	request = { Request, makeRequest, fromInnerRequest, cloneRequest };
	return request;
}

var fetch_1;
var hasRequiredFetch;

function requireFetch () {
	if (hasRequiredFetch) return fetch_1;
	hasRequiredFetch = 1;

	const {
	  makeNetworkError,
	  makeAppropriateNetworkError,
	  filterResponse,
	  makeResponse,
	  fromInnerResponse
	} = requireResponse();
	const { HeadersList } = requireHeaders();
	const { Request, cloneRequest } = requireRequest();
	const zlib = require$$1;
	const {
	  bytesMatch,
	  makePolicyContainer,
	  clonePolicyContainer,
	  requestBadPort,
	  TAOCheck,
	  appendRequestOriginHeader,
	  responseLocationURL,
	  requestCurrentURL,
	  setRequestReferrerPolicyOnRedirect,
	  tryUpgradeRequestToAPotentiallyTrustworthyURL,
	  createOpaqueTimingInfo,
	  appendFetchMetadata,
	  corsCheck,
	  crossOriginResourcePolicyCheck,
	  determineRequestsReferrer,
	  coarsenedSharedCurrentTime,
	  createDeferredPromise,
	  isBlobLike,
	  sameOrigin,
	  isCancelled,
	  isAborted,
	  isErrorLike,
	  fullyReadBody,
	  readableStreamClose,
	  isomorphicEncode,
	  urlIsLocal,
	  urlIsHttpHttpsScheme,
	  urlHasHttpsScheme,
	  clampAndCoarsenConnectionTimingInfo,
	  simpleRangeHeaderValue,
	  buildContentRange,
	  createInflate,
	  extractMimeType
	} = requireUtil$6();
	const { kState, kDispatcher } = requireSymbols$3();
	const assert = require$$0$4;
	const { safelyExtractBody, extractBody } = requireBody();
	const {
	  redirectStatusSet,
	  nullBodyStatus,
	  safeMethodsSet,
	  requestBodyHeader,
	  subresourceSet
	} = requireConstants$2();
	const EE = require$$8;
	const { Readable, pipeline, finished } = require$$0$5;
	const { addAbortListener, isErrored, isReadable, bufferToLowerCasedHeaderName } = requireUtil$7();
	const { dataURLProcessor, serializeAMimeType, minimizeSupportedMimeType } = requireDataUrl();
	const { getGlobalDispatcher } = requireGlobal();
	const { webidl } = requireWebidl();
	const { STATUS_CODES } = require$$2;
	const GET_OR_HEAD = ['GET', 'HEAD'];

	const defaultUserAgent = typeof __UNDICI_IS_NODE__ !== 'undefined' || typeof esbuildDetection !== 'undefined'
	  ? 'node'
	  : 'undici';

	/** @type {import('buffer').resolveObjectURL} */
	let resolveObjectURL;

	class Fetch extends EE {
	  constructor (dispatcher) {
	    super();

	    this.dispatcher = dispatcher;
	    this.connection = null;
	    this.dump = false;
	    this.state = 'ongoing';
	  }

	  terminate (reason) {
	    if (this.state !== 'ongoing') {
	      return
	    }

	    this.state = 'terminated';
	    this.connection?.destroy(reason);
	    this.emit('terminated', reason);
	  }

	  // https://fetch.spec.whatwg.org/#fetch-controller-abort
	  abort (error) {
	    if (this.state !== 'ongoing') {
	      return
	    }

	    // 1. Set controllerâs state to "aborted".
	    this.state = 'aborted';

	    // 2. Let fallbackError be an "AbortError" DOMException.
	    // 3. Set error to fallbackError if it is not given.
	    if (!error) {
	      error = new DOMException('The operation was aborted.', 'AbortError');
	    }

	    // 4. Let serializedError be StructuredSerialize(error).
	    //    If that threw an exception, catch it, and let
	    //    serializedError be StructuredSerialize(fallbackError).

	    // 5. Set controllerâs serialized abort reason to serializedError.
	    this.serializedAbortReason = error;

	    this.connection?.destroy(error);
	    this.emit('terminated', error);
	  }
	}

	function handleFetchDone (response) {
	  finalizeAndReportTiming(response, 'fetch');
	}

	// https://fetch.spec.whatwg.org/#fetch-method
	function fetch (input, init = undefined) {
	  webidl.argumentLengthCheck(arguments, 1, 'globalThis.fetch');

	  // 1. Let p be a new promise.
	  let p = createDeferredPromise();

	  // 2. Let requestObject be the result of invoking the initial value of
	  // Request as constructor with input and init as arguments. If this throws
	  // an exception, reject p with it and return p.
	  let requestObject;

	  try {
	    requestObject = new Request(input, init);
	  } catch (e) {
	    p.reject(e);
	    return p.promise
	  }

	  // 3. Let request be requestObjectâs request.
	  const request = requestObject[kState];

	  // 4. If requestObjectâs signalâs aborted flag is set, then:
	  if (requestObject.signal.aborted) {
	    // 1. Abort the fetch() call with p, request, null, and
	    //    requestObjectâs signalâs abort reason.
	    abortFetch(p, request, null, requestObject.signal.reason);

	    // 2. Return p.
	    return p.promise
	  }

	  // 5. Let globalObject be requestâs clientâs global object.
	  const globalObject = request.client.globalObject;

	  // 6. If globalObject is a ServiceWorkerGlobalScope object, then set
	  // requestâs service-workers mode to "none".
	  if (globalObject?.constructor?.name === 'ServiceWorkerGlobalScope') {
	    request.serviceWorkers = 'none';
	  }

	  // 7. Let responseObject be null.
	  let responseObject = null;

	  // 8. Let relevantRealm be thisâs relevant Realm.

	  // 9. Let locallyAborted be false.
	  let locallyAborted = false;

	  // 10. Let controller be null.
	  let controller = null;

	  // 11. Add the following abort steps to requestObjectâs signal:
	  addAbortListener(
	    requestObject.signal,
	    () => {
	      // 1. Set locallyAborted to true.
	      locallyAborted = true;

	      // 2. Assert: controller is non-null.
	      assert(controller != null);

	      // 3. Abort controller with requestObjectâs signalâs abort reason.
	      controller.abort(requestObject.signal.reason);

	      const realResponse = responseObject?.deref();

	      // 4. Abort the fetch() call with p, request, responseObject,
	      //    and requestObjectâs signalâs abort reason.
	      abortFetch(p, request, realResponse, requestObject.signal.reason);
	    }
	  );

	  // 12. Let handleFetchDone given response response be to finalize and
	  // report timing with response, globalObject, and "fetch".
	  // see function handleFetchDone

	  // 13. Set controller to the result of calling fetch given request,
	  // with processResponseEndOfBody set to handleFetchDone, and processResponse
	  // given response being these substeps:

	  const processResponse = (response) => {
	    // 1. If locallyAborted is true, terminate these substeps.
	    if (locallyAborted) {
	      return
	    }

	    // 2. If responseâs aborted flag is set, then:
	    if (response.aborted) {
	      // 1. Let deserializedError be the result of deserialize a serialized
	      //    abort reason given controllerâs serialized abort reason and
	      //    relevantRealm.

	      // 2. Abort the fetch() call with p, request, responseObject, and
	      //    deserializedError.

	      abortFetch(p, request, responseObject, controller.serializedAbortReason);
	      return
	    }

	    // 3. If response is a network error, then reject p with a TypeError
	    // and terminate these substeps.
	    if (response.type === 'error') {
	      p.reject(new TypeError('fetch failed', { cause: response.error }));
	      return
	    }

	    // 4. Set responseObject to the result of creating a Response object,
	    // given response, "immutable", and relevantRealm.
	    responseObject = new WeakRef(fromInnerResponse(response, 'immutable'));

	    // 5. Resolve p with responseObject.
	    p.resolve(responseObject.deref());
	    p = null;
	  };

	  controller = fetching({
	    request,
	    processResponseEndOfBody: handleFetchDone,
	    processResponse,
	    dispatcher: requestObject[kDispatcher] // undici
	  });

	  // 14. Return p.
	  return p.promise
	}

	// https://fetch.spec.whatwg.org/#finalize-and-report-timing
	function finalizeAndReportTiming (response, initiatorType = 'other') {
	  // 1. If response is an aborted network error, then return.
	  if (response.type === 'error' && response.aborted) {
	    return
	  }

	  // 2. If responseâs URL list is null or empty, then return.
	  if (!response.urlList?.length) {
	    return
	  }

	  // 3. Let originalURL be responseâs URL list[0].
	  const originalURL = response.urlList[0];

	  // 4. Let timingInfo be responseâs timing info.
	  let timingInfo = response.timingInfo;

	  // 5. Let cacheState be responseâs cache state.
	  let cacheState = response.cacheState;

	  // 6. If originalURLâs scheme is not an HTTP(S) scheme, then return.
	  if (!urlIsHttpHttpsScheme(originalURL)) {
	    return
	  }

	  // 7. If timingInfo is null, then return.
	  if (timingInfo === null) {
	    return
	  }

	  // 8. If responseâs timing allow passed flag is not set, then:
	  if (!response.timingAllowPassed) {
	    //  1. Set timingInfo to a the result of creating an opaque timing info for timingInfo.
	    timingInfo = createOpaqueTimingInfo({
	      startTime: timingInfo.startTime
	    });

	    //  2. Set cacheState to the empty string.
	    cacheState = '';
	  }

	  // 9. Set timingInfoâs end time to the coarsened shared current time
	  // given globalâs relevant settings objectâs cross-origin isolated
	  // capability.
	  // TODO: given globalâs relevant settings objectâs cross-origin isolated
	  // capability?
	  timingInfo.endTime = coarsenedSharedCurrentTime();

	  // 10. Set responseâs timing info to timingInfo.
	  response.timingInfo = timingInfo;

	  // 11. Mark resource timing for timingInfo, originalURL, initiatorType,
	  // global, and cacheState.
	  markResourceTiming(
	    timingInfo,
	    originalURL.href,
	    initiatorType,
	    globalThis,
	    cacheState
	  );
	}

	// https://w3c.github.io/resource-timing/#dfn-mark-resource-timing
	const markResourceTiming = performance.markResourceTiming;

	// https://fetch.spec.whatwg.org/#abort-fetch
	function abortFetch (p, request, responseObject, error) {
	  // 1. Reject promise with error.
	  if (p) {
	    // We might have already resolved the promise at this stage
	    p.reject(error);
	  }

	  // 2. If requestâs body is not null and is readable, then cancel requestâs
	  // body with error.
	  if (request.body != null && isReadable(request.body?.stream)) {
	    request.body.stream.cancel(error).catch((err) => {
	      if (err.code === 'ERR_INVALID_STATE') {
	        // Node bug?
	        return
	      }
	      throw err
	    });
	  }

	  // 3. If responseObject is null, then return.
	  if (responseObject == null) {
	    return
	  }

	  // 4. Let response be responseObjectâs response.
	  const response = responseObject[kState];

	  // 5. If responseâs body is not null and is readable, then error responseâs
	  // body with error.
	  if (response.body != null && isReadable(response.body?.stream)) {
	    response.body.stream.cancel(error).catch((err) => {
	      if (err.code === 'ERR_INVALID_STATE') {
	        // Node bug?
	        return
	      }
	      throw err
	    });
	  }
	}

	// https://fetch.spec.whatwg.org/#fetching
	function fetching ({
	  request,
	  processRequestBodyChunkLength,
	  processRequestEndOfBody,
	  processResponse,
	  processResponseEndOfBody,
	  processResponseConsumeBody,
	  useParallelQueue = false,
	  dispatcher = getGlobalDispatcher() // undici
	}) {
	  // Ensure that the dispatcher is set accordingly
	  assert(dispatcher);

	  // 1. Let taskDestination be null.
	  let taskDestination = null;

	  // 2. Let crossOriginIsolatedCapability be false.
	  let crossOriginIsolatedCapability = false;

	  // 3. If requestâs client is non-null, then:
	  if (request.client != null) {
	    // 1. Set taskDestination to requestâs clientâs global object.
	    taskDestination = request.client.globalObject;

	    // 2. Set crossOriginIsolatedCapability to requestâs clientâs cross-origin
	    // isolated capability.
	    crossOriginIsolatedCapability =
	      request.client.crossOriginIsolatedCapability;
	  }

	  // 4. If useParallelQueue is true, then set taskDestination to the result of
	  // starting a new parallel queue.
	  // TODO

	  // 5. Let timingInfo be a new fetch timing info whose start time and
	  // post-redirect start time are the coarsened shared current time given
	  // crossOriginIsolatedCapability.
	  const currentTime = coarsenedSharedCurrentTime(crossOriginIsolatedCapability);
	  const timingInfo = createOpaqueTimingInfo({
	    startTime: currentTime
	  });

	  // 6. Let fetchParams be a new fetch params whose
	  // request is request,
	  // timing info is timingInfo,
	  // process request body chunk length is processRequestBodyChunkLength,
	  // process request end-of-body is processRequestEndOfBody,
	  // process response is processResponse,
	  // process response consume body is processResponseConsumeBody,
	  // process response end-of-body is processResponseEndOfBody,
	  // task destination is taskDestination,
	  // and cross-origin isolated capability is crossOriginIsolatedCapability.
	  const fetchParams = {
	    controller: new Fetch(dispatcher),
	    request,
	    timingInfo,
	    processRequestBodyChunkLength,
	    processRequestEndOfBody,
	    processResponse,
	    processResponseConsumeBody,
	    processResponseEndOfBody,
	    taskDestination,
	    crossOriginIsolatedCapability
	  };

	  // 7. If requestâs body is a byte sequence, then set requestâs body to
	  //    requestâs body as a body.
	  // NOTE: Since fetching is only called from fetch, body should already be
	  // extracted.
	  assert(!request.body || request.body.stream);

	  // 8. If requestâs window is "client", then set requestâs window to requestâs
	  // client, if requestâs clientâs global object is a Window object; otherwise
	  // "no-window".
	  if (request.window === 'client') {
	    // TODO: What if request.client is null?
	    request.window =
	      request.client?.globalObject?.constructor?.name === 'Window'
	        ? request.client
	        : 'no-window';
	  }

	  // 9. If requestâs origin is "client", then set requestâs origin to requestâs
	  // clientâs origin.
	  if (request.origin === 'client') {
	    request.origin = request.client.origin;
	  }

	  // 10. If all of the following conditions are true:
	  // TODO

	  // 11. If requestâs policy container is "client", then:
	  if (request.policyContainer === 'client') {
	    // 1. If requestâs client is non-null, then set requestâs policy
	    // container to a clone of requestâs clientâs policy container. [HTML]
	    if (request.client != null) {
	      request.policyContainer = clonePolicyContainer(
	        request.client.policyContainer
	      );
	    } else {
	      // 2. Otherwise, set requestâs policy container to a new policy
	      // container.
	      request.policyContainer = makePolicyContainer();
	    }
	  }

	  // 12. If requestâs header list does not contain `Accept`, then:
	  if (!request.headersList.contains('accept', true)) {
	    // 1. Let value be `*/*`.
	    const value = '*/*';

	    // 2. A user agent should set value to the first matching statement, if
	    // any, switching on requestâs destination:
	    // "document"
	    // "frame"
	    // "iframe"
	    // `text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8`
	    // "image"
	    // `image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5`
	    // "style"
	    // `text/css,*/*;q=0.1`
	    // TODO

	    // 3. Append `Accept`/value to requestâs header list.
	    request.headersList.append('accept', value, true);
	  }

	  // 13. If requestâs header list does not contain `Accept-Language`, then
	  // user agents should append `Accept-Language`/an appropriate value to
	  // requestâs header list.
	  if (!request.headersList.contains('accept-language', true)) {
	    request.headersList.append('accept-language', '*', true);
	  }

	  // 14. If requestâs priority is null, then use requestâs initiator and
	  // destination appropriately in setting requestâs priority to a
	  // user-agent-defined object.
	  if (request.priority === null) ;

	  // 15. If request is a subresource request, then:
	  if (subresourceSet.has(request.destination)) ;

	  // 16. Run main fetch given fetchParams.
	  mainFetch(fetchParams)
	    .catch(err => {
	      fetchParams.controller.terminate(err);
	    });

	  // 17. Return fetchParam's controller
	  return fetchParams.controller
	}

	// https://fetch.spec.whatwg.org/#concept-main-fetch
	async function mainFetch (fetchParams, recursive = false) {
	  // 1. Let request be fetchParamsâs request.
	  const request = fetchParams.request;

	  // 2. Let response be null.
	  let response = null;

	  // 3. If requestâs local-URLs-only flag is set and requestâs current URL is
	  // not local, then set response to a network error.
	  if (request.localURLsOnly && !urlIsLocal(requestCurrentURL(request))) {
	    response = makeNetworkError('local URLs only');
	  }

	  // 4. Run report Content Security Policy violations for request.
	  // TODO

	  // 5. Upgrade request to a potentially trustworthy URL, if appropriate.
	  tryUpgradeRequestToAPotentiallyTrustworthyURL(request);

	  // 6. If should request be blocked due to a bad port, should fetching request
	  // be blocked as mixed content, or should request be blocked by Content
	  // Security Policy returns blocked, then set response to a network error.
	  if (requestBadPort(request) === 'blocked') {
	    response = makeNetworkError('bad port');
	  }
	  // TODO: should fetching request be blocked as mixed content?
	  // TODO: should request be blocked by Content Security Policy?

	  // 7. If requestâs referrer policy is the empty string, then set requestâs
	  // referrer policy to requestâs policy containerâs referrer policy.
	  if (request.referrerPolicy === '') {
	    request.referrerPolicy = request.policyContainer.referrerPolicy;
	  }

	  // 8. If requestâs referrer is not "no-referrer", then set requestâs
	  // referrer to the result of invoking determine requestâs referrer.
	  if (request.referrer !== 'no-referrer') {
	    request.referrer = determineRequestsReferrer(request);
	  }

	  // 9. Set requestâs current URLâs scheme to "https" if all of the following
	  // conditions are true:
	  // - requestâs current URLâs scheme is "http"
	  // - requestâs current URLâs host is a domain
	  // - Matching requestâs current URLâs host per Known HSTS Host Domain Name
	  //   Matching results in either a superdomain match with an asserted
	  //   includeSubDomains directive or a congruent match (with or without an
	  //   asserted includeSubDomains directive). [HSTS]
	  // TODO

	  // 10. If recursive is false, then run the remaining steps in parallel.
	  // TODO

	  // 11. If response is null, then set response to the result of running
	  // the steps corresponding to the first matching statement:
	  if (response === null) {
	    response = await (async () => {
	      const currentURL = requestCurrentURL(request);

	      if (
	        // - requestâs current URLâs origin is same origin with requestâs origin,
	        //   and requestâs response tainting is "basic"
	        (sameOrigin(currentURL, request.url) && request.responseTainting === 'basic') ||
	        // requestâs current URLâs scheme is "data"
	        (currentURL.protocol === 'data:') ||
	        // - requestâs mode is "navigate" or "websocket"
	        (request.mode === 'navigate' || request.mode === 'websocket')
	      ) {
	        // 1. Set requestâs response tainting to "basic".
	        request.responseTainting = 'basic';

	        // 2. Return the result of running scheme fetch given fetchParams.
	        return await schemeFetch(fetchParams)
	      }

	      // requestâs mode is "same-origin"
	      if (request.mode === 'same-origin') {
	        // 1. Return a network error.
	        return makeNetworkError('request mode cannot be "same-origin"')
	      }

	      // requestâs mode is "no-cors"
	      if (request.mode === 'no-cors') {
	        // 1. If requestâs redirect mode is not "follow", then return a network
	        // error.
	        if (request.redirect !== 'follow') {
	          return makeNetworkError(
	            'redirect mode cannot be "follow" for "no-cors" request'
	          )
	        }

	        // 2. Set requestâs response tainting to "opaque".
	        request.responseTainting = 'opaque';

	        // 3. Return the result of running scheme fetch given fetchParams.
	        return await schemeFetch(fetchParams)
	      }

	      // requestâs current URLâs scheme is not an HTTP(S) scheme
	      if (!urlIsHttpHttpsScheme(requestCurrentURL(request))) {
	        // Return a network error.
	        return makeNetworkError('URL scheme must be a HTTP(S) scheme')
	      }

	      // - requestâs use-CORS-preflight flag is set
	      // - requestâs unsafe-request flag is set and either requestâs method is
	      //   not a CORS-safelisted method or CORS-unsafe request-header names with
	      //   requestâs header list is not empty
	      //    1. Set requestâs response tainting to "cors".
	      //    2. Let corsWithPreflightResponse be the result of running HTTP fetch
	      //    given fetchParams and true.
	      //    3. If corsWithPreflightResponse is a network error, then clear cache
	      //    entries using request.
	      //    4. Return corsWithPreflightResponse.
	      // TODO

	      // Otherwise
	      //    1. Set requestâs response tainting to "cors".
	      request.responseTainting = 'cors';

	      //    2. Return the result of running HTTP fetch given fetchParams.
	      return await httpFetch(fetchParams)
	    })();
	  }

	  // 12. If recursive is true, then return response.
	  if (recursive) {
	    return response
	  }

	  // 13. If response is not a network error and response is not a filtered
	  // response, then:
	  if (response.status !== 0 && !response.internalResponse) {
	    // If requestâs response tainting is "cors", then:
	    if (request.responseTainting === 'cors') ;

	    // Set response to the following filtered response with response as its
	    // internal response, depending on requestâs response tainting:
	    if (request.responseTainting === 'basic') {
	      response = filterResponse(response, 'basic');
	    } else if (request.responseTainting === 'cors') {
	      response = filterResponse(response, 'cors');
	    } else if (request.responseTainting === 'opaque') {
	      response = filterResponse(response, 'opaque');
	    } else {
	      assert(false);
	    }
	  }

	  // 14. Let internalResponse be response, if response is a network error,
	  // and responseâs internal response otherwise.
	  let internalResponse =
	    response.status === 0 ? response : response.internalResponse;

	  // 15. If internalResponseâs URL list is empty, then set it to a clone of
	  // requestâs URL list.
	  if (internalResponse.urlList.length === 0) {
	    internalResponse.urlList.push(...request.urlList);
	  }

	  // 16. If requestâs timing allow failed flag is unset, then set
	  // internalResponseâs timing allow passed flag.
	  if (!request.timingAllowFailed) {
	    response.timingAllowPassed = true;
	  }

	  // 17. If response is not a network error and any of the following returns
	  // blocked
	  // - should internalResponse to request be blocked as mixed content
	  // - should internalResponse to request be blocked by Content Security Policy
	  // - should internalResponse to request be blocked due to its MIME type
	  // - should internalResponse to request be blocked due to nosniff
	  // TODO

	  // 18. If responseâs type is "opaque", internalResponseâs status is 206,
	  // internalResponseâs range-requested flag is set, and requestâs header
	  // list does not contain `Range`, then set response and internalResponse
	  // to a network error.
	  if (
	    response.type === 'opaque' &&
	    internalResponse.status === 206 &&
	    internalResponse.rangeRequested &&
	    !request.headers.contains('range', true)
	  ) {
	    response = internalResponse = makeNetworkError();
	  }

	  // 19. If response is not a network error and either requestâs method is
	  // `HEAD` or `CONNECT`, or internalResponseâs status is a null body status,
	  // set internalResponseâs body to null and disregard any enqueuing toward
	  // it (if any).
	  if (
	    response.status !== 0 &&
	    (request.method === 'HEAD' ||
	      request.method === 'CONNECT' ||
	      nullBodyStatus.includes(internalResponse.status))
	  ) {
	    internalResponse.body = null;
	    fetchParams.controller.dump = true;
	  }

	  // 20. If requestâs integrity metadata is not the empty string, then:
	  if (request.integrity) {
	    // 1. Let processBodyError be this step: run fetch finale given fetchParams
	    // and a network error.
	    const processBodyError = (reason) =>
	      fetchFinale(fetchParams, makeNetworkError(reason));

	    // 2. If requestâs response tainting is "opaque", or responseâs body is null,
	    // then run processBodyError and abort these steps.
	    if (request.responseTainting === 'opaque' || response.body == null) {
	      processBodyError(response.error);
	      return
	    }

	    // 3. Let processBody given bytes be these steps:
	    const processBody = (bytes) => {
	      // 1. If bytes do not match requestâs integrity metadata,
	      // then run processBodyError and abort these steps. [SRI]
	      if (!bytesMatch(bytes, request.integrity)) {
	        processBodyError('integrity mismatch');
	        return
	      }

	      // 2. Set responseâs body to bytes as a body.
	      response.body = safelyExtractBody(bytes)[0];

	      // 3. Run fetch finale given fetchParams and response.
	      fetchFinale(fetchParams, response);
	    };

	    // 4. Fully read responseâs body given processBody and processBodyError.
	    await fullyReadBody(response.body, processBody, processBodyError);
	  } else {
	    // 21. Otherwise, run fetch finale given fetchParams and response.
	    fetchFinale(fetchParams, response);
	  }
	}

	// https://fetch.spec.whatwg.org/#concept-scheme-fetch
	// given a fetch params fetchParams
	function schemeFetch (fetchParams) {
	  // Note: since the connection is destroyed on redirect, which sets fetchParams to a
	  // cancelled state, we do not want this condition to trigger *unless* there have been
	  // no redirects. See https://github.com/nodejs/undici/issues/1776
	  // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.
	  if (isCancelled(fetchParams) && fetchParams.request.redirectCount === 0) {
	    return Promise.resolve(makeAppropriateNetworkError(fetchParams))
	  }

	  // 2. Let request be fetchParamsâs request.
	  const { request } = fetchParams;

	  const { protocol: scheme } = requestCurrentURL(request);

	  // 3. Switch on requestâs current URLâs scheme and run the associated steps:
	  switch (scheme) {
	    case 'about:': {
	      // If requestâs current URLâs path is the string "blank", then return a new response
	      // whose status message is `OK`, header list is Â« (`Content-Type`, `text/html;charset=utf-8`) Â»,
	      // and body is the empty byte sequence as a body.

	      // Otherwise, return a network error.
	      return Promise.resolve(makeNetworkError('about scheme is not supported'))
	    }
	    case 'blob:': {
	      if (!resolveObjectURL) {
	        resolveObjectURL = require$$0$3.resolveObjectURL;
	      }

	      // 1. Let blobURLEntry be requestâs current URLâs blob URL entry.
	      const blobURLEntry = requestCurrentURL(request);

	      // https://github.com/web-platform-tests/wpt/blob/7b0ebaccc62b566a1965396e5be7bb2bc06f841f/FileAPI/url/resources/fetch-tests.js#L52-L56
	      // Buffer.resolveObjectURL does not ignore URL queries.
	      if (blobURLEntry.search.length !== 0) {
	        return Promise.resolve(makeNetworkError('NetworkError when attempting to fetch resource.'))
	      }

	      const blob = resolveObjectURL(blobURLEntry.toString());

	      // 2. If requestâs method is not `GET`, blobURLEntry is null, or blobURLEntryâs
	      //    object is not a Blob object, then return a network error.
	      if (request.method !== 'GET' || !isBlobLike(blob)) {
	        return Promise.resolve(makeNetworkError('invalid method'))
	      }

	      // 3. Let blob be blobURLEntryâs object.
	      // Note: done above

	      // 4. Let response be a new response.
	      const response = makeResponse();

	      // 5. Let fullLength be blobâs size.
	      const fullLength = blob.size;

	      // 6. Let serializedFullLength be fullLength, serialized and isomorphic encoded.
	      const serializedFullLength = isomorphicEncode(`${fullLength}`);

	      // 7. Let type be blobâs type.
	      const type = blob.type;

	      // 8. If requestâs header list does not contain `Range`:
	      // 9. Otherwise:
	      if (!request.headersList.contains('range', true)) {
	        // 1. Let bodyWithType be the result of safely extracting blob.
	        // Note: in the FileAPI a blob "object" is a Blob *or* a MediaSource.
	        // In node, this can only ever be a Blob. Therefore we can safely
	        // use extractBody directly.
	        const bodyWithType = extractBody(blob);

	        // 2. Set responseâs status message to `OK`.
	        response.statusText = 'OK';

	        // 3. Set responseâs body to bodyWithTypeâs body.
	        response.body = bodyWithType[0];

	        // 4. Set responseâs header list to Â« (`Content-Length`, serializedFullLength), (`Content-Type`, type) Â».
	        response.headersList.set('content-length', serializedFullLength, true);
	        response.headersList.set('content-type', type, true);
	      } else {
	        // 1. Set responseâs range-requested flag.
	        response.rangeRequested = true;

	        // 2. Let rangeHeader be the result of getting `Range` from requestâs header list.
	        const rangeHeader = request.headersList.get('range', true);

	        // 3. Let rangeValue be the result of parsing a single range header value given rangeHeader and true.
	        const rangeValue = simpleRangeHeaderValue(rangeHeader, true);

	        // 4. If rangeValue is failure, then return a network error.
	        if (rangeValue === 'failure') {
	          return Promise.resolve(makeNetworkError('failed to fetch the data URL'))
	        }

	        // 5. Let (rangeStart, rangeEnd) be rangeValue.
	        let { rangeStartValue: rangeStart, rangeEndValue: rangeEnd } = rangeValue;

	        // 6. If rangeStart is null:
	        // 7. Otherwise:
	        if (rangeStart === null) {
	          // 1. Set rangeStart to fullLength â rangeEnd.
	          rangeStart = fullLength - rangeEnd;

	          // 2. Set rangeEnd to rangeStart + rangeEnd â 1.
	          rangeEnd = rangeStart + rangeEnd - 1;
	        } else {
	          // 1. If rangeStart is greater than or equal to fullLength, then return a network error.
	          if (rangeStart >= fullLength) {
	            return Promise.resolve(makeNetworkError('Range start is greater than the blob\'s size.'))
	          }

	          // 2. If rangeEnd is null or rangeEnd is greater than or equal to fullLength, then set
	          //    rangeEnd to fullLength â 1.
	          if (rangeEnd === null || rangeEnd >= fullLength) {
	            rangeEnd = fullLength - 1;
	          }
	        }

	        // 8. Let slicedBlob be the result of invoking slice blob given blob, rangeStart,
	        //    rangeEnd + 1, and type.
	        const slicedBlob = blob.slice(rangeStart, rangeEnd, type);

	        // 9. Let slicedBodyWithType be the result of safely extracting slicedBlob.
	        // Note: same reason as mentioned above as to why we use extractBody
	        const slicedBodyWithType = extractBody(slicedBlob);

	        // 10. Set responseâs body to slicedBodyWithTypeâs body.
	        response.body = slicedBodyWithType[0];

	        // 11. Let serializedSlicedLength be slicedBlobâs size, serialized and isomorphic encoded.
	        const serializedSlicedLength = isomorphicEncode(`${slicedBlob.size}`);

	        // 12. Let contentRange be the result of invoking build a content range given rangeStart,
	        //     rangeEnd, and fullLength.
	        const contentRange = buildContentRange(rangeStart, rangeEnd, fullLength);

	        // 13. Set responseâs status to 206.
	        response.status = 206;

	        // 14. Set responseâs status message to `Partial Content`.
	        response.statusText = 'Partial Content';

	        // 15. Set responseâs header list to Â« (`Content-Length`, serializedSlicedLength),
	        //     (`Content-Type`, type), (`Content-Range`, contentRange) Â».
	        response.headersList.set('content-length', serializedSlicedLength, true);
	        response.headersList.set('content-type', type, true);
	        response.headersList.set('content-range', contentRange, true);
	      }

	      // 10. Return response.
	      return Promise.resolve(response)
	    }
	    case 'data:': {
	      // 1. Let dataURLStruct be the result of running the
	      //    data: URL processor on requestâs current URL.
	      const currentURL = requestCurrentURL(request);
	      const dataURLStruct = dataURLProcessor(currentURL);

	      // 2. If dataURLStruct is failure, then return a
	      //    network error.
	      if (dataURLStruct === 'failure') {
	        return Promise.resolve(makeNetworkError('failed to fetch the data URL'))
	      }

	      // 3. Let mimeType be dataURLStructâs MIME type, serialized.
	      const mimeType = serializeAMimeType(dataURLStruct.mimeType);

	      // 4. Return a response whose status message is `OK`,
	      //    header list is Â« (`Content-Type`, mimeType) Â»,
	      //    and body is dataURLStructâs body as a body.
	      return Promise.resolve(makeResponse({
	        statusText: 'OK',
	        headersList: [
	          ['content-type', { name: 'Content-Type', value: mimeType }]
	        ],
	        body: safelyExtractBody(dataURLStruct.body)[0]
	      }))
	    }
	    case 'file:': {
	      // For now, unfortunate as it is, file URLs are left as an exercise for the reader.
	      // When in doubt, return a network error.
	      return Promise.resolve(makeNetworkError('not implemented... yet...'))
	    }
	    case 'http:':
	    case 'https:': {
	      // Return the result of running HTTP fetch given fetchParams.

	      return httpFetch(fetchParams)
	        .catch((err) => makeNetworkError(err))
	    }
	    default: {
	      return Promise.resolve(makeNetworkError('unknown scheme'))
	    }
	  }
	}

	// https://fetch.spec.whatwg.org/#finalize-response
	function finalizeResponse (fetchParams, response) {
	  // 1. Set fetchParamsâs requestâs done flag.
	  fetchParams.request.done = true;

	  // 2, If fetchParamsâs process response done is not null, then queue a fetch
	  // task to run fetchParamsâs process response done given response, with
	  // fetchParamsâs task destination.
	  if (fetchParams.processResponseDone != null) {
	    queueMicrotask(() => fetchParams.processResponseDone(response));
	  }
	}

	// https://fetch.spec.whatwg.org/#fetch-finale
	function fetchFinale (fetchParams, response) {
	  // 1. Let timingInfo be fetchParamsâs timing info.
	  let timingInfo = fetchParams.timingInfo;

	  // 2. If response is not a network error and fetchParamsâs requestâs client is a secure context,
	  //    then set timingInfoâs server-timing headers to the result of getting, decoding, and splitting
	  //    `Server-Timing` from responseâs internal responseâs header list.
	  // TODO

	  // 3. Let processResponseEndOfBody be the following steps:
	  const processResponseEndOfBody = () => {
	    // 1. Let unsafeEndTime be the unsafe shared current time.
	    const unsafeEndTime = Date.now(); // ?

	    // 2. If fetchParamsâs requestâs destination is "document", then set fetchParamsâs controllerâs
	    //    full timing info to fetchParamsâs timing info.
	    if (fetchParams.request.destination === 'document') {
	      fetchParams.controller.fullTimingInfo = timingInfo;
	    }

	    // 3. Set fetchParamsâs controllerâs report timing steps to the following steps given a global object global:
	    fetchParams.controller.reportTimingSteps = () => {
	      // 1. If fetchParamsâs requestâs URLâs scheme is not an HTTP(S) scheme, then return.
	      if (fetchParams.request.url.protocol !== 'https:') {
	        return
	      }

	      // 2. Set timingInfoâs end time to the relative high resolution time given unsafeEndTime and global.
	      timingInfo.endTime = unsafeEndTime;

	      // 3. Let cacheState be responseâs cache state.
	      let cacheState = response.cacheState;

	      // 4. Let bodyInfo be responseâs body info.
	      const bodyInfo = response.bodyInfo;

	      // 5. If responseâs timing allow passed flag is not set, then set timingInfo to the result of creating an
	      //    opaque timing info for timingInfo and set cacheState to the empty string.
	      if (!response.timingAllowPassed) {
	        timingInfo = createOpaqueTimingInfo(timingInfo);

	        cacheState = '';
	      }

	      // 6. Let responseStatus be 0.
	      let responseStatus = 0;

	      // 7. If fetchParamsâs requestâs mode is not "navigate" or responseâs has-cross-origin-redirects is false:
	      if (fetchParams.request.mode !== 'navigator' || !response.hasCrossOriginRedirects) {
	        // 1. Set responseStatus to responseâs status.
	        responseStatus = response.status;

	        // 2. Let mimeType be the result of extracting a MIME type from responseâs header list.
	        const mimeType = extractMimeType(response.headersList);

	        // 3. If mimeType is not failure, then set bodyInfoâs content type to the result of minimizing a supported MIME type given mimeType.
	        if (mimeType !== 'failure') {
	          bodyInfo.contentType = minimizeSupportedMimeType(mimeType);
	        }
	      }

	      // 8. If fetchParamsâs requestâs initiator type is non-null, then mark resource timing given timingInfo,
	      //    fetchParamsâs requestâs URL, fetchParamsâs requestâs initiator type, global, cacheState, bodyInfo,
	      //    and responseStatus.
	      if (fetchParams.request.initiatorType != null) {
	        // TODO: update markresourcetiming
	        markResourceTiming(timingInfo, fetchParams.request.url.href, fetchParams.request.initiatorType, globalThis, cacheState, bodyInfo, responseStatus);
	      }
	    };

	    // 4. Let processResponseEndOfBodyTask be the following steps:
	    const processResponseEndOfBodyTask = () => {
	      // 1. Set fetchParamsâs requestâs done flag.
	      fetchParams.request.done = true;

	      // 2. If fetchParamsâs process response end-of-body is non-null, then run fetchParamsâs process
	      //    response end-of-body given response.
	      if (fetchParams.processResponseEndOfBody != null) {
	        queueMicrotask(() => fetchParams.processResponseEndOfBody(response));
	      }

	      // 3. If fetchParamsâs requestâs initiator type is non-null and fetchParamsâs requestâs clientâs
	      //    global object is fetchParamsâs task destination, then run fetchParamsâs controllerâs report
	      //    timing steps given fetchParamsâs requestâs clientâs global object.
	      if (fetchParams.request.initiatorType != null) {
	        fetchParams.controller.reportTimingSteps();
	      }
	    };

	    // 5. Queue a fetch task to run processResponseEndOfBodyTask with fetchParamsâs task destination
	    queueMicrotask(() => processResponseEndOfBodyTask());
	  };

	  // 4. If fetchParamsâs process response is non-null, then queue a fetch task to run fetchParamsâs
	  //    process response given response, with fetchParamsâs task destination.
	  if (fetchParams.processResponse != null) {
	    queueMicrotask(() => {
	      fetchParams.processResponse(response);
	      fetchParams.processResponse = null;
	    });
	  }

	  // 5. Let internalResponse be response, if response is a network error; otherwise responseâs internal response.
	  const internalResponse = response.type === 'error' ? response : (response.internalResponse ?? response);

	  // 6. If internalResponseâs body is null, then run processResponseEndOfBody.
	  // 7. Otherwise:
	  if (internalResponse.body == null) {
	    processResponseEndOfBody();
	  } else {
	    // mcollina: all the following steps of the specs are skipped.
	    // The internal transform stream is not needed.
	    // See https://github.com/nodejs/undici/pull/3093#issuecomment-2050198541

	    // 1. Let transformStream be a new TransformStream.
	    // 2. Let identityTransformAlgorithm be an algorithm which, given chunk, enqueues chunk in transformStream.
	    // 3. Set up transformStream with transformAlgorithm set to identityTransformAlgorithm and flushAlgorithm
	    //    set to processResponseEndOfBody.
	    // 4. Set internalResponseâs bodyâs stream to the result of internalResponseâs bodyâs stream piped through transformStream.

	    finished(internalResponse.body.stream, () => {
	      processResponseEndOfBody();
	    });
	  }
	}

	// https://fetch.spec.whatwg.org/#http-fetch
	async function httpFetch (fetchParams) {
	  // 1. Let request be fetchParamsâs request.
	  const request = fetchParams.request;

	  // 2. Let response be null.
	  let response = null;

	  // 3. Let actualResponse be null.
	  let actualResponse = null;

	  // 4. Let timingInfo be fetchParamsâs timing info.
	  const timingInfo = fetchParams.timingInfo;

	  // 5. If requestâs service-workers mode is "all", then:
	  if (request.serviceWorkers === 'all') ;

	  // 6. If response is null, then:
	  if (response === null) {
	    // 1. If makeCORSPreflight is true and one of these conditions is true:
	    // TODO

	    // 2. If requestâs redirect mode is "follow", then set requestâs
	    // service-workers mode to "none".
	    if (request.redirect === 'follow') {
	      request.serviceWorkers = 'none';
	    }

	    // 3. Set response and actualResponse to the result of running
	    // HTTP-network-or-cache fetch given fetchParams.
	    actualResponse = response = await httpNetworkOrCacheFetch(fetchParams);

	    // 4. If requestâs response tainting is "cors" and a CORS check
	    // for request and response returns failure, then return a network error.
	    if (
	      request.responseTainting === 'cors' &&
	      corsCheck(request, response) === 'failure'
	    ) {
	      return makeNetworkError('cors failure')
	    }

	    // 5. If the TAO check for request and response returns failure, then set
	    // requestâs timing allow failed flag.
	    if (TAOCheck(request, response) === 'failure') {
	      request.timingAllowFailed = true;
	    }
	  }

	  // 7. If either requestâs response tainting or responseâs type
	  // is "opaque", and the cross-origin resource policy check with
	  // requestâs origin, requestâs client, requestâs destination,
	  // and actualResponse returns blocked, then return a network error.
	  if (
	    (request.responseTainting === 'opaque' || response.type === 'opaque') &&
	    crossOriginResourcePolicyCheck(
	      request.origin,
	      request.client,
	      request.destination,
	      actualResponse
	    ) === 'blocked'
	  ) {
	    return makeNetworkError('blocked')
	  }

	  // 8. If actualResponseâs status is a redirect status, then:
	  if (redirectStatusSet.has(actualResponse.status)) {
	    // 1. If actualResponseâs status is not 303, requestâs body is not null,
	    // and the connection uses HTTP/2, then user agents may, and are even
	    // encouraged to, transmit an RST_STREAM frame.
	    // See, https://github.com/whatwg/fetch/issues/1288
	    if (request.redirect !== 'manual') {
	      fetchParams.controller.connection.destroy(undefined, false);
	    }

	    // 2. Switch on requestâs redirect mode:
	    if (request.redirect === 'error') {
	      // Set response to a network error.
	      response = makeNetworkError('unexpected redirect');
	    } else if (request.redirect === 'manual') {
	      // Set response to an opaque-redirect filtered response whose internal
	      // response is actualResponse.
	      // NOTE(spec): On the web this would return an `opaqueredirect` response,
	      // but that doesn't make sense server side.
	      // See https://github.com/nodejs/undici/issues/1193.
	      response = actualResponse;
	    } else if (request.redirect === 'follow') {
	      // Set response to the result of running HTTP-redirect fetch given
	      // fetchParams and response.
	      response = await httpRedirectFetch(fetchParams, response);
	    } else {
	      assert(false);
	    }
	  }

	  // 9. Set responseâs timing info to timingInfo.
	  response.timingInfo = timingInfo;

	  // 10. Return response.
	  return response
	}

	// https://fetch.spec.whatwg.org/#http-redirect-fetch
	function httpRedirectFetch (fetchParams, response) {
	  // 1. Let request be fetchParamsâs request.
	  const request = fetchParams.request;

	  // 2. Let actualResponse be response, if response is not a filtered response,
	  // and responseâs internal response otherwise.
	  const actualResponse = response.internalResponse
	    ? response.internalResponse
	    : response;

	  // 3. Let locationURL be actualResponseâs location URL given requestâs current
	  // URLâs fragment.
	  let locationURL;

	  try {
	    locationURL = responseLocationURL(
	      actualResponse,
	      requestCurrentURL(request).hash
	    );

	    // 4. If locationURL is null, then return response.
	    if (locationURL == null) {
	      return response
	    }
	  } catch (err) {
	    // 5. If locationURL is failure, then return a network error.
	    return Promise.resolve(makeNetworkError(err))
	  }

	  // 6. If locationURLâs scheme is not an HTTP(S) scheme, then return a network
	  // error.
	  if (!urlIsHttpHttpsScheme(locationURL)) {
	    return Promise.resolve(makeNetworkError('URL scheme must be a HTTP(S) scheme'))
	  }

	  // 7. If requestâs redirect count is 20, then return a network error.
	  if (request.redirectCount === 20) {
	    return Promise.resolve(makeNetworkError('redirect count exceeded'))
	  }

	  // 8. Increase requestâs redirect count by 1.
	  request.redirectCount += 1;

	  // 9. If requestâs mode is "cors", locationURL includes credentials, and
	  // requestâs origin is not same origin with locationURLâs origin, then return
	  //  a network error.
	  if (
	    request.mode === 'cors' &&
	    (locationURL.username || locationURL.password) &&
	    !sameOrigin(request, locationURL)
	  ) {
	    return Promise.resolve(makeNetworkError('cross origin not allowed for request mode "cors"'))
	  }

	  // 10. If requestâs response tainting is "cors" and locationURL includes
	  // credentials, then return a network error.
	  if (
	    request.responseTainting === 'cors' &&
	    (locationURL.username || locationURL.password)
	  ) {
	    return Promise.resolve(makeNetworkError(
	      'URL cannot contain credentials for request mode "cors"'
	    ))
	  }

	  // 11. If actualResponseâs status is not 303, requestâs body is non-null,
	  // and requestâs bodyâs source is null, then return a network error.
	  if (
	    actualResponse.status !== 303 &&
	    request.body != null &&
	    request.body.source == null
	  ) {
	    return Promise.resolve(makeNetworkError())
	  }

	  // 12. If one of the following is true
	  // - actualResponseâs status is 301 or 302 and requestâs method is `POST`
	  // - actualResponseâs status is 303 and requestâs method is not `GET` or `HEAD`
	  if (
	    ([301, 302].includes(actualResponse.status) && request.method === 'POST') ||
	    (actualResponse.status === 303 &&
	      !GET_OR_HEAD.includes(request.method))
	  ) {
	    // then:
	    // 1. Set requestâs method to `GET` and requestâs body to null.
	    request.method = 'GET';
	    request.body = null;

	    // 2. For each headerName of request-body-header name, delete headerName from
	    // requestâs header list.
	    for (const headerName of requestBodyHeader) {
	      request.headersList.delete(headerName);
	    }
	  }

	  // 13. If requestâs current URLâs origin is not same origin with locationURLâs
	  //     origin, then for each headerName of CORS non-wildcard request-header name,
	  //     delete headerName from requestâs header list.
	  if (!sameOrigin(requestCurrentURL(request), locationURL)) {
	    // https://fetch.spec.whatwg.org/#cors-non-wildcard-request-header-name
	    request.headersList.delete('authorization', true);

	    // https://fetch.spec.whatwg.org/#authentication-entries
	    request.headersList.delete('proxy-authorization', true);

	    // "Cookie" and "Host" are forbidden request-headers, which undici doesn't implement.
	    request.headersList.delete('cookie', true);
	    request.headersList.delete('host', true);
	  }

	  // 14. If requestâs body is non-null, then set requestâs body to the first return
	  // value of safely extracting requestâs bodyâs source.
	  if (request.body != null) {
	    assert(request.body.source != null);
	    request.body = safelyExtractBody(request.body.source)[0];
	  }

	  // 15. Let timingInfo be fetchParamsâs timing info.
	  const timingInfo = fetchParams.timingInfo;

	  // 16. Set timingInfoâs redirect end time and post-redirect start time to the
	  // coarsened shared current time given fetchParamsâs cross-origin isolated
	  // capability.
	  timingInfo.redirectEndTime = timingInfo.postRedirectStartTime =
	    coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability);

	  // 17. If timingInfoâs redirect start time is 0, then set timingInfoâs
	  //  redirect start time to timingInfoâs start time.
	  if (timingInfo.redirectStartTime === 0) {
	    timingInfo.redirectStartTime = timingInfo.startTime;
	  }

	  // 18. Append locationURL to requestâs URL list.
	  request.urlList.push(locationURL);

	  // 19. Invoke set requestâs referrer policy on redirect on request and
	  // actualResponse.
	  setRequestReferrerPolicyOnRedirect(request, actualResponse);

	  // 20. Return the result of running main fetch given fetchParams and true.
	  return mainFetch(fetchParams, true)
	}

	// https://fetch.spec.whatwg.org/#http-network-or-cache-fetch
	async function httpNetworkOrCacheFetch (
	  fetchParams,
	  isAuthenticationFetch = false,
	  isNewConnectionFetch = false
	) {
	  // 1. Let request be fetchParamsâs request.
	  const request = fetchParams.request;

	  // 2. Let httpFetchParams be null.
	  let httpFetchParams = null;

	  // 3. Let httpRequest be null.
	  let httpRequest = null;

	  // 4. Let response be null.
	  let response = null;

	  // 8. Run these steps, but abort when the ongoing fetch is terminated:

	  //    1. If requestâs window is "no-window" and requestâs redirect mode is
	  //    "error", then set httpFetchParams to fetchParams and httpRequest to
	  //    request.
	  if (request.window === 'no-window' && request.redirect === 'error') {
	    httpFetchParams = fetchParams;
	    httpRequest = request;
	  } else {
	    // Otherwise:

	    // 1. Set httpRequest to a clone of request.
	    httpRequest = cloneRequest(request);

	    // 2. Set httpFetchParams to a copy of fetchParams.
	    httpFetchParams = { ...fetchParams };

	    // 3. Set httpFetchParamsâs request to httpRequest.
	    httpFetchParams.request = httpRequest;
	  }

	  //    3. Let includeCredentials be true if one of
	  const includeCredentials =
	    request.credentials === 'include' ||
	    (request.credentials === 'same-origin' &&
	      request.responseTainting === 'basic');

	  //    4. Let contentLength be httpRequestâs bodyâs length, if httpRequestâs
	  //    body is non-null; otherwise null.
	  const contentLength = httpRequest.body ? httpRequest.body.length : null;

	  //    5. Let contentLengthHeaderValue be null.
	  let contentLengthHeaderValue = null;

	  //    6. If httpRequestâs body is null and httpRequestâs method is `POST` or
	  //    `PUT`, then set contentLengthHeaderValue to `0`.
	  if (
	    httpRequest.body == null &&
	    ['POST', 'PUT'].includes(httpRequest.method)
	  ) {
	    contentLengthHeaderValue = '0';
	  }

	  //    7. If contentLength is non-null, then set contentLengthHeaderValue to
	  //    contentLength, serialized and isomorphic encoded.
	  if (contentLength != null) {
	    contentLengthHeaderValue = isomorphicEncode(`${contentLength}`);
	  }

	  //    8. If contentLengthHeaderValue is non-null, then append
	  //    `Content-Length`/contentLengthHeaderValue to httpRequestâs header
	  //    list.
	  if (contentLengthHeaderValue != null) {
	    httpRequest.headersList.append('content-length', contentLengthHeaderValue, true);
	  }

	  //    9. If contentLengthHeaderValue is non-null, then append (`Content-Length`,
	  //    contentLengthHeaderValue) to httpRequestâs header list.

	  //    10. If contentLength is non-null and httpRequestâs keepalive is true,
	  //    then:
	  if (contentLength != null && httpRequest.keepalive) ;

	  //    11. If httpRequestâs referrer is a URL, then append
	  //    `Referer`/httpRequestâs referrer, serialized and isomorphic encoded,
	  //     to httpRequestâs header list.
	  if (httpRequest.referrer instanceof URL) {
	    httpRequest.headersList.append('referer', isomorphicEncode(httpRequest.referrer.href), true);
	  }

	  //    12. Append a request `Origin` header for httpRequest.
	  appendRequestOriginHeader(httpRequest);

	  //    13. Append the Fetch metadata headers for httpRequest. [FETCH-METADATA]
	  appendFetchMetadata(httpRequest);

	  //    14. If httpRequestâs header list does not contain `User-Agent`, then
	  //    user agents should append `User-Agent`/default `User-Agent` value to
	  //    httpRequestâs header list.
	  if (!httpRequest.headersList.contains('user-agent', true)) {
	    httpRequest.headersList.append('user-agent', defaultUserAgent);
	  }

	  //    15. If httpRequestâs cache mode is "default" and httpRequestâs header
	  //    list contains `If-Modified-Since`, `If-None-Match`,
	  //    `If-Unmodified-Since`, `If-Match`, or `If-Range`, then set
	  //    httpRequestâs cache mode to "no-store".
	  if (
	    httpRequest.cache === 'default' &&
	    (httpRequest.headersList.contains('if-modified-since', true) ||
	      httpRequest.headersList.contains('if-none-match', true) ||
	      httpRequest.headersList.contains('if-unmodified-since', true) ||
	      httpRequest.headersList.contains('if-match', true) ||
	      httpRequest.headersList.contains('if-range', true))
	  ) {
	    httpRequest.cache = 'no-store';
	  }

	  //    16. If httpRequestâs cache mode is "no-cache", httpRequestâs prevent
	  //    no-cache cache-control header modification flag is unset, and
	  //    httpRequestâs header list does not contain `Cache-Control`, then append
	  //    `Cache-Control`/`max-age=0` to httpRequestâs header list.
	  if (
	    httpRequest.cache === 'no-cache' &&
	    !httpRequest.preventNoCacheCacheControlHeaderModification &&
	    !httpRequest.headersList.contains('cache-control', true)
	  ) {
	    httpRequest.headersList.append('cache-control', 'max-age=0', true);
	  }

	  //    17. If httpRequestâs cache mode is "no-store" or "reload", then:
	  if (httpRequest.cache === 'no-store' || httpRequest.cache === 'reload') {
	    // 1. If httpRequestâs header list does not contain `Pragma`, then append
	    // `Pragma`/`no-cache` to httpRequestâs header list.
	    if (!httpRequest.headersList.contains('pragma', true)) {
	      httpRequest.headersList.append('pragma', 'no-cache', true);
	    }

	    // 2. If httpRequestâs header list does not contain `Cache-Control`,
	    // then append `Cache-Control`/`no-cache` to httpRequestâs header list.
	    if (!httpRequest.headersList.contains('cache-control', true)) {
	      httpRequest.headersList.append('cache-control', 'no-cache', true);
	    }
	  }

	  //    18. If httpRequestâs header list contains `Range`, then append
	  //    `Accept-Encoding`/`identity` to httpRequestâs header list.
	  if (httpRequest.headersList.contains('range', true)) {
	    httpRequest.headersList.append('accept-encoding', 'identity', true);
	  }

	  //    19. Modify httpRequestâs header list per HTTP. Do not append a given
	  //    header if httpRequestâs header list contains that headerâs name.
	  //    TODO: https://github.com/whatwg/fetch/issues/1285#issuecomment-896560129
	  if (!httpRequest.headersList.contains('accept-encoding', true)) {
	    if (urlHasHttpsScheme(requestCurrentURL(httpRequest))) {
	      httpRequest.headersList.append('accept-encoding', 'br, gzip, deflate', true);
	    } else {
	      httpRequest.headersList.append('accept-encoding', 'gzip, deflate', true);
	    }
	  }

	  httpRequest.headersList.delete('host', true);

	  //    21. If thereâs a proxy-authentication entry, use it as appropriate.
	  //    TODO: proxy-authentication

	  //    22. Set httpCache to the result of determining the HTTP cache
	  //    partition, given httpRequest.
	  //    TODO: cache

	  //    23. If httpCache is null, then set httpRequestâs cache mode to
	  //    "no-store".
	  {
	    httpRequest.cache = 'no-store';
	  }

	  //    24. If httpRequestâs cache mode is neither "no-store" nor "reload",
	  //    then:
	  if (httpRequest.cache !== 'no-store' && httpRequest.cache !== 'reload') ;

	  // 9. If aborted, then return the appropriate network error for fetchParams.
	  // TODO

	  // 10. If response is null, then:
	  if (response == null) {
	    // 1. If httpRequestâs cache mode is "only-if-cached", then return a
	    // network error.
	    if (httpRequest.cache === 'only-if-cached') {
	      return makeNetworkError('only if cached')
	    }

	    // 2. Let forwardResponse be the result of running HTTP-network fetch
	    // given httpFetchParams, includeCredentials, and isNewConnectionFetch.
	    const forwardResponse = await httpNetworkFetch(
	      httpFetchParams,
	      includeCredentials,
	      isNewConnectionFetch
	    );

	    // 3. If httpRequestâs method is unsafe and forwardResponseâs status is
	    // in the range 200 to 399, inclusive, invalidate appropriate stored
	    // responses in httpCache, as per the "Invalidation" chapter of HTTP
	    // Caching, and set storedResponse to null. [HTTP-CACHING]
	    if (
	      !safeMethodsSet.has(httpRequest.method) &&
	      forwardResponse.status >= 200 &&
	      forwardResponse.status <= 399
	    ) ;

	    // 5. If response is null, then:
	    if (response == null) {
	      // 1. Set response to forwardResponse.
	      response = forwardResponse;

	      // 2. Store httpRequest and forwardResponse in httpCache, as per the
	      // "Storing Responses in Caches" chapter of HTTP Caching. [HTTP-CACHING]
	      // TODO: cache
	    }
	  }

	  // 11. Set responseâs URL list to a clone of httpRequestâs URL list.
	  response.urlList = [...httpRequest.urlList];

	  // 12. If httpRequestâs header list contains `Range`, then set responseâs
	  // range-requested flag.
	  if (httpRequest.headersList.contains('range', true)) {
	    response.rangeRequested = true;
	  }

	  // 13. Set responseâs request-includes-credentials to includeCredentials.
	  response.requestIncludesCredentials = includeCredentials;

	  // 14. If responseâs status is 401, httpRequestâs response tainting is not
	  // "cors", includeCredentials is true, and requestâs window is an environment
	  // settings object, then:
	  // TODO

	  // 15. If responseâs status is 407, then:
	  if (response.status === 407) {
	    // 1. If requestâs window is "no-window", then return a network error.
	    if (request.window === 'no-window') {
	      return makeNetworkError()
	    }

	    // 2. ???

	    // 3. If fetchParams is canceled, then return the appropriate network error for fetchParams.
	    if (isCancelled(fetchParams)) {
	      return makeAppropriateNetworkError(fetchParams)
	    }

	    // 4. Prompt the end user as appropriate in requestâs window and store
	    // the result as a proxy-authentication entry. [HTTP-AUTH]
	    // TODO: Invoke some kind of callback?

	    // 5. Set response to the result of running HTTP-network-or-cache fetch given
	    // fetchParams.
	    // TODO
	    return makeNetworkError('proxy authentication required')
	  }

	  // 16. If all of the following are true
	  if (
	    // responseâs status is 421
	    response.status === 421 &&
	    // isNewConnectionFetch is false
	    !isNewConnectionFetch &&
	    // requestâs body is null, or requestâs body is non-null and requestâs bodyâs source is non-null
	    (request.body == null || request.body.source != null)
	  ) {
	    // then:

	    // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.
	    if (isCancelled(fetchParams)) {
	      return makeAppropriateNetworkError(fetchParams)
	    }

	    // 2. Set response to the result of running HTTP-network-or-cache
	    // fetch given fetchParams, isAuthenticationFetch, and true.

	    // TODO (spec): The spec doesn't specify this but we need to cancel
	    // the active response before we can start a new one.
	    // https://github.com/whatwg/fetch/issues/1293
	    fetchParams.controller.connection.destroy();

	    response = await httpNetworkOrCacheFetch(
	      fetchParams,
	      isAuthenticationFetch,
	      true
	    );
	  }

	  // 18. Return response.
	  return response
	}

	// https://fetch.spec.whatwg.org/#http-network-fetch
	async function httpNetworkFetch (
	  fetchParams,
	  includeCredentials = false,
	  forceNewConnection = false
	) {
	  assert(!fetchParams.controller.connection || fetchParams.controller.connection.destroyed);

	  fetchParams.controller.connection = {
	    abort: null,
	    destroyed: false,
	    destroy (err, abort = true) {
	      if (!this.destroyed) {
	        this.destroyed = true;
	        if (abort) {
	          this.abort?.(err ?? new DOMException('The operation was aborted.', 'AbortError'));
	        }
	      }
	    }
	  };

	  // 1. Let request be fetchParamsâs request.
	  const request = fetchParams.request;

	  // 2. Let response be null.
	  let response = null;

	  // 3. Let timingInfo be fetchParamsâs timing info.
	  const timingInfo = fetchParams.timingInfo;

	  // 5. If httpCache is null, then set requestâs cache mode to "no-store".
	  {
	    request.cache = 'no-store';
	  }

	  // 8. Switch on requestâs mode:
	  if (request.mode === 'websocket') ;

	  // 9. Run these steps, but abort when the ongoing fetch is terminated:

	  //    1. If connection is failure, then return a network error.

	  //    2. Set timingInfoâs final connection timing info to the result of
	  //    calling clamp and coarsen connection timing info with connectionâs
	  //    timing info, timingInfoâs post-redirect start time, and fetchParamsâs
	  //    cross-origin isolated capability.

	  //    3. If connection is not an HTTP/2 connection, requestâs body is non-null,
	  //    and requestâs bodyâs source is null, then append (`Transfer-Encoding`,
	  //    `chunked`) to requestâs header list.

	  //    4. Set timingInfoâs final network-request start time to the coarsened
	  //    shared current time given fetchParamsâs cross-origin isolated
	  //    capability.

	  //    5. Set response to the result of making an HTTP request over connection
	  //    using request with the following caveats:

	  //        - Follow the relevant requirements from HTTP. [HTTP] [HTTP-SEMANTICS]
	  //        [HTTP-COND] [HTTP-CACHING] [HTTP-AUTH]

	  //        - If requestâs body is non-null, and requestâs bodyâs source is null,
	  //        then the user agent may have a buffer of up to 64 kibibytes and store
	  //        a part of requestâs body in that buffer. If the user agent reads from
	  //        requestâs body beyond that bufferâs size and the user agent needs to
	  //        resend request, then instead return a network error.

	  //        - Set timingInfoâs final network-response start time to the coarsened
	  //        shared current time given fetchParamsâs cross-origin isolated capability,
	  //        immediately after the user agentâs HTTP parser receives the first byte
	  //        of the response (e.g., frame header bytes for HTTP/2 or response status
	  //        line for HTTP/1.x).

	  //        - Wait until all the headers are transmitted.

	  //        - Any responses whose status is in the range 100 to 199, inclusive,
	  //        and is not 101, are to be ignored, except for the purposes of setting
	  //        timingInfoâs final network-response start time above.

	  //    - If requestâs header list contains `Transfer-Encoding`/`chunked` and
	  //    response is transferred via HTTP/1.0 or older, then return a network
	  //    error.

	  //    - If the HTTP request results in a TLS client certificate dialog, then:

	  //        1. If requestâs window is an environment settings object, make the
	  //        dialog available in requestâs window.

	  //        2. Otherwise, return a network error.

	  // To transmit requestâs body body, run these steps:
	  let requestBody = null;
	  // 1. If body is null and fetchParamsâs process request end-of-body is
	  // non-null, then queue a fetch task given fetchParamsâs process request
	  // end-of-body and fetchParamsâs task destination.
	  if (request.body == null && fetchParams.processRequestEndOfBody) {
	    queueMicrotask(() => fetchParams.processRequestEndOfBody());
	  } else if (request.body != null) {
	    // 2. Otherwise, if body is non-null:

	    //    1. Let processBodyChunk given bytes be these steps:
	    const processBodyChunk = async function * (bytes) {
	      // 1. If the ongoing fetch is terminated, then abort these steps.
	      if (isCancelled(fetchParams)) {
	        return
	      }

	      // 2. Run this step in parallel: transmit bytes.
	      yield bytes;

	      // 3. If fetchParamsâs process request body is non-null, then run
	      // fetchParamsâs process request body given bytesâs length.
	      fetchParams.processRequestBodyChunkLength?.(bytes.byteLength);
	    };

	    // 2. Let processEndOfBody be these steps:
	    const processEndOfBody = () => {
	      // 1. If fetchParams is canceled, then abort these steps.
	      if (isCancelled(fetchParams)) {
	        return
	      }

	      // 2. If fetchParamsâs process request end-of-body is non-null,
	      // then run fetchParamsâs process request end-of-body.
	      if (fetchParams.processRequestEndOfBody) {
	        fetchParams.processRequestEndOfBody();
	      }
	    };

	    // 3. Let processBodyError given e be these steps:
	    const processBodyError = (e) => {
	      // 1. If fetchParams is canceled, then abort these steps.
	      if (isCancelled(fetchParams)) {
	        return
	      }

	      // 2. If e is an "AbortError" DOMException, then abort fetchParamsâs controller.
	      if (e.name === 'AbortError') {
	        fetchParams.controller.abort();
	      } else {
	        fetchParams.controller.terminate(e);
	      }
	    };

	    // 4. Incrementally read requestâs body given processBodyChunk, processEndOfBody,
	    // processBodyError, and fetchParamsâs task destination.
	    requestBody = (async function * () {
	      try {
	        for await (const bytes of request.body.stream) {
	          yield * processBodyChunk(bytes);
	        }
	        processEndOfBody();
	      } catch (err) {
	        processBodyError(err);
	      }
	    })();
	  }

	  try {
	    // socket is only provided for websockets
	    const { body, status, statusText, headersList, socket } = await dispatch({ body: requestBody });

	    if (socket) {
	      response = makeResponse({ status, statusText, headersList, socket });
	    } else {
	      const iterator = body[Symbol.asyncIterator]();
	      fetchParams.controller.next = () => iterator.next();

	      response = makeResponse({ status, statusText, headersList });
	    }
	  } catch (err) {
	    // 10. If aborted, then:
	    if (err.name === 'AbortError') {
	      // 1. If connection uses HTTP/2, then transmit an RST_STREAM frame.
	      fetchParams.controller.connection.destroy();

	      // 2. Return the appropriate network error for fetchParams.
	      return makeAppropriateNetworkError(fetchParams, err)
	    }

	    return makeNetworkError(err)
	  }

	  // 11. Let pullAlgorithm be an action that resumes the ongoing fetch
	  // if it is suspended.
	  const pullAlgorithm = async () => {
	    await fetchParams.controller.resume();
	  };

	  // 12. Let cancelAlgorithm be an algorithm that aborts fetchParamsâs
	  // controller with reason, given reason.
	  const cancelAlgorithm = (reason) => {
	    // If the aborted fetch was already terminated, then we do not
	    // need to do anything.
	    if (!isCancelled(fetchParams)) {
	      fetchParams.controller.abort(reason);
	    }
	  };

	  // 13. Let highWaterMark be a non-negative, non-NaN number, chosen by
	  // the user agent.
	  // TODO

	  // 14. Let sizeAlgorithm be an algorithm that accepts a chunk object
	  // and returns a non-negative, non-NaN, non-infinite number, chosen by the user agent.
	  // TODO

	  // 15. Let stream be a new ReadableStream.
	  // 16. Set up stream with byte reading support with pullAlgorithm set to pullAlgorithm,
	  //     cancelAlgorithm set to cancelAlgorithm.
	  const stream = new ReadableStream(
	    {
	      async start (controller) {
	        fetchParams.controller.controller = controller;
	      },
	      async pull (controller) {
	        await pullAlgorithm();
	      },
	      async cancel (reason) {
	        await cancelAlgorithm(reason);
	      },
	      type: 'bytes'
	    }
	  );

	  // 17. Run these steps, but abort when the ongoing fetch is terminated:

	  //    1. Set responseâs body to a new body whose stream is stream.
	  response.body = { stream, source: null, length: null };

	  //    2. If response is not a network error and requestâs cache mode is
	  //    not "no-store", then update response in httpCache for request.
	  //    TODO

	  //    3. If includeCredentials is true and the user agent is not configured
	  //    to block cookies for request (see section 7 of [COOKIES]), then run the
	  //    "set-cookie-string" parsing algorithm (see section 5.2 of [COOKIES]) on
	  //    the value of each header whose name is a byte-case-insensitive match for
	  //    `Set-Cookie` in responseâs header list, if any, and requestâs current URL.
	  //    TODO

	  // 18. If aborted, then:
	  // TODO

	  // 19. Run these steps in parallel:

	  //    1. Run these steps, but abort when fetchParams is canceled:
	  fetchParams.controller.onAborted = onAborted;
	  fetchParams.controller.on('terminated', onAborted);
	  fetchParams.controller.resume = async () => {
	    // 1. While true
	    while (true) {
	      // 1-3. See onData...

	      // 4. Set bytes to the result of handling content codings given
	      // codings and bytes.
	      let bytes;
	      let isFailure;
	      try {
	        const { done, value } = await fetchParams.controller.next();

	        if (isAborted(fetchParams)) {
	          break
	        }

	        bytes = done ? undefined : value;
	      } catch (err) {
	        if (fetchParams.controller.ended && !timingInfo.encodedBodySize) {
	          // zlib doesn't like empty streams.
	          bytes = undefined;
	        } else {
	          bytes = err;

	          // err may be propagated from the result of calling readablestream.cancel,
	          // which might not be an error. https://github.com/nodejs/undici/issues/2009
	          isFailure = true;
	        }
	      }

	      if (bytes === undefined) {
	        // 2. Otherwise, if the bytes transmission for responseâs message
	        // body is done normally and stream is readable, then close
	        // stream, finalize response for fetchParams and response, and
	        // abort these in-parallel steps.
	        readableStreamClose(fetchParams.controller.controller);

	        finalizeResponse(fetchParams, response);

	        return
	      }

	      // 5. Increase timingInfoâs decoded body size by bytesâs length.
	      timingInfo.decodedBodySize += bytes?.byteLength ?? 0;

	      // 6. If bytes is failure, then terminate fetchParamsâs controller.
	      if (isFailure) {
	        fetchParams.controller.terminate(bytes);
	        return
	      }

	      // 7. Enqueue a Uint8Array wrapping an ArrayBuffer containing bytes
	      // into stream.
	      const buffer = new Uint8Array(bytes);
	      if (buffer.byteLength) {
	        fetchParams.controller.controller.enqueue(buffer);
	      }

	      // 8. If stream is errored, then terminate the ongoing fetch.
	      if (isErrored(stream)) {
	        fetchParams.controller.terminate();
	        return
	      }

	      // 9. If stream doesnât need more data ask the user agent to suspend
	      // the ongoing fetch.
	      if (fetchParams.controller.controller.desiredSize <= 0) {
	        return
	      }
	    }
	  };

	  //    2. If aborted, then:
	  function onAborted (reason) {
	    // 2. If fetchParams is aborted, then:
	    if (isAborted(fetchParams)) {
	      // 1. Set responseâs aborted flag.
	      response.aborted = true;

	      // 2. If stream is readable, then error stream with the result of
	      //    deserialize a serialized abort reason given fetchParamsâs
	      //    controllerâs serialized abort reason and an
	      //    implementation-defined realm.
	      if (isReadable(stream)) {
	        fetchParams.controller.controller.error(
	          fetchParams.controller.serializedAbortReason
	        );
	      }
	    } else {
	      // 3. Otherwise, if stream is readable, error stream with a TypeError.
	      if (isReadable(stream)) {
	        fetchParams.controller.controller.error(new TypeError('terminated', {
	          cause: isErrorLike(reason) ? reason : undefined
	        }));
	      }
	    }

	    // 4. If connection uses HTTP/2, then transmit an RST_STREAM frame.
	    // 5. Otherwise, the user agent should close connection unless it would be bad for performance to do so.
	    fetchParams.controller.connection.destroy();
	  }

	  // 20. Return response.
	  return response

	  function dispatch ({ body }) {
	    const url = requestCurrentURL(request);
	    /** @type {import('../..').Agent} */
	    const agent = fetchParams.controller.dispatcher;

	    return new Promise((resolve, reject) => agent.dispatch(
	      {
	        path: url.pathname + url.search,
	        origin: url.origin,
	        method: request.method,
	        body: agent.isMockActive ? request.body && (request.body.source || request.body.stream) : body,
	        headers: request.headersList.entries,
	        maxRedirections: 0,
	        upgrade: request.mode === 'websocket' ? 'websocket' : undefined
	      },
	      {
	        body: null,
	        abort: null,

	        onConnect (abort) {
	          // TODO (fix): Do we need connection here?
	          const { connection } = fetchParams.controller;

	          // Set timingInfoâs final connection timing info to the result of calling clamp and coarsen
	          // connection timing info with connectionâs timing info, timingInfoâs post-redirect start
	          // time, and fetchParamsâs cross-origin isolated capability.
	          // TODO: implement connection timing
	          timingInfo.finalConnectionTimingInfo = clampAndCoarsenConnectionTimingInfo(undefined, timingInfo.postRedirectStartTime, fetchParams.crossOriginIsolatedCapability);

	          if (connection.destroyed) {
	            abort(new DOMException('The operation was aborted.', 'AbortError'));
	          } else {
	            fetchParams.controller.on('terminated', abort);
	            this.abort = connection.abort = abort;
	          }

	          // Set timingInfoâs final network-request start time to the coarsened shared current time given
	          // fetchParamsâs cross-origin isolated capability.
	          timingInfo.finalNetworkRequestStartTime = coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability);
	        },

	        onResponseStarted () {
	          // Set timingInfoâs final network-response start time to the coarsened shared current
	          // time given fetchParamsâs cross-origin isolated capability, immediately after the
	          // user agentâs HTTP parser receives the first byte of the response (e.g., frame header
	          // bytes for HTTP/2 or response status line for HTTP/1.x).
	          timingInfo.finalNetworkResponseStartTime = coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability);
	        },

	        onHeaders (status, rawHeaders, resume, statusText) {
	          if (status < 200) {
	            return
	          }

	          /** @type {string[]} */
	          let codings = [];
	          let location = '';

	          const headersList = new HeadersList();

	          for (let i = 0; i < rawHeaders.length; i += 2) {
	            headersList.append(bufferToLowerCasedHeaderName(rawHeaders[i]), rawHeaders[i + 1].toString('latin1'), true);
	          }
	          const contentEncoding = headersList.get('content-encoding', true);
	          if (contentEncoding) {
	            // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1
	            // "All content-coding values are case-insensitive..."
	            codings = contentEncoding.toLowerCase().split(',').map((x) => x.trim());
	          }
	          location = headersList.get('location', true);

	          this.body = new Readable({ read: resume });

	          const decoders = [];

	          const willFollow = location && request.redirect === 'follow' &&
	            redirectStatusSet.has(status);

	          // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding
	          if (codings.length !== 0 && request.method !== 'HEAD' && request.method !== 'CONNECT' && !nullBodyStatus.includes(status) && !willFollow) {
	            for (let i = 0; i < codings.length; ++i) {
	              const coding = codings[i];
	              // https://www.rfc-editor.org/rfc/rfc9112.html#section-7.2
	              if (coding === 'x-gzip' || coding === 'gzip') {
	                decoders.push(zlib.createGunzip({
	                  // Be less strict when decoding compressed responses, since sometimes
	                  // servers send slightly invalid responses that are still accepted
	                  // by common browsers.
	                  // Always using Z_SYNC_FLUSH is what cURL does.
	                  flush: zlib.constants.Z_SYNC_FLUSH,
	                  finishFlush: zlib.constants.Z_SYNC_FLUSH
	                }));
	              } else if (coding === 'deflate') {
	                decoders.push(createInflate());
	              } else if (coding === 'br') {
	                decoders.push(zlib.createBrotliDecompress());
	              } else {
	                decoders.length = 0;
	                break
	              }
	            }
	          }

	          resolve({
	            status,
	            statusText,
	            headersList,
	            body: decoders.length
	              ? pipeline(this.body, ...decoders, () => { })
	              : this.body.on('error', () => { })
	          });

	          return true
	        },

	        onData (chunk) {
	          if (fetchParams.controller.dump) {
	            return
	          }

	          // 1. If one or more bytes have been transmitted from responseâs
	          // message body, then:

	          //  1. Let bytes be the transmitted bytes.
	          const bytes = chunk;

	          //  2. Let codings be the result of extracting header list values
	          //  given `Content-Encoding` and responseâs header list.
	          //  See pullAlgorithm.

	          //  3. Increase timingInfoâs encoded body size by bytesâs length.
	          timingInfo.encodedBodySize += bytes.byteLength;

	          //  4. See pullAlgorithm...

	          return this.body.push(bytes)
	        },

	        onComplete () {
	          if (this.abort) {
	            fetchParams.controller.off('terminated', this.abort);
	          }

	          if (fetchParams.controller.onAborted) {
	            fetchParams.controller.off('terminated', fetchParams.controller.onAborted);
	          }

	          fetchParams.controller.ended = true;

	          this.body.push(null);
	        },

	        onError (error) {
	          if (this.abort) {
	            fetchParams.controller.off('terminated', this.abort);
	          }

	          this.body?.destroy(error);

	          fetchParams.controller.terminate(error);

	          reject(error);
	        },

	        onUpgrade (status, rawHeaders, socket) {
	          if (status !== 101) {
	            return
	          }

	          const headersList = new HeadersList();

	          for (let i = 0; i < rawHeaders.length; i += 2) {
	            headersList.append(bufferToLowerCasedHeaderName(rawHeaders[i]), rawHeaders[i + 1].toString('latin1'), true);
	          }

	          resolve({
	            status,
	            statusText: STATUS_CODES[status],
	            headersList,
	            socket
	          });

	          return true
	        }
	      }
	    ))
	  }
	}

	fetch_1 = {
	  fetch,
	  Fetch,
	  fetching,
	  finalizeAndReportTiming
	};
	return fetch_1;
}

var symbols$2;
var hasRequiredSymbols$2;

function requireSymbols$2 () {
	if (hasRequiredSymbols$2) return symbols$2;
	hasRequiredSymbols$2 = 1;

	symbols$2 = {
	  kState: Symbol('FileReader state'),
	  kResult: Symbol('FileReader result'),
	  kError: Symbol('FileReader error'),
	  kLastProgressEventFired: Symbol('FileReader last progress event fired timestamp'),
	  kEvents: Symbol('FileReader events'),
	  kAborted: Symbol('FileReader aborted')
	};
	return symbols$2;
}

var progressevent;
var hasRequiredProgressevent;

function requireProgressevent () {
	if (hasRequiredProgressevent) return progressevent;
	hasRequiredProgressevent = 1;

	const { webidl } = requireWebidl();

	const kState = Symbol('ProgressEvent state');

	/**
	 * @see https://xhr.spec.whatwg.org/#progressevent
	 */
	class ProgressEvent extends Event {
	  constructor (type, eventInitDict = {}) {
	    type = webidl.converters.DOMString(type, 'ProgressEvent constructor', 'type');
	    eventInitDict = webidl.converters.ProgressEventInit(eventInitDict ?? {});

	    super(type, eventInitDict);

	    this[kState] = {
	      lengthComputable: eventInitDict.lengthComputable,
	      loaded: eventInitDict.loaded,
	      total: eventInitDict.total
	    };
	  }

	  get lengthComputable () {
	    webidl.brandCheck(this, ProgressEvent);

	    return this[kState].lengthComputable
	  }

	  get loaded () {
	    webidl.brandCheck(this, ProgressEvent);

	    return this[kState].loaded
	  }

	  get total () {
	    webidl.brandCheck(this, ProgressEvent);

	    return this[kState].total
	  }
	}

	webidl.converters.ProgressEventInit = webidl.dictionaryConverter([
	  {
	    key: 'lengthComputable',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'loaded',
	    converter: webidl.converters['unsigned long long'],
	    defaultValue: () => 0
	  },
	  {
	    key: 'total',
	    converter: webidl.converters['unsigned long long'],
	    defaultValue: () => 0
	  },
	  {
	    key: 'bubbles',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'cancelable',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'composed',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  }
	]);

	progressevent = {
	  ProgressEvent
	};
	return progressevent;
}

var encoding;
var hasRequiredEncoding;

function requireEncoding () {
	if (hasRequiredEncoding) return encoding;
	hasRequiredEncoding = 1;

	/**
	 * @see https://encoding.spec.whatwg.org/#concept-encoding-get
	 * @param {string|undefined} label
	 */
	function getEncoding (label) {
	  if (!label) {
	    return 'failure'
	  }

	  // 1. Remove any leading and trailing ASCII whitespace from label.
	  // 2. If label is an ASCII case-insensitive match for any of the
	  //    labels listed in the table below, then return the
	  //    corresponding encoding; otherwise return failure.
	  switch (label.trim().toLowerCase()) {
	    case 'unicode-1-1-utf-8':
	    case 'unicode11utf8':
	    case 'unicode20utf8':
	    case 'utf-8':
	    case 'utf8':
	    case 'x-unicode20utf8':
	      return 'UTF-8'
	    case '866':
	    case 'cp866':
	    case 'csibm866':
	    case 'ibm866':
	      return 'IBM866'
	    case 'csisolatin2':
	    case 'iso-8859-2':
	    case 'iso-ir-101':
	    case 'iso8859-2':
	    case 'iso88592':
	    case 'iso_8859-2':
	    case 'iso_8859-2:1987':
	    case 'l2':
	    case 'latin2':
	      return 'ISO-8859-2'
	    case 'csisolatin3':
	    case 'iso-8859-3':
	    case 'iso-ir-109':
	    case 'iso8859-3':
	    case 'iso88593':
	    case 'iso_8859-3':
	    case 'iso_8859-3:1988':
	    case 'l3':
	    case 'latin3':
	      return 'ISO-8859-3'
	    case 'csisolatin4':
	    case 'iso-8859-4':
	    case 'iso-ir-110':
	    case 'iso8859-4':
	    case 'iso88594':
	    case 'iso_8859-4':
	    case 'iso_8859-4:1988':
	    case 'l4':
	    case 'latin4':
	      return 'ISO-8859-4'
	    case 'csisolatincyrillic':
	    case 'cyrillic':
	    case 'iso-8859-5':
	    case 'iso-ir-144':
	    case 'iso8859-5':
	    case 'iso88595':
	    case 'iso_8859-5':
	    case 'iso_8859-5:1988':
	      return 'ISO-8859-5'
	    case 'arabic':
	    case 'asmo-708':
	    case 'csiso88596e':
	    case 'csiso88596i':
	    case 'csisolatinarabic':
	    case 'ecma-114':
	    case 'iso-8859-6':
	    case 'iso-8859-6-e':
	    case 'iso-8859-6-i':
	    case 'iso-ir-127':
	    case 'iso8859-6':
	    case 'iso88596':
	    case 'iso_8859-6':
	    case 'iso_8859-6:1987':
	      return 'ISO-8859-6'
	    case 'csisolatingreek':
	    case 'ecma-118':
	    case 'elot_928':
	    case 'greek':
	    case 'greek8':
	    case 'iso-8859-7':
	    case 'iso-ir-126':
	    case 'iso8859-7':
	    case 'iso88597':
	    case 'iso_8859-7':
	    case 'iso_8859-7:1987':
	    case 'sun_eu_greek':
	      return 'ISO-8859-7'
	    case 'csiso88598e':
	    case 'csisolatinhebrew':
	    case 'hebrew':
	    case 'iso-8859-8':
	    case 'iso-8859-8-e':
	    case 'iso-ir-138':
	    case 'iso8859-8':
	    case 'iso88598':
	    case 'iso_8859-8':
	    case 'iso_8859-8:1988':
	    case 'visual':
	      return 'ISO-8859-8'
	    case 'csiso88598i':
	    case 'iso-8859-8-i':
	    case 'logical':
	      return 'ISO-8859-8-I'
	    case 'csisolatin6':
	    case 'iso-8859-10':
	    case 'iso-ir-157':
	    case 'iso8859-10':
	    case 'iso885910':
	    case 'l6':
	    case 'latin6':
	      return 'ISO-8859-10'
	    case 'iso-8859-13':
	    case 'iso8859-13':
	    case 'iso885913':
	      return 'ISO-8859-13'
	    case 'iso-8859-14':
	    case 'iso8859-14':
	    case 'iso885914':
	      return 'ISO-8859-14'
	    case 'csisolatin9':
	    case 'iso-8859-15':
	    case 'iso8859-15':
	    case 'iso885915':
	    case 'iso_8859-15':
	    case 'l9':
	      return 'ISO-8859-15'
	    case 'iso-8859-16':
	      return 'ISO-8859-16'
	    case 'cskoi8r':
	    case 'koi':
	    case 'koi8':
	    case 'koi8-r':
	    case 'koi8_r':
	      return 'KOI8-R'
	    case 'koi8-ru':
	    case 'koi8-u':
	      return 'KOI8-U'
	    case 'csmacintosh':
	    case 'mac':
	    case 'macintosh':
	    case 'x-mac-roman':
	      return 'macintosh'
	    case 'iso-8859-11':
	    case 'iso8859-11':
	    case 'iso885911':
	    case 'tis-620':
	    case 'windows-874':
	      return 'windows-874'
	    case 'cp1250':
	    case 'windows-1250':
	    case 'x-cp1250':
	      return 'windows-1250'
	    case 'cp1251':
	    case 'windows-1251':
	    case 'x-cp1251':
	      return 'windows-1251'
	    case 'ansi_x3.4-1968':
	    case 'ascii':
	    case 'cp1252':
	    case 'cp819':
	    case 'csisolatin1':
	    case 'ibm819':
	    case 'iso-8859-1':
	    case 'iso-ir-100':
	    case 'iso8859-1':
	    case 'iso88591':
	    case 'iso_8859-1':
	    case 'iso_8859-1:1987':
	    case 'l1':
	    case 'latin1':
	    case 'us-ascii':
	    case 'windows-1252':
	    case 'x-cp1252':
	      return 'windows-1252'
	    case 'cp1253':
	    case 'windows-1253':
	    case 'x-cp1253':
	      return 'windows-1253'
	    case 'cp1254':
	    case 'csisolatin5':
	    case 'iso-8859-9':
	    case 'iso-ir-148':
	    case 'iso8859-9':
	    case 'iso88599':
	    case 'iso_8859-9':
	    case 'iso_8859-9:1989':
	    case 'l5':
	    case 'latin5':
	    case 'windows-1254':
	    case 'x-cp1254':
	      return 'windows-1254'
	    case 'cp1255':
	    case 'windows-1255':
	    case 'x-cp1255':
	      return 'windows-1255'
	    case 'cp1256':
	    case 'windows-1256':
	    case 'x-cp1256':
	      return 'windows-1256'
	    case 'cp1257':
	    case 'windows-1257':
	    case 'x-cp1257':
	      return 'windows-1257'
	    case 'cp1258':
	    case 'windows-1258':
	    case 'x-cp1258':
	      return 'windows-1258'
	    case 'x-mac-cyrillic':
	    case 'x-mac-ukrainian':
	      return 'x-mac-cyrillic'
	    case 'chinese':
	    case 'csgb2312':
	    case 'csiso58gb231280':
	    case 'gb2312':
	    case 'gb_2312':
	    case 'gb_2312-80':
	    case 'gbk':
	    case 'iso-ir-58':
	    case 'x-gbk':
	      return 'GBK'
	    case 'gb18030':
	      return 'gb18030'
	    case 'big5':
	    case 'big5-hkscs':
	    case 'cn-big5':
	    case 'csbig5':
	    case 'x-x-big5':
	      return 'Big5'
	    case 'cseucpkdfmtjapanese':
	    case 'euc-jp':
	    case 'x-euc-jp':
	      return 'EUC-JP'
	    case 'csiso2022jp':
	    case 'iso-2022-jp':
	      return 'ISO-2022-JP'
	    case 'csshiftjis':
	    case 'ms932':
	    case 'ms_kanji':
	    case 'shift-jis':
	    case 'shift_jis':
	    case 'sjis':
	    case 'windows-31j':
	    case 'x-sjis':
	      return 'Shift_JIS'
	    case 'cseuckr':
	    case 'csksc56011987':
	    case 'euc-kr':
	    case 'iso-ir-149':
	    case 'korean':
	    case 'ks_c_5601-1987':
	    case 'ks_c_5601-1989':
	    case 'ksc5601':
	    case 'ksc_5601':
	    case 'windows-949':
	      return 'EUC-KR'
	    case 'csiso2022kr':
	    case 'hz-gb-2312':
	    case 'iso-2022-cn':
	    case 'iso-2022-cn-ext':
	    case 'iso-2022-kr':
	    case 'replacement':
	      return 'replacement'
	    case 'unicodefffe':
	    case 'utf-16be':
	      return 'UTF-16BE'
	    case 'csunicode':
	    case 'iso-10646-ucs-2':
	    case 'ucs-2':
	    case 'unicode':
	    case 'unicodefeff':
	    case 'utf-16':
	    case 'utf-16le':
	      return 'UTF-16LE'
	    case 'x-user-defined':
	      return 'x-user-defined'
	    default: return 'failure'
	  }
	}

	encoding = {
	  getEncoding
	};
	return encoding;
}

var util$4;
var hasRequiredUtil$4;

function requireUtil$4 () {
	if (hasRequiredUtil$4) return util$4;
	hasRequiredUtil$4 = 1;

	const {
	  kState,
	  kError,
	  kResult,
	  kAborted,
	  kLastProgressEventFired
	} = requireSymbols$2();
	const { ProgressEvent } = requireProgressevent();
	const { getEncoding } = requireEncoding();
	const { serializeAMimeType, parseMIMEType } = requireDataUrl();
	const { types } = require$$0$6;
	const { StringDecoder } = require$$5$2;
	const { btoa } = require$$0$3;

	/** @type {PropertyDescriptor} */
	const staticPropertyDescriptors = {
	  enumerable: true,
	  writable: false,
	  configurable: false
	};

	/**
	 * @see https://w3c.github.io/FileAPI/#readOperation
	 * @param {import('./filereader').FileReader} fr
	 * @param {import('buffer').Blob} blob
	 * @param {string} type
	 * @param {string?} encodingName
	 */
	function readOperation (fr, blob, type, encodingName) {
	  // 1. If frâs state is "loading", throw an InvalidStateError
	  //    DOMException.
	  if (fr[kState] === 'loading') {
	    throw new DOMException('Invalid state', 'InvalidStateError')
	  }

	  // 2. Set frâs state to "loading".
	  fr[kState] = 'loading';

	  // 3. Set frâs result to null.
	  fr[kResult] = null;

	  // 4. Set frâs error to null.
	  fr[kError] = null;

	  // 5. Let stream be the result of calling get stream on blob.
	  /** @type {import('stream/web').ReadableStream} */
	  const stream = blob.stream();

	  // 6. Let reader be the result of getting a reader from stream.
	  const reader = stream.getReader();

	  // 7. Let bytes be an empty byte sequence.
	  /** @type {Uint8Array[]} */
	  const bytes = [];

	  // 8. Let chunkPromise be the result of reading a chunk from
	  //    stream with reader.
	  let chunkPromise = reader.read();

	  // 9. Let isFirstChunk be true.
	  let isFirstChunk = true

	  // 10. In parallel, while true:
	  // Note: "In parallel" just means non-blocking
	  // Note 2: readOperation itself cannot be async as double
	  // reading the body would then reject the promise, instead
	  // of throwing an error.
	  ;(async () => {
	    while (!fr[kAborted]) {
	      // 1. Wait for chunkPromise to be fulfilled or rejected.
	      try {
	        const { done, value } = await chunkPromise;

	        // 2. If chunkPromise is fulfilled, and isFirstChunk is
	        //    true, queue a task to fire a progress event called
	        //    loadstart at fr.
	        if (isFirstChunk && !fr[kAborted]) {
	          queueMicrotask(() => {
	            fireAProgressEvent('loadstart', fr);
	          });
	        }

	        // 3. Set isFirstChunk to false.
	        isFirstChunk = false;

	        // 4. If chunkPromise is fulfilled with an object whose
	        //    done property is false and whose value property is
	        //    a Uint8Array object, run these steps:
	        if (!done && types.isUint8Array(value)) {
	          // 1. Let bs be the byte sequence represented by the
	          //    Uint8Array object.

	          // 2. Append bs to bytes.
	          bytes.push(value);

	          // 3. If roughly 50ms have passed since these steps
	          //    were last invoked, queue a task to fire a
	          //    progress event called progress at fr.
	          if (
	            (
	              fr[kLastProgressEventFired] === undefined ||
	              Date.now() - fr[kLastProgressEventFired] >= 50
	            ) &&
	            !fr[kAborted]
	          ) {
	            fr[kLastProgressEventFired] = Date.now();
	            queueMicrotask(() => {
	              fireAProgressEvent('progress', fr);
	            });
	          }

	          // 4. Set chunkPromise to the result of reading a
	          //    chunk from stream with reader.
	          chunkPromise = reader.read();
	        } else if (done) {
	          // 5. Otherwise, if chunkPromise is fulfilled with an
	          //    object whose done property is true, queue a task
	          //    to run the following steps and abort this algorithm:
	          queueMicrotask(() => {
	            // 1. Set frâs state to "done".
	            fr[kState] = 'done';

	            // 2. Let result be the result of package data given
	            //    bytes, type, blobâs type, and encodingName.
	            try {
	              const result = packageData(bytes, type, blob.type, encodingName);

	              // 4. Else:

	              if (fr[kAborted]) {
	                return
	              }

	              // 1. Set frâs result to result.
	              fr[kResult] = result;

	              // 2. Fire a progress event called load at the fr.
	              fireAProgressEvent('load', fr);
	            } catch (error) {
	              // 3. If package data threw an exception error:

	              // 1. Set frâs error to error.
	              fr[kError] = error;

	              // 2. Fire a progress event called error at fr.
	              fireAProgressEvent('error', fr);
	            }

	            // 5. If frâs state is not "loading", fire a progress
	            //    event called loadend at the fr.
	            if (fr[kState] !== 'loading') {
	              fireAProgressEvent('loadend', fr);
	            }
	          });

	          break
	        }
	      } catch (error) {
	        if (fr[kAborted]) {
	          return
	        }

	        // 6. Otherwise, if chunkPromise is rejected with an
	        //    error error, queue a task to run the following
	        //    steps and abort this algorithm:
	        queueMicrotask(() => {
	          // 1. Set frâs state to "done".
	          fr[kState] = 'done';

	          // 2. Set frâs error to error.
	          fr[kError] = error;

	          // 3. Fire a progress event called error at fr.
	          fireAProgressEvent('error', fr);

	          // 4. If frâs state is not "loading", fire a progress
	          //    event called loadend at fr.
	          if (fr[kState] !== 'loading') {
	            fireAProgressEvent('loadend', fr);
	          }
	        });

	        break
	      }
	    }
	  })();
	}

	/**
	 * @see https://w3c.github.io/FileAPI/#fire-a-progress-event
	 * @see https://dom.spec.whatwg.org/#concept-event-fire
	 * @param {string} e The name of the event
	 * @param {import('./filereader').FileReader} reader
	 */
	function fireAProgressEvent (e, reader) {
	  // The progress event e does not bubble. e.bubbles must be false
	  // The progress event e is NOT cancelable. e.cancelable must be false
	  const event = new ProgressEvent(e, {
	    bubbles: false,
	    cancelable: false
	  });

	  reader.dispatchEvent(event);
	}

	/**
	 * @see https://w3c.github.io/FileAPI/#blob-package-data
	 * @param {Uint8Array[]} bytes
	 * @param {string} type
	 * @param {string?} mimeType
	 * @param {string?} encodingName
	 */
	function packageData (bytes, type, mimeType, encodingName) {
	  // 1. A Blob has an associated package data algorithm, given
	  //    bytes, a type, a optional mimeType, and a optional
	  //    encodingName, which switches on type and runs the
	  //    associated steps:

	  switch (type) {
	    case 'DataURL': {
	      // 1. Return bytes as a DataURL [RFC2397] subject to
	      //    the considerations below:
	      //  * Use mimeType as part of the Data URL if it is
	      //    available in keeping with the Data URL
	      //    specification [RFC2397].
	      //  * If mimeType is not available return a Data URL
	      //    without a media-type. [RFC2397].

	      // https://datatracker.ietf.org/doc/html/rfc2397#section-3
	      // dataurl    := "data:" [ mediatype ] [ ";base64" ] "," data
	      // mediatype  := [ type "/" subtype ] *( ";" parameter )
	      // data       := *urlchar
	      // parameter  := attribute "=" value
	      let dataURL = 'data:';

	      const parsed = parseMIMEType(mimeType || 'application/octet-stream');

	      if (parsed !== 'failure') {
	        dataURL += serializeAMimeType(parsed);
	      }

	      dataURL += ';base64,';

	      const decoder = new StringDecoder('latin1');

	      for (const chunk of bytes) {
	        dataURL += btoa(decoder.write(chunk));
	      }

	      dataURL += btoa(decoder.end());

	      return dataURL
	    }
	    case 'Text': {
	      // 1. Let encoding be failure
	      let encoding = 'failure';

	      // 2. If the encodingName is present, set encoding to the
	      //    result of getting an encoding from encodingName.
	      if (encodingName) {
	        encoding = getEncoding(encodingName);
	      }

	      // 3. If encoding is failure, and mimeType is present:
	      if (encoding === 'failure' && mimeType) {
	        // 1. Let type be the result of parse a MIME type
	        //    given mimeType.
	        const type = parseMIMEType(mimeType);

	        // 2. If type is not failure, set encoding to the result
	        //    of getting an encoding from typeâs parameters["charset"].
	        if (type !== 'failure') {
	          encoding = getEncoding(type.parameters.get('charset'));
	        }
	      }

	      // 4. If encoding is failure, then set encoding to UTF-8.
	      if (encoding === 'failure') {
	        encoding = 'UTF-8';
	      }

	      // 5. Decode bytes using fallback encoding encoding, and
	      //    return the result.
	      return decode(bytes, encoding)
	    }
	    case 'ArrayBuffer': {
	      // Return a new ArrayBuffer whose contents are bytes.
	      const sequence = combineByteSequences(bytes);

	      return sequence.buffer
	    }
	    case 'BinaryString': {
	      // Return bytes as a binary string, in which every byte
	      //  is represented by a code unit of equal value [0..255].
	      let binaryString = '';

	      const decoder = new StringDecoder('latin1');

	      for (const chunk of bytes) {
	        binaryString += decoder.write(chunk);
	      }

	      binaryString += decoder.end();

	      return binaryString
	    }
	  }
	}

	/**
	 * @see https://encoding.spec.whatwg.org/#decode
	 * @param {Uint8Array[]} ioQueue
	 * @param {string} encoding
	 */
	function decode (ioQueue, encoding) {
	  const bytes = combineByteSequences(ioQueue);

	  // 1. Let BOMEncoding be the result of BOM sniffing ioQueue.
	  const BOMEncoding = BOMSniffing(bytes);

	  let slice = 0;

	  // 2. If BOMEncoding is non-null:
	  if (BOMEncoding !== null) {
	    // 1. Set encoding to BOMEncoding.
	    encoding = BOMEncoding;

	    // 2. Read three bytes from ioQueue, if BOMEncoding is
	    //    UTF-8; otherwise read two bytes.
	    //    (Do nothing with those bytes.)
	    slice = BOMEncoding === 'UTF-8' ? 3 : 2;
	  }

	  // 3. Process a queue with an instance of encodingâs
	  //    decoder, ioQueue, output, and "replacement".

	  // 4. Return output.

	  const sliced = bytes.slice(slice);
	  return new TextDecoder(encoding).decode(sliced)
	}

	/**
	 * @see https://encoding.spec.whatwg.org/#bom-sniff
	 * @param {Uint8Array} ioQueue
	 */
	function BOMSniffing (ioQueue) {
	  // 1. Let BOM be the result of peeking 3 bytes from ioQueue,
	  //    converted to a byte sequence.
	  const [a, b, c] = ioQueue;

	  // 2. For each of the rows in the table below, starting with
	  //    the first one and going down, if BOM starts with the
	  //    bytes given in the first column, then return the
	  //    encoding given in the cell in the second column of that
	  //    row. Otherwise, return null.
	  if (a === 0xEF && b === 0xBB && c === 0xBF) {
	    return 'UTF-8'
	  } else if (a === 0xFE && b === 0xFF) {
	    return 'UTF-16BE'
	  } else if (a === 0xFF && b === 0xFE) {
	    return 'UTF-16LE'
	  }

	  return null
	}

	/**
	 * @param {Uint8Array[]} sequences
	 */
	function combineByteSequences (sequences) {
	  const size = sequences.reduce((a, b) => {
	    return a + b.byteLength
	  }, 0);

	  let offset = 0;

	  return sequences.reduce((a, b) => {
	    a.set(b, offset);
	    offset += b.byteLength;
	    return a
	  }, new Uint8Array(size))
	}

	util$4 = {
	  staticPropertyDescriptors,
	  readOperation,
	  fireAProgressEvent
	};
	return util$4;
}

var filereader;
var hasRequiredFilereader;

function requireFilereader () {
	if (hasRequiredFilereader) return filereader;
	hasRequiredFilereader = 1;

	const {
	  staticPropertyDescriptors,
	  readOperation,
	  fireAProgressEvent
	} = requireUtil$4();
	const {
	  kState,
	  kError,
	  kResult,
	  kEvents,
	  kAborted
	} = requireSymbols$2();
	const { webidl } = requireWebidl();
	const { kEnumerableProperty } = requireUtil$7();

	class FileReader extends EventTarget {
	  constructor () {
	    super();

	    this[kState] = 'empty';
	    this[kResult] = null;
	    this[kError] = null;
	    this[kEvents] = {
	      loadend: null,
	      error: null,
	      abort: null,
	      load: null,
	      progress: null,
	      loadstart: null
	    };
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#dfn-readAsArrayBuffer
	   * @param {import('buffer').Blob} blob
	   */
	  readAsArrayBuffer (blob) {
	    webidl.brandCheck(this, FileReader);

	    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsArrayBuffer');

	    blob = webidl.converters.Blob(blob, { strict: false });

	    // The readAsArrayBuffer(blob) method, when invoked,
	    // must initiate a read operation for blob with ArrayBuffer.
	    readOperation(this, blob, 'ArrayBuffer');
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#readAsBinaryString
	   * @param {import('buffer').Blob} blob
	   */
	  readAsBinaryString (blob) {
	    webidl.brandCheck(this, FileReader);

	    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsBinaryString');

	    blob = webidl.converters.Blob(blob, { strict: false });

	    // The readAsBinaryString(blob) method, when invoked,
	    // must initiate a read operation for blob with BinaryString.
	    readOperation(this, blob, 'BinaryString');
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#readAsDataText
	   * @param {import('buffer').Blob} blob
	   * @param {string?} encoding
	   */
	  readAsText (blob, encoding = undefined) {
	    webidl.brandCheck(this, FileReader);

	    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsText');

	    blob = webidl.converters.Blob(blob, { strict: false });

	    if (encoding !== undefined) {
	      encoding = webidl.converters.DOMString(encoding, 'FileReader.readAsText', 'encoding');
	    }

	    // The readAsText(blob, encoding) method, when invoked,
	    // must initiate a read operation for blob with Text and encoding.
	    readOperation(this, blob, 'Text', encoding);
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#dfn-readAsDataURL
	   * @param {import('buffer').Blob} blob
	   */
	  readAsDataURL (blob) {
	    webidl.brandCheck(this, FileReader);

	    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsDataURL');

	    blob = webidl.converters.Blob(blob, { strict: false });

	    // The readAsDataURL(blob) method, when invoked, must
	    // initiate a read operation for blob with DataURL.
	    readOperation(this, blob, 'DataURL');
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#dfn-abort
	   */
	  abort () {
	    // 1. If this's state is "empty" or if this's state is
	    //    "done" set this's result to null and terminate
	    //    this algorithm.
	    if (this[kState] === 'empty' || this[kState] === 'done') {
	      this[kResult] = null;
	      return
	    }

	    // 2. If this's state is "loading" set this's state to
	    //    "done" and set this's result to null.
	    if (this[kState] === 'loading') {
	      this[kState] = 'done';
	      this[kResult] = null;
	    }

	    // 3. If there are any tasks from this on the file reading
	    //    task source in an affiliated task queue, then remove
	    //    those tasks from that task queue.
	    this[kAborted] = true;

	    // 4. Terminate the algorithm for the read method being processed.
	    // TODO

	    // 5. Fire a progress event called abort at this.
	    fireAProgressEvent('abort', this);

	    // 6. If this's state is not "loading", fire a progress
	    //    event called loadend at this.
	    if (this[kState] !== 'loading') {
	      fireAProgressEvent('loadend', this);
	    }
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#dom-filereader-readystate
	   */
	  get readyState () {
	    webidl.brandCheck(this, FileReader);

	    switch (this[kState]) {
	      case 'empty': return this.EMPTY
	      case 'loading': return this.LOADING
	      case 'done': return this.DONE
	    }
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#dom-filereader-result
	   */
	  get result () {
	    webidl.brandCheck(this, FileReader);

	    // The result attributeâs getter, when invoked, must return
	    // this's result.
	    return this[kResult]
	  }

	  /**
	   * @see https://w3c.github.io/FileAPI/#dom-filereader-error
	   */
	  get error () {
	    webidl.brandCheck(this, FileReader);

	    // The error attributeâs getter, when invoked, must return
	    // this's error.
	    return this[kError]
	  }

	  get onloadend () {
	    webidl.brandCheck(this, FileReader);

	    return this[kEvents].loadend
	  }

	  set onloadend (fn) {
	    webidl.brandCheck(this, FileReader);

	    if (this[kEvents].loadend) {
	      this.removeEventListener('loadend', this[kEvents].loadend);
	    }

	    if (typeof fn === 'function') {
	      this[kEvents].loadend = fn;
	      this.addEventListener('loadend', fn);
	    } else {
	      this[kEvents].loadend = null;
	    }
	  }

	  get onerror () {
	    webidl.brandCheck(this, FileReader);

	    return this[kEvents].error
	  }

	  set onerror (fn) {
	    webidl.brandCheck(this, FileReader);

	    if (this[kEvents].error) {
	      this.removeEventListener('error', this[kEvents].error);
	    }

	    if (typeof fn === 'function') {
	      this[kEvents].error = fn;
	      this.addEventListener('error', fn);
	    } else {
	      this[kEvents].error = null;
	    }
	  }

	  get onloadstart () {
	    webidl.brandCheck(this, FileReader);

	    return this[kEvents].loadstart
	  }

	  set onloadstart (fn) {
	    webidl.brandCheck(this, FileReader);

	    if (this[kEvents].loadstart) {
	      this.removeEventListener('loadstart', this[kEvents].loadstart);
	    }

	    if (typeof fn === 'function') {
	      this[kEvents].loadstart = fn;
	      this.addEventListener('loadstart', fn);
	    } else {
	      this[kEvents].loadstart = null;
	    }
	  }

	  get onprogress () {
	    webidl.brandCheck(this, FileReader);

	    return this[kEvents].progress
	  }

	  set onprogress (fn) {
	    webidl.brandCheck(this, FileReader);

	    if (this[kEvents].progress) {
	      this.removeEventListener('progress', this[kEvents].progress);
	    }

	    if (typeof fn === 'function') {
	      this[kEvents].progress = fn;
	      this.addEventListener('progress', fn);
	    } else {
	      this[kEvents].progress = null;
	    }
	  }

	  get onload () {
	    webidl.brandCheck(this, FileReader);

	    return this[kEvents].load
	  }

	  set onload (fn) {
	    webidl.brandCheck(this, FileReader);

	    if (this[kEvents].load) {
	      this.removeEventListener('load', this[kEvents].load);
	    }

	    if (typeof fn === 'function') {
	      this[kEvents].load = fn;
	      this.addEventListener('load', fn);
	    } else {
	      this[kEvents].load = null;
	    }
	  }

	  get onabort () {
	    webidl.brandCheck(this, FileReader);

	    return this[kEvents].abort
	  }

	  set onabort (fn) {
	    webidl.brandCheck(this, FileReader);

	    if (this[kEvents].abort) {
	      this.removeEventListener('abort', this[kEvents].abort);
	    }

	    if (typeof fn === 'function') {
	      this[kEvents].abort = fn;
	      this.addEventListener('abort', fn);
	    } else {
	      this[kEvents].abort = null;
	    }
	  }
	}

	// https://w3c.github.io/FileAPI/#dom-filereader-empty
	FileReader.EMPTY = FileReader.prototype.EMPTY = 0;
	// https://w3c.github.io/FileAPI/#dom-filereader-loading
	FileReader.LOADING = FileReader.prototype.LOADING = 1;
	// https://w3c.github.io/FileAPI/#dom-filereader-done
	FileReader.DONE = FileReader.prototype.DONE = 2;

	Object.defineProperties(FileReader.prototype, {
	  EMPTY: staticPropertyDescriptors,
	  LOADING: staticPropertyDescriptors,
	  DONE: staticPropertyDescriptors,
	  readAsArrayBuffer: kEnumerableProperty,
	  readAsBinaryString: kEnumerableProperty,
	  readAsText: kEnumerableProperty,
	  readAsDataURL: kEnumerableProperty,
	  abort: kEnumerableProperty,
	  readyState: kEnumerableProperty,
	  result: kEnumerableProperty,
	  error: kEnumerableProperty,
	  onloadstart: kEnumerableProperty,
	  onprogress: kEnumerableProperty,
	  onload: kEnumerableProperty,
	  onabort: kEnumerableProperty,
	  onerror: kEnumerableProperty,
	  onloadend: kEnumerableProperty,
	  [Symbol.toStringTag]: {
	    value: 'FileReader',
	    writable: false,
	    enumerable: false,
	    configurable: true
	  }
	});

	Object.defineProperties(FileReader, {
	  EMPTY: staticPropertyDescriptors,
	  LOADING: staticPropertyDescriptors,
	  DONE: staticPropertyDescriptors
	});

	filereader = {
	  FileReader
	};
	return filereader;
}

var symbols$1;
var hasRequiredSymbols$1;

function requireSymbols$1 () {
	if (hasRequiredSymbols$1) return symbols$1;
	hasRequiredSymbols$1 = 1;

	symbols$1 = {
	  kConstruct: requireSymbols$4().kConstruct
	};
	return symbols$1;
}

var util$3;
var hasRequiredUtil$3;

function requireUtil$3 () {
	if (hasRequiredUtil$3) return util$3;
	hasRequiredUtil$3 = 1;

	const assert = require$$0$4;
	const { URLSerializer } = requireDataUrl();
	const { isValidHeaderName } = requireUtil$6();

	/**
	 * @see https://url.spec.whatwg.org/#concept-url-equals
	 * @param {URL} A
	 * @param {URL} B
	 * @param {boolean | undefined} excludeFragment
	 * @returns {boolean}
	 */
	function urlEquals (A, B, excludeFragment = false) {
	  const serializedA = URLSerializer(A, excludeFragment);

	  const serializedB = URLSerializer(B, excludeFragment);

	  return serializedA === serializedB
	}

	/**
	 * @see https://github.com/chromium/chromium/blob/694d20d134cb553d8d89e5500b9148012b1ba299/content/browser/cache_storage/cache_storage_cache.cc#L260-L262
	 * @param {string} header
	 */
	function getFieldValues (header) {
	  assert(header !== null);

	  const values = [];

	  for (let value of header.split(',')) {
	    value = value.trim();

	    if (isValidHeaderName(value)) {
	      values.push(value);
	    }
	  }

	  return values
	}

	util$3 = {
	  urlEquals,
	  getFieldValues
	};
	return util$3;
}

var cache;
var hasRequiredCache;

function requireCache () {
	if (hasRequiredCache) return cache;
	hasRequiredCache = 1;

	const { kConstruct } = requireSymbols$1();
	const { urlEquals, getFieldValues } = requireUtil$3();
	const { kEnumerableProperty, isDisturbed } = requireUtil$7();
	const { webidl } = requireWebidl();
	const { Response, cloneResponse, fromInnerResponse } = requireResponse();
	const { Request, fromInnerRequest } = requireRequest();
	const { kState } = requireSymbols$3();
	const { fetching } = requireFetch();
	const { urlIsHttpHttpsScheme, createDeferredPromise, readAllBytes } = requireUtil$6();
	const assert = require$$0$4;

	/**
	 * @see https://w3c.github.io/ServiceWorker/#dfn-cache-batch-operation
	 * @typedef {Object} CacheBatchOperation
	 * @property {'delete' | 'put'} type
	 * @property {any} request
	 * @property {any} response
	 * @property {import('../../types/cache').CacheQueryOptions} options
	 */

	/**
	 * @see https://w3c.github.io/ServiceWorker/#dfn-request-response-list
	 * @typedef {[any, any][]} requestResponseList
	 */

	class Cache {
	  /**
	   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-request-response-list
	   * @type {requestResponseList}
	   */
	  #relevantRequestResponseList

	  constructor () {
	    if (arguments[0] !== kConstruct) {
	      webidl.illegalConstructor();
	    }

	    this.#relevantRequestResponseList = arguments[1];
	  }

	  async match (request, options = {}) {
	    webidl.brandCheck(this, Cache);

	    const prefix = 'Cache.match';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    request = webidl.converters.RequestInfo(request, prefix, 'request');
	    options = webidl.converters.CacheQueryOptions(options, prefix, 'options');

	    const p = this.#internalMatchAll(request, options, 1);

	    if (p.length === 0) {
	      return
	    }

	    return p[0]
	  }

	  async matchAll (request = undefined, options = {}) {
	    webidl.brandCheck(this, Cache);

	    const prefix = 'Cache.matchAll';
	    if (request !== undefined) request = webidl.converters.RequestInfo(request, prefix, 'request');
	    options = webidl.converters.CacheQueryOptions(options, prefix, 'options');

	    return this.#internalMatchAll(request, options)
	  }

	  async add (request) {
	    webidl.brandCheck(this, Cache);

	    const prefix = 'Cache.add';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    request = webidl.converters.RequestInfo(request, prefix, 'request');

	    // 1.
	    const requests = [request];

	    // 2.
	    const responseArrayPromise = this.addAll(requests);

	    // 3.
	    return await responseArrayPromise
	  }

	  async addAll (requests) {
	    webidl.brandCheck(this, Cache);

	    const prefix = 'Cache.addAll';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    // 1.
	    const responsePromises = [];

	    // 2.
	    const requestList = [];

	    // 3.
	    for (let request of requests) {
	      if (request === undefined) {
	        throw webidl.errors.conversionFailed({
	          prefix,
	          argument: 'Argument 1',
	          types: ['undefined is not allowed']
	        })
	      }

	      request = webidl.converters.RequestInfo(request);

	      if (typeof request === 'string') {
	        continue
	      }

	      // 3.1
	      const r = request[kState];

	      // 3.2
	      if (!urlIsHttpHttpsScheme(r.url) || r.method !== 'GET') {
	        throw webidl.errors.exception({
	          header: prefix,
	          message: 'Expected http/s scheme when method is not GET.'
	        })
	      }
	    }

	    // 4.
	    /** @type {ReturnType<typeof fetching>[]} */
	    const fetchControllers = [];

	    // 5.
	    for (const request of requests) {
	      // 5.1
	      const r = new Request(request)[kState];

	      // 5.2
	      if (!urlIsHttpHttpsScheme(r.url)) {
	        throw webidl.errors.exception({
	          header: prefix,
	          message: 'Expected http/s scheme.'
	        })
	      }

	      // 5.4
	      r.initiator = 'fetch';
	      r.destination = 'subresource';

	      // 5.5
	      requestList.push(r);

	      // 5.6
	      const responsePromise = createDeferredPromise();

	      // 5.7
	      fetchControllers.push(fetching({
	        request: r,
	        processResponse (response) {
	          // 1.
	          if (response.type === 'error' || response.status === 206 || response.status < 200 || response.status > 299) {
	            responsePromise.reject(webidl.errors.exception({
	              header: 'Cache.addAll',
	              message: 'Received an invalid status code or the request failed.'
	            }));
	          } else if (response.headersList.contains('vary')) { // 2.
	            // 2.1
	            const fieldValues = getFieldValues(response.headersList.get('vary'));

	            // 2.2
	            for (const fieldValue of fieldValues) {
	              // 2.2.1
	              if (fieldValue === '*') {
	                responsePromise.reject(webidl.errors.exception({
	                  header: 'Cache.addAll',
	                  message: 'invalid vary field value'
	                }));

	                for (const controller of fetchControllers) {
	                  controller.abort();
	                }

	                return
	              }
	            }
	          }
	        },
	        processResponseEndOfBody (response) {
	          // 1.
	          if (response.aborted) {
	            responsePromise.reject(new DOMException('aborted', 'AbortError'));
	            return
	          }

	          // 2.
	          responsePromise.resolve(response);
	        }
	      }));

	      // 5.8
	      responsePromises.push(responsePromise.promise);
	    }

	    // 6.
	    const p = Promise.all(responsePromises);

	    // 7.
	    const responses = await p;

	    // 7.1
	    const operations = [];

	    // 7.2
	    let index = 0;

	    // 7.3
	    for (const response of responses) {
	      // 7.3.1
	      /** @type {CacheBatchOperation} */
	      const operation = {
	        type: 'put', // 7.3.2
	        request: requestList[index], // 7.3.3
	        response // 7.3.4
	      };

	      operations.push(operation); // 7.3.5

	      index++; // 7.3.6
	    }

	    // 7.5
	    const cacheJobPromise = createDeferredPromise();

	    // 7.6.1
	    let errorData = null;

	    // 7.6.2
	    try {
	      this.#batchCacheOperations(operations);
	    } catch (e) {
	      errorData = e;
	    }

	    // 7.6.3
	    queueMicrotask(() => {
	      // 7.6.3.1
	      if (errorData === null) {
	        cacheJobPromise.resolve(undefined);
	      } else {
	        // 7.6.3.2
	        cacheJobPromise.reject(errorData);
	      }
	    });

	    // 7.7
	    return cacheJobPromise.promise
	  }

	  async put (request, response) {
	    webidl.brandCheck(this, Cache);

	    const prefix = 'Cache.put';
	    webidl.argumentLengthCheck(arguments, 2, prefix);

	    request = webidl.converters.RequestInfo(request, prefix, 'request');
	    response = webidl.converters.Response(response, prefix, 'response');

	    // 1.
	    let innerRequest = null;

	    // 2.
	    if (request instanceof Request) {
	      innerRequest = request[kState];
	    } else { // 3.
	      innerRequest = new Request(request)[kState];
	    }

	    // 4.
	    if (!urlIsHttpHttpsScheme(innerRequest.url) || innerRequest.method !== 'GET') {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: 'Expected an http/s scheme when method is not GET'
	      })
	    }

	    // 5.
	    const innerResponse = response[kState];

	    // 6.
	    if (innerResponse.status === 206) {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: 'Got 206 status'
	      })
	    }

	    // 7.
	    if (innerResponse.headersList.contains('vary')) {
	      // 7.1.
	      const fieldValues = getFieldValues(innerResponse.headersList.get('vary'));

	      // 7.2.
	      for (const fieldValue of fieldValues) {
	        // 7.2.1
	        if (fieldValue === '*') {
	          throw webidl.errors.exception({
	            header: prefix,
	            message: 'Got * vary field value'
	          })
	        }
	      }
	    }

	    // 8.
	    if (innerResponse.body && (isDisturbed(innerResponse.body.stream) || innerResponse.body.stream.locked)) {
	      throw webidl.errors.exception({
	        header: prefix,
	        message: 'Response body is locked or disturbed'
	      })
	    }

	    // 9.
	    const clonedResponse = cloneResponse(innerResponse);

	    // 10.
	    const bodyReadPromise = createDeferredPromise();

	    // 11.
	    if (innerResponse.body != null) {
	      // 11.1
	      const stream = innerResponse.body.stream;

	      // 11.2
	      const reader = stream.getReader();

	      // 11.3
	      readAllBytes(reader).then(bodyReadPromise.resolve, bodyReadPromise.reject);
	    } else {
	      bodyReadPromise.resolve(undefined);
	    }

	    // 12.
	    /** @type {CacheBatchOperation[]} */
	    const operations = [];

	    // 13.
	    /** @type {CacheBatchOperation} */
	    const operation = {
	      type: 'put', // 14.
	      request: innerRequest, // 15.
	      response: clonedResponse // 16.
	    };

	    // 17.
	    operations.push(operation);

	    // 19.
	    const bytes = await bodyReadPromise.promise;

	    if (clonedResponse.body != null) {
	      clonedResponse.body.source = bytes;
	    }

	    // 19.1
	    const cacheJobPromise = createDeferredPromise();

	    // 19.2.1
	    let errorData = null;

	    // 19.2.2
	    try {
	      this.#batchCacheOperations(operations);
	    } catch (e) {
	      errorData = e;
	    }

	    // 19.2.3
	    queueMicrotask(() => {
	      // 19.2.3.1
	      if (errorData === null) {
	        cacheJobPromise.resolve();
	      } else { // 19.2.3.2
	        cacheJobPromise.reject(errorData);
	      }
	    });

	    return cacheJobPromise.promise
	  }

	  async delete (request, options = {}) {
	    webidl.brandCheck(this, Cache);

	    const prefix = 'Cache.delete';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    request = webidl.converters.RequestInfo(request, prefix, 'request');
	    options = webidl.converters.CacheQueryOptions(options, prefix, 'options');

	    /**
	     * @type {Request}
	     */
	    let r = null;

	    if (request instanceof Request) {
	      r = request[kState];

	      if (r.method !== 'GET' && !options.ignoreMethod) {
	        return false
	      }
	    } else {
	      assert(typeof request === 'string');

	      r = new Request(request)[kState];
	    }

	    /** @type {CacheBatchOperation[]} */
	    const operations = [];

	    /** @type {CacheBatchOperation} */
	    const operation = {
	      type: 'delete',
	      request: r,
	      options
	    };

	    operations.push(operation);

	    const cacheJobPromise = createDeferredPromise();

	    let errorData = null;
	    let requestResponses;

	    try {
	      requestResponses = this.#batchCacheOperations(operations);
	    } catch (e) {
	      errorData = e;
	    }

	    queueMicrotask(() => {
	      if (errorData === null) {
	        cacheJobPromise.resolve(!!requestResponses?.length);
	      } else {
	        cacheJobPromise.reject(errorData);
	      }
	    });

	    return cacheJobPromise.promise
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#dom-cache-keys
	   * @param {any} request
	   * @param {import('../../types/cache').CacheQueryOptions} options
	   * @returns {Promise<readonly Request[]>}
	   */
	  async keys (request = undefined, options = {}) {
	    webidl.brandCheck(this, Cache);

	    const prefix = 'Cache.keys';

	    if (request !== undefined) request = webidl.converters.RequestInfo(request, prefix, 'request');
	    options = webidl.converters.CacheQueryOptions(options, prefix, 'options');

	    // 1.
	    let r = null;

	    // 2.
	    if (request !== undefined) {
	      // 2.1
	      if (request instanceof Request) {
	        // 2.1.1
	        r = request[kState];

	        // 2.1.2
	        if (r.method !== 'GET' && !options.ignoreMethod) {
	          return []
	        }
	      } else if (typeof request === 'string') { // 2.2
	        r = new Request(request)[kState];
	      }
	    }

	    // 4.
	    const promise = createDeferredPromise();

	    // 5.
	    // 5.1
	    const requests = [];

	    // 5.2
	    if (request === undefined) {
	      // 5.2.1
	      for (const requestResponse of this.#relevantRequestResponseList) {
	        // 5.2.1.1
	        requests.push(requestResponse[0]);
	      }
	    } else { // 5.3
	      // 5.3.1
	      const requestResponses = this.#queryCache(r, options);

	      // 5.3.2
	      for (const requestResponse of requestResponses) {
	        // 5.3.2.1
	        requests.push(requestResponse[0]);
	      }
	    }

	    // 5.4
	    queueMicrotask(() => {
	      // 5.4.1
	      const requestList = [];

	      // 5.4.2
	      for (const request of requests) {
	        const requestObject = fromInnerRequest(
	          request,
	          new AbortController().signal,
	          'immutable'
	        );
	        // 5.4.2.1
	        requestList.push(requestObject);
	      }

	      // 5.4.3
	      promise.resolve(Object.freeze(requestList));
	    });

	    return promise.promise
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#batch-cache-operations-algorithm
	   * @param {CacheBatchOperation[]} operations
	   * @returns {requestResponseList}
	   */
	  #batchCacheOperations (operations) {
	    // 1.
	    const cache = this.#relevantRequestResponseList;

	    // 2.
	    const backupCache = [...cache];

	    // 3.
	    const addedItems = [];

	    // 4.1
	    const resultList = [];

	    try {
	      // 4.2
	      for (const operation of operations) {
	        // 4.2.1
	        if (operation.type !== 'delete' && operation.type !== 'put') {
	          throw webidl.errors.exception({
	            header: 'Cache.#batchCacheOperations',
	            message: 'operation type does not match "delete" or "put"'
	          })
	        }

	        // 4.2.2
	        if (operation.type === 'delete' && operation.response != null) {
	          throw webidl.errors.exception({
	            header: 'Cache.#batchCacheOperations',
	            message: 'delete operation should not have an associated response'
	          })
	        }

	        // 4.2.3
	        if (this.#queryCache(operation.request, operation.options, addedItems).length) {
	          throw new DOMException('???', 'InvalidStateError')
	        }

	        // 4.2.4
	        let requestResponses;

	        // 4.2.5
	        if (operation.type === 'delete') {
	          // 4.2.5.1
	          requestResponses = this.#queryCache(operation.request, operation.options);

	          // TODO: the spec is wrong, this is needed to pass WPTs
	          if (requestResponses.length === 0) {
	            return []
	          }

	          // 4.2.5.2
	          for (const requestResponse of requestResponses) {
	            const idx = cache.indexOf(requestResponse);
	            assert(idx !== -1);

	            // 4.2.5.2.1
	            cache.splice(idx, 1);
	          }
	        } else if (operation.type === 'put') { // 4.2.6
	          // 4.2.6.1
	          if (operation.response == null) {
	            throw webidl.errors.exception({
	              header: 'Cache.#batchCacheOperations',
	              message: 'put operation should have an associated response'
	            })
	          }

	          // 4.2.6.2
	          const r = operation.request;

	          // 4.2.6.3
	          if (!urlIsHttpHttpsScheme(r.url)) {
	            throw webidl.errors.exception({
	              header: 'Cache.#batchCacheOperations',
	              message: 'expected http or https scheme'
	            })
	          }

	          // 4.2.6.4
	          if (r.method !== 'GET') {
	            throw webidl.errors.exception({
	              header: 'Cache.#batchCacheOperations',
	              message: 'not get method'
	            })
	          }

	          // 4.2.6.5
	          if (operation.options != null) {
	            throw webidl.errors.exception({
	              header: 'Cache.#batchCacheOperations',
	              message: 'options must not be defined'
	            })
	          }

	          // 4.2.6.6
	          requestResponses = this.#queryCache(operation.request);

	          // 4.2.6.7
	          for (const requestResponse of requestResponses) {
	            const idx = cache.indexOf(requestResponse);
	            assert(idx !== -1);

	            // 4.2.6.7.1
	            cache.splice(idx, 1);
	          }

	          // 4.2.6.8
	          cache.push([operation.request, operation.response]);

	          // 4.2.6.10
	          addedItems.push([operation.request, operation.response]);
	        }

	        // 4.2.7
	        resultList.push([operation.request, operation.response]);
	      }

	      // 4.3
	      return resultList
	    } catch (e) { // 5.
	      // 5.1
	      this.#relevantRequestResponseList.length = 0;

	      // 5.2
	      this.#relevantRequestResponseList = backupCache;

	      // 5.3
	      throw e
	    }
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#query-cache
	   * @param {any} requestQuery
	   * @param {import('../../types/cache').CacheQueryOptions} options
	   * @param {requestResponseList} targetStorage
	   * @returns {requestResponseList}
	   */
	  #queryCache (requestQuery, options, targetStorage) {
	    /** @type {requestResponseList} */
	    const resultList = [];

	    const storage = targetStorage ?? this.#relevantRequestResponseList;

	    for (const requestResponse of storage) {
	      const [cachedRequest, cachedResponse] = requestResponse;
	      if (this.#requestMatchesCachedItem(requestQuery, cachedRequest, cachedResponse, options)) {
	        resultList.push(requestResponse);
	      }
	    }

	    return resultList
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#request-matches-cached-item-algorithm
	   * @param {any} requestQuery
	   * @param {any} request
	   * @param {any | null} response
	   * @param {import('../../types/cache').CacheQueryOptions | undefined} options
	   * @returns {boolean}
	   */
	  #requestMatchesCachedItem (requestQuery, request, response = null, options) {
	    // if (options?.ignoreMethod === false && request.method === 'GET') {
	    //   return false
	    // }

	    const queryURL = new URL(requestQuery.url);

	    const cachedURL = new URL(request.url);

	    if (options?.ignoreSearch) {
	      cachedURL.search = '';

	      queryURL.search = '';
	    }

	    if (!urlEquals(queryURL, cachedURL, true)) {
	      return false
	    }

	    if (
	      response == null ||
	      options?.ignoreVary ||
	      !response.headersList.contains('vary')
	    ) {
	      return true
	    }

	    const fieldValues = getFieldValues(response.headersList.get('vary'));

	    for (const fieldValue of fieldValues) {
	      if (fieldValue === '*') {
	        return false
	      }

	      const requestValue = request.headersList.get(fieldValue);
	      const queryValue = requestQuery.headersList.get(fieldValue);

	      // If one has the header and the other doesn't, or one has
	      // a different value than the other, return false
	      if (requestValue !== queryValue) {
	        return false
	      }
	    }

	    return true
	  }

	  #internalMatchAll (request, options, maxResponses = Infinity) {
	    // 1.
	    let r = null;

	    // 2.
	    if (request !== undefined) {
	      if (request instanceof Request) {
	        // 2.1.1
	        r = request[kState];

	        // 2.1.2
	        if (r.method !== 'GET' && !options.ignoreMethod) {
	          return []
	        }
	      } else if (typeof request === 'string') {
	        // 2.2.1
	        r = new Request(request)[kState];
	      }
	    }

	    // 5.
	    // 5.1
	    const responses = [];

	    // 5.2
	    if (request === undefined) {
	      // 5.2.1
	      for (const requestResponse of this.#relevantRequestResponseList) {
	        responses.push(requestResponse[1]);
	      }
	    } else { // 5.3
	      // 5.3.1
	      const requestResponses = this.#queryCache(r, options);

	      // 5.3.2
	      for (const requestResponse of requestResponses) {
	        responses.push(requestResponse[1]);
	      }
	    }

	    // 5.4
	    // We don't implement CORs so we don't need to loop over the responses, yay!

	    // 5.5.1
	    const responseList = [];

	    // 5.5.2
	    for (const response of responses) {
	      // 5.5.2.1
	      const responseObject = fromInnerResponse(response, 'immutable');

	      responseList.push(responseObject.clone());

	      if (responseList.length >= maxResponses) {
	        break
	      }
	    }

	    // 6.
	    return Object.freeze(responseList)
	  }
	}

	Object.defineProperties(Cache.prototype, {
	  [Symbol.toStringTag]: {
	    value: 'Cache',
	    configurable: true
	  },
	  match: kEnumerableProperty,
	  matchAll: kEnumerableProperty,
	  add: kEnumerableProperty,
	  addAll: kEnumerableProperty,
	  put: kEnumerableProperty,
	  delete: kEnumerableProperty,
	  keys: kEnumerableProperty
	});

	const cacheQueryOptionConverters = [
	  {
	    key: 'ignoreSearch',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'ignoreMethod',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'ignoreVary',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  }
	];

	webidl.converters.CacheQueryOptions = webidl.dictionaryConverter(cacheQueryOptionConverters);

	webidl.converters.MultiCacheQueryOptions = webidl.dictionaryConverter([
	  ...cacheQueryOptionConverters,
	  {
	    key: 'cacheName',
	    converter: webidl.converters.DOMString
	  }
	]);

	webidl.converters.Response = webidl.interfaceConverter(Response);

	webidl.converters['sequence<RequestInfo>'] = webidl.sequenceConverter(
	  webidl.converters.RequestInfo
	);

	cache = {
	  Cache
	};
	return cache;
}

var cachestorage;
var hasRequiredCachestorage;

function requireCachestorage () {
	if (hasRequiredCachestorage) return cachestorage;
	hasRequiredCachestorage = 1;

	const { kConstruct } = requireSymbols$1();
	const { Cache } = requireCache();
	const { webidl } = requireWebidl();
	const { kEnumerableProperty } = requireUtil$7();

	class CacheStorage {
	  /**
	   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-name-to-cache-map
	   * @type {Map<string, import('./cache').requestResponseList}
	   */
	  #caches = new Map()

	  constructor () {
	    if (arguments[0] !== kConstruct) {
	      webidl.illegalConstructor();
	    }
	  }

	  async match (request, options = {}) {
	    webidl.brandCheck(this, CacheStorage);
	    webidl.argumentLengthCheck(arguments, 1, 'CacheStorage.match');

	    request = webidl.converters.RequestInfo(request);
	    options = webidl.converters.MultiCacheQueryOptions(options);

	    // 1.
	    if (options.cacheName != null) {
	      // 1.1.1.1
	      if (this.#caches.has(options.cacheName)) {
	        // 1.1.1.1.1
	        const cacheList = this.#caches.get(options.cacheName);
	        const cache = new Cache(kConstruct, cacheList);

	        return await cache.match(request, options)
	      }
	    } else { // 2.
	      // 2.2
	      for (const cacheList of this.#caches.values()) {
	        const cache = new Cache(kConstruct, cacheList);

	        // 2.2.1.2
	        const response = await cache.match(request, options);

	        if (response !== undefined) {
	          return response
	        }
	      }
	    }
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#cache-storage-has
	   * @param {string} cacheName
	   * @returns {Promise<boolean>}
	   */
	  async has (cacheName) {
	    webidl.brandCheck(this, CacheStorage);

	    const prefix = 'CacheStorage.has';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    cacheName = webidl.converters.DOMString(cacheName, prefix, 'cacheName');

	    // 2.1.1
	    // 2.2
	    return this.#caches.has(cacheName)
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#dom-cachestorage-open
	   * @param {string} cacheName
	   * @returns {Promise<Cache>}
	   */
	  async open (cacheName) {
	    webidl.brandCheck(this, CacheStorage);

	    const prefix = 'CacheStorage.open';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    cacheName = webidl.converters.DOMString(cacheName, prefix, 'cacheName');

	    // 2.1
	    if (this.#caches.has(cacheName)) {
	      // await caches.open('v1') !== await caches.open('v1')

	      // 2.1.1
	      const cache = this.#caches.get(cacheName);

	      // 2.1.1.1
	      return new Cache(kConstruct, cache)
	    }

	    // 2.2
	    const cache = [];

	    // 2.3
	    this.#caches.set(cacheName, cache);

	    // 2.4
	    return new Cache(kConstruct, cache)
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#cache-storage-delete
	   * @param {string} cacheName
	   * @returns {Promise<boolean>}
	   */
	  async delete (cacheName) {
	    webidl.brandCheck(this, CacheStorage);

	    const prefix = 'CacheStorage.delete';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    cacheName = webidl.converters.DOMString(cacheName, prefix, 'cacheName');

	    return this.#caches.delete(cacheName)
	  }

	  /**
	   * @see https://w3c.github.io/ServiceWorker/#cache-storage-keys
	   * @returns {Promise<string[]>}
	   */
	  async keys () {
	    webidl.brandCheck(this, CacheStorage);

	    // 2.1
	    const keys = this.#caches.keys();

	    // 2.2
	    return [...keys]
	  }
	}

	Object.defineProperties(CacheStorage.prototype, {
	  [Symbol.toStringTag]: {
	    value: 'CacheStorage',
	    configurable: true
	  },
	  match: kEnumerableProperty,
	  has: kEnumerableProperty,
	  open: kEnumerableProperty,
	  delete: kEnumerableProperty,
	  keys: kEnumerableProperty
	});

	cachestorage = {
	  CacheStorage
	};
	return cachestorage;
}

var constants$1;
var hasRequiredConstants$1;

function requireConstants$1 () {
	if (hasRequiredConstants$1) return constants$1;
	hasRequiredConstants$1 = 1;

	// https://wicg.github.io/cookie-store/#cookie-maximum-attribute-value-size
	const maxAttributeValueSize = 1024;

	// https://wicg.github.io/cookie-store/#cookie-maximum-name-value-pair-size
	const maxNameValuePairSize = 4096;

	constants$1 = {
	  maxAttributeValueSize,
	  maxNameValuePairSize
	};
	return constants$1;
}

var util$2;
var hasRequiredUtil$2;

function requireUtil$2 () {
	if (hasRequiredUtil$2) return util$2;
	hasRequiredUtil$2 = 1;

	/**
	 * @param {string} value
	 * @returns {boolean}
	 */
	function isCTLExcludingHtab (value) {
	  for (let i = 0; i < value.length; ++i) {
	    const code = value.charCodeAt(i);

	    if (
	      (code >= 0x00 && code <= 0x08) ||
	      (code >= 0x0A && code <= 0x1F) ||
	      code === 0x7F
	    ) {
	      return true
	    }
	  }
	  return false
	}

	/**
	 CHAR           = <any US-ASCII character (octets 0 - 127)>
	 token          = 1*<any CHAR except CTLs or separators>
	 separators     = "(" | ")" | "<" | ">" | "@"
	                | "," | ";" | ":" | "\" | <">
	                | "/" | "[" | "]" | "?" | "="
	                | "{" | "}" | SP | HT
	 * @param {string} name
	 */
	function validateCookieName (name) {
	  for (let i = 0; i < name.length; ++i) {
	    const code = name.charCodeAt(i);

	    if (
	      code < 0x21 || // exclude CTLs (0-31), SP and HT
	      code > 0x7E || // exclude non-ascii and DEL
	      code === 0x22 || // "
	      code === 0x28 || // (
	      code === 0x29 || // )
	      code === 0x3C || // <
	      code === 0x3E || // >
	      code === 0x40 || // @
	      code === 0x2C || // ,
	      code === 0x3B || // ;
	      code === 0x3A || // :
	      code === 0x5C || // \
	      code === 0x2F || // /
	      code === 0x5B || // [
	      code === 0x5D || // ]
	      code === 0x3F || // ?
	      code === 0x3D || // =
	      code === 0x7B || // {
	      code === 0x7D // }
	    ) {
	      throw new Error('Invalid cookie name')
	    }
	  }
	}

	/**
	 cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )
	 cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E
	                       ; US-ASCII characters excluding CTLs,
	                       ; whitespace DQUOTE, comma, semicolon,
	                       ; and backslash
	 * @param {string} value
	 */
	function validateCookieValue (value) {
	  let len = value.length;
	  let i = 0;

	  // if the value is wrapped in DQUOTE
	  if (value[0] === '"') {
	    if (len === 1 || value[len - 1] !== '"') {
	      throw new Error('Invalid cookie value')
	    }
	    --len;
	    ++i;
	  }

	  while (i < len) {
	    const code = value.charCodeAt(i++);

	    if (
	      code < 0x21 || // exclude CTLs (0-31)
	      code > 0x7E || // non-ascii and DEL (127)
	      code === 0x22 || // "
	      code === 0x2C || // ,
	      code === 0x3B || // ;
	      code === 0x5C // \
	    ) {
	      throw new Error('Invalid cookie value')
	    }
	  }
	}

	/**
	 * path-value        = <any CHAR except CTLs or ";">
	 * @param {string} path
	 */
	function validateCookiePath (path) {
	  for (let i = 0; i < path.length; ++i) {
	    const code = path.charCodeAt(i);

	    if (
	      code < 0x20 || // exclude CTLs (0-31)
	      code === 0x7F || // DEL
	      code === 0x3B // ;
	    ) {
	      throw new Error('Invalid cookie path')
	    }
	  }
	}

	/**
	 * I have no idea why these values aren't allowed to be honest,
	 * but Deno tests these. - Khafra
	 * @param {string} domain
	 */
	function validateCookieDomain (domain) {
	  if (
	    domain.startsWith('-') ||
	    domain.endsWith('.') ||
	    domain.endsWith('-')
	  ) {
	    throw new Error('Invalid cookie domain')
	  }
	}

	const IMFDays = [
	  'Sun', 'Mon', 'Tue', 'Wed',
	  'Thu', 'Fri', 'Sat'
	];

	const IMFMonths = [
	  'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
	  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'
	];

	const IMFPaddedNumbers = Array(61).fill(0).map((_, i) => i.toString().padStart(2, '0'));

	/**
	 * @see https://www.rfc-editor.org/rfc/rfc7231#section-7.1.1.1
	 * @param {number|Date} date
	  IMF-fixdate  = day-name "," SP date1 SP time-of-day SP GMT
	  ; fixed length/zone/capitalization subset of the format
	  ; see Section 3.3 of [RFC5322]

	  day-name     = %x4D.6F.6E ; "Mon", case-sensitive
	              / %x54.75.65 ; "Tue", case-sensitive
	              / %x57.65.64 ; "Wed", case-sensitive
	              / %x54.68.75 ; "Thu", case-sensitive
	              / %x46.72.69 ; "Fri", case-sensitive
	              / %x53.61.74 ; "Sat", case-sensitive
	              / %x53.75.6E ; "Sun", case-sensitive
	  date1        = day SP month SP year
	                  ; e.g., 02 Jun 1982

	  day          = 2DIGIT
	  month        = %x4A.61.6E ; "Jan", case-sensitive
	              / %x46.65.62 ; "Feb", case-sensitive
	              / %x4D.61.72 ; "Mar", case-sensitive
	              / %x41.70.72 ; "Apr", case-sensitive
	              / %x4D.61.79 ; "May", case-sensitive
	              / %x4A.75.6E ; "Jun", case-sensitive
	              / %x4A.75.6C ; "Jul", case-sensitive
	              / %x41.75.67 ; "Aug", case-sensitive
	              / %x53.65.70 ; "Sep", case-sensitive
	              / %x4F.63.74 ; "Oct", case-sensitive
	              / %x4E.6F.76 ; "Nov", case-sensitive
	              / %x44.65.63 ; "Dec", case-sensitive
	  year         = 4DIGIT

	  GMT          = %x47.4D.54 ; "GMT", case-sensitive

	  time-of-day  = hour ":" minute ":" second
	              ; 00:00:00 - 23:59:60 (leap second)

	  hour         = 2DIGIT
	  minute       = 2DIGIT
	  second       = 2DIGIT
	 */
	function toIMFDate (date) {
	  if (typeof date === 'number') {
	    date = new Date(date);
	  }

	  return `${IMFDays[date.getUTCDay()]}, ${IMFPaddedNumbers[date.getUTCDate()]} ${IMFMonths[date.getUTCMonth()]} ${date.getUTCFullYear()} ${IMFPaddedNumbers[date.getUTCHours()]}:${IMFPaddedNumbers[date.getUTCMinutes()]}:${IMFPaddedNumbers[date.getUTCSeconds()]} GMT`
	}

	/**
	 max-age-av        = "Max-Age=" non-zero-digit *DIGIT
	                       ; In practice, both expires-av and max-age-av
	                       ; are limited to dates representable by the
	                       ; user agent.
	 * @param {number} maxAge
	 */
	function validateCookieMaxAge (maxAge) {
	  if (maxAge < 0) {
	    throw new Error('Invalid cookie max-age')
	  }
	}

	/**
	 * @see https://www.rfc-editor.org/rfc/rfc6265#section-4.1.1
	 * @param {import('./index').Cookie} cookie
	 */
	function stringify (cookie) {
	  if (cookie.name.length === 0) {
	    return null
	  }

	  validateCookieName(cookie.name);
	  validateCookieValue(cookie.value);

	  const out = [`${cookie.name}=${cookie.value}`];

	  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.1
	  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.2
	  if (cookie.name.startsWith('__Secure-')) {
	    cookie.secure = true;
	  }

	  if (cookie.name.startsWith('__Host-')) {
	    cookie.secure = true;
	    cookie.domain = null;
	    cookie.path = '/';
	  }

	  if (cookie.secure) {
	    out.push('Secure');
	  }

	  if (cookie.httpOnly) {
	    out.push('HttpOnly');
	  }

	  if (typeof cookie.maxAge === 'number') {
	    validateCookieMaxAge(cookie.maxAge);
	    out.push(`Max-Age=${cookie.maxAge}`);
	  }

	  if (cookie.domain) {
	    validateCookieDomain(cookie.domain);
	    out.push(`Domain=${cookie.domain}`);
	  }

	  if (cookie.path) {
	    validateCookiePath(cookie.path);
	    out.push(`Path=${cookie.path}`);
	  }

	  if (cookie.expires && cookie.expires.toString() !== 'Invalid Date') {
	    out.push(`Expires=${toIMFDate(cookie.expires)}`);
	  }

	  if (cookie.sameSite) {
	    out.push(`SameSite=${cookie.sameSite}`);
	  }

	  for (const part of cookie.unparsed) {
	    if (!part.includes('=')) {
	      throw new Error('Invalid unparsed')
	    }

	    const [key, ...value] = part.split('=');

	    out.push(`${key.trim()}=${value.join('=')}`);
	  }

	  return out.join('; ')
	}

	util$2 = {
	  isCTLExcludingHtab,
	  validateCookieName,
	  validateCookiePath,
	  validateCookieValue,
	  toIMFDate,
	  stringify
	};
	return util$2;
}

var parse;
var hasRequiredParse;

function requireParse () {
	if (hasRequiredParse) return parse;
	hasRequiredParse = 1;

	const { maxNameValuePairSize, maxAttributeValueSize } = requireConstants$1();
	const { isCTLExcludingHtab } = requireUtil$2();
	const { collectASequenceOfCodePointsFast } = requireDataUrl();
	const assert = require$$0$4;

	/**
	 * @description Parses the field-value attributes of a set-cookie header string.
	 * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4
	 * @param {string} header
	 * @returns if the header is invalid, null will be returned
	 */
	function parseSetCookie (header) {
	  // 1. If the set-cookie-string contains a %x00-08 / %x0A-1F / %x7F
	  //    character (CTL characters excluding HTAB): Abort these steps and
	  //    ignore the set-cookie-string entirely.
	  if (isCTLExcludingHtab(header)) {
	    return null
	  }

	  let nameValuePair = '';
	  let unparsedAttributes = '';
	  let name = '';
	  let value = '';

	  // 2. If the set-cookie-string contains a %x3B (";") character:
	  if (header.includes(';')) {
	    // 1. The name-value-pair string consists of the characters up to,
	    //    but not including, the first %x3B (";"), and the unparsed-
	    //    attributes consist of the remainder of the set-cookie-string
	    //    (including the %x3B (";") in question).
	    const position = { position: 0 };

	    nameValuePair = collectASequenceOfCodePointsFast(';', header, position);
	    unparsedAttributes = header.slice(position.position);
	  } else {
	    // Otherwise:

	    // 1. The name-value-pair string consists of all the characters
	    //    contained in the set-cookie-string, and the unparsed-
	    //    attributes is the empty string.
	    nameValuePair = header;
	  }

	  // 3. If the name-value-pair string lacks a %x3D ("=") character, then
	  //    the name string is empty, and the value string is the value of
	  //    name-value-pair.
	  if (!nameValuePair.includes('=')) {
	    value = nameValuePair;
	  } else {
	    //    Otherwise, the name string consists of the characters up to, but
	    //    not including, the first %x3D ("=") character, and the (possibly
	    //    empty) value string consists of the characters after the first
	    //    %x3D ("=") character.
	    const position = { position: 0 };
	    name = collectASequenceOfCodePointsFast(
	      '=',
	      nameValuePair,
	      position
	    );
	    value = nameValuePair.slice(position.position + 1);
	  }

	  // 4. Remove any leading or trailing WSP characters from the name
	  //    string and the value string.
	  name = name.trim();
	  value = value.trim();

	  // 5. If the sum of the lengths of the name string and the value string
	  //    is more than 4096 octets, abort these steps and ignore the set-
	  //    cookie-string entirely.
	  if (name.length + value.length > maxNameValuePairSize) {
	    return null
	  }

	  // 6. The cookie-name is the name string, and the cookie-value is the
	  //    value string.
	  return {
	    name, value, ...parseUnparsedAttributes(unparsedAttributes)
	  }
	}

	/**
	 * Parses the remaining attributes of a set-cookie header
	 * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4
	 * @param {string} unparsedAttributes
	 * @param {[Object.<string, unknown>]={}} cookieAttributeList
	 */
	function parseUnparsedAttributes (unparsedAttributes, cookieAttributeList = {}) {
	  // 1. If the unparsed-attributes string is empty, skip the rest of
	  //    these steps.
	  if (unparsedAttributes.length === 0) {
	    return cookieAttributeList
	  }

	  // 2. Discard the first character of the unparsed-attributes (which
	  //    will be a %x3B (";") character).
	  assert(unparsedAttributes[0] === ';');
	  unparsedAttributes = unparsedAttributes.slice(1);

	  let cookieAv = '';

	  // 3. If the remaining unparsed-attributes contains a %x3B (";")
	  //    character:
	  if (unparsedAttributes.includes(';')) {
	    // 1. Consume the characters of the unparsed-attributes up to, but
	    //    not including, the first %x3B (";") character.
	    cookieAv = collectASequenceOfCodePointsFast(
	      ';',
	      unparsedAttributes,
	      { position: 0 }
	    );
	    unparsedAttributes = unparsedAttributes.slice(cookieAv.length);
	  } else {
	    // Otherwise:

	    // 1. Consume the remainder of the unparsed-attributes.
	    cookieAv = unparsedAttributes;
	    unparsedAttributes = '';
	  }

	  // Let the cookie-av string be the characters consumed in this step.

	  let attributeName = '';
	  let attributeValue = '';

	  // 4. If the cookie-av string contains a %x3D ("=") character:
	  if (cookieAv.includes('=')) {
	    // 1. The (possibly empty) attribute-name string consists of the
	    //    characters up to, but not including, the first %x3D ("=")
	    //    character, and the (possibly empty) attribute-value string
	    //    consists of the characters after the first %x3D ("=")
	    //    character.
	    const position = { position: 0 };

	    attributeName = collectASequenceOfCodePointsFast(
	      '=',
	      cookieAv,
	      position
	    );
	    attributeValue = cookieAv.slice(position.position + 1);
	  } else {
	    // Otherwise:

	    // 1. The attribute-name string consists of the entire cookie-av
	    //    string, and the attribute-value string is empty.
	    attributeName = cookieAv;
	  }

	  // 5. Remove any leading or trailing WSP characters from the attribute-
	  //    name string and the attribute-value string.
	  attributeName = attributeName.trim();
	  attributeValue = attributeValue.trim();

	  // 6. If the attribute-value is longer than 1024 octets, ignore the
	  //    cookie-av string and return to Step 1 of this algorithm.
	  if (attributeValue.length > maxAttributeValueSize) {
	    return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
	  }

	  // 7. Process the attribute-name and attribute-value according to the
	  //    requirements in the following subsections.  (Notice that
	  //    attributes with unrecognized attribute-names are ignored.)
	  const attributeNameLowercase = attributeName.toLowerCase();

	  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.1
	  // If the attribute-name case-insensitively matches the string
	  // "Expires", the user agent MUST process the cookie-av as follows.
	  if (attributeNameLowercase === 'expires') {
	    // 1. Let the expiry-time be the result of parsing the attribute-value
	    //    as cookie-date (see Section 5.1.1).
	    const expiryTime = new Date(attributeValue);

	    // 2. If the attribute-value failed to parse as a cookie date, ignore
	    //    the cookie-av.

	    cookieAttributeList.expires = expiryTime;
	  } else if (attributeNameLowercase === 'max-age') {
	    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.2
	    // If the attribute-name case-insensitively matches the string "Max-
	    // Age", the user agent MUST process the cookie-av as follows.

	    // 1. If the first character of the attribute-value is not a DIGIT or a
	    //    "-" character, ignore the cookie-av.
	    const charCode = attributeValue.charCodeAt(0);

	    if ((charCode < 48 || charCode > 57) && attributeValue[0] !== '-') {
	      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
	    }

	    // 2. If the remainder of attribute-value contains a non-DIGIT
	    //    character, ignore the cookie-av.
	    if (!/^\d+$/.test(attributeValue)) {
	      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
	    }

	    // 3. Let delta-seconds be the attribute-value converted to an integer.
	    const deltaSeconds = Number(attributeValue);

	    // 4. Let cookie-age-limit be the maximum age of the cookie (which
	    //    SHOULD be 400 days or less, see Section 4.1.2.2).

	    // 5. Set delta-seconds to the smaller of its present value and cookie-
	    //    age-limit.
	    // deltaSeconds = Math.min(deltaSeconds * 1000, maxExpiresMs)

	    // 6. If delta-seconds is less than or equal to zero (0), let expiry-
	    //    time be the earliest representable date and time.  Otherwise, let
	    //    the expiry-time be the current date and time plus delta-seconds
	    //    seconds.
	    // const expiryTime = deltaSeconds <= 0 ? Date.now() : Date.now() + deltaSeconds

	    // 7. Append an attribute to the cookie-attribute-list with an
	    //    attribute-name of Max-Age and an attribute-value of expiry-time.
	    cookieAttributeList.maxAge = deltaSeconds;
	  } else if (attributeNameLowercase === 'domain') {
	    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.3
	    // If the attribute-name case-insensitively matches the string "Domain",
	    // the user agent MUST process the cookie-av as follows.

	    // 1. Let cookie-domain be the attribute-value.
	    let cookieDomain = attributeValue;

	    // 2. If cookie-domain starts with %x2E ("."), let cookie-domain be
	    //    cookie-domain without its leading %x2E (".").
	    if (cookieDomain[0] === '.') {
	      cookieDomain = cookieDomain.slice(1);
	    }

	    // 3. Convert the cookie-domain to lower case.
	    cookieDomain = cookieDomain.toLowerCase();

	    // 4. Append an attribute to the cookie-attribute-list with an
	    //    attribute-name of Domain and an attribute-value of cookie-domain.
	    cookieAttributeList.domain = cookieDomain;
	  } else if (attributeNameLowercase === 'path') {
	    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.4
	    // If the attribute-name case-insensitively matches the string "Path",
	    // the user agent MUST process the cookie-av as follows.

	    // 1. If the attribute-value is empty or if the first character of the
	    //    attribute-value is not %x2F ("/"):
	    let cookiePath = '';
	    if (attributeValue.length === 0 || attributeValue[0] !== '/') {
	      // 1. Let cookie-path be the default-path.
	      cookiePath = '/';
	    } else {
	      // Otherwise:

	      // 1. Let cookie-path be the attribute-value.
	      cookiePath = attributeValue;
	    }

	    // 2. Append an attribute to the cookie-attribute-list with an
	    //    attribute-name of Path and an attribute-value of cookie-path.
	    cookieAttributeList.path = cookiePath;
	  } else if (attributeNameLowercase === 'secure') {
	    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.5
	    // If the attribute-name case-insensitively matches the string "Secure",
	    // the user agent MUST append an attribute to the cookie-attribute-list
	    // with an attribute-name of Secure and an empty attribute-value.

	    cookieAttributeList.secure = true;
	  } else if (attributeNameLowercase === 'httponly') {
	    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.6
	    // If the attribute-name case-insensitively matches the string
	    // "HttpOnly", the user agent MUST append an attribute to the cookie-
	    // attribute-list with an attribute-name of HttpOnly and an empty
	    // attribute-value.

	    cookieAttributeList.httpOnly = true;
	  } else if (attributeNameLowercase === 'samesite') {
	    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.7
	    // If the attribute-name case-insensitively matches the string
	    // "SameSite", the user agent MUST process the cookie-av as follows:

	    // 1. Let enforcement be "Default".
	    let enforcement = 'Default';

	    const attributeValueLowercase = attributeValue.toLowerCase();
	    // 2. If cookie-av's attribute-value is a case-insensitive match for
	    //    "None", set enforcement to "None".
	    if (attributeValueLowercase.includes('none')) {
	      enforcement = 'None';
	    }

	    // 3. If cookie-av's attribute-value is a case-insensitive match for
	    //    "Strict", set enforcement to "Strict".
	    if (attributeValueLowercase.includes('strict')) {
	      enforcement = 'Strict';
	    }

	    // 4. If cookie-av's attribute-value is a case-insensitive match for
	    //    "Lax", set enforcement to "Lax".
	    if (attributeValueLowercase.includes('lax')) {
	      enforcement = 'Lax';
	    }

	    // 5. Append an attribute to the cookie-attribute-list with an
	    //    attribute-name of "SameSite" and an attribute-value of
	    //    enforcement.
	    cookieAttributeList.sameSite = enforcement;
	  } else {
	    cookieAttributeList.unparsed ??= [];

	    cookieAttributeList.unparsed.push(`${attributeName}=${attributeValue}`);
	  }

	  // 8. Return to Step 1 of this algorithm.
	  return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)
	}

	parse = {
	  parseSetCookie,
	  parseUnparsedAttributes
	};
	return parse;
}

var cookies;
var hasRequiredCookies;

function requireCookies () {
	if (hasRequiredCookies) return cookies;
	hasRequiredCookies = 1;

	const { parseSetCookie } = requireParse();
	const { stringify } = requireUtil$2();
	const { webidl } = requireWebidl();
	const { Headers } = requireHeaders();

	/**
	 * @typedef {Object} Cookie
	 * @property {string} name
	 * @property {string} value
	 * @property {Date|number|undefined} expires
	 * @property {number|undefined} maxAge
	 * @property {string|undefined} domain
	 * @property {string|undefined} path
	 * @property {boolean|undefined} secure
	 * @property {boolean|undefined} httpOnly
	 * @property {'Strict'|'Lax'|'None'} sameSite
	 * @property {string[]} unparsed
	 */

	/**
	 * @param {Headers} headers
	 * @returns {Record<string, string>}
	 */
	function getCookies (headers) {
	  webidl.argumentLengthCheck(arguments, 1, 'getCookies');

	  webidl.brandCheck(headers, Headers, { strict: false });

	  const cookie = headers.get('cookie');
	  const out = {};

	  if (!cookie) {
	    return out
	  }

	  for (const piece of cookie.split(';')) {
	    const [name, ...value] = piece.split('=');

	    out[name.trim()] = value.join('=');
	  }

	  return out
	}

	/**
	 * @param {Headers} headers
	 * @param {string} name
	 * @param {{ path?: string, domain?: string }|undefined} attributes
	 * @returns {void}
	 */
	function deleteCookie (headers, name, attributes) {
	  webidl.brandCheck(headers, Headers, { strict: false });

	  const prefix = 'deleteCookie';
	  webidl.argumentLengthCheck(arguments, 2, prefix);

	  name = webidl.converters.DOMString(name, prefix, 'name');
	  attributes = webidl.converters.DeleteCookieAttributes(attributes);

	  // Matches behavior of
	  // https://github.com/denoland/deno_std/blob/63827b16330b82489a04614027c33b7904e08be5/http/cookie.ts#L278
	  setCookie(headers, {
	    name,
	    value: '',
	    expires: new Date(0),
	    ...attributes
	  });
	}

	/**
	 * @param {Headers} headers
	 * @returns {Cookie[]}
	 */
	function getSetCookies (headers) {
	  webidl.argumentLengthCheck(arguments, 1, 'getSetCookies');

	  webidl.brandCheck(headers, Headers, { strict: false });

	  const cookies = headers.getSetCookie();

	  if (!cookies) {
	    return []
	  }

	  return cookies.map((pair) => parseSetCookie(pair))
	}

	/**
	 * @param {Headers} headers
	 * @param {Cookie} cookie
	 * @returns {void}
	 */
	function setCookie (headers, cookie) {
	  webidl.argumentLengthCheck(arguments, 2, 'setCookie');

	  webidl.brandCheck(headers, Headers, { strict: false });

	  cookie = webidl.converters.Cookie(cookie);

	  const str = stringify(cookie);

	  if (str) {
	    headers.append('Set-Cookie', str);
	  }
	}

	webidl.converters.DeleteCookieAttributes = webidl.dictionaryConverter([
	  {
	    converter: webidl.nullableConverter(webidl.converters.DOMString),
	    key: 'path',
	    defaultValue: () => null
	  },
	  {
	    converter: webidl.nullableConverter(webidl.converters.DOMString),
	    key: 'domain',
	    defaultValue: () => null
	  }
	]);

	webidl.converters.Cookie = webidl.dictionaryConverter([
	  {
	    converter: webidl.converters.DOMString,
	    key: 'name'
	  },
	  {
	    converter: webidl.converters.DOMString,
	    key: 'value'
	  },
	  {
	    converter: webidl.nullableConverter((value) => {
	      if (typeof value === 'number') {
	        return webidl.converters['unsigned long long'](value)
	      }

	      return new Date(value)
	    }),
	    key: 'expires',
	    defaultValue: () => null
	  },
	  {
	    converter: webidl.nullableConverter(webidl.converters['long long']),
	    key: 'maxAge',
	    defaultValue: () => null
	  },
	  {
	    converter: webidl.nullableConverter(webidl.converters.DOMString),
	    key: 'domain',
	    defaultValue: () => null
	  },
	  {
	    converter: webidl.nullableConverter(webidl.converters.DOMString),
	    key: 'path',
	    defaultValue: () => null
	  },
	  {
	    converter: webidl.nullableConverter(webidl.converters.boolean),
	    key: 'secure',
	    defaultValue: () => null
	  },
	  {
	    converter: webidl.nullableConverter(webidl.converters.boolean),
	    key: 'httpOnly',
	    defaultValue: () => null
	  },
	  {
	    converter: webidl.converters.USVString,
	    key: 'sameSite',
	    allowedValues: ['Strict', 'Lax', 'None']
	  },
	  {
	    converter: webidl.sequenceConverter(webidl.converters.DOMString),
	    key: 'unparsed',
	    defaultValue: () => new Array(0)
	  }
	]);

	cookies = {
	  getCookies,
	  deleteCookie,
	  getSetCookies,
	  setCookie
	};
	return cookies;
}

var events;
var hasRequiredEvents;

function requireEvents () {
	if (hasRequiredEvents) return events;
	hasRequiredEvents = 1;

	const { webidl } = requireWebidl();
	const { kEnumerableProperty } = requireUtil$7();
	const { kConstruct } = requireSymbols$4();
	const { MessagePort } = require$$3;

	/**
	 * @see https://html.spec.whatwg.org/multipage/comms.html#messageevent
	 */
	class MessageEvent extends Event {
	  #eventInit

	  constructor (type, eventInitDict = {}) {
	    if (type === kConstruct) {
	      super(arguments[1], arguments[2]);
	      return
	    }

	    const prefix = 'MessageEvent constructor';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    type = webidl.converters.DOMString(type, prefix, 'type');
	    eventInitDict = webidl.converters.MessageEventInit(eventInitDict, prefix, 'eventInitDict');

	    super(type, eventInitDict);

	    this.#eventInit = eventInitDict;
	  }

	  get data () {
	    webidl.brandCheck(this, MessageEvent);

	    return this.#eventInit.data
	  }

	  get origin () {
	    webidl.brandCheck(this, MessageEvent);

	    return this.#eventInit.origin
	  }

	  get lastEventId () {
	    webidl.brandCheck(this, MessageEvent);

	    return this.#eventInit.lastEventId
	  }

	  get source () {
	    webidl.brandCheck(this, MessageEvent);

	    return this.#eventInit.source
	  }

	  get ports () {
	    webidl.brandCheck(this, MessageEvent);

	    if (!Object.isFrozen(this.#eventInit.ports)) {
	      Object.freeze(this.#eventInit.ports);
	    }

	    return this.#eventInit.ports
	  }

	  initMessageEvent (
	    type,
	    bubbles = false,
	    cancelable = false,
	    data = null,
	    origin = '',
	    lastEventId = '',
	    source = null,
	    ports = []
	  ) {
	    webidl.brandCheck(this, MessageEvent);

	    webidl.argumentLengthCheck(arguments, 1, 'MessageEvent.initMessageEvent');

	    return new MessageEvent(type, {
	      bubbles, cancelable, data, origin, lastEventId, source, ports
	    })
	  }

	  static createFastMessageEvent (type, init) {
	    const messageEvent = new MessageEvent(kConstruct, type, init);
	    messageEvent.#eventInit = init;
	    messageEvent.#eventInit.data ??= null;
	    messageEvent.#eventInit.origin ??= '';
	    messageEvent.#eventInit.lastEventId ??= '';
	    messageEvent.#eventInit.source ??= null;
	    messageEvent.#eventInit.ports ??= [];
	    return messageEvent
	  }
	}

	const { createFastMessageEvent } = MessageEvent;
	delete MessageEvent.createFastMessageEvent;

	/**
	 * @see https://websockets.spec.whatwg.org/#the-closeevent-interface
	 */
	class CloseEvent extends Event {
	  #eventInit

	  constructor (type, eventInitDict = {}) {
	    const prefix = 'CloseEvent constructor';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    type = webidl.converters.DOMString(type, prefix, 'type');
	    eventInitDict = webidl.converters.CloseEventInit(eventInitDict);

	    super(type, eventInitDict);

	    this.#eventInit = eventInitDict;
	  }

	  get wasClean () {
	    webidl.brandCheck(this, CloseEvent);

	    return this.#eventInit.wasClean
	  }

	  get code () {
	    webidl.brandCheck(this, CloseEvent);

	    return this.#eventInit.code
	  }

	  get reason () {
	    webidl.brandCheck(this, CloseEvent);

	    return this.#eventInit.reason
	  }
	}

	// https://html.spec.whatwg.org/multipage/webappapis.html#the-errorevent-interface
	class ErrorEvent extends Event {
	  #eventInit

	  constructor (type, eventInitDict) {
	    const prefix = 'ErrorEvent constructor';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    super(type, eventInitDict);

	    type = webidl.converters.DOMString(type, prefix, 'type');
	    eventInitDict = webidl.converters.ErrorEventInit(eventInitDict ?? {});

	    this.#eventInit = eventInitDict;
	  }

	  get message () {
	    webidl.brandCheck(this, ErrorEvent);

	    return this.#eventInit.message
	  }

	  get filename () {
	    webidl.brandCheck(this, ErrorEvent);

	    return this.#eventInit.filename
	  }

	  get lineno () {
	    webidl.brandCheck(this, ErrorEvent);

	    return this.#eventInit.lineno
	  }

	  get colno () {
	    webidl.brandCheck(this, ErrorEvent);

	    return this.#eventInit.colno
	  }

	  get error () {
	    webidl.brandCheck(this, ErrorEvent);

	    return this.#eventInit.error
	  }
	}

	Object.defineProperties(MessageEvent.prototype, {
	  [Symbol.toStringTag]: {
	    value: 'MessageEvent',
	    configurable: true
	  },
	  data: kEnumerableProperty,
	  origin: kEnumerableProperty,
	  lastEventId: kEnumerableProperty,
	  source: kEnumerableProperty,
	  ports: kEnumerableProperty,
	  initMessageEvent: kEnumerableProperty
	});

	Object.defineProperties(CloseEvent.prototype, {
	  [Symbol.toStringTag]: {
	    value: 'CloseEvent',
	    configurable: true
	  },
	  reason: kEnumerableProperty,
	  code: kEnumerableProperty,
	  wasClean: kEnumerableProperty
	});

	Object.defineProperties(ErrorEvent.prototype, {
	  [Symbol.toStringTag]: {
	    value: 'ErrorEvent',
	    configurable: true
	  },
	  message: kEnumerableProperty,
	  filename: kEnumerableProperty,
	  lineno: kEnumerableProperty,
	  colno: kEnumerableProperty,
	  error: kEnumerableProperty
	});

	webidl.converters.MessagePort = webidl.interfaceConverter(MessagePort);

	webidl.converters['sequence<MessagePort>'] = webidl.sequenceConverter(
	  webidl.converters.MessagePort
	);

	const eventInit = [
	  {
	    key: 'bubbles',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'cancelable',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'composed',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  }
	];

	webidl.converters.MessageEventInit = webidl.dictionaryConverter([
	  ...eventInit,
	  {
	    key: 'data',
	    converter: webidl.converters.any,
	    defaultValue: () => null
	  },
	  {
	    key: 'origin',
	    converter: webidl.converters.USVString,
	    defaultValue: () => ''
	  },
	  {
	    key: 'lastEventId',
	    converter: webidl.converters.DOMString,
	    defaultValue: () => ''
	  },
	  {
	    key: 'source',
	    // Node doesn't implement WindowProxy or ServiceWorker, so the only
	    // valid value for source is a MessagePort.
	    converter: webidl.nullableConverter(webidl.converters.MessagePort),
	    defaultValue: () => null
	  },
	  {
	    key: 'ports',
	    converter: webidl.converters['sequence<MessagePort>'],
	    defaultValue: () => new Array(0)
	  }
	]);

	webidl.converters.CloseEventInit = webidl.dictionaryConverter([
	  ...eventInit,
	  {
	    key: 'wasClean',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'code',
	    converter: webidl.converters['unsigned short'],
	    defaultValue: () => 0
	  },
	  {
	    key: 'reason',
	    converter: webidl.converters.USVString,
	    defaultValue: () => ''
	  }
	]);

	webidl.converters.ErrorEventInit = webidl.dictionaryConverter([
	  ...eventInit,
	  {
	    key: 'message',
	    converter: webidl.converters.DOMString,
	    defaultValue: () => ''
	  },
	  {
	    key: 'filename',
	    converter: webidl.converters.USVString,
	    defaultValue: () => ''
	  },
	  {
	    key: 'lineno',
	    converter: webidl.converters['unsigned long'],
	    defaultValue: () => 0
	  },
	  {
	    key: 'colno',
	    converter: webidl.converters['unsigned long'],
	    defaultValue: () => 0
	  },
	  {
	    key: 'error',
	    converter: webidl.converters.any
	  }
	]);

	events = {
	  MessageEvent,
	  CloseEvent,
	  ErrorEvent,
	  createFastMessageEvent
	};
	return events;
}

var constants;
var hasRequiredConstants;

function requireConstants () {
	if (hasRequiredConstants) return constants;
	hasRequiredConstants = 1;

	// This is a Globally Unique Identifier unique used
	// to validate that the endpoint accepts websocket
	// connections.
	// See https://www.rfc-editor.org/rfc/rfc6455.html#section-1.3
	const uid = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11';

	/** @type {PropertyDescriptor} */
	const staticPropertyDescriptors = {
	  enumerable: true,
	  writable: false,
	  configurable: false
	};

	const states = {
	  CONNECTING: 0,
	  OPEN: 1,
	  CLOSING: 2,
	  CLOSED: 3
	};

	const sentCloseFrameState = {
	  NOT_SENT: 0,
	  PROCESSING: 1,
	  SENT: 2
	};

	const opcodes = {
	  CONTINUATION: 0x0,
	  TEXT: 0x1,
	  BINARY: 0x2,
	  CLOSE: 0x8,
	  PING: 0x9,
	  PONG: 0xA
	};

	const maxUnsigned16Bit = 2 ** 16 - 1; // 65535

	const parserStates = {
	  INFO: 0,
	  PAYLOADLENGTH_16: 2,
	  PAYLOADLENGTH_64: 3,
	  READ_DATA: 4
	};

	const emptyBuffer = Buffer.allocUnsafe(0);

	const sendHints = {
	  string: 1,
	  typedArray: 2,
	  arrayBuffer: 3,
	  blob: 4
	};

	constants = {
	  uid,
	  sentCloseFrameState,
	  staticPropertyDescriptors,
	  states,
	  opcodes,
	  maxUnsigned16Bit,
	  parserStates,
	  emptyBuffer,
	  sendHints
	};
	return constants;
}

var symbols;
var hasRequiredSymbols;

function requireSymbols () {
	if (hasRequiredSymbols) return symbols;
	hasRequiredSymbols = 1;

	symbols = {
	  kWebSocketURL: Symbol('url'),
	  kReadyState: Symbol('ready state'),
	  kController: Symbol('controller'),
	  kResponse: Symbol('response'),
	  kBinaryType: Symbol('binary type'),
	  kSentClose: Symbol('sent close'),
	  kReceivedClose: Symbol('received close'),
	  kByteParser: Symbol('byte parser')
	};
	return symbols;
}

var util$1;
var hasRequiredUtil$1;

function requireUtil$1 () {
	if (hasRequiredUtil$1) return util$1;
	hasRequiredUtil$1 = 1;

	const { kReadyState, kController, kResponse, kBinaryType, kWebSocketURL } = requireSymbols();
	const { states, opcodes } = requireConstants();
	const { ErrorEvent, createFastMessageEvent } = requireEvents();
	const { isUtf8 } = require$$0$3;
	const { collectASequenceOfCodePointsFast, removeHTTPWhitespace } = requireDataUrl();

	/* globals Blob */

	/**
	 * @param {import('./websocket').WebSocket} ws
	 * @returns {boolean}
	 */
	function isConnecting (ws) {
	  // If the WebSocket connection is not yet established, and the connection
	  // is not yet closed, then the WebSocket connection is in the CONNECTING state.
	  return ws[kReadyState] === states.CONNECTING
	}

	/**
	 * @param {import('./websocket').WebSocket} ws
	 * @returns {boolean}
	 */
	function isEstablished (ws) {
	  // If the server's response is validated as provided for above, it is
	  // said that _The WebSocket Connection is Established_ and that the
	  // WebSocket Connection is in the OPEN state.
	  return ws[kReadyState] === states.OPEN
	}

	/**
	 * @param {import('./websocket').WebSocket} ws
	 * @returns {boolean}
	 */
	function isClosing (ws) {
	  // Upon either sending or receiving a Close control frame, it is said
	  // that _The WebSocket Closing Handshake is Started_ and that the
	  // WebSocket connection is in the CLOSING state.
	  return ws[kReadyState] === states.CLOSING
	}

	/**
	 * @param {import('./websocket').WebSocket} ws
	 * @returns {boolean}
	 */
	function isClosed (ws) {
	  return ws[kReadyState] === states.CLOSED
	}

	/**
	 * @see https://dom.spec.whatwg.org/#concept-event-fire
	 * @param {string} e
	 * @param {EventTarget} target
	 * @param {(...args: ConstructorParameters<typeof Event>) => Event} eventFactory
	 * @param {EventInit | undefined} eventInitDict
	 */
	function fireEvent (e, target, eventFactory = (type, init) => new Event(type, init), eventInitDict = {}) {
	  // 1. If eventConstructor is not given, then let eventConstructor be Event.

	  // 2. Let event be the result of creating an event given eventConstructor,
	  //    in the relevant realm of target.
	  // 3. Initialize eventâs type attribute to e.
	  const event = eventFactory(e, eventInitDict);

	  // 4. Initialize any other IDL attributes of event as described in the
	  //    invocation of this algorithm.

	  // 5. Return the result of dispatching event at target, with legacy target
	  //    override flag set if set.
	  target.dispatchEvent(event);
	}

	/**
	 * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol
	 * @param {import('./websocket').WebSocket} ws
	 * @param {number} type Opcode
	 * @param {Buffer} data application data
	 */
	function websocketMessageReceived (ws, type, data) {
	  // 1. If ready state is not OPEN (1), then return.
	  if (ws[kReadyState] !== states.OPEN) {
	    return
	  }

	  // 2. Let dataForEvent be determined by switching on type and binary type:
	  let dataForEvent;

	  if (type === opcodes.TEXT) {
	    // -> type indicates that the data is Text
	    //      a new DOMString containing data
	    try {
	      dataForEvent = utf8Decode(data);
	    } catch {
	      failWebsocketConnection(ws, 'Received invalid UTF-8 in text frame.');
	      return
	    }
	  } else if (type === opcodes.BINARY) {
	    if (ws[kBinaryType] === 'blob') {
	      // -> type indicates that the data is Binary and binary type is "blob"
	      //      a new Blob object, created in the relevant Realm of the WebSocket
	      //      object, that represents data as its raw data
	      dataForEvent = new Blob([data]);
	    } else {
	      // -> type indicates that the data is Binary and binary type is "arraybuffer"
	      //      a new ArrayBuffer object, created in the relevant Realm of the
	      //      WebSocket object, whose contents are data
	      dataForEvent = toArrayBuffer(data);
	    }
	  }

	  // 3. Fire an event named message at the WebSocket object, using MessageEvent,
	  //    with the origin attribute initialized to the serialization of the WebSocket
	  //    objectâs url's origin, and the data attribute initialized to dataForEvent.
	  fireEvent('message', ws, createFastMessageEvent, {
	    origin: ws[kWebSocketURL].origin,
	    data: dataForEvent
	  });
	}

	function toArrayBuffer (buffer) {
	  if (buffer.byteLength === buffer.buffer.byteLength) {
	    return buffer.buffer
	  }
	  return buffer.buffer.slice(buffer.byteOffset, buffer.byteOffset + buffer.byteLength)
	}

	/**
	 * @see https://datatracker.ietf.org/doc/html/rfc6455
	 * @see https://datatracker.ietf.org/doc/html/rfc2616
	 * @see https://bugs.chromium.org/p/chromium/issues/detail?id=398407
	 * @param {string} protocol
	 */
	function isValidSubprotocol (protocol) {
	  // If present, this value indicates one
	  // or more comma-separated subprotocol the client wishes to speak,
	  // ordered by preference.  The elements that comprise this value
	  // MUST be non-empty strings with characters in the range U+0021 to
	  // U+007E not including separator characters as defined in
	  // [RFC2616] and MUST all be unique strings.
	  if (protocol.length === 0) {
	    return false
	  }

	  for (let i = 0; i < protocol.length; ++i) {
	    const code = protocol.charCodeAt(i);

	    if (
	      code < 0x21 || // CTL, contains SP (0x20) and HT (0x09)
	      code > 0x7E ||
	      code === 0x22 || // "
	      code === 0x28 || // (
	      code === 0x29 || // )
	      code === 0x2C || // ,
	      code === 0x2F || // /
	      code === 0x3A || // :
	      code === 0x3B || // ;
	      code === 0x3C || // <
	      code === 0x3D || // =
	      code === 0x3E || // >
	      code === 0x3F || // ?
	      code === 0x40 || // @
	      code === 0x5B || // [
	      code === 0x5C || // \
	      code === 0x5D || // ]
	      code === 0x7B || // {
	      code === 0x7D // }
	    ) {
	      return false
	    }
	  }

	  return true
	}

	/**
	 * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7-4
	 * @param {number} code
	 */
	function isValidStatusCode (code) {
	  if (code >= 1000 && code < 1015) {
	    return (
	      code !== 1004 && // reserved
	      code !== 1005 && // "MUST NOT be set as a status code"
	      code !== 1006 // "MUST NOT be set as a status code"
	    )
	  }

	  return code >= 3000 && code <= 4999
	}

	/**
	 * @param {import('./websocket').WebSocket} ws
	 * @param {string|undefined} reason
	 */
	function failWebsocketConnection (ws, reason) {
	  const { [kController]: controller, [kResponse]: response } = ws;

	  controller.abort();

	  if (response?.socket && !response.socket.destroyed) {
	    response.socket.destroy();
	  }

	  if (reason) {
	    // TODO: process.nextTick
	    fireEvent('error', ws, (type, init) => new ErrorEvent(type, init), {
	      error: new Error(reason),
	      message: reason
	    });
	  }
	}

	/**
	 * @see https://datatracker.ietf.org/doc/html/rfc6455#section-5.5
	 * @param {number} opcode
	 */
	function isControlFrame (opcode) {
	  return (
	    opcode === opcodes.CLOSE ||
	    opcode === opcodes.PING ||
	    opcode === opcodes.PONG
	  )
	}

	function isContinuationFrame (opcode) {
	  return opcode === opcodes.CONTINUATION
	}

	function isTextBinaryFrame (opcode) {
	  return opcode === opcodes.TEXT || opcode === opcodes.BINARY
	}

	function isValidOpcode (opcode) {
	  return isTextBinaryFrame(opcode) || isContinuationFrame(opcode) || isControlFrame(opcode)
	}

	/**
	 * Parses a Sec-WebSocket-Extensions header value.
	 * @param {string} extensions
	 * @returns {Map<string, string>}
	 */
	// TODO(@Uzlopak, @KhafraDev): make compliant https://datatracker.ietf.org/doc/html/rfc6455#section-9.1
	function parseExtensions (extensions) {
	  const position = { position: 0 };
	  const extensionList = new Map();

	  while (position.position < extensions.length) {
	    const pair = collectASequenceOfCodePointsFast(';', extensions, position);
	    const [name, value = ''] = pair.split('=');

	    extensionList.set(
	      removeHTTPWhitespace(name, true, false),
	      removeHTTPWhitespace(value, false, true)
	    );

	    position.position++;
	  }

	  return extensionList
	}

	/**
	 * @see https://www.rfc-editor.org/rfc/rfc7692#section-7.1.2.2
	 * @description "client-max-window-bits = 1*DIGIT"
	 * @param {string} value
	 */
	function isValidClientWindowBits (value) {
	  for (let i = 0; i < value.length; i++) {
	    const byte = value.charCodeAt(i);

	    if (byte < 0x30 || byte > 0x39) {
	      return false
	    }
	  }

	  return true
	}

	// https://nodejs.org/api/intl.html#detecting-internationalization-support
	const hasIntl = typeof process.versions.icu === 'string';
	const fatalDecoder = hasIntl ? new TextDecoder('utf-8', { fatal: true }) : undefined;

	/**
	 * Converts a Buffer to utf-8, even on platforms without icu.
	 * @param {Buffer} buffer
	 */
	const utf8Decode = hasIntl
	  ? fatalDecoder.decode.bind(fatalDecoder)
	  : function (buffer) {
	    if (isUtf8(buffer)) {
	      return buffer.toString('utf-8')
	    }
	    throw new TypeError('Invalid utf-8 received.')
	  };

	util$1 = {
	  isConnecting,
	  isEstablished,
	  isClosing,
	  isClosed,
	  fireEvent,
	  isValidSubprotocol,
	  isValidStatusCode,
	  failWebsocketConnection,
	  websocketMessageReceived,
	  utf8Decode,
	  isControlFrame,
	  isContinuationFrame,
	  isTextBinaryFrame,
	  isValidOpcode,
	  parseExtensions,
	  isValidClientWindowBits
	};
	return util$1;
}

var frame;
var hasRequiredFrame;

function requireFrame () {
	if (hasRequiredFrame) return frame;
	hasRequiredFrame = 1;

	const { maxUnsigned16Bit } = requireConstants();

	const BUFFER_SIZE = 16386;

	/** @type {import('crypto')} */
	let crypto;
	let buffer = null;
	let bufIdx = BUFFER_SIZE;

	try {
	  crypto = require('node:crypto');
	/* c8 ignore next 3 */
	} catch {
	  crypto = {
	    // not full compatibility, but minimum.
	    randomFillSync: function randomFillSync (buffer, _offset, _size) {
	      for (let i = 0; i < buffer.length; ++i) {
	        buffer[i] = Math.random() * 255 | 0;
	      }
	      return buffer
	    }
	  };
	}

	function generateMask () {
	  if (bufIdx === BUFFER_SIZE) {
	    bufIdx = 0;
	    crypto.randomFillSync((buffer ??= Buffer.allocUnsafe(BUFFER_SIZE)), 0, BUFFER_SIZE);
	  }
	  return [buffer[bufIdx++], buffer[bufIdx++], buffer[bufIdx++], buffer[bufIdx++]]
	}

	class WebsocketFrameSend {
	  /**
	   * @param {Buffer|undefined} data
	   */
	  constructor (data) {
	    this.frameData = data;
	  }

	  createFrame (opcode) {
	    const frameData = this.frameData;
	    const maskKey = generateMask();
	    const bodyLength = frameData?.byteLength ?? 0;

	    /** @type {number} */
	    let payloadLength = bodyLength; // 0-125
	    let offset = 6;

	    if (bodyLength > maxUnsigned16Bit) {
	      offset += 8; // payload length is next 8 bytes
	      payloadLength = 127;
	    } else if (bodyLength > 125) {
	      offset += 2; // payload length is next 2 bytes
	      payloadLength = 126;
	    }

	    const buffer = Buffer.allocUnsafe(bodyLength + offset);

	    // Clear first 2 bytes, everything else is overwritten
	    buffer[0] = buffer[1] = 0;
	    buffer[0] |= 0x80; // FIN
	    buffer[0] = (buffer[0] & 0xF0) + opcode; // opcode

	    /*! ws. MIT License. Einar Otto Stangvik <einaros@gmail.com> */
	    buffer[offset - 4] = maskKey[0];
	    buffer[offset - 3] = maskKey[1];
	    buffer[offset - 2] = maskKey[2];
	    buffer[offset - 1] = maskKey[3];

	    buffer[1] = payloadLength;

	    if (payloadLength === 126) {
	      buffer.writeUInt16BE(bodyLength, 2);
	    } else if (payloadLength === 127) {
	      // Clear extended payload length
	      buffer[2] = buffer[3] = 0;
	      buffer.writeUIntBE(bodyLength, 4, 6);
	    }

	    buffer[1] |= 0x80; // MASK

	    // mask body
	    for (let i = 0; i < bodyLength; ++i) {
	      buffer[offset + i] = frameData[i] ^ maskKey[i & 3];
	    }

	    return buffer
	  }
	}

	frame = {
	  WebsocketFrameSend
	};
	return frame;
}

var connection;
var hasRequiredConnection;

function requireConnection () {
	if (hasRequiredConnection) return connection;
	hasRequiredConnection = 1;

	const { uid, states, sentCloseFrameState, emptyBuffer, opcodes } = requireConstants();
	const {
	  kReadyState,
	  kSentClose,
	  kByteParser,
	  kReceivedClose,
	  kResponse
	} = requireSymbols();
	const { fireEvent, failWebsocketConnection, isClosing, isClosed, isEstablished, parseExtensions } = requireUtil$1();
	const { channels } = requireDiagnostics();
	const { CloseEvent } = requireEvents();
	const { makeRequest } = requireRequest();
	const { fetching } = requireFetch();
	const { Headers, getHeadersList } = requireHeaders();
	const { getDecodeSplit } = requireUtil$6();
	const { WebsocketFrameSend } = requireFrame();

	/** @type {import('crypto')} */
	let crypto;
	try {
	  crypto = require('node:crypto');
	/* c8 ignore next 3 */
	} catch {

	}

	/**
	 * @see https://websockets.spec.whatwg.org/#concept-websocket-establish
	 * @param {URL} url
	 * @param {string|string[]} protocols
	 * @param {import('./websocket').WebSocket} ws
	 * @param {(response: any, extensions: string[] | undefined) => void} onEstablish
	 * @param {Partial<import('../../types/websocket').WebSocketInit>} options
	 */
	function establishWebSocketConnection (url, protocols, client, ws, onEstablish, options) {
	  // 1. Let requestURL be a copy of url, with its scheme set to "http", if urlâs
	  //    scheme is "ws", and to "https" otherwise.
	  const requestURL = url;

	  requestURL.protocol = url.protocol === 'ws:' ? 'http:' : 'https:';

	  // 2. Let request be a new request, whose URL is requestURL, client is client,
	  //    service-workers mode is "none", referrer is "no-referrer", mode is
	  //    "websocket", credentials mode is "include", cache mode is "no-store" ,
	  //    and redirect mode is "error".
	  const request = makeRequest({
	    urlList: [requestURL],
	    client,
	    serviceWorkers: 'none',
	    referrer: 'no-referrer',
	    mode: 'websocket',
	    credentials: 'include',
	    cache: 'no-store',
	    redirect: 'error'
	  });

	  // Note: undici extension, allow setting custom headers.
	  if (options.headers) {
	    const headersList = getHeadersList(new Headers(options.headers));

	    request.headersList = headersList;
	  }

	  // 3. Append (`Upgrade`, `websocket`) to requestâs header list.
	  // 4. Append (`Connection`, `Upgrade`) to requestâs header list.
	  // Note: both of these are handled by undici currently.
	  // https://github.com/nodejs/undici/blob/68c269c4144c446f3f1220951338daef4a6b5ec4/lib/client.js#L1397

	  // 5. Let keyValue be a nonce consisting of a randomly selected
	  //    16-byte value that has been forgiving-base64-encoded and
	  //    isomorphic encoded.
	  const keyValue = crypto.randomBytes(16).toString('base64');

	  // 6. Append (`Sec-WebSocket-Key`, keyValue) to requestâs
	  //    header list.
	  request.headersList.append('sec-websocket-key', keyValue);

	  // 7. Append (`Sec-WebSocket-Version`, `13`) to requestâs
	  //    header list.
	  request.headersList.append('sec-websocket-version', '13');

	  // 8. For each protocol in protocols, combine
	  //    (`Sec-WebSocket-Protocol`, protocol) in requestâs header
	  //    list.
	  for (const protocol of protocols) {
	    request.headersList.append('sec-websocket-protocol', protocol);
	  }

	  // 9. Let permessageDeflate be a user-agent defined
	  //    "permessage-deflate" extension header value.
	  // https://github.com/mozilla/gecko-dev/blob/ce78234f5e653a5d3916813ff990f053510227bc/netwerk/protocol/websocket/WebSocketChannel.cpp#L2673
	  const permessageDeflate = 'permessage-deflate; client_max_window_bits';

	  // 10. Append (`Sec-WebSocket-Extensions`, permessageDeflate) to
	  //     requestâs header list.
	  request.headersList.append('sec-websocket-extensions', permessageDeflate);

	  // 11. Fetch request with useParallelQueue set to true, and
	  //     processResponse given response being these steps:
	  const controller = fetching({
	    request,
	    useParallelQueue: true,
	    dispatcher: options.dispatcher,
	    processResponse (response) {
	      // 1. If response is a network error or its status is not 101,
	      //    fail the WebSocket connection.
	      if (response.type === 'error' || response.status !== 101) {
	        failWebsocketConnection(ws, 'Received network error or non-101 status code.');
	        return
	      }

	      // 2. If protocols is not the empty list and extracting header
	      //    list values given `Sec-WebSocket-Protocol` and responseâs
	      //    header list results in null, failure, or the empty byte
	      //    sequence, then fail the WebSocket connection.
	      if (protocols.length !== 0 && !response.headersList.get('Sec-WebSocket-Protocol')) {
	        failWebsocketConnection(ws, 'Server did not respond with sent protocols.');
	        return
	      }

	      // 3. Follow the requirements stated step 2 to step 6, inclusive,
	      //    of the last set of steps in section 4.1 of The WebSocket
	      //    Protocol to validate response. This either results in fail
	      //    the WebSocket connection or the WebSocket connection is
	      //    established.

	      // 2. If the response lacks an |Upgrade| header field or the |Upgrade|
	      //    header field contains a value that is not an ASCII case-
	      //    insensitive match for the value "websocket", the client MUST
	      //    _Fail the WebSocket Connection_.
	      if (response.headersList.get('Upgrade')?.toLowerCase() !== 'websocket') {
	        failWebsocketConnection(ws, 'Server did not set Upgrade header to "websocket".');
	        return
	      }

	      // 3. If the response lacks a |Connection| header field or the
	      //    |Connection| header field doesn't contain a token that is an
	      //    ASCII case-insensitive match for the value "Upgrade", the client
	      //    MUST _Fail the WebSocket Connection_.
	      if (response.headersList.get('Connection')?.toLowerCase() !== 'upgrade') {
	        failWebsocketConnection(ws, 'Server did not set Connection header to "upgrade".');
	        return
	      }

	      // 4. If the response lacks a |Sec-WebSocket-Accept| header field or
	      //    the |Sec-WebSocket-Accept| contains a value other than the
	      //    base64-encoded SHA-1 of the concatenation of the |Sec-WebSocket-
	      //    Key| (as a string, not base64-decoded) with the string "258EAFA5-
	      //    E914-47DA-95CA-C5AB0DC85B11" but ignoring any leading and
	      //    trailing whitespace, the client MUST _Fail the WebSocket
	      //    Connection_.
	      const secWSAccept = response.headersList.get('Sec-WebSocket-Accept');
	      const digest = crypto.createHash('sha1').update(keyValue + uid).digest('base64');
	      if (secWSAccept !== digest) {
	        failWebsocketConnection(ws, 'Incorrect hash received in Sec-WebSocket-Accept header.');
	        return
	      }

	      // 5. If the response includes a |Sec-WebSocket-Extensions| header
	      //    field and this header field indicates the use of an extension
	      //    that was not present in the client's handshake (the server has
	      //    indicated an extension not requested by the client), the client
	      //    MUST _Fail the WebSocket Connection_.  (The parsing of this
	      //    header field to determine which extensions are requested is
	      //    discussed in Section 9.1.)
	      const secExtension = response.headersList.get('Sec-WebSocket-Extensions');
	      let extensions;

	      if (secExtension !== null) {
	        extensions = parseExtensions(secExtension);

	        if (!extensions.has('permessage-deflate')) {
	          failWebsocketConnection(ws, 'Sec-WebSocket-Extensions header does not match.');
	          return
	        }
	      }

	      // 6. If the response includes a |Sec-WebSocket-Protocol| header field
	      //    and this header field indicates the use of a subprotocol that was
	      //    not present in the client's handshake (the server has indicated a
	      //    subprotocol not requested by the client), the client MUST _Fail
	      //    the WebSocket Connection_.
	      const secProtocol = response.headersList.get('Sec-WebSocket-Protocol');

	      if (secProtocol !== null) {
	        const requestProtocols = getDecodeSplit('sec-websocket-protocol', request.headersList);

	        // The client can request that the server use a specific subprotocol by
	        // including the |Sec-WebSocket-Protocol| field in its handshake.  If it
	        // is specified, the server needs to include the same field and one of
	        // the selected subprotocol values in its response for the connection to
	        // be established.
	        if (!requestProtocols.includes(secProtocol)) {
	          failWebsocketConnection(ws, 'Protocol was not set in the opening handshake.');
	          return
	        }
	      }

	      response.socket.on('data', onSocketData);
	      response.socket.on('close', onSocketClose);
	      response.socket.on('error', onSocketError);

	      if (channels.open.hasSubscribers) {
	        channels.open.publish({
	          address: response.socket.address(),
	          protocol: secProtocol,
	          extensions: secExtension
	        });
	      }

	      onEstablish(response, extensions);
	    }
	  });

	  return controller
	}

	function closeWebSocketConnection (ws, code, reason, reasonByteLength) {
	  if (isClosing(ws) || isClosed(ws)) ; else if (!isEstablished(ws)) {
	    // If the WebSocket connection is not yet established
	    // Fail the WebSocket connection and set this's ready state
	    // to CLOSING (2).
	    failWebsocketConnection(ws, 'Connection was closed before it was established.');
	    ws[kReadyState] = states.CLOSING;
	  } else if (ws[kSentClose] === sentCloseFrameState.NOT_SENT) {
	    // If the WebSocket closing handshake has not yet been started
	    // Start the WebSocket closing handshake and set this's ready
	    // state to CLOSING (2).
	    // - If neither code nor reason is present, the WebSocket Close
	    //   message must not have a body.
	    // - If code is present, then the status code to use in the
	    //   WebSocket Close message must be the integer given by code.
	    // - If reason is also present, then reasonBytes must be
	    //   provided in the Close message after the status code.

	    ws[kSentClose] = sentCloseFrameState.PROCESSING;

	    const frame = new WebsocketFrameSend();

	    // If neither code nor reason is present, the WebSocket Close
	    // message must not have a body.

	    // If code is present, then the status code to use in the
	    // WebSocket Close message must be the integer given by code.
	    if (code !== undefined && reason === undefined) {
	      frame.frameData = Buffer.allocUnsafe(2);
	      frame.frameData.writeUInt16BE(code, 0);
	    } else if (code !== undefined && reason !== undefined) {
	      // If reason is also present, then reasonBytes must be
	      // provided in the Close message after the status code.
	      frame.frameData = Buffer.allocUnsafe(2 + reasonByteLength);
	      frame.frameData.writeUInt16BE(code, 0);
	      // the body MAY contain UTF-8-encoded data with value /reason/
	      frame.frameData.write(reason, 2, 'utf-8');
	    } else {
	      frame.frameData = emptyBuffer;
	    }

	    /** @type {import('stream').Duplex} */
	    const socket = ws[kResponse].socket;

	    socket.write(frame.createFrame(opcodes.CLOSE));

	    ws[kSentClose] = sentCloseFrameState.SENT;

	    // Upon either sending or receiving a Close control frame, it is said
	    // that _The WebSocket Closing Handshake is Started_ and that the
	    // WebSocket connection is in the CLOSING state.
	    ws[kReadyState] = states.CLOSING;
	  } else {
	    // Otherwise
	    // Set this's ready state to CLOSING (2).
	    ws[kReadyState] = states.CLOSING;
	  }
	}

	/**
	 * @param {Buffer} chunk
	 */
	function onSocketData (chunk) {
	  if (!this.ws[kByteParser].write(chunk)) {
	    this.pause();
	  }
	}

	/**
	 * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol
	 * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.4
	 */
	function onSocketClose () {
	  const { ws } = this;
	  const { [kResponse]: response } = ws;

	  response.socket.off('data', onSocketData);
	  response.socket.off('close', onSocketClose);
	  response.socket.off('error', onSocketError);

	  // If the TCP connection was closed after the
	  // WebSocket closing handshake was completed, the WebSocket connection
	  // is said to have been closed _cleanly_.
	  const wasClean = ws[kSentClose] === sentCloseFrameState.SENT && ws[kReceivedClose];

	  let code = 1005;
	  let reason = '';

	  const result = ws[kByteParser].closingInfo;

	  if (result && !result.error) {
	    code = result.code ?? 1005;
	    reason = result.reason;
	  } else if (!ws[kReceivedClose]) {
	    // If _The WebSocket
	    // Connection is Closed_ and no Close control frame was received by the
	    // endpoint (such as could occur if the underlying transport connection
	    // is lost), _The WebSocket Connection Close Code_ is considered to be
	    // 1006.
	    code = 1006;
	  }

	  // 1. Change the ready state to CLOSED (3).
	  ws[kReadyState] = states.CLOSED;

	  // 2. If the user agent was required to fail the WebSocket
	  //    connection, or if the WebSocket connection was closed
	  //    after being flagged as full, fire an event named error
	  //    at the WebSocket object.
	  // TODO

	  // 3. Fire an event named close at the WebSocket object,
	  //    using CloseEvent, with the wasClean attribute
	  //    initialized to true if the connection closed cleanly
	  //    and false otherwise, the code attribute initialized to
	  //    the WebSocket connection close code, and the reason
	  //    attribute initialized to the result of applying UTF-8
	  //    decode without BOM to the WebSocket connection close
	  //    reason.
	  // TODO: process.nextTick
	  fireEvent('close', ws, (type, init) => new CloseEvent(type, init), {
	    wasClean, code, reason
	  });

	  if (channels.close.hasSubscribers) {
	    channels.close.publish({
	      websocket: ws,
	      code,
	      reason
	    });
	  }
	}

	function onSocketError (error) {
	  const { ws } = this;

	  ws[kReadyState] = states.CLOSING;

	  if (channels.socketError.hasSubscribers) {
	    channels.socketError.publish(error);
	  }

	  this.destroy();
	}

	connection = {
	  establishWebSocketConnection,
	  closeWebSocketConnection
	};
	return connection;
}

var permessageDeflate;
var hasRequiredPermessageDeflate;

function requirePermessageDeflate () {
	if (hasRequiredPermessageDeflate) return permessageDeflate;
	hasRequiredPermessageDeflate = 1;

	const { createInflateRaw, Z_DEFAULT_WINDOWBITS } = require$$1;
	const { isValidClientWindowBits } = requireUtil$1();

	const tail = Buffer.from([0x00, 0x00, 0xff, 0xff]);
	const kBuffer = Symbol('kBuffer');
	const kLength = Symbol('kLength');

	class PerMessageDeflate {
	  /** @type {import('node:zlib').InflateRaw} */
	  #inflate

	  #options = {}

	  constructor (extensions) {
	    this.#options.serverNoContextTakeover = extensions.has('server_no_context_takeover');
	    this.#options.serverMaxWindowBits = extensions.get('server_max_window_bits');
	  }

	  decompress (chunk, fin, callback) {
	    // An endpoint uses the following algorithm to decompress a message.
	    // 1.  Append 4 octets of 0x00 0x00 0xff 0xff to the tail end of the
	    //     payload of the message.
	    // 2.  Decompress the resulting data using DEFLATE.

	    if (!this.#inflate) {
	      let windowBits = Z_DEFAULT_WINDOWBITS;

	      if (this.#options.serverMaxWindowBits) { // empty values default to Z_DEFAULT_WINDOWBITS
	        if (!isValidClientWindowBits(this.#options.serverMaxWindowBits)) {
	          callback(new Error('Invalid server_max_window_bits'));
	          return
	        }

	        windowBits = Number.parseInt(this.#options.serverMaxWindowBits);
	      }

	      this.#inflate = createInflateRaw({ windowBits });
	      this.#inflate[kBuffer] = [];
	      this.#inflate[kLength] = 0;

	      this.#inflate.on('data', (data) => {
	        this.#inflate[kBuffer].push(data);
	        this.#inflate[kLength] += data.length;
	      });

	      this.#inflate.on('error', (err) => {
	        this.#inflate = null;
	        callback(err);
	      });
	    }

	    this.#inflate.write(chunk);
	    if (fin) {
	      this.#inflate.write(tail);
	    }

	    this.#inflate.flush(() => {
	      const full = Buffer.concat(this.#inflate[kBuffer], this.#inflate[kLength]);

	      this.#inflate[kBuffer].length = 0;
	      this.#inflate[kLength] = 0;

	      callback(null, full);
	    });
	  }
	}

	permessageDeflate = { PerMessageDeflate };
	return permessageDeflate;
}

var receiver;
var hasRequiredReceiver;

function requireReceiver () {
	if (hasRequiredReceiver) return receiver;
	hasRequiredReceiver = 1;

	const { Writable } = require$$0$5;
	const assert = require$$0$4;
	const { parserStates, opcodes, states, emptyBuffer, sentCloseFrameState } = requireConstants();
	const { kReadyState, kSentClose, kResponse, kReceivedClose } = requireSymbols();
	const { channels } = requireDiagnostics();
	const {
	  isValidStatusCode,
	  isValidOpcode,
	  failWebsocketConnection,
	  websocketMessageReceived,
	  utf8Decode,
	  isControlFrame,
	  isTextBinaryFrame,
	  isContinuationFrame
	} = requireUtil$1();
	const { WebsocketFrameSend } = requireFrame();
	const { closeWebSocketConnection } = requireConnection();
	const { PerMessageDeflate } = requirePermessageDeflate();

	// This code was influenced by ws released under the MIT license.
	// Copyright (c) 2011 Einar Otto Stangvik <einaros@gmail.com>
	// Copyright (c) 2013 Arnout Kazemier and contributors
	// Copyright (c) 2016 Luigi Pinca and contributors

	class ByteParser extends Writable {
	  #buffers = []
	  #byteOffset = 0
	  #loop = false

	  #state = parserStates.INFO

	  #info = {}
	  #fragments = []

	  /** @type {Map<string, PerMessageDeflate>} */
	  #extensions

	  constructor (ws, extensions) {
	    super();

	    this.ws = ws;
	    this.#extensions = extensions == null ? new Map() : extensions;

	    if (this.#extensions.has('permessage-deflate')) {
	      this.#extensions.set('permessage-deflate', new PerMessageDeflate(extensions));
	    }
	  }

	  /**
	   * @param {Buffer} chunk
	   * @param {() => void} callback
	   */
	  _write (chunk, _, callback) {
	    this.#buffers.push(chunk);
	    this.#byteOffset += chunk.length;
	    this.#loop = true;

	    this.run(callback);
	  }

	  /**
	   * Runs whenever a new chunk is received.
	   * Callback is called whenever there are no more chunks buffering,
	   * or not enough bytes are buffered to parse.
	   */
	  run (callback) {
	    while (this.#loop) {
	      if (this.#state === parserStates.INFO) {
	        // If there aren't enough bytes to parse the payload length, etc.
	        if (this.#byteOffset < 2) {
	          return callback()
	        }

	        const buffer = this.consume(2);
	        const fin = (buffer[0] & 0x80) !== 0;
	        const opcode = buffer[0] & 0x0F;
	        const masked = (buffer[1] & 0x80) === 0x80;

	        const fragmented = !fin && opcode !== opcodes.CONTINUATION;
	        const payloadLength = buffer[1] & 0x7F;

	        const rsv1 = buffer[0] & 0x40;
	        const rsv2 = buffer[0] & 0x20;
	        const rsv3 = buffer[0] & 0x10;

	        if (!isValidOpcode(opcode)) {
	          failWebsocketConnection(this.ws, 'Invalid opcode received');
	          return callback()
	        }

	        if (masked) {
	          failWebsocketConnection(this.ws, 'Frame cannot be masked');
	          return callback()
	        }

	        // MUST be 0 unless an extension is negotiated that defines meanings
	        // for non-zero values.  If a nonzero value is received and none of
	        // the negotiated extensions defines the meaning of such a nonzero
	        // value, the receiving endpoint MUST _Fail the WebSocket
	        // Connection_.
	        // This document allocates the RSV1 bit of the WebSocket header for
	        // PMCEs and calls the bit the "Per-Message Compressed" bit.  On a
	        // WebSocket connection where a PMCE is in use, this bit indicates
	        // whether a message is compressed or not.
	        if (rsv1 !== 0 && !this.#extensions.has('permessage-deflate')) {
	          failWebsocketConnection(this.ws, 'Expected RSV1 to be clear.');
	          return
	        }

	        if (rsv2 !== 0 || rsv3 !== 0) {
	          failWebsocketConnection(this.ws, 'RSV1, RSV2, RSV3 must be clear');
	          return
	        }

	        if (fragmented && !isTextBinaryFrame(opcode)) {
	          // Only text and binary frames can be fragmented
	          failWebsocketConnection(this.ws, 'Invalid frame type was fragmented.');
	          return
	        }

	        // If we are already parsing a text/binary frame and do not receive either
	        // a continuation frame or close frame, fail the connection.
	        if (isTextBinaryFrame(opcode) && this.#fragments.length > 0) {
	          failWebsocketConnection(this.ws, 'Expected continuation frame');
	          return
	        }

	        if (this.#info.fragmented && fragmented) {
	          // A fragmented frame can't be fragmented itself
	          failWebsocketConnection(this.ws, 'Fragmented frame exceeded 125 bytes.');
	          return
	        }

	        // "All control frames MUST have a payload length of 125 bytes or less
	        // and MUST NOT be fragmented."
	        if ((payloadLength > 125 || fragmented) && isControlFrame(opcode)) {
	          failWebsocketConnection(this.ws, 'Control frame either too large or fragmented');
	          return
	        }

	        if (isContinuationFrame(opcode) && this.#fragments.length === 0 && !this.#info.compressed) {
	          failWebsocketConnection(this.ws, 'Unexpected continuation frame');
	          return
	        }

	        if (payloadLength <= 125) {
	          this.#info.payloadLength = payloadLength;
	          this.#state = parserStates.READ_DATA;
	        } else if (payloadLength === 126) {
	          this.#state = parserStates.PAYLOADLENGTH_16;
	        } else if (payloadLength === 127) {
	          this.#state = parserStates.PAYLOADLENGTH_64;
	        }

	        if (isTextBinaryFrame(opcode)) {
	          this.#info.binaryType = opcode;
	          this.#info.compressed = rsv1 !== 0;
	        }

	        this.#info.opcode = opcode;
	        this.#info.masked = masked;
	        this.#info.fin = fin;
	        this.#info.fragmented = fragmented;
	      } else if (this.#state === parserStates.PAYLOADLENGTH_16) {
	        if (this.#byteOffset < 2) {
	          return callback()
	        }

	        const buffer = this.consume(2);

	        this.#info.payloadLength = buffer.readUInt16BE(0);
	        this.#state = parserStates.READ_DATA;
	      } else if (this.#state === parserStates.PAYLOADLENGTH_64) {
	        if (this.#byteOffset < 8) {
	          return callback()
	        }

	        const buffer = this.consume(8);
	        const upper = buffer.readUInt32BE(0);

	        // 2^31 is the maximum bytes an arraybuffer can contain
	        // on 32-bit systems. Although, on 64-bit systems, this is
	        // 2^53-1 bytes.
	        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length
	        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/common/globals.h;drc=1946212ac0100668f14eb9e2843bdd846e510a1e;bpv=1;bpt=1;l=1275
	        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-array-buffer.h;l=34;drc=1946212ac0100668f14eb9e2843bdd846e510a1e
	        if (upper > 2 ** 31 - 1) {
	          failWebsocketConnection(this.ws, 'Received payload length > 2^31 bytes.');
	          return
	        }

	        const lower = buffer.readUInt32BE(4);

	        this.#info.payloadLength = (upper << 8) + lower;
	        this.#state = parserStates.READ_DATA;
	      } else if (this.#state === parserStates.READ_DATA) {
	        if (this.#byteOffset < this.#info.payloadLength) {
	          return callback()
	        }

	        const body = this.consume(this.#info.payloadLength);

	        if (isControlFrame(this.#info.opcode)) {
	          this.#loop = this.parseControlFrame(body);
	          this.#state = parserStates.INFO;
	        } else {
	          if (!this.#info.compressed) {
	            this.#fragments.push(body);

	            // If the frame is not fragmented, a message has been received.
	            // If the frame is fragmented, it will terminate with a fin bit set
	            // and an opcode of 0 (continuation), therefore we handle that when
	            // parsing continuation frames, not here.
	            if (!this.#info.fragmented && this.#info.fin) {
	              const fullMessage = Buffer.concat(this.#fragments);
	              websocketMessageReceived(this.ws, this.#info.binaryType, fullMessage);
	              this.#fragments.length = 0;
	            }

	            this.#state = parserStates.INFO;
	          } else {
	            this.#extensions.get('permessage-deflate').decompress(body, this.#info.fin, (error, data) => {
	              if (error) {
	                closeWebSocketConnection(this.ws, 1007, error.message, error.message.length);
	                return
	              }

	              this.#fragments.push(data);

	              if (!this.#info.fin) {
	                this.#state = parserStates.INFO;
	                this.#loop = true;
	                this.run(callback);
	                return
	              }

	              websocketMessageReceived(this.ws, this.#info.binaryType, Buffer.concat(this.#fragments));

	              this.#loop = true;
	              this.#state = parserStates.INFO;
	              this.#fragments.length = 0;
	              this.run(callback);
	            });

	            this.#loop = false;
	            break
	          }
	        }
	      }
	    }
	  }

	  /**
	   * Take n bytes from the buffered Buffers
	   * @param {number} n
	   * @returns {Buffer}
	   */
	  consume (n) {
	    if (n > this.#byteOffset) {
	      throw new Error('Called consume() before buffers satiated.')
	    } else if (n === 0) {
	      return emptyBuffer
	    }

	    if (this.#buffers[0].length === n) {
	      this.#byteOffset -= this.#buffers[0].length;
	      return this.#buffers.shift()
	    }

	    const buffer = Buffer.allocUnsafe(n);
	    let offset = 0;

	    while (offset !== n) {
	      const next = this.#buffers[0];
	      const { length } = next;

	      if (length + offset === n) {
	        buffer.set(this.#buffers.shift(), offset);
	        break
	      } else if (length + offset > n) {
	        buffer.set(next.subarray(0, n - offset), offset);
	        this.#buffers[0] = next.subarray(n - offset);
	        break
	      } else {
	        buffer.set(this.#buffers.shift(), offset);
	        offset += next.length;
	      }
	    }

	    this.#byteOffset -= n;

	    return buffer
	  }

	  parseCloseBody (data) {
	    assert(data.length !== 1);

	    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.5
	    /** @type {number|undefined} */
	    let code;

	    if (data.length >= 2) {
	      // _The WebSocket Connection Close Code_ is
	      // defined as the status code (Section 7.4) contained in the first Close
	      // control frame received by the application
	      code = data.readUInt16BE(0);
	    }

	    if (code !== undefined && !isValidStatusCode(code)) {
	      return { code: 1002, reason: 'Invalid status code', error: true }
	    }

	    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.6
	    /** @type {Buffer} */
	    let reason = data.subarray(2);

	    // Remove BOM
	    if (reason[0] === 0xEF && reason[1] === 0xBB && reason[2] === 0xBF) {
	      reason = reason.subarray(3);
	    }

	    try {
	      reason = utf8Decode(reason);
	    } catch {
	      return { code: 1007, reason: 'Invalid UTF-8', error: true }
	    }

	    return { code, reason, error: false }
	  }

	  /**
	   * Parses control frames.
	   * @param {Buffer} body
	   */
	  parseControlFrame (body) {
	    const { opcode, payloadLength } = this.#info;

	    if (opcode === opcodes.CLOSE) {
	      if (payloadLength === 1) {
	        failWebsocketConnection(this.ws, 'Received close frame with a 1-byte body.');
	        return false
	      }

	      this.#info.closeInfo = this.parseCloseBody(body);

	      if (this.#info.closeInfo.error) {
	        const { code, reason } = this.#info.closeInfo;

	        closeWebSocketConnection(this.ws, code, reason, reason.length);
	        failWebsocketConnection(this.ws, reason);
	        return false
	      }

	      if (this.ws[kSentClose] !== sentCloseFrameState.SENT) {
	        // If an endpoint receives a Close frame and did not previously send a
	        // Close frame, the endpoint MUST send a Close frame in response.  (When
	        // sending a Close frame in response, the endpoint typically echos the
	        // status code it received.)
	        let body = emptyBuffer;
	        if (this.#info.closeInfo.code) {
	          body = Buffer.allocUnsafe(2);
	          body.writeUInt16BE(this.#info.closeInfo.code, 0);
	        }
	        const closeFrame = new WebsocketFrameSend(body);

	        this.ws[kResponse].socket.write(
	          closeFrame.createFrame(opcodes.CLOSE),
	          (err) => {
	            if (!err) {
	              this.ws[kSentClose] = sentCloseFrameState.SENT;
	            }
	          }
	        );
	      }

	      // Upon either sending or receiving a Close control frame, it is said
	      // that _The WebSocket Closing Handshake is Started_ and that the
	      // WebSocket connection is in the CLOSING state.
	      this.ws[kReadyState] = states.CLOSING;
	      this.ws[kReceivedClose] = true;

	      return false
	    } else if (opcode === opcodes.PING) {
	      // Upon receipt of a Ping frame, an endpoint MUST send a Pong frame in
	      // response, unless it already received a Close frame.
	      // A Pong frame sent in response to a Ping frame must have identical
	      // "Application data"

	      if (!this.ws[kReceivedClose]) {
	        const frame = new WebsocketFrameSend(body);

	        this.ws[kResponse].socket.write(frame.createFrame(opcodes.PONG));

	        if (channels.ping.hasSubscribers) {
	          channels.ping.publish({
	            payload: body
	          });
	        }
	      }
	    } else if (opcode === opcodes.PONG) {
	      // A Pong frame MAY be sent unsolicited.  This serves as a
	      // unidirectional heartbeat.  A response to an unsolicited Pong frame is
	      // not expected.

	      if (channels.pong.hasSubscribers) {
	        channels.pong.publish({
	          payload: body
	        });
	      }
	    }

	    return true
	  }

	  get closingInfo () {
	    return this.#info.closeInfo
	  }
	}

	receiver = {
	  ByteParser
	};
	return receiver;
}

var sender;
var hasRequiredSender;

function requireSender () {
	if (hasRequiredSender) return sender;
	hasRequiredSender = 1;

	const { WebsocketFrameSend } = requireFrame();
	const { opcodes, sendHints } = requireConstants();
	const FixedQueue = requireFixedQueue();

	/** @type {typeof Uint8Array} */
	const FastBuffer = Buffer[Symbol.species];

	/**
	 * @typedef {object} SendQueueNode
	 * @property {Promise<void> | null} promise
	 * @property {((...args: any[]) => any)} callback
	 * @property {Buffer | null} frame
	 */

	class SendQueue {
	  /**
	   * @type {FixedQueue}
	   */
	  #queue = new FixedQueue()

	  /**
	   * @type {boolean}
	   */
	  #running = false

	  /** @type {import('node:net').Socket} */
	  #socket

	  constructor (socket) {
	    this.#socket = socket;
	  }

	  add (item, cb, hint) {
	    if (hint !== sendHints.blob) {
	      const frame = createFrame(item, hint);
	      if (!this.#running) {
	        // fast-path
	        this.#socket.write(frame, cb);
	      } else {
	        /** @type {SendQueueNode} */
	        const node = {
	          promise: null,
	          callback: cb,
	          frame
	        };
	        this.#queue.push(node);
	      }
	      return
	    }

	    /** @type {SendQueueNode} */
	    const node = {
	      promise: item.arrayBuffer().then((ab) => {
	        node.promise = null;
	        node.frame = createFrame(ab, hint);
	      }),
	      callback: cb,
	      frame: null
	    };

	    this.#queue.push(node);

	    if (!this.#running) {
	      this.#run();
	    }
	  }

	  async #run () {
	    this.#running = true;
	    const queue = this.#queue;
	    while (!queue.isEmpty()) {
	      const node = queue.shift();
	      // wait pending promise
	      if (node.promise !== null) {
	        await node.promise;
	      }
	      // write
	      this.#socket.write(node.frame, node.callback);
	      // cleanup
	      node.callback = node.frame = null;
	    }
	    this.#running = false;
	  }
	}

	function createFrame (data, hint) {
	  return new WebsocketFrameSend(toBuffer(data, hint)).createFrame(hint === sendHints.string ? opcodes.TEXT : opcodes.BINARY)
	}

	function toBuffer (data, hint) {
	  switch (hint) {
	    case sendHints.string:
	      return Buffer.from(data)
	    case sendHints.arrayBuffer:
	    case sendHints.blob:
	      return new FastBuffer(data)
	    case sendHints.typedArray:
	      return new FastBuffer(data.buffer, data.byteOffset, data.byteLength)
	  }
	}

	sender = { SendQueue };
	return sender;
}

var websocket;
var hasRequiredWebsocket;

function requireWebsocket () {
	if (hasRequiredWebsocket) return websocket;
	hasRequiredWebsocket = 1;

	const { webidl } = requireWebidl();
	const { URLSerializer } = requireDataUrl();
	const { environmentSettingsObject } = requireUtil$6();
	const { staticPropertyDescriptors, states, sentCloseFrameState, sendHints } = requireConstants();
	const {
	  kWebSocketURL,
	  kReadyState,
	  kController,
	  kBinaryType,
	  kResponse,
	  kSentClose,
	  kByteParser
	} = requireSymbols();
	const {
	  isConnecting,
	  isEstablished,
	  isClosing,
	  isValidSubprotocol,
	  fireEvent
	} = requireUtil$1();
	const { establishWebSocketConnection, closeWebSocketConnection } = requireConnection();
	const { ByteParser } = requireReceiver();
	const { kEnumerableProperty, isBlobLike } = requireUtil$7();
	const { getGlobalDispatcher } = requireGlobal();
	const { types } = require$$0$6;
	const { ErrorEvent, CloseEvent } = requireEvents();
	const { SendQueue } = requireSender();

	// https://websockets.spec.whatwg.org/#interface-definition
	class WebSocket extends EventTarget {
	  #events = {
	    open: null,
	    error: null,
	    close: null,
	    message: null
	  }

	  #bufferedAmount = 0
	  #protocol = ''
	  #extensions = ''

	  /** @type {SendQueue} */
	  #sendQueue

	  /**
	   * @param {string} url
	   * @param {string|string[]} protocols
	   */
	  constructor (url, protocols = []) {
	    super();

	    const prefix = 'WebSocket constructor';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    const options = webidl.converters['DOMString or sequence<DOMString> or WebSocketInit'](protocols, prefix, 'options');

	    url = webidl.converters.USVString(url, prefix, 'url');
	    protocols = options.protocols;

	    // 1. Let baseURL be this's relevant settings object's API base URL.
	    const baseURL = environmentSettingsObject.settingsObject.baseUrl;

	    // 1. Let urlRecord be the result of applying the URL parser to url with baseURL.
	    let urlRecord;

	    try {
	      urlRecord = new URL(url, baseURL);
	    } catch (e) {
	      // 3. If urlRecord is failure, then throw a "SyntaxError" DOMException.
	      throw new DOMException(e, 'SyntaxError')
	    }

	    // 4. If urlRecordâs scheme is "http", then set urlRecordâs scheme to "ws".
	    if (urlRecord.protocol === 'http:') {
	      urlRecord.protocol = 'ws:';
	    } else if (urlRecord.protocol === 'https:') {
	      // 5. Otherwise, if urlRecordâs scheme is "https", set urlRecordâs scheme to "wss".
	      urlRecord.protocol = 'wss:';
	    }

	    // 6. If urlRecordâs scheme is not "ws" or "wss", then throw a "SyntaxError" DOMException.
	    if (urlRecord.protocol !== 'ws:' && urlRecord.protocol !== 'wss:') {
	      throw new DOMException(
	        `Expected a ws: or wss: protocol, got ${urlRecord.protocol}`,
	        'SyntaxError'
	      )
	    }

	    // 7. If urlRecordâs fragment is non-null, then throw a "SyntaxError"
	    //    DOMException.
	    if (urlRecord.hash || urlRecord.href.endsWith('#')) {
	      throw new DOMException('Got fragment', 'SyntaxError')
	    }

	    // 8. If protocols is a string, set protocols to a sequence consisting
	    //    of just that string.
	    if (typeof protocols === 'string') {
	      protocols = [protocols];
	    }

	    // 9. If any of the values in protocols occur more than once or otherwise
	    //    fail to match the requirements for elements that comprise the value
	    //    of `Sec-WebSocket-Protocol` fields as defined by The WebSocket
	    //    protocol, then throw a "SyntaxError" DOMException.
	    if (protocols.length !== new Set(protocols.map(p => p.toLowerCase())).size) {
	      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')
	    }

	    if (protocols.length > 0 && !protocols.every(p => isValidSubprotocol(p))) {
	      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')
	    }

	    // 10. Set this's url to urlRecord.
	    this[kWebSocketURL] = new URL(urlRecord.href);

	    // 11. Let client be this's relevant settings object.
	    const client = environmentSettingsObject.settingsObject;

	    // 12. Run this step in parallel:

	    //    1. Establish a WebSocket connection given urlRecord, protocols,
	    //       and client.
	    this[kController] = establishWebSocketConnection(
	      urlRecord,
	      protocols,
	      client,
	      this,
	      (response, extensions) => this.#onConnectionEstablished(response, extensions),
	      options
	    );

	    // Each WebSocket object has an associated ready state, which is a
	    // number representing the state of the connection. Initially it must
	    // be CONNECTING (0).
	    this[kReadyState] = WebSocket.CONNECTING;

	    this[kSentClose] = sentCloseFrameState.NOT_SENT;

	    // The extensions attribute must initially return the empty string.

	    // The protocol attribute must initially return the empty string.

	    // Each WebSocket object has an associated binary type, which is a
	    // BinaryType. Initially it must be "blob".
	    this[kBinaryType] = 'blob';
	  }

	  /**
	   * @see https://websockets.spec.whatwg.org/#dom-websocket-close
	   * @param {number|undefined} code
	   * @param {string|undefined} reason
	   */
	  close (code = undefined, reason = undefined) {
	    webidl.brandCheck(this, WebSocket);

	    const prefix = 'WebSocket.close';

	    if (code !== undefined) {
	      code = webidl.converters['unsigned short'](code, prefix, 'code', { clamp: true });
	    }

	    if (reason !== undefined) {
	      reason = webidl.converters.USVString(reason, prefix, 'reason');
	    }

	    // 1. If code is present, but is neither an integer equal to 1000 nor an
	    //    integer in the range 3000 to 4999, inclusive, throw an
	    //    "InvalidAccessError" DOMException.
	    if (code !== undefined) {
	      if (code !== 1000 && (code < 3000 || code > 4999)) {
	        throw new DOMException('invalid code', 'InvalidAccessError')
	      }
	    }

	    let reasonByteLength = 0;

	    // 2. If reason is present, then run these substeps:
	    if (reason !== undefined) {
	      // 1. Let reasonBytes be the result of encoding reason.
	      // 2. If reasonBytes is longer than 123 bytes, then throw a
	      //    "SyntaxError" DOMException.
	      reasonByteLength = Buffer.byteLength(reason);

	      if (reasonByteLength > 123) {
	        throw new DOMException(
	          `Reason must be less than 123 bytes; received ${reasonByteLength}`,
	          'SyntaxError'
	        )
	      }
	    }

	    // 3. Run the first matching steps from the following list:
	    closeWebSocketConnection(this, code, reason, reasonByteLength);
	  }

	  /**
	   * @see https://websockets.spec.whatwg.org/#dom-websocket-send
	   * @param {NodeJS.TypedArray|ArrayBuffer|Blob|string} data
	   */
	  send (data) {
	    webidl.brandCheck(this, WebSocket);

	    const prefix = 'WebSocket.send';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    data = webidl.converters.WebSocketSendData(data, prefix, 'data');

	    // 1. If this's ready state is CONNECTING, then throw an
	    //    "InvalidStateError" DOMException.
	    if (isConnecting(this)) {
	      throw new DOMException('Sent before connected.', 'InvalidStateError')
	    }

	    // 2. Run the appropriate set of steps from the following list:
	    // https://datatracker.ietf.org/doc/html/rfc6455#section-6.1
	    // https://datatracker.ietf.org/doc/html/rfc6455#section-5.2

	    if (!isEstablished(this) || isClosing(this)) {
	      return
	    }

	    // If data is a string
	    if (typeof data === 'string') {
	      // If the WebSocket connection is established and the WebSocket
	      // closing handshake has not yet started, then the user agent
	      // must send a WebSocket Message comprised of the data argument
	      // using a text frame opcode; if the data cannot be sent, e.g.
	      // because it would need to be buffered but the buffer is full,
	      // the user agent must flag the WebSocket as full and then close
	      // the WebSocket connection. Any invocation of this method with a
	      // string argument that does not throw an exception must increase
	      // the bufferedAmount attribute by the number of bytes needed to
	      // express the argument as UTF-8.

	      const length = Buffer.byteLength(data);

	      this.#bufferedAmount += length;
	      this.#sendQueue.add(data, () => {
	        this.#bufferedAmount -= length;
	      }, sendHints.string);
	    } else if (types.isArrayBuffer(data)) {
	      // If the WebSocket connection is established, and the WebSocket
	      // closing handshake has not yet started, then the user agent must
	      // send a WebSocket Message comprised of data using a binary frame
	      // opcode; if the data cannot be sent, e.g. because it would need
	      // to be buffered but the buffer is full, the user agent must flag
	      // the WebSocket as full and then close the WebSocket connection.
	      // The data to be sent is the data stored in the buffer described
	      // by the ArrayBuffer object. Any invocation of this method with an
	      // ArrayBuffer argument that does not throw an exception must
	      // increase the bufferedAmount attribute by the length of the
	      // ArrayBuffer in bytes.

	      this.#bufferedAmount += data.byteLength;
	      this.#sendQueue.add(data, () => {
	        this.#bufferedAmount -= data.byteLength;
	      }, sendHints.arrayBuffer);
	    } else if (ArrayBuffer.isView(data)) {
	      // If the WebSocket connection is established, and the WebSocket
	      // closing handshake has not yet started, then the user agent must
	      // send a WebSocket Message comprised of data using a binary frame
	      // opcode; if the data cannot be sent, e.g. because it would need to
	      // be buffered but the buffer is full, the user agent must flag the
	      // WebSocket as full and then close the WebSocket connection. The
	      // data to be sent is the data stored in the section of the buffer
	      // described by the ArrayBuffer object that data references. Any
	      // invocation of this method with this kind of argument that does
	      // not throw an exception must increase the bufferedAmount attribute
	      // by the length of dataâs buffer in bytes.

	      this.#bufferedAmount += data.byteLength;
	      this.#sendQueue.add(data, () => {
	        this.#bufferedAmount -= data.byteLength;
	      }, sendHints.typedArray);
	    } else if (isBlobLike(data)) {
	      // If the WebSocket connection is established, and the WebSocket
	      // closing handshake has not yet started, then the user agent must
	      // send a WebSocket Message comprised of data using a binary frame
	      // opcode; if the data cannot be sent, e.g. because it would need to
	      // be buffered but the buffer is full, the user agent must flag the
	      // WebSocket as full and then close the WebSocket connection. The data
	      // to be sent is the raw data represented by the Blob object. Any
	      // invocation of this method with a Blob argument that does not throw
	      // an exception must increase the bufferedAmount attribute by the size
	      // of the Blob objectâs raw data, in bytes.

	      this.#bufferedAmount += data.size;
	      this.#sendQueue.add(data, () => {
	        this.#bufferedAmount -= data.size;
	      }, sendHints.blob);
	    }
	  }

	  get readyState () {
	    webidl.brandCheck(this, WebSocket);

	    // The readyState getter steps are to return this's ready state.
	    return this[kReadyState]
	  }

	  get bufferedAmount () {
	    webidl.brandCheck(this, WebSocket);

	    return this.#bufferedAmount
	  }

	  get url () {
	    webidl.brandCheck(this, WebSocket);

	    // The url getter steps are to return this's url, serialized.
	    return URLSerializer(this[kWebSocketURL])
	  }

	  get extensions () {
	    webidl.brandCheck(this, WebSocket);

	    return this.#extensions
	  }

	  get protocol () {
	    webidl.brandCheck(this, WebSocket);

	    return this.#protocol
	  }

	  get onopen () {
	    webidl.brandCheck(this, WebSocket);

	    return this.#events.open
	  }

	  set onopen (fn) {
	    webidl.brandCheck(this, WebSocket);

	    if (this.#events.open) {
	      this.removeEventListener('open', this.#events.open);
	    }

	    if (typeof fn === 'function') {
	      this.#events.open = fn;
	      this.addEventListener('open', fn);
	    } else {
	      this.#events.open = null;
	    }
	  }

	  get onerror () {
	    webidl.brandCheck(this, WebSocket);

	    return this.#events.error
	  }

	  set onerror (fn) {
	    webidl.brandCheck(this, WebSocket);

	    if (this.#events.error) {
	      this.removeEventListener('error', this.#events.error);
	    }

	    if (typeof fn === 'function') {
	      this.#events.error = fn;
	      this.addEventListener('error', fn);
	    } else {
	      this.#events.error = null;
	    }
	  }

	  get onclose () {
	    webidl.brandCheck(this, WebSocket);

	    return this.#events.close
	  }

	  set onclose (fn) {
	    webidl.brandCheck(this, WebSocket);

	    if (this.#events.close) {
	      this.removeEventListener('close', this.#events.close);
	    }

	    if (typeof fn === 'function') {
	      this.#events.close = fn;
	      this.addEventListener('close', fn);
	    } else {
	      this.#events.close = null;
	    }
	  }

	  get onmessage () {
	    webidl.brandCheck(this, WebSocket);

	    return this.#events.message
	  }

	  set onmessage (fn) {
	    webidl.brandCheck(this, WebSocket);

	    if (this.#events.message) {
	      this.removeEventListener('message', this.#events.message);
	    }

	    if (typeof fn === 'function') {
	      this.#events.message = fn;
	      this.addEventListener('message', fn);
	    } else {
	      this.#events.message = null;
	    }
	  }

	  get binaryType () {
	    webidl.brandCheck(this, WebSocket);

	    return this[kBinaryType]
	  }

	  set binaryType (type) {
	    webidl.brandCheck(this, WebSocket);

	    if (type !== 'blob' && type !== 'arraybuffer') {
	      this[kBinaryType] = 'blob';
	    } else {
	      this[kBinaryType] = type;
	    }
	  }

	  /**
	   * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol
	   */
	  #onConnectionEstablished (response, parsedExtensions) {
	    // processResponse is called when the "responseâs header list has been received and initialized."
	    // once this happens, the connection is open
	    this[kResponse] = response;

	    const parser = new ByteParser(this, parsedExtensions);
	    parser.on('drain', onParserDrain);
	    parser.on('error', onParserError.bind(this));

	    response.socket.ws = this;
	    this[kByteParser] = parser;

	    this.#sendQueue = new SendQueue(response.socket);

	    // 1. Change the ready state to OPEN (1).
	    this[kReadyState] = states.OPEN;

	    // 2. Change the extensions attributeâs value to the extensions in use, if
	    //    it is not the null value.
	    // https://datatracker.ietf.org/doc/html/rfc6455#section-9.1
	    const extensions = response.headersList.get('sec-websocket-extensions');

	    if (extensions !== null) {
	      this.#extensions = extensions;
	    }

	    // 3. Change the protocol attributeâs value to the subprotocol in use, if
	    //    it is not the null value.
	    // https://datatracker.ietf.org/doc/html/rfc6455#section-1.9
	    const protocol = response.headersList.get('sec-websocket-protocol');

	    if (protocol !== null) {
	      this.#protocol = protocol;
	    }

	    // 4. Fire an event named open at the WebSocket object.
	    fireEvent('open', this);
	  }
	}

	// https://websockets.spec.whatwg.org/#dom-websocket-connecting
	WebSocket.CONNECTING = WebSocket.prototype.CONNECTING = states.CONNECTING;
	// https://websockets.spec.whatwg.org/#dom-websocket-open
	WebSocket.OPEN = WebSocket.prototype.OPEN = states.OPEN;
	// https://websockets.spec.whatwg.org/#dom-websocket-closing
	WebSocket.CLOSING = WebSocket.prototype.CLOSING = states.CLOSING;
	// https://websockets.spec.whatwg.org/#dom-websocket-closed
	WebSocket.CLOSED = WebSocket.prototype.CLOSED = states.CLOSED;

	Object.defineProperties(WebSocket.prototype, {
	  CONNECTING: staticPropertyDescriptors,
	  OPEN: staticPropertyDescriptors,
	  CLOSING: staticPropertyDescriptors,
	  CLOSED: staticPropertyDescriptors,
	  url: kEnumerableProperty,
	  readyState: kEnumerableProperty,
	  bufferedAmount: kEnumerableProperty,
	  onopen: kEnumerableProperty,
	  onerror: kEnumerableProperty,
	  onclose: kEnumerableProperty,
	  close: kEnumerableProperty,
	  onmessage: kEnumerableProperty,
	  binaryType: kEnumerableProperty,
	  send: kEnumerableProperty,
	  extensions: kEnumerableProperty,
	  protocol: kEnumerableProperty,
	  [Symbol.toStringTag]: {
	    value: 'WebSocket',
	    writable: false,
	    enumerable: false,
	    configurable: true
	  }
	});

	Object.defineProperties(WebSocket, {
	  CONNECTING: staticPropertyDescriptors,
	  OPEN: staticPropertyDescriptors,
	  CLOSING: staticPropertyDescriptors,
	  CLOSED: staticPropertyDescriptors
	});

	webidl.converters['sequence<DOMString>'] = webidl.sequenceConverter(
	  webidl.converters.DOMString
	);

	webidl.converters['DOMString or sequence<DOMString>'] = function (V, prefix, argument) {
	  if (webidl.util.Type(V) === 'Object' && Symbol.iterator in V) {
	    return webidl.converters['sequence<DOMString>'](V)
	  }

	  return webidl.converters.DOMString(V, prefix, argument)
	};

	// This implements the proposal made in https://github.com/whatwg/websockets/issues/42
	webidl.converters.WebSocketInit = webidl.dictionaryConverter([
	  {
	    key: 'protocols',
	    converter: webidl.converters['DOMString or sequence<DOMString>'],
	    defaultValue: () => new Array(0)
	  },
	  {
	    key: 'dispatcher',
	    converter: webidl.converters.any,
	    defaultValue: () => getGlobalDispatcher()
	  },
	  {
	    key: 'headers',
	    converter: webidl.nullableConverter(webidl.converters.HeadersInit)
	  }
	]);

	webidl.converters['DOMString or sequence<DOMString> or WebSocketInit'] = function (V) {
	  if (webidl.util.Type(V) === 'Object' && !(Symbol.iterator in V)) {
	    return webidl.converters.WebSocketInit(V)
	  }

	  return { protocols: webidl.converters['DOMString or sequence<DOMString>'](V) }
	};

	webidl.converters.WebSocketSendData = function (V) {
	  if (webidl.util.Type(V) === 'Object') {
	    if (isBlobLike(V)) {
	      return webidl.converters.Blob(V, { strict: false })
	    }

	    if (ArrayBuffer.isView(V) || types.isArrayBuffer(V)) {
	      return webidl.converters.BufferSource(V)
	    }
	  }

	  return webidl.converters.USVString(V)
	};

	function onParserDrain () {
	  this.ws[kResponse].socket.resume();
	}

	function onParserError (err) {
	  let message;
	  let code;

	  if (err instanceof CloseEvent) {
	    message = err.reason;
	    code = err.code;
	  } else {
	    message = err.message;
	  }

	  fireEvent('error', this, () => new ErrorEvent('error', { error: err, message }));

	  closeWebSocketConnection(this, code);
	}

	websocket = {
	  WebSocket
	};
	return websocket;
}

var util;
var hasRequiredUtil;

function requireUtil () {
	if (hasRequiredUtil) return util;
	hasRequiredUtil = 1;

	/**
	 * Checks if the given value is a valid LastEventId.
	 * @param {string} value
	 * @returns {boolean}
	 */
	function isValidLastEventId (value) {
	  // LastEventId should not contain U+0000 NULL
	  return value.indexOf('\u0000') === -1
	}

	/**
	 * Checks if the given value is a base 10 digit.
	 * @param {string} value
	 * @returns {boolean}
	 */
	function isASCIINumber (value) {
	  if (value.length === 0) return false
	  for (let i = 0; i < value.length; i++) {
	    if (value.charCodeAt(i) < 0x30 || value.charCodeAt(i) > 0x39) return false
	  }
	  return true
	}

	// https://github.com/nodejs/undici/issues/2664
	function delay (ms) {
	  return new Promise((resolve) => {
	    setTimeout(resolve, ms).unref();
	  })
	}

	util = {
	  isValidLastEventId,
	  isASCIINumber,
	  delay
	};
	return util;
}

var eventsourceStream;
var hasRequiredEventsourceStream;

function requireEventsourceStream () {
	if (hasRequiredEventsourceStream) return eventsourceStream;
	hasRequiredEventsourceStream = 1;
	const { Transform } = require$$0$5;
	const { isASCIINumber, isValidLastEventId } = requireUtil();

	/**
	 * @type {number[]} BOM
	 */
	const BOM = [0xEF, 0xBB, 0xBF];
	/**
	 * @type {10} LF
	 */
	const LF = 0x0A;
	/**
	 * @type {13} CR
	 */
	const CR = 0x0D;
	/**
	 * @type {58} COLON
	 */
	const COLON = 0x3A;
	/**
	 * @type {32} SPACE
	 */
	const SPACE = 0x20;

	/**
	 * @typedef {object} EventSourceStreamEvent
	 * @type {object}
	 * @property {string} [event] The event type.
	 * @property {string} [data] The data of the message.
	 * @property {string} [id] A unique ID for the event.
	 * @property {string} [retry] The reconnection time, in milliseconds.
	 */

	/**
	 * @typedef eventSourceSettings
	 * @type {object}
	 * @property {string} lastEventId The last event ID received from the server.
	 * @property {string} origin The origin of the event source.
	 * @property {number} reconnectionTime The reconnection time, in milliseconds.
	 */

	class EventSourceStream extends Transform {
	  /**
	   * @type {eventSourceSettings}
	   */
	  state = null

	  /**
	   * Leading byte-order-mark check.
	   * @type {boolean}
	   */
	  checkBOM = true

	  /**
	   * @type {boolean}
	   */
	  crlfCheck = false

	  /**
	   * @type {boolean}
	   */
	  eventEndCheck = false

	  /**
	   * @type {Buffer}
	   */
	  buffer = null

	  pos = 0

	  event = {
	    data: undefined,
	    event: undefined,
	    id: undefined,
	    retry: undefined
	  }

	  /**
	   * @param {object} options
	   * @param {eventSourceSettings} options.eventSourceSettings
	   * @param {Function} [options.push]
	   */
	  constructor (options = {}) {
	    // Enable object mode as EventSourceStream emits objects of shape
	    // EventSourceStreamEvent
	    options.readableObjectMode = true;

	    super(options);

	    this.state = options.eventSourceSettings || {};
	    if (options.push) {
	      this.push = options.push;
	    }
	  }

	  /**
	   * @param {Buffer} chunk
	   * @param {string} _encoding
	   * @param {Function} callback
	   * @returns {void}
	   */
	  _transform (chunk, _encoding, callback) {
	    if (chunk.length === 0) {
	      callback();
	      return
	    }

	    // Cache the chunk in the buffer, as the data might not be complete while
	    // processing it
	    // TODO: Investigate if there is a more performant way to handle
	    // incoming chunks
	    // see: https://github.com/nodejs/undici/issues/2630
	    if (this.buffer) {
	      this.buffer = Buffer.concat([this.buffer, chunk]);
	    } else {
	      this.buffer = chunk;
	    }

	    // Strip leading byte-order-mark if we opened the stream and started
	    // the processing of the incoming data
	    if (this.checkBOM) {
	      switch (this.buffer.length) {
	        case 1:
	          // Check if the first byte is the same as the first byte of the BOM
	          if (this.buffer[0] === BOM[0]) {
	            // If it is, we need to wait for more data
	            callback();
	            return
	          }
	          // Set the checkBOM flag to false as we don't need to check for the
	          // BOM anymore
	          this.checkBOM = false;

	          // The buffer only contains one byte so we need to wait for more data
	          callback();
	          return
	        case 2:
	          // Check if the first two bytes are the same as the first two bytes
	          // of the BOM
	          if (
	            this.buffer[0] === BOM[0] &&
	            this.buffer[1] === BOM[1]
	          ) {
	            // If it is, we need to wait for more data, because the third byte
	            // is needed to determine if it is the BOM or not
	            callback();
	            return
	          }

	          // Set the checkBOM flag to false as we don't need to check for the
	          // BOM anymore
	          this.checkBOM = false;
	          break
	        case 3:
	          // Check if the first three bytes are the same as the first three
	          // bytes of the BOM
	          if (
	            this.buffer[0] === BOM[0] &&
	            this.buffer[1] === BOM[1] &&
	            this.buffer[2] === BOM[2]
	          ) {
	            // If it is, we can drop the buffered data, as it is only the BOM
	            this.buffer = Buffer.alloc(0);
	            // Set the checkBOM flag to false as we don't need to check for the
	            // BOM anymore
	            this.checkBOM = false;

	            // Await more data
	            callback();
	            return
	          }
	          // If it is not the BOM, we can start processing the data
	          this.checkBOM = false;
	          break
	        default:
	          // The buffer is longer than 3 bytes, so we can drop the BOM if it is
	          // present
	          if (
	            this.buffer[0] === BOM[0] &&
	            this.buffer[1] === BOM[1] &&
	            this.buffer[2] === BOM[2]
	          ) {
	            // Remove the BOM from the buffer
	            this.buffer = this.buffer.subarray(3);
	          }

	          // Set the checkBOM flag to false as we don't need to check for the
	          this.checkBOM = false;
	          break
	      }
	    }

	    while (this.pos < this.buffer.length) {
	      // If the previous line ended with an end-of-line, we need to check
	      // if the next character is also an end-of-line.
	      if (this.eventEndCheck) {
	        // If the the current character is an end-of-line, then the event
	        // is finished and we can process it

	        // If the previous line ended with a carriage return, we need to
	        // check if the current character is a line feed and remove it
	        // from the buffer.
	        if (this.crlfCheck) {
	          // If the current character is a line feed, we can remove it
	          // from the buffer and reset the crlfCheck flag
	          if (this.buffer[this.pos] === LF) {
	            this.buffer = this.buffer.subarray(this.pos + 1);
	            this.pos = 0;
	            this.crlfCheck = false;

	            // It is possible that the line feed is not the end of the
	            // event. We need to check if the next character is an
	            // end-of-line character to determine if the event is
	            // finished. We simply continue the loop to check the next
	            // character.

	            // As we removed the line feed from the buffer and set the
	            // crlfCheck flag to false, we basically don't make any
	            // distinction between a line feed and a carriage return.
	            continue
	          }
	          this.crlfCheck = false;
	        }

	        if (this.buffer[this.pos] === LF || this.buffer[this.pos] === CR) {
	          // If the current character is a carriage return, we need to
	          // set the crlfCheck flag to true, as we need to check if the
	          // next character is a line feed so we can remove it from the
	          // buffer
	          if (this.buffer[this.pos] === CR) {
	            this.crlfCheck = true;
	          }

	          this.buffer = this.buffer.subarray(this.pos + 1);
	          this.pos = 0;
	          if (
	            this.event.data !== undefined || this.event.event || this.event.id || this.event.retry) {
	            this.processEvent(this.event);
	          }
	          this.clearEvent();
	          continue
	        }
	        // If the current character is not an end-of-line, then the event
	        // is not finished and we have to reset the eventEndCheck flag
	        this.eventEndCheck = false;
	        continue
	      }

	      // If the current character is an end-of-line, we can process the
	      // line
	      if (this.buffer[this.pos] === LF || this.buffer[this.pos] === CR) {
	        // If the current character is a carriage return, we need to
	        // set the crlfCheck flag to true, as we need to check if the
	        // next character is a line feed
	        if (this.buffer[this.pos] === CR) {
	          this.crlfCheck = true;
	        }

	        // In any case, we can process the line as we reached an
	        // end-of-line character
	        this.parseLine(this.buffer.subarray(0, this.pos), this.event);

	        // Remove the processed line from the buffer
	        this.buffer = this.buffer.subarray(this.pos + 1);
	        // Reset the position as we removed the processed line from the buffer
	        this.pos = 0;
	        // A line was processed and this could be the end of the event. We need
	        // to check if the next line is empty to determine if the event is
	        // finished.
	        this.eventEndCheck = true;
	        continue
	      }

	      this.pos++;
	    }

	    callback();
	  }

	  /**
	   * @param {Buffer} line
	   * @param {EventStreamEvent} event
	   */
	  parseLine (line, event) {
	    // If the line is empty (a blank line)
	    // Dispatch the event, as defined below.
	    // This will be handled in the _transform method
	    if (line.length === 0) {
	      return
	    }

	    // If the line starts with a U+003A COLON character (:)
	    // Ignore the line.
	    const colonPosition = line.indexOf(COLON);
	    if (colonPosition === 0) {
	      return
	    }

	    let field = '';
	    let value = '';

	    // If the line contains a U+003A COLON character (:)
	    if (colonPosition !== -1) {
	      // Collect the characters on the line before the first U+003A COLON
	      // character (:), and let field be that string.
	      // TODO: Investigate if there is a more performant way to extract the
	      // field
	      // see: https://github.com/nodejs/undici/issues/2630
	      field = line.subarray(0, colonPosition).toString('utf8');

	      // Collect the characters on the line after the first U+003A COLON
	      // character (:), and let value be that string.
	      // If value starts with a U+0020 SPACE character, remove it from value.
	      let valueStart = colonPosition + 1;
	      if (line[valueStart] === SPACE) {
	        ++valueStart;
	      }
	      // TODO: Investigate if there is a more performant way to extract the
	      // value
	      // see: https://github.com/nodejs/undici/issues/2630
	      value = line.subarray(valueStart).toString('utf8');

	      // Otherwise, the string is not empty but does not contain a U+003A COLON
	      // character (:)
	    } else {
	      // Process the field using the steps described below, using the whole
	      // line as the field name, and the empty string as the field value.
	      field = line.toString('utf8');
	      value = '';
	    }

	    // Modify the event with the field name and value. The value is also
	    // decoded as UTF-8
	    switch (field) {
	      case 'data':
	        if (event[field] === undefined) {
	          event[field] = value;
	        } else {
	          event[field] += `\n${value}`;
	        }
	        break
	      case 'retry':
	        if (isASCIINumber(value)) {
	          event[field] = value;
	        }
	        break
	      case 'id':
	        if (isValidLastEventId(value)) {
	          event[field] = value;
	        }
	        break
	      case 'event':
	        if (value.length > 0) {
	          event[field] = value;
	        }
	        break
	    }
	  }

	  /**
	   * @param {EventSourceStreamEvent} event
	   */
	  processEvent (event) {
	    if (event.retry && isASCIINumber(event.retry)) {
	      this.state.reconnectionTime = parseInt(event.retry, 10);
	    }

	    if (event.id && isValidLastEventId(event.id)) {
	      this.state.lastEventId = event.id;
	    }

	    // only dispatch event, when data is provided
	    if (event.data !== undefined) {
	      this.push({
	        type: event.event || 'message',
	        options: {
	          data: event.data,
	          lastEventId: this.state.lastEventId,
	          origin: this.state.origin
	        }
	      });
	    }
	  }

	  clearEvent () {
	    this.event = {
	      data: undefined,
	      event: undefined,
	      id: undefined,
	      retry: undefined
	    };
	  }
	}

	eventsourceStream = {
	  EventSourceStream
	};
	return eventsourceStream;
}

var eventsource;
var hasRequiredEventsource;

function requireEventsource () {
	if (hasRequiredEventsource) return eventsource;
	hasRequiredEventsource = 1;

	const { pipeline } = require$$0$5;
	const { fetching } = requireFetch();
	const { makeRequest } = requireRequest();
	const { webidl } = requireWebidl();
	const { EventSourceStream } = requireEventsourceStream();
	const { parseMIMEType } = requireDataUrl();
	const { createFastMessageEvent } = requireEvents();
	const { isNetworkError } = requireResponse();
	const { delay } = requireUtil();
	const { kEnumerableProperty } = requireUtil$7();
	const { environmentSettingsObject } = requireUtil$6();

	let experimentalWarned = false;

	/**
	 * A reconnection time, in milliseconds. This must initially be an implementation-defined value,
	 * probably in the region of a few seconds.
	 *
	 * In Comparison:
	 * - Chrome uses 3000ms.
	 * - Deno uses 5000ms.
	 *
	 * @type {3000}
	 */
	const defaultReconnectionTime = 3000;

	/**
	 * The readyState attribute represents the state of the connection.
	 * @enum
	 * @readonly
	 * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#dom-eventsource-readystate-dev
	 */

	/**
	 * The connection has not yet been established, or it was closed and the user
	 * agent is reconnecting.
	 * @type {0}
	 */
	const CONNECTING = 0;

	/**
	 * The user agent has an open connection and is dispatching events as it
	 * receives them.
	 * @type {1}
	 */
	const OPEN = 1;

	/**
	 * The connection is not open, and the user agent is not trying to reconnect.
	 * @type {2}
	 */
	const CLOSED = 2;

	/**
	 * Requests for the element will have their mode set to "cors" and their credentials mode set to "same-origin".
	 * @type {'anonymous'}
	 */
	const ANONYMOUS = 'anonymous';

	/**
	 * Requests for the element will have their mode set to "cors" and their credentials mode set to "include".
	 * @type {'use-credentials'}
	 */
	const USE_CREDENTIALS = 'use-credentials';

	/**
	 * The EventSource interface is used to receive server-sent events. It
	 * connects to a server over HTTP and receives events in text/event-stream
	 * format without closing the connection.
	 * @extends {EventTarget}
	 * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events
	 * @api public
	 */
	class EventSource extends EventTarget {
	  #events = {
	    open: null,
	    error: null,
	    message: null
	  }

	  #url = null
	  #withCredentials = false

	  #readyState = CONNECTING

	  #request = null
	  #controller = null

	  #dispatcher

	  /**
	   * @type {import('./eventsource-stream').eventSourceSettings}
	   */
	  #state

	  /**
	   * Creates a new EventSource object.
	   * @param {string} url
	   * @param {EventSourceInit} [eventSourceInitDict]
	   * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#the-eventsource-interface
	   */
	  constructor (url, eventSourceInitDict = {}) {
	    // 1. Let ev be a new EventSource object.
	    super();

	    const prefix = 'EventSource constructor';
	    webidl.argumentLengthCheck(arguments, 1, prefix);

	    if (!experimentalWarned) {
	      experimentalWarned = true;
	      process.emitWarning('EventSource is experimental, expect them to change at any time.', {
	        code: 'UNDICI-ES'
	      });
	    }

	    url = webidl.converters.USVString(url, prefix, 'url');
	    eventSourceInitDict = webidl.converters.EventSourceInitDict(eventSourceInitDict, prefix, 'eventSourceInitDict');

	    this.#dispatcher = eventSourceInitDict.dispatcher;
	    this.#state = {
	      lastEventId: '',
	      reconnectionTime: defaultReconnectionTime
	    };

	    // 2. Let settings be ev's relevant settings object.
	    // https://html.spec.whatwg.org/multipage/webappapis.html#environment-settings-object
	    const settings = environmentSettingsObject;

	    let urlRecord;

	    try {
	      // 3. Let urlRecord be the result of encoding-parsing a URL given url, relative to settings.
	      urlRecord = new URL(url, settings.settingsObject.baseUrl);
	      this.#state.origin = urlRecord.origin;
	    } catch (e) {
	      // 4. If urlRecord is failure, then throw a "SyntaxError" DOMException.
	      throw new DOMException(e, 'SyntaxError')
	    }

	    // 5. Set ev's url to urlRecord.
	    this.#url = urlRecord.href;

	    // 6. Let corsAttributeState be Anonymous.
	    let corsAttributeState = ANONYMOUS;

	    // 7. If the value of eventSourceInitDict's withCredentials member is true,
	    // then set corsAttributeState to Use Credentials and set ev's
	    // withCredentials attribute to true.
	    if (eventSourceInitDict.withCredentials) {
	      corsAttributeState = USE_CREDENTIALS;
	      this.#withCredentials = true;
	    }

	    // 8. Let request be the result of creating a potential-CORS request given
	    // urlRecord, the empty string, and corsAttributeState.
	    const initRequest = {
	      redirect: 'follow',
	      keepalive: true,
	      // @see https://html.spec.whatwg.org/multipage/urls-and-fetching.html#cors-settings-attributes
	      mode: 'cors',
	      credentials: corsAttributeState === 'anonymous'
	        ? 'same-origin'
	        : 'omit',
	      referrer: 'no-referrer'
	    };

	    // 9. Set request's client to settings.
	    initRequest.client = environmentSettingsObject.settingsObject;

	    // 10. User agents may set (`Accept`, `text/event-stream`) in request's header list.
	    initRequest.headersList = [['accept', { name: 'accept', value: 'text/event-stream' }]];

	    // 11. Set request's cache mode to "no-store".
	    initRequest.cache = 'no-store';

	    // 12. Set request's initiator type to "other".
	    initRequest.initiator = 'other';

	    initRequest.urlList = [new URL(this.#url)];

	    // 13. Set ev's request to request.
	    this.#request = makeRequest(initRequest);

	    this.#connect();
	  }

	  /**
	   * Returns the state of this EventSource object's connection. It can have the
	   * values described below.
	   * @returns {0|1|2}
	   * @readonly
	   */
	  get readyState () {
	    return this.#readyState
	  }

	  /**
	   * Returns the URL providing the event stream.
	   * @readonly
	   * @returns {string}
	   */
	  get url () {
	    return this.#url
	  }

	  /**
	   * Returns a boolean indicating whether the EventSource object was
	   * instantiated with CORS credentials set (true), or not (false, the default).
	   */
	  get withCredentials () {
	    return this.#withCredentials
	  }

	  #connect () {
	    if (this.#readyState === CLOSED) return

	    this.#readyState = CONNECTING;

	    const fetchParams = {
	      request: this.#request,
	      dispatcher: this.#dispatcher
	    };

	    // 14. Let processEventSourceEndOfBody given response res be the following step: if res is not a network error, then reestablish the connection.
	    const processEventSourceEndOfBody = (response) => {
	      if (isNetworkError(response)) {
	        this.dispatchEvent(new Event('error'));
	        this.close();
	      }

	      this.#reconnect();
	    };

	    // 15. Fetch request, with processResponseEndOfBody set to processEventSourceEndOfBody...
	    fetchParams.processResponseEndOfBody = processEventSourceEndOfBody;

	    // and processResponse set to the following steps given response res:
	    fetchParams.processResponse = (response) => {
	      // 1. If res is an aborted network error, then fail the connection.

	      if (isNetworkError(response)) {
	        // 1. When a user agent is to fail the connection, the user agent
	        // must queue a task which, if the readyState attribute is set to a
	        // value other than CLOSED, sets the readyState attribute to CLOSED
	        // and fires an event named error at the EventSource object. Once the
	        // user agent has failed the connection, it does not attempt to
	        // reconnect.
	        if (response.aborted) {
	          this.close();
	          this.dispatchEvent(new Event('error'));
	          return
	          // 2. Otherwise, if res is a network error, then reestablish the
	          // connection, unless the user agent knows that to be futile, in
	          // which case the user agent may fail the connection.
	        } else {
	          this.#reconnect();
	          return
	        }
	      }

	      // 3. Otherwise, if res's status is not 200, or if res's `Content-Type`
	      // is not `text/event-stream`, then fail the connection.
	      const contentType = response.headersList.get('content-type', true);
	      const mimeType = contentType !== null ? parseMIMEType(contentType) : 'failure';
	      const contentTypeValid = mimeType !== 'failure' && mimeType.essence === 'text/event-stream';
	      if (
	        response.status !== 200 ||
	        contentTypeValid === false
	      ) {
	        this.close();
	        this.dispatchEvent(new Event('error'));
	        return
	      }

	      // 4. Otherwise, announce the connection and interpret res's body
	      // line by line.

	      // When a user agent is to announce the connection, the user agent
	      // must queue a task which, if the readyState attribute is set to a
	      // value other than CLOSED, sets the readyState attribute to OPEN
	      // and fires an event named open at the EventSource object.
	      // @see https://html.spec.whatwg.org/multipage/server-sent-events.html#sse-processing-model
	      this.#readyState = OPEN;
	      this.dispatchEvent(new Event('open'));

	      // If redirected to a different origin, set the origin to the new origin.
	      this.#state.origin = response.urlList[response.urlList.length - 1].origin;

	      const eventSourceStream = new EventSourceStream({
	        eventSourceSettings: this.#state,
	        push: (event) => {
	          this.dispatchEvent(createFastMessageEvent(
	            event.type,
	            event.options
	          ));
	        }
	      });

	      pipeline(response.body.stream,
	        eventSourceStream,
	        (error) => {
	          if (
	            error?.aborted === false
	          ) {
	            this.close();
	            this.dispatchEvent(new Event('error'));
	          }
	        });
	    };

	    this.#controller = fetching(fetchParams);
	  }

	  /**
	   * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#sse-processing-model
	   * @returns {Promise<void>}
	   */
	  async #reconnect () {
	    // When a user agent is to reestablish the connection, the user agent must
	    // run the following steps. These steps are run in parallel, not as part of
	    // a task. (The tasks that it queues, of course, are run like normal tasks
	    // and not themselves in parallel.)

	    // 1. Queue a task to run the following steps:

	    //   1. If the readyState attribute is set to CLOSED, abort the task.
	    if (this.#readyState === CLOSED) return

	    //   2. Set the readyState attribute to CONNECTING.
	    this.#readyState = CONNECTING;

	    //   3. Fire an event named error at the EventSource object.
	    this.dispatchEvent(new Event('error'));

	    // 2. Wait a delay equal to the reconnection time of the event source.
	    await delay(this.#state.reconnectionTime);

	    // 5. Queue a task to run the following steps:

	    //   1. If the EventSource object's readyState attribute is not set to
	    //      CONNECTING, then return.
	    if (this.#readyState !== CONNECTING) return

	    //   2. Let request be the EventSource object's request.
	    //   3. If the EventSource object's last event ID string is not the empty
	    //      string, then:
	    //      1. Let lastEventIDValue be the EventSource object's last event ID
	    //         string, encoded as UTF-8.
	    //      2. Set (`Last-Event-ID`, lastEventIDValue) in request's header
	    //         list.
	    if (this.#state.lastEventId.length) {
	      this.#request.headersList.set('last-event-id', this.#state.lastEventId, true);
	    }

	    //   4. Fetch request and process the response obtained in this fashion, if any, as described earlier in this section.
	    this.#connect();
	  }

	  /**
	   * Closes the connection, if any, and sets the readyState attribute to
	   * CLOSED.
	   */
	  close () {
	    webidl.brandCheck(this, EventSource);

	    if (this.#readyState === CLOSED) return
	    this.#readyState = CLOSED;
	    this.#controller.abort();
	    this.#request = null;
	  }

	  get onopen () {
	    return this.#events.open
	  }

	  set onopen (fn) {
	    if (this.#events.open) {
	      this.removeEventListener('open', this.#events.open);
	    }

	    if (typeof fn === 'function') {
	      this.#events.open = fn;
	      this.addEventListener('open', fn);
	    } else {
	      this.#events.open = null;
	    }
	  }

	  get onmessage () {
	    return this.#events.message
	  }

	  set onmessage (fn) {
	    if (this.#events.message) {
	      this.removeEventListener('message', this.#events.message);
	    }

	    if (typeof fn === 'function') {
	      this.#events.message = fn;
	      this.addEventListener('message', fn);
	    } else {
	      this.#events.message = null;
	    }
	  }

	  get onerror () {
	    return this.#events.error
	  }

	  set onerror (fn) {
	    if (this.#events.error) {
	      this.removeEventListener('error', this.#events.error);
	    }

	    if (typeof fn === 'function') {
	      this.#events.error = fn;
	      this.addEventListener('error', fn);
	    } else {
	      this.#events.error = null;
	    }
	  }
	}

	const constantsPropertyDescriptors = {
	  CONNECTING: {
	    __proto__: null,
	    configurable: false,
	    enumerable: true,
	    value: CONNECTING,
	    writable: false
	  },
	  OPEN: {
	    __proto__: null,
	    configurable: false,
	    enumerable: true,
	    value: OPEN,
	    writable: false
	  },
	  CLOSED: {
	    __proto__: null,
	    configurable: false,
	    enumerable: true,
	    value: CLOSED,
	    writable: false
	  }
	};

	Object.defineProperties(EventSource, constantsPropertyDescriptors);
	Object.defineProperties(EventSource.prototype, constantsPropertyDescriptors);

	Object.defineProperties(EventSource.prototype, {
	  close: kEnumerableProperty,
	  onerror: kEnumerableProperty,
	  onmessage: kEnumerableProperty,
	  onopen: kEnumerableProperty,
	  readyState: kEnumerableProperty,
	  url: kEnumerableProperty,
	  withCredentials: kEnumerableProperty
	});

	webidl.converters.EventSourceInitDict = webidl.dictionaryConverter([
	  {
	    key: 'withCredentials',
	    converter: webidl.converters.boolean,
	    defaultValue: () => false
	  },
	  {
	    key: 'dispatcher', // undici only
	    converter: webidl.converters.any
	  }
	]);

	eventsource = {
	  EventSource,
	  defaultReconnectionTime
	};
	return eventsource;
}

var hasRequiredUndici;

function requireUndici () {
	if (hasRequiredUndici) return undici;
	hasRequiredUndici = 1;

	const Client = requireClient();
	const Dispatcher = requireDispatcher();
	const Pool = requirePool();
	const BalancedPool = requireBalancedPool();
	const Agent = requireAgent();
	const ProxyAgent = requireProxyAgent();
	const EnvHttpProxyAgent = requireEnvHttpProxyAgent();
	const RetryAgent = requireRetryAgent();
	const errors = requireErrors();
	const util = requireUtil$7();
	const { InvalidArgumentError } = errors;
	const api = requireApi();
	const buildConnector = requireConnect();
	const MockClient = requireMockClient();
	const MockAgent = requireMockAgent();
	const MockPool = requireMockPool();
	const mockErrors = requireMockErrors();
	const RetryHandler = requireRetryHandler();
	const { getGlobalDispatcher, setGlobalDispatcher } = requireGlobal();
	const DecoratorHandler = requireDecoratorHandler();
	const RedirectHandler = requireRedirectHandler();
	const createRedirectInterceptor = requireRedirectInterceptor();

	Object.assign(Dispatcher.prototype, api);

	undici.Dispatcher = Dispatcher;
	undici.Client = Client;
	undici.Pool = Pool;
	undici.BalancedPool = BalancedPool;
	undici.Agent = Agent;
	undici.ProxyAgent = ProxyAgent;
	undici.EnvHttpProxyAgent = EnvHttpProxyAgent;
	undici.RetryAgent = RetryAgent;
	undici.RetryHandler = RetryHandler;

	undici.DecoratorHandler = DecoratorHandler;
	undici.RedirectHandler = RedirectHandler;
	undici.createRedirectInterceptor = createRedirectInterceptor;
	undici.interceptors = {
	  redirect: requireRedirect(),
	  retry: requireRetry(),
	  dump: requireDump()
	};

	undici.buildConnector = buildConnector;
	undici.errors = errors;
	undici.util = {
	  parseHeaders: util.parseHeaders,
	  headerNameToString: util.headerNameToString
	};

	function makeDispatcher (fn) {
	  return (url, opts, handler) => {
	    if (typeof opts === 'function') {
	      handler = opts;
	      opts = null;
	    }

	    if (!url || (typeof url !== 'string' && typeof url !== 'object' && !(url instanceof URL))) {
	      throw new InvalidArgumentError('invalid url')
	    }

	    if (opts != null && typeof opts !== 'object') {
	      throw new InvalidArgumentError('invalid opts')
	    }

	    if (opts && opts.path != null) {
	      if (typeof opts.path !== 'string') {
	        throw new InvalidArgumentError('invalid opts.path')
	      }

	      let path = opts.path;
	      if (!opts.path.startsWith('/')) {
	        path = `/${path}`;
	      }

	      url = new URL(util.parseOrigin(url).origin + path);
	    } else {
	      if (!opts) {
	        opts = typeof url === 'object' ? url : {};
	      }

	      url = util.parseURL(url);
	    }

	    const { agent, dispatcher = getGlobalDispatcher() } = opts;

	    if (agent) {
	      throw new InvalidArgumentError('unsupported opts.agent. Did you mean opts.client?')
	    }

	    return fn.call(dispatcher, {
	      ...opts,
	      origin: url.origin,
	      path: url.search ? `${url.pathname}${url.search}` : url.pathname,
	      method: opts.method || (opts.body ? 'PUT' : 'GET')
	    }, handler)
	  }
	}

	undici.setGlobalDispatcher = setGlobalDispatcher;
	undici.getGlobalDispatcher = getGlobalDispatcher;

	const fetchImpl = requireFetch().fetch;
	undici.fetch = async function fetch (init, options = undefined) {
	  try {
	    return await fetchImpl(init, options)
	  } catch (err) {
	    if (err && typeof err === 'object') {
	      Error.captureStackTrace(err);
	    }

	    throw err
	  }
	};
	undici.Headers = requireHeaders().Headers;
	undici.Response = requireResponse().Response;
	undici.Request = requireRequest().Request;
	undici.FormData = requireFormdata().FormData;
	undici.File = globalThis.File ?? require$$0$3.File;
	undici.FileReader = requireFilereader().FileReader;

	const { setGlobalOrigin, getGlobalOrigin } = requireGlobal$1();

	undici.setGlobalOrigin = setGlobalOrigin;
	undici.getGlobalOrigin = getGlobalOrigin;

	const { CacheStorage } = requireCachestorage();
	const { kConstruct } = requireSymbols$1();

	// Cache & CacheStorage are tightly coupled with fetch. Even if it may run
	// in an older version of Node, it doesn't have any use without fetch.
	undici.caches = new CacheStorage(kConstruct);

	const { deleteCookie, getCookies, getSetCookies, setCookie } = requireCookies();

	undici.deleteCookie = deleteCookie;
	undici.getCookies = getCookies;
	undici.getSetCookies = getSetCookies;
	undici.setCookie = setCookie;

	const { parseMIMEType, serializeAMimeType } = requireDataUrl();

	undici.parseMIMEType = parseMIMEType;
	undici.serializeAMimeType = serializeAMimeType;

	const { CloseEvent, ErrorEvent, MessageEvent } = requireEvents();
	undici.WebSocket = requireWebsocket().WebSocket;
	undici.CloseEvent = CloseEvent;
	undici.ErrorEvent = ErrorEvent;
	undici.MessageEvent = MessageEvent;

	undici.request = makeDispatcher(api.request);
	undici.stream = makeDispatcher(api.stream);
	undici.pipeline = makeDispatcher(api.pipeline);
	undici.connect = makeDispatcher(api.connect);
	undici.upgrade = makeDispatcher(api.upgrade);

	undici.MockClient = MockClient;
	undici.MockPool = MockPool;
	undici.MockAgent = MockAgent;
	undici.mockErrors = mockErrors;

	const { EventSource } = requireEventsource();

	undici.EventSource = EventSource;
	return undici;
}

var undiciExports = requireUndici();

// For local queue, there is no technical limit on the message visibility lifespan,
// but the environment variable can be used for testing purposes to set a max visibility limit.
const LOCAL_QUEUE_MAX_VISIBILITY = parseInt(process.env.WORKFLOW_LOCAL_QUEUE_MAX_VISIBILITY ?? "0", 10) ||
    Infinity;
// Create a custom agent with unlimited headers timeout for long-running steps
const httpAgent = new undiciExports.Agent({
    headersTimeout: 0,
});
function createQueue$1(port) {
    const transport = new JsonTransport$1();
    const generateId = monotonicFactory();
    /**
     * holds inflight messages by idempotency key to ensure
     * that we don't queue the same message multiple times
     */
    const inflightMessages = new Map();
    const queue = async (queueName, message, opts) => {
        const cleanup = [];
        if (opts?.idempotencyKey) {
            const existing = inflightMessages.get(opts.idempotencyKey);
            if (existing) {
                return { messageId: existing };
            }
        }
        const body = transport.serialize(message);
        let pathname;
        if (queueName.startsWith("__wkf_step_")) {
            pathname = `step`;
        }
        else if (queueName.startsWith("__wkf_workflow_")) {
            pathname = `flow`;
        }
        else {
            throw new Error("Unknown queue name prefix");
        }
        const messageId = MessageId.parse(`msg_${generateId()}`);
        if (opts?.idempotencyKey) {
            const key = opts.idempotencyKey;
            inflightMessages.set(key, messageId);
            cleanup.push(() => {
                inflightMessages.delete(key);
            });
        }
        (async () => {
            let defaultRetriesLeft = 3;
            const portToUse = port ?? (await getPort());
            for (let attempt = 0; defaultRetriesLeft > 0; attempt++) {
                defaultRetriesLeft--;
                const response = await fetch(`http://localhost:${portToUse}/.well-known/workflow/v1/${pathname}`, {
                    method: "POST",
                    duplex: "half",
                    // @ts-expect-error undici type differences
                    dispatcher: httpAgent,
                    headers: {
                        "content-type": "application/json",
                        "x-vqs-queue-name": queueName,
                        "x-vqs-message-id": messageId,
                        "x-vqs-message-attempt": String(attempt + 1),
                    },
                    body,
                });
                if (response.ok) {
                    return;
                }
                const text = await response.text();
                if (response.status === 503) {
                    try {
                        const timeoutSeconds = Number(JSON.parse(text).timeoutSeconds);
                        await setTimeout$1(timeoutSeconds * 1000);
                        defaultRetriesLeft++;
                        continue;
                    }
                    catch { }
                }
                console.error(`[embedded world] Failed to queue message`, {
                    queueName,
                    text,
                    status: response.status,
                    headers: Object.fromEntries(response.headers.entries()),
                    body: body.toString(),
                });
            }
            console.error(`[embedded world] Reached max retries of embedded world queue implementation`);
        })().finally(() => {
            for (const fn of cleanup) {
                fn();
            }
        });
        return { messageId };
    };
    const HeaderParser = z__default.object({
        "x-vqs-queue-name": ValidQueueName,
        "x-vqs-message-id": MessageId,
        "x-vqs-message-attempt": z__default.coerce.number(),
    });
    const createQueueHandler = (prefix, handler) => {
        return async (req) => {
            const headers = HeaderParser.safeParse(Object.fromEntries(req.headers));
            if (!headers.success || !req.body) {
                console.log(!headers.success);
                console.log(!req.body);
                return Response.json({
                    error: !req.body
                        ? "Missing request body"
                        : "Missing required headers",
                }, { status: 400 });
            }
            const queueName = headers.data["x-vqs-queue-name"];
            const messageId = headers.data["x-vqs-message-id"];
            const attempt = headers.data["x-vqs-message-attempt"];
            if (!queueName.startsWith(prefix)) {
                return Response.json({ error: "Unhandled queue" }, { status: 400 });
            }
            const body = await new JsonTransport$1().deserialize(req.body);
            try {
                const result = await handler(body, { attempt, queueName, messageId });
                let timeoutSeconds = null;
                if (typeof result?.timeoutSeconds === "number") {
                    timeoutSeconds = Math.min(result.timeoutSeconds, LOCAL_QUEUE_MAX_VISIBILITY);
                }
                if (timeoutSeconds) {
                    return Response.json({ timeoutSeconds }, { status: 503 });
                }
                return Response.json({ ok: true });
            }
            catch (error) {
                return Response.json(String(error), { status: 500 });
            }
        };
    };
    const getDeploymentId = async () => {
        return "dpl_embedded";
    };
    return { queue, createQueueHandler, getDeploymentId };
}

const ulid = monotonicFactory(() => Math.random());
const Ulid = z$1.string().ulid();
function ulidToDate(maybeUlid) {
    const ulid = Ulid.safeParse(maybeUlid);
    if (!ulid.success) {
        return null;
    }
    return new Date(decodeTime(ulid.data));
}
async function ensureDir(dirPath) {
    try {
        await promises.mkdir(dirPath, { recursive: true });
    }
    catch (_error) {
        // Ignore if already exists
    }
}
async function writeJSON(filePath, data, opts) {
    return write(filePath, JSON.stringify(data, null, 2), opts);
}
async function write(filePath, data, opts) {
    if (!opts?.overwrite) {
        try {
            await promises.access(filePath);
            throw new WorkflowAPIError(`File ${filePath} already exists and 'overwrite' is false`, { status: 409 });
        }
        catch (error) {
            // If file doesn't exist (ENOENT), continue with write
            if (error.code !== 'ENOENT') {
                throw error;
            }
        }
    }
    const tempPath = `${filePath}.tmp.${ulid()}`;
    try {
        await ensureDir(path.dirname(filePath));
        await promises.writeFile(tempPath, data);
        await promises.rename(tempPath, filePath);
    }
    catch (error) {
        await promises.unlink(tempPath).catch(() => { });
        throw error;
    }
}
async function readJSON(filePath, decoder) {
    try {
        const content = await promises.readFile(filePath, 'utf-8');
        return decoder.parse(JSON.parse(content));
    }
    catch (error) {
        if (error.code === 'ENOENT')
            return null;
        throw error;
    }
}
async function readBuffer(filePath) {
    const content = await promises.readFile(filePath);
    return content;
}
async function deleteJSON(filePath) {
    try {
        await promises.unlink(filePath);
    }
    catch (error) {
        if (error.code !== 'ENOENT')
            throw error;
    }
}
async function listJSONFiles(dirPath) {
    try {
        const files = await promises.readdir(dirPath);
        return files
            .filter((f) => f.endsWith('.json'))
            .map((f) => f.replace('.json', ''));
    }
    catch (error) {
        if (error.code === 'ENOENT')
            return [];
        throw error;
    }
}
function parseCursor(cursor) {
    if (!cursor)
        return null;
    const parts = cursor.split('|');
    return {
        timestamp: new Date(parts[0]),
        id: parts[1] || null,
    };
}
function createCursor(timestamp, id) {
    return id ? `${timestamp.toISOString()}|${id}` : timestamp.toISOString();
}
async function paginatedFileSystemQuery(config) {
    const { directory, schema, filePrefix, filter, sortOrder = 'desc', limit = 20, cursor, getCreatedAt, getId, } = config;
    // 1. Get all JSON files in directory
    const fileIds = await listJSONFiles(directory);
    // 2. Filter by prefix if provided
    const relevantFileIds = filePrefix
        ? fileIds.filter((fileId) => fileId.startsWith(filePrefix))
        : fileIds;
    // 3. ULID Optimization: Filter by cursor using filename timestamps before loading JSON
    const parsedCursor = parseCursor(cursor);
    let candidateFileIds = relevantFileIds;
    if (parsedCursor) {
        candidateFileIds = relevantFileIds.filter((fileId) => {
            const filenameDate = getCreatedAt(`${fileId}.json`);
            if (filenameDate) {
                // Use filename timestamp for cursor filtering
                // We need to be careful here: if parsedCursor has an ID (for tie-breaking),
                // we need to include items with the same timestamp for later ID-based filtering.
                // If no ID, we can use strict inequality for optimization.
                const cursorTime = parsedCursor.timestamp.getTime();
                const fileTime = filenameDate.getTime();
                if (parsedCursor.id) {
                    // Tie-breaking mode: include items at or near cursor timestamp
                    return sortOrder === 'desc'
                        ? fileTime <= cursorTime
                        : fileTime >= cursorTime;
                }
                else {
                    // No tie-breaking: strict inequality
                    return sortOrder === 'desc'
                        ? fileTime < cursorTime
                        : fileTime > cursorTime;
                }
            }
            // Skip files where we can't extract timestamp - no optimization benefit
            return false;
        });
    }
    else {
        // Even without cursor, skip files where getCreatedAt returns null for consistency
        candidateFileIds = relevantFileIds.filter((fileId) => {
            return getCreatedAt(`${fileId}.json`) !== null;
        });
    }
    // 4. Load files individually and collect valid items
    const validItems = [];
    for (const fileId of candidateFileIds) {
        const filePath = path.join(directory, `${fileId}.json`);
        const item = await readJSON(filePath, schema);
        if (item) {
            // Apply custom filter early if provided
            if (filter && !filter(item))
                continue;
            // Double-check cursor filtering with actual createdAt from JSON
            // (in case ULID timestamp differs from stored createdAt)
            if (parsedCursor) {
                const itemTime = item.createdAt.getTime();
                const cursorTime = parsedCursor.timestamp.getTime();
                if (sortOrder === 'desc') {
                    // For descending order, skip items >= cursor
                    if (itemTime > cursorTime)
                        continue;
                    // If timestamps are equal, use ID for tie-breaking (skip if ID >= cursorId)
                    if (itemTime === cursorTime && parsedCursor.id && getId) {
                        const itemId = getId(item);
                        if (itemId >= parsedCursor.id)
                            continue;
                    }
                }
                else {
                    // For ascending order, skip items <= cursor
                    if (itemTime < cursorTime)
                        continue;
                    // If timestamps are equal, use ID for tie-breaking (skip if ID <= cursorId)
                    if (itemTime === cursorTime && parsedCursor.id && getId) {
                        const itemId = getId(item);
                        if (itemId <= parsedCursor.id)
                            continue;
                    }
                }
            }
            validItems.push(item);
        }
    }
    // 5. Sort by createdAt (and by ID for tie-breaking if getId is provided)
    validItems.sort((a, b) => {
        const aTime = a.createdAt.getTime();
        const bTime = b.createdAt.getTime();
        const timeComparison = sortOrder === 'asc' ? aTime - bTime : bTime - aTime;
        // If timestamps are equal and we have getId, use ID for stable sorting
        if (timeComparison === 0 && getId) {
            const aId = getId(a);
            const bId = getId(b);
            return sortOrder === 'asc'
                ? aId.localeCompare(bId)
                : bId.localeCompare(aId);
        }
        return timeComparison;
    });
    // 6. Apply pagination
    const hasMore = validItems.length > limit;
    const items = hasMore ? validItems.slice(0, limit) : validItems;
    const nextCursor = items.length > 0
        ? createCursor(items[items.length - 1].createdAt, getId?.(items[items.length - 1]))
        : null;
    return {
        data: items,
        cursor: nextCursor,
        hasMore,
    };
}

// Create a monotonic ULID factory that ensures ULIDs are always increasing
// even when generated within the same millisecond
const monotonicUlid$1 = monotonicFactory(() => Math.random());
// Helper functions to filter data based on resolveData setting
function filterRunData$1(run, resolveData) {
    if (resolveData === 'none') {
        return {
            ...run,
            input: [],
            output: undefined,
        };
    }
    return run;
}
function filterStepData$1(step, resolveData) {
    if (resolveData === 'none') {
        return {
            ...step,
            input: [],
            output: undefined,
        };
    }
    return step;
}
function filterEventData$1(event, resolveData) {
    if (resolveData === 'none') {
        const { eventData: _eventData, ...rest } = event;
        return rest;
    }
    return event;
}
function filterHookData$1(hook, resolveData) {
    if (resolveData === 'none') {
        const { metadata: _metadata, ...rest } = hook;
        return rest;
    }
    return hook;
}
const getObjectCreatedAt = (idPrefix) => (filename) => {
    const replaceRegex = new RegExp(`^${idPrefix}_`, 'g');
    const dashIndex = filename.indexOf('-');
    if (dashIndex === -1) {
        // No dash - extract ULID from the filename (e.g., wrun_ULID.json, evnt_ULID.json)
        const ulid = filename.replace(/\.json$/, '').replace(replaceRegex, '');
        return ulidToDate(ulid);
    }
    // For composite keys like {runId}-{stepId}, extract from the appropriate part
    if (idPrefix === 'step') {
        // For steps: wrun_ULID-step_123.json - extract from the runId part
        const runId = filename.substring(0, dashIndex);
        const ulid = runId.replace(/^wrun_/, '');
        return ulidToDate(ulid);
    }
    // For events: wrun_ULID-evnt_ULID.json - extract from the eventId part
    const id = filename.substring(dashIndex + 1).replace(/\.json$/, '');
    const ulid = id.replace(replaceRegex, '');
    return ulidToDate(ulid);
};
/**
 * Creates a hooks storage implementation using the filesystem.
 * Implements the Storage['hooks'] interface with hook CRUD operations.
 */
function createHooksStorage(basedir) {
    // Helper function to find a hook by token (shared between create and getByToken)
    async function findHookByToken(token) {
        const hooksDir = path.join(basedir, 'hooks');
        const files = await listJSONFiles(hooksDir);
        for (const file of files) {
            const hookPath = path.join(hooksDir, `${file}.json`);
            const hook = await readJSON(hookPath, HookSchema);
            if (hook && hook.token === token) {
                return hook;
            }
        }
        return null;
    }
    async function create(runId, data) {
        // Check if a hook with the same token already exists
        // Token uniqueness is enforced globally per embedded environment
        const existingHook = await findHookByToken(data.token);
        if (existingHook) {
            throw new Error(`Hook with token ${data.token} already exists for this project`);
        }
        const now = new Date();
        const result = {
            runId,
            hookId: data.hookId,
            token: data.token,
            metadata: data.metadata,
            ownerId: 'embedded-owner',
            projectId: 'embedded-project',
            environment: 'embedded',
            createdAt: now,
        };
        const hookPath = path.join(basedir, 'hooks', `${data.hookId}.json`);
        await writeJSON(hookPath, result);
        return result;
    }
    async function get(hookId, params) {
        const hookPath = path.join(basedir, 'hooks', `${hookId}.json`);
        const hook = await readJSON(hookPath, HookSchema);
        if (!hook) {
            throw new Error(`Hook ${hookId} not found`);
        }
        const resolveData = params?.resolveData || DEFAULT_RESOLVE_DATA_OPTION$1;
        return filterHookData$1(hook, resolveData);
    }
    async function getByToken(token) {
        const hook = await findHookByToken(token);
        if (!hook) {
            throw new Error(`Hook with token ${token} not found`);
        }
        return hook;
    }
    async function list(params) {
        const hooksDir = path.join(basedir, 'hooks');
        const resolveData = params.resolveData || DEFAULT_RESOLVE_DATA_OPTION$1;
        const result = await paginatedFileSystemQuery({
            directory: hooksDir,
            schema: HookSchema,
            sortOrder: params.pagination?.sortOrder,
            limit: params.pagination?.limit,
            cursor: params.pagination?.cursor,
            filePrefix: undefined, // Hooks don't have ULIDs, so we can't optimize by filename
            filter: (hook) => {
                // Filter by runId if provided
                if (params.runId && hook.runId !== params.runId) {
                    return false;
                }
                return true;
            },
            getCreatedAt: () => {
                // Hook files don't have ULID timestamps in filename
                // We need to read the file to get createdAt, but that's inefficient
                // So we return the hook's createdAt directly (item.createdAt will be used for sorting)
                // Return a dummy date to pass the null check, actual sorting uses item.createdAt
                return new Date(0);
            },
            getId: (hook) => hook.hookId,
        });
        // Transform the data after pagination
        return {
            ...result,
            data: result.data.map((hook) => filterHookData$1(hook, resolveData)),
        };
    }
    async function dispose(hookId) {
        const hookPath = path.join(basedir, 'hooks', `${hookId}.json`);
        const hook = await readJSON(hookPath, HookSchema);
        if (!hook) {
            throw new Error(`Hook ${hookId} not found`);
        }
        await deleteJSON(hookPath);
        return hook;
    }
    return { create, get, getByToken, list, dispose };
}
/**
 * Helper function to delete all hooks associated with a workflow run
 */
async function deleteAllHooksForRun(basedir, runId) {
    const hooksDir = path.join(basedir, 'hooks');
    const files = await listJSONFiles(hooksDir);
    for (const file of files) {
        const hookPath = path.join(hooksDir, `${file}.json`);
        const hook = await readJSON(hookPath, HookSchema);
        if (hook && hook.runId === runId) {
            await deleteJSON(hookPath);
        }
    }
}
function createStorage$1(basedir) {
    return {
        runs: {
            async create(data) {
                const runId = `wrun_${monotonicUlid$1()}`;
                const now = new Date();
                const result = {
                    runId,
                    deploymentId: data.deploymentId,
                    status: 'pending',
                    workflowName: data.workflowName,
                    executionContext: data.executionContext,
                    input: data.input || [],
                    output: undefined,
                    error: undefined,
                    startedAt: undefined,
                    completedAt: undefined,
                    createdAt: now,
                    updatedAt: now,
                };
                const runPath = path.join(basedir, 'runs', `${runId}.json`);
                await writeJSON(runPath, result);
                return result;
            },
            async get(id, params) {
                const runPath = path.join(basedir, 'runs', `${id}.json`);
                const run = await readJSON(runPath, WorkflowRunSchema);
                if (!run) {
                    throw new WorkflowRunNotFoundError(id);
                }
                const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                return filterRunData$1(run, resolveData);
            },
            async update(id, data) {
                const runPath = path.join(basedir, 'runs', `${id}.json`);
                const run = await readJSON(runPath, WorkflowRunSchema);
                if (!run) {
                    throw new WorkflowRunNotFoundError(id);
                }
                const now = new Date();
                const updatedRun = {
                    ...run,
                    ...data,
                    updatedAt: now,
                };
                // Only set startedAt the first time the run transitions to 'running'
                if (data.status === 'running' && !updatedRun.startedAt) {
                    updatedRun.startedAt = now;
                }
                const isBecomingTerminal = data.status === 'completed' ||
                    data.status === 'failed' ||
                    data.status === 'cancelled';
                if (isBecomingTerminal) {
                    updatedRun.completedAt = now;
                }
                await writeJSON(runPath, updatedRun, { overwrite: true });
                // If transitioning to a terminal status, clean up all hooks for this run
                if (isBecomingTerminal) {
                    await deleteAllHooksForRun(basedir, id);
                }
                return updatedRun;
            },
            async list(params) {
                const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                const result = await paginatedFileSystemQuery({
                    directory: path.join(basedir, 'runs'),
                    schema: WorkflowRunSchema,
                    filter: (run) => {
                        if (params?.workflowName &&
                            run.workflowName !== params.workflowName) {
                            return false;
                        }
                        if (params?.status && run.status !== params.status) {
                            return false;
                        }
                        return true;
                    },
                    sortOrder: params?.pagination?.sortOrder ?? 'desc',
                    limit: params?.pagination?.limit,
                    cursor: params?.pagination?.cursor,
                    getCreatedAt: getObjectCreatedAt('wrun'),
                    getId: (run) => run.runId,
                });
                // If resolveData is "none", replace input/output with empty data
                if (resolveData === 'none') {
                    return {
                        ...result,
                        data: result.data.map((run) => ({
                            ...run,
                            input: [],
                            output: undefined,
                        })),
                    };
                }
                return result;
            },
            async cancel(id, params) {
                // This will call update which triggers hook cleanup automatically
                const run = await this.update(id, { status: 'cancelled' });
                const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                return filterRunData$1(run, resolveData);
            },
            async pause(id, params) {
                const run = await this.update(id, { status: 'paused' });
                const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                return filterRunData$1(run, resolveData);
            },
            async resume(id, params) {
                const run = await this.update(id, { status: 'running' });
                const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                return filterRunData$1(run, resolveData);
            },
        },
        steps: {
            async create(runId, data) {
                const now = new Date();
                const result = {
                    runId,
                    stepId: data.stepId,
                    stepName: data.stepName,
                    status: 'pending',
                    input: data.input,
                    output: undefined,
                    error: undefined,
                    attempt: 0,
                    startedAt: undefined,
                    completedAt: undefined,
                    createdAt: now,
                    updatedAt: now,
                };
                const compositeKey = `${runId}-${data.stepId}`;
                const stepPath = path.join(basedir, 'steps', `${compositeKey}.json`);
                await writeJSON(stepPath, result);
                return result;
            },
            async get(runId, stepId, params) {
                if (!runId) {
                    const fileIds = await listJSONFiles(path.join(basedir, 'steps'));
                    const fileId = fileIds.find((fileId) => fileId.endsWith(`-${stepId}`));
                    if (!fileId) {
                        throw new Error(`Step ${stepId} not found`);
                    }
                    runId = fileId.split('-')[0];
                }
                const compositeKey = `${runId}-${stepId}`;
                const stepPath = path.join(basedir, 'steps', `${compositeKey}.json`);
                const step = await readJSON(stepPath, StepSchema);
                if (!step) {
                    throw new Error(`Step ${stepId} in run ${runId} not found`);
                }
                const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                return filterStepData$1(step, resolveData);
            },
            async update(runId, stepId, data) {
                const compositeKey = `${runId}-${stepId}`;
                const stepPath = path.join(basedir, 'steps', `${compositeKey}.json`);
                const step = await readJSON(stepPath, StepSchema);
                if (!step) {
                    throw new Error(`Step ${stepId} in run ${runId} not found`);
                }
                const now = new Date();
                const updatedStep = {
                    ...step,
                    ...data,
                    updatedAt: now,
                };
                // Only set startedAt the first time the step transitions to 'running'
                if (data.status === 'running' && !updatedStep.startedAt) {
                    updatedStep.startedAt = now;
                }
                if (data.status === 'completed' || data.status === 'failed') {
                    updatedStep.completedAt = now;
                }
                await writeJSON(stepPath, updatedStep, { overwrite: true });
                return updatedStep;
            },
            async list(params) {
                const resolveData = params.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                const result = await paginatedFileSystemQuery({
                    directory: path.join(basedir, 'steps'),
                    schema: StepSchema,
                    filePrefix: `${params.runId}-`,
                    sortOrder: params.pagination?.sortOrder ?? 'desc',
                    limit: params.pagination?.limit,
                    cursor: params.pagination?.cursor,
                    getCreatedAt: getObjectCreatedAt('step'),
                    getId: (step) => step.stepId,
                });
                // If resolveData is "none", replace input/output with empty data
                if (resolveData === 'none') {
                    return {
                        ...result,
                        data: result.data.map((step) => ({
                            ...step,
                            input: [],
                            output: undefined,
                        })),
                    };
                }
                return result;
            },
        },
        // Events - filesystem-backed storage
        events: {
            async create(runId, data, params) {
                const eventId = `evnt_${monotonicUlid$1()}`;
                const now = new Date();
                const result = {
                    ...data,
                    runId,
                    eventId,
                    createdAt: now,
                };
                // Store event using composite key {runId}-{eventId}
                const compositeKey = `${runId}-${eventId}`;
                const eventPath = path.join(basedir, 'events', `${compositeKey}.json`);
                await writeJSON(eventPath, result);
                const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                return filterEventData$1(result, resolveData);
            },
            async list(params) {
                const { runId } = params;
                const resolveData = params.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                const result = await paginatedFileSystemQuery({
                    directory: path.join(basedir, 'events'),
                    schema: EventSchema,
                    filePrefix: `${runId}-`,
                    // Events in chronological order (oldest first) by default,
                    // different from the default for other list calls.
                    sortOrder: params.pagination?.sortOrder ?? 'asc',
                    limit: params.pagination?.limit,
                    cursor: params.pagination?.cursor,
                    getCreatedAt: getObjectCreatedAt('evnt'),
                    getId: (event) => event.eventId,
                });
                // If resolveData is "none", remove eventData from events
                if (resolveData === 'none') {
                    return {
                        ...result,
                        data: result.data.map((event) => {
                            const { eventData: _eventData, ...rest } = event;
                            return rest;
                        }),
                    };
                }
                return result;
            },
            async listByCorrelationId(params) {
                const correlationId = params.correlationId;
                const resolveData = params.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION$1;
                const result = await paginatedFileSystemQuery({
                    directory: path.join(basedir, 'events'),
                    schema: EventSchema,
                    // No filePrefix - search all events
                    filter: (event) => event.correlationId === correlationId,
                    // Events in chronological order (oldest first) by default,
                    // different from the default for other list calls.
                    sortOrder: params.pagination?.sortOrder ?? 'asc',
                    limit: params.pagination?.limit,
                    cursor: params.pagination?.cursor,
                    getCreatedAt: getObjectCreatedAt('evnt'),
                    getId: (event) => event.eventId,
                });
                // If resolveData is "none", remove eventData from events
                if (resolveData === 'none') {
                    return {
                        ...result,
                        data: result.data.map((event) => {
                            const { eventData: _eventData, ...rest } = event;
                            return rest;
                        }),
                    };
                }
                return result;
            },
        },
        // Hooks
        hooks: createHooksStorage(basedir),
    };
}

// Create a monotonic ULID factory that ensures ULIDs are always increasing
// even when generated within the same millisecond
const monotonicUlid = monotonicFactory(() => Math.random());
function serializeChunk(chunk) {
    const eofByte = Buffer.from([chunk.eof ? 1 : 0]);
    return Buffer.concat([eofByte, chunk.chunk]);
}
function deserializeChunk(serialized) {
    const eof = serialized[0] === 1;
    const chunk = serialized.subarray(1);
    return { eof, chunk };
}
function createStreamer$1(basedir) {
    const streamEmitter = new EventEmitter();
    return {
        async writeToStream(name, chunk) {
            const chunkId = `strm_${monotonicUlid()}`;
            if (typeof chunk === 'string') {
                chunk = new TextEncoder().encode(chunk);
            }
            const serialized = serializeChunk({
                chunk: Buffer.from(chunk),
                eof: false,
            });
            const chunkPath = path.join(basedir, 'streams', 'chunks', `${name}-${chunkId}.json`);
            await write(chunkPath, serialized);
            // Emit real-time event
            const chunkData = typeof chunk === 'string'
                ? new TextEncoder().encode(chunk)
                : chunk instanceof Buffer
                    ? new Uint8Array(chunk)
                    : chunk;
            streamEmitter.emit(`chunk:${name}`, {
                streamName: name,
                chunkData,
                chunkId,
            });
        },
        async closeStream(name) {
            const chunkId = `strm_${monotonicUlid()}`;
            const chunkPath = path.join(basedir, 'streams', 'chunks', `${name}-${chunkId}.json`);
            await write(chunkPath, serializeChunk({ chunk: Buffer.from([]), eof: true }));
            streamEmitter.emit(`close:${name}`, { streamName: name });
        },
        async readFromStream(name, startIndex = 0) {
            const chunksDir = path.join(basedir, 'streams', 'chunks');
            let removeListeners = () => { };
            return new ReadableStream({
                async start(controller) {
                    // Track chunks delivered via events to prevent duplicates and maintain order.
                    const deliveredChunkIds = new Set();
                    // Buffer for chunks that arrive via events during disk reading
                    const bufferedEventChunks = [];
                    let isReadingFromDisk = true;
                    const chunkListener = (event) => {
                        deliveredChunkIds.add(event.chunkId);
                        if (isReadingFromDisk) {
                            // Buffer chunks that arrive during disk reading to maintain order
                            bufferedEventChunks.push({
                                chunkId: event.chunkId,
                                chunkData: event.chunkData,
                            });
                        }
                        else {
                            // After disk reading is complete, deliver chunks immediately
                            controller.enqueue(event.chunkData);
                        }
                    };
                    const closeListener = () => {
                        // Remove listeners before closing
                        streamEmitter.off(`chunk:${name}`, chunkListener);
                        streamEmitter.off(`close:${name}`, closeListener);
                        controller.close();
                    };
                    removeListeners = closeListener;
                    // Set up listeners FIRST to avoid missing events
                    streamEmitter.on(`chunk:${name}`, chunkListener);
                    streamEmitter.on(`close:${name}`, closeListener);
                    // Now load existing chunks from disk
                    const files = await listJSONFiles(chunksDir);
                    const chunkFiles = files
                        .filter((file) => file.startsWith(`${name}-`))
                        .sort(); // ULID lexicographic sort = chronological order
                    // Process existing chunks, skipping any already delivered via events
                    let isComplete = false;
                    for (let i = startIndex; i < chunkFiles.length; i++) {
                        const file = chunkFiles[i];
                        // Extract chunk ID from filename: "streamName-chunkId"
                        const chunkId = file.substring(name.length + 1);
                        // Skip if already delivered via event
                        if (deliveredChunkIds.has(chunkId)) {
                            continue;
                        }
                        const chunk = deserializeChunk(await readBuffer(path.join(chunksDir, `${file}.json`)));
                        if (chunk?.eof === true) {
                            isComplete = true;
                            break;
                        }
                        if (chunk.chunk.byteLength) {
                            controller.enqueue(chunk.chunk);
                        }
                    }
                    // Finished reading from disk - now deliver buffered event chunks in chronological order
                    isReadingFromDisk = false;
                    // Sort buffered chunks by ULID (chronological order)
                    bufferedEventChunks.sort((a, b) => a.chunkId.localeCompare(b.chunkId));
                    for (const buffered of bufferedEventChunks) {
                        controller.enqueue(buffered.chunkData);
                    }
                    if (isComplete) {
                        removeListeners();
                        controller.close();
                        return;
                    }
                },
                cancel() {
                    removeListeners();
                },
            });
        },
    };
}

/**
 * Creates an embedded world instance that combines queue, storage, and streamer functionalities.
 *
 * @param dataDir - The directory to use for storage. If not provided, the default data dir will be used.
 * @param port - The port to use for the queue. If not provided, the default port will be used.
 */
function createEmbeddedWorld({ dataDir, port, }) {
    const dir = dataDir ?? config.value.dataDir;
    const queuePort = port ?? config.value.port;
    return {
        ...createQueue$1(queuePort),
        ...createStorage$1(dir),
        ...createStreamer$1(dir),
    };
}

// src/parser.ts
var MultipartParseError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "MultipartParseError";
  }
};
function createSearch(pattern) {
  const needle = new TextEncoder().encode(pattern);
  return (haystack, start = 0) => Buffer.prototype.indexOf.call(haystack, needle, start);
}
function createPartialTailSearch(pattern) {
  const needle = new TextEncoder().encode(pattern);
  const byteIndexes = {};
  for (let i = 0; i < needle.length; ++i) {
    const byte = needle[i];
    if (byteIndexes[byte] === void 0) byteIndexes[byte] = [];
    byteIndexes[byte].push(i);
  }
  return function(haystack) {
    const haystackEnd = haystack.length - 1;
    if (haystack[haystackEnd] in byteIndexes) {
      const indexes = byteIndexes[haystack[haystackEnd]];
      for (let i = indexes.length - 1; i >= 0; --i) {
        for (let j = indexes[i], k = haystackEnd; j >= 0 && haystack[k] === needle[j]; --j, --k) {
          if (j === 0) return k;
        }
      }
    }
    return -1;
  };
}
function parseHeaders(headerBytes) {
  const headerText = new TextDecoder("iso-8859-1").decode(headerBytes);
  const lines = headerText.trim().split(/\r?\n/);
  const headerInit = [];
  for (const line of lines) {
    const colonIndex = line.indexOf(":");
    if (colonIndex > 0) {
      const name = line.slice(0, colonIndex).trim();
      const value = line.slice(colonIndex + 1).trim();
      headerInit.push([name, value]);
    }
  }
  return new Headers(headerInit);
}
function extractBoundary(contentType) {
  const boundaryMatch = contentType.match(/boundary=(?:"([^"]+)"|([^;]+))/i);
  if (!boundaryMatch) {
    throw new MultipartParseError("No boundary found in Content-Type header");
  }
  return boundaryMatch[1] ?? boundaryMatch[2];
}
var AsyncMessageQueue = class {
  queue = [];
  waiters = [];
  finished = false;
  cancelled = false;
  error = null;
  /**
   * Producer: Enqueue a message for consumption
   */
  enqueue(message) {
    if (this.finished || this.cancelled) return;
    if (this.waiters.length > 0) {
      const waiter = this.waiters.shift();
      waiter.resolve(message);
    } else {
      this.queue.push(message);
    }
  }
  /**
   * Producer: Signal completion (with optional error)
   */
  finish(error) {
    if (this.finished) return;
    this.finished = true;
    this.error = error || null;
    while (this.waiters.length > 0) {
      const waiter = this.waiters.shift();
      if (error) {
        waiter.reject(error);
      } else {
        waiter.resolve(null);
      }
    }
  }
  /**
   * Consumer: Cancel the queue (stops accepting new messages and notifies waiters)
   */
  cancel() {
    if (this.cancelled || this.finished) return;
    this.cancelled = true;
    while (this.waiters.length > 0) {
      const waiter = this.waiters.shift();
      waiter.resolve(null);
    }
  }
  /**
   * Consumer: Dequeue next message (or null if finished/cancelled)
   */
  async dequeue() {
    if (this.queue.length > 0) {
      return this.queue.shift();
    }
    if (this.finished || this.cancelled) {
      if (this.error) throw this.error;
      return null;
    }
    return new Promise((resolve, reject) => {
      this.waiters.push({ resolve, reject });
    });
  }
  /**
   * Check if the queue is in a terminal state
   */
  get isTerminal() {
    return this.finished || this.cancelled;
  }
};
async function* parseMultipartStream(response, options) {
  if (!response.body) {
    throw new MultipartParseError("Response body is null");
  }
  const contentType = response.headers.get("content-type");
  if (!contentType) {
    throw new MultipartParseError("Missing Content-Type header");
  }
  const boundary = extractBoundary(contentType);
  const parser = new StreamingMultipartParser(boundary, options);
  yield* parser.parseStream(response.body);
}
var StreamingMultipartParser = class {
  boundary;
  findOpeningBoundary;
  openingBoundaryLength;
  findBoundary;
  findPartialTailBoundary;
  boundaryLength;
  findDoubleNewline;
  // Safety limits
  maxHeaderSize;
  maxBoundaryBuffer;
  state = 0 /* Start */;
  buffer = null;
  currentHeaders = new Headers();
  currentPayloadController = null;
  constructor(boundary, options = {}) {
    this.boundary = boundary;
    this.findOpeningBoundary = createSearch(`--${boundary}`);
    this.openingBoundaryLength = 2 + boundary.length;
    this.findBoundary = createSearch(`\r
--${boundary}`);
    this.findPartialTailBoundary = createPartialTailSearch(`\r
--${boundary}`);
    this.boundaryLength = 4 + boundary.length;
    this.findDoubleNewline = createSearch("\r\n\r\n");
    this.maxHeaderSize = options.maxHeaderSize ?? 65536;
    this.maxBoundaryBuffer = options.maxBoundaryBuffer ?? 8192;
  }
  async *parseStream(stream) {
    const reader = stream.getReader();
    const messageQueue = new AsyncMessageQueue();
    const producer = this.startProducer(reader, messageQueue);
    try {
      yield* this.consumeMessages(messageQueue);
    } finally {
      messageQueue.cancel();
      this.closeCurrentPayload();
      try {
        await reader.cancel();
      } catch (error) {
      }
      await producer;
    }
  }
  /**
   * Producer: Continuously read chunks and parse messages
   */
  async startProducer(reader, messageQueue) {
    try {
      while (!messageQueue.isTerminal) {
        let result;
        try {
          result = await reader.read();
        } catch (readError) {
          if (readError instanceof Error && (readError.name === "AbortError" || readError.constructor.name === "AbortError" || readError.name === "TimeoutError" || readError.constructor.name === "TimeoutError")) {
            break;
          }
          throw readError;
        }
        const { done, value } = result;
        if (done) {
          if (this.buffer !== null && this.buffer.length > 0) {
            const messages2 = this.write(new Uint8Array(0));
            for (const message of messages2) {
              if (messageQueue.isTerminal) break;
              messageQueue.enqueue(message);
            }
          }
          if (this.state !== 4 /* Done */) {
            if (this.state === 0 /* Start */) {
              throw new MultipartParseError(
                "Invalid multipart stream: missing initial boundary"
              );
            }
            throw new MultipartParseError("Unexpected end of stream");
          }
          break;
        }
        if (!(value instanceof Uint8Array)) {
          throw new MultipartParseError(
            `Invalid chunk type: expected Uint8Array, got ${typeof value}`
          );
        }
        const messages = this.write(value);
        for (const message of messages) {
          if (messageQueue.isTerminal) break;
          messageQueue.enqueue(message);
        }
      }
      if (!messageQueue.isTerminal) {
        messageQueue.finish();
      }
    } catch (error) {
      this.closeCurrentPayload(error);
      if (!messageQueue.isTerminal) {
        messageQueue.finish(error);
      }
    } finally {
      try {
        reader.releaseLock();
      } catch (error) {
      }
    }
  }
  /**
   * Consumer: Yield messages from the queue
   */
  async *consumeMessages(messageQueue) {
    while (true) {
      const message = await messageQueue.dequeue();
      if (message === null) {
        break;
      }
      yield message;
    }
  }
  /**
   * Process a chunk of data through the state machine and return any complete messages.
   *
   * Returns an array because a single chunk can contain multiple complete messages
   * when small messages with headers + body + boundary all fit in one network chunk.
   * All messages must be captured and queued to maintain proper message ordering.
   */
  write(chunk) {
    const newMessages = [];
    if (this.state === 4 /* Done */) {
      throw new MultipartParseError("Unexpected data after end of stream");
    }
    let index = 0;
    let chunkLength = chunk.length;
    if (this.buffer !== null) {
      const newSize = this.buffer.length + chunkLength;
      const maxAllowedSize = this.state === 2 /* Header */ ? this.maxHeaderSize : this.maxBoundaryBuffer;
      if (newSize > maxAllowedSize) {
        throw new MultipartParseError(
          `Buffer size limit exceeded: ${newSize} bytes > ${maxAllowedSize} bytes. This may indicate malformed multipart data with ${this.state === 2 /* Header */ ? "oversized headers" : "invalid boundaries"}.`
        );
      }
      const newChunk = new Uint8Array(newSize);
      newChunk.set(this.buffer, 0);
      newChunk.set(chunk, this.buffer.length);
      chunk = newChunk;
      chunkLength = chunk.length;
      this.buffer = null;
    }
    if (chunkLength === 0 && this.state === 0 /* Start */) {
      throw new MultipartParseError(
        "Invalid multipart stream: missing initial boundary"
      );
    }
    while (true) {
      if (this.state === 3 /* Body */) {
        if (chunkLength - index < this.boundaryLength) {
          const remainingData = chunk.subarray(index);
          if (remainingData.length > this.maxBoundaryBuffer) {
            throw new MultipartParseError(
              `Boundary buffer limit exceeded: ${remainingData.length} > ${this.maxBoundaryBuffer}`
            );
          }
          this.buffer = remainingData;
          break;
        }
        const boundaryIndex = this.findBoundary(chunk, index);
        if (boundaryIndex === -1) {
          const partialTailIndex = this.findPartialTailBoundary(chunk);
          if (partialTailIndex === -1) {
            this.writeBody(index === 0 ? chunk : chunk.subarray(index));
          } else {
            this.writeBody(chunk.subarray(index, partialTailIndex));
            const partialBoundary = chunk.subarray(partialTailIndex);
            if (partialBoundary.length > this.maxBoundaryBuffer) {
              throw new MultipartParseError(
                `Partial boundary too large: ${partialBoundary.length} > ${this.maxBoundaryBuffer}`
              );
            }
            this.buffer = partialBoundary;
          }
          break;
        }
        this.writeBody(chunk.subarray(index, boundaryIndex));
        this.finishMessage();
        index = boundaryIndex + this.boundaryLength;
        this.state = 1 /* AfterBoundary */;
      }
      if (this.state === 1 /* AfterBoundary */) {
        if (chunkLength - index < 2) {
          const remainingData = chunk.subarray(index);
          if (remainingData.length > this.maxBoundaryBuffer) {
            throw new MultipartParseError(
              `After-boundary buffer limit exceeded: ${remainingData.length} > ${this.maxBoundaryBuffer}`
            );
          }
          this.buffer = remainingData;
          break;
        }
        if (chunk[index] === 45 && chunk[index + 1] === 45) {
          this.state = 4 /* Done */;
          break;
        }
        if (chunk[index] === 13 && chunk[index + 1] === 10) {
          index += 2;
        } else if (chunk[index] === 10) {
          index += 1;
        } else {
          throw new MultipartParseError(
            `Invalid character after boundary: expected CRLF or LF, got 0x${chunk[index].toString(16)}`
          );
        }
        this.state = 2 /* Header */;
      }
      if (this.state === 2 /* Header */) {
        if (chunkLength - index < 4) {
          const remainingData = chunk.subarray(index);
          if (remainingData.length > this.maxHeaderSize) {
            throw new MultipartParseError(
              `Header buffer limit exceeded: ${remainingData.length} > ${this.maxHeaderSize}`
            );
          }
          this.buffer = remainingData;
          break;
        }
        let headerEndIndex = this.findDoubleNewline(chunk, index);
        let headerEndOffset = 4;
        if (headerEndIndex === -1) {
          const lfDoubleNewline = createSearch("\n\n");
          headerEndIndex = lfDoubleNewline(chunk, index);
          headerEndOffset = 2;
        }
        if (headerEndIndex === -1) {
          const headerData = chunk.subarray(index);
          if (headerData.length > this.maxHeaderSize) {
            throw new MultipartParseError(
              `Headers too large: ${headerData.length} > ${this.maxHeaderSize} bytes`
            );
          }
          this.buffer = headerData;
          break;
        }
        const headerBytes = chunk.subarray(index, headerEndIndex);
        this.currentHeaders = parseHeaders(headerBytes);
        const message = this.createStreamingMessage();
        newMessages.push(message);
        index = headerEndIndex + headerEndOffset;
        this.state = 3 /* Body */;
        continue;
      }
      if (this.state === 0 /* Start */) {
        if (chunkLength < this.openingBoundaryLength) {
          if (chunk.length > this.maxBoundaryBuffer) {
            throw new MultipartParseError(
              `Initial chunk too large for boundary detection: ${chunk.length} > ${this.maxBoundaryBuffer}`
            );
          }
          this.buffer = chunk;
          break;
        }
        const boundaryIndex = this.findOpeningBoundary(chunk);
        if (boundaryIndex !== 0) {
          throw new MultipartParseError(
            "Invalid multipart stream: missing initial boundary"
          );
        }
        index = this.openingBoundaryLength;
        this.state = 1 /* AfterBoundary */;
      }
    }
    return newMessages;
  }
  createStreamingMessage() {
    const headers = new Headers(this.currentHeaders);
    const payload = new ReadableStream({
      start: (controller) => {
        this.currentPayloadController = controller;
      }
    });
    this.currentHeaders = new Headers();
    return {
      headers,
      payload
    };
  }
  writeBody(chunk) {
    if (this.currentPayloadController) {
      this.currentPayloadController.enqueue(chunk);
    }
  }
  finishMessage() {
    if (this.currentPayloadController) {
      this.currentPayloadController.close();
      this.currentPayloadController = null;
    }
  }
  /**
   * Close current payload controller if open (used during cleanup)
   * If an error is provided, forwards it to the payload consumer
   */
  closeCurrentPayload(error) {
    if (this.currentPayloadController) {
      try {
        if (error) {
          this.currentPayloadController.error(error);
        } else {
          this.currentPayloadController.close();
        }
      } catch (controllerError) {
      }
      this.currentPayloadController = null;
    }
  }
};

var getContext_1;
var hasRequiredGetContext;

function requireGetContext () {
	if (hasRequiredGetContext) return getContext_1;
	hasRequiredGetContext = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var get_context_exports = {};
	__export(get_context_exports, {
	  SYMBOL_FOR_REQ_CONTEXT: () => SYMBOL_FOR_REQ_CONTEXT,
	  getContext: () => getContext
	});
	getContext_1 = __toCommonJS(get_context_exports);
	const SYMBOL_FOR_REQ_CONTEXT = Symbol.for("@vercel/request-context");
	function getContext() {
	  const fromSymbol = globalThis;
	  return fromSymbol[SYMBOL_FOR_REQ_CONTEXT]?.get?.() ?? {};
	}
	return getContext_1;
}

var tokenError;
var hasRequiredTokenError;

function requireTokenError () {
	if (hasRequiredTokenError) return tokenError;
	hasRequiredTokenError = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var token_error_exports = {};
	__export(token_error_exports, {
	  VercelOidcTokenError: () => VercelOidcTokenError
	});
	tokenError = __toCommonJS(token_error_exports);
	class VercelOidcTokenError extends Error {
	  constructor(message, cause) {
	    super(message);
	    this.name = "VercelOidcTokenError";
	    this.cause = cause;
	  }
	  toString() {
	    if (this.cause) {
	      return `${this.name}: ${this.message}: ${this.cause}`;
	    }
	    return `${this.name}: ${this.message}`;
	  }
	}
	return tokenError;
}

var getVercelOidcToken_1;
var hasRequiredGetVercelOidcToken;

function requireGetVercelOidcToken () {
	if (hasRequiredGetVercelOidcToken) return getVercelOidcToken_1;
	hasRequiredGetVercelOidcToken = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var get_vercel_oidc_token_exports = {};
	__export(get_vercel_oidc_token_exports, {
	  getVercelOidcToken: () => getVercelOidcToken,
	  getVercelOidcTokenSync: () => getVercelOidcTokenSync
	});
	getVercelOidcToken_1 = __toCommonJS(get_vercel_oidc_token_exports);
	var import_get_context = requireGetContext();
	var import_token_error = requireTokenError();
	async function getVercelOidcToken() {
	  let token = "";
	  let err;
	  try {
	    token = getVercelOidcTokenSync();
	  } catch (error) {
	    err = error;
	  }
	  try {
	    const [{ getTokenPayload, isExpired }, { refreshToken }] = await Promise.all([
	      await import('./token-util_D6r3xWR2.mjs').then(n => n.t),
	      await import('./token_CrOFk7pc.mjs').then(n => n.t)
	    ]);
	    if (!token || isExpired(getTokenPayload(token))) {
	      await refreshToken();
	      token = getVercelOidcTokenSync();
	    }
	  } catch (error) {
	    if (err?.message && error instanceof Error) {
	      error.message = `${err.message}
${error.message}`;
	    }
	    throw new import_token_error.VercelOidcTokenError(`Failed to refresh OIDC token`, error);
	  }
	  return token;
	}
	function getVercelOidcTokenSync() {
	  const token = (0, import_get_context.getContext)().headers?.["x-vercel-oidc-token"] ?? process.env.VERCEL_OIDC_TOKEN;
	  if (!token) {
	    throw new Error(
	      `The 'x-vercel-oidc-token' header is missing from the request. Do you have the OIDC option enabled in the Vercel project settings?`
	    );
	  }
	  return token;
	}
	return getVercelOidcToken_1;
}

var dist;
var hasRequiredDist;

function requireDist () {
	if (hasRequiredDist) return dist;
	hasRequiredDist = 1;
	var __defProp = Object.defineProperty;
	var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
	var __getOwnPropNames = Object.getOwnPropertyNames;
	var __hasOwnProp = Object.prototype.hasOwnProperty;
	var __export = (target, all) => {
	  for (var name in all)
	    __defProp(target, name, { get: all[name], enumerable: true });
	};
	var __copyProps = (to, from, except, desc) => {
	  if (from && typeof from === "object" || typeof from === "function") {
	    for (let key of __getOwnPropNames(from))
	      if (!__hasOwnProp.call(to, key) && key !== except)
	        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
	  }
	  return to;
	};
	var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
	var src_exports = {};
	__export(src_exports, {
	  getContext: () => import_get_context.getContext,
	  getVercelOidcToken: () => import_get_vercel_oidc_token.getVercelOidcToken,
	  getVercelOidcTokenSync: () => import_get_vercel_oidc_token.getVercelOidcTokenSync
	});
	dist = __toCommonJS(src_exports);
	var import_get_vercel_oidc_token = requireGetVercelOidcToken();
	var import_get_context = requireGetContext();
	return dist;
}

var distExports = requireDist();

// src/transports.ts
async function streamToBuffer(stream) {
  let totalLength = 0;
  const reader = stream.getReader();
  const chunks = [];
  try {
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      chunks.push(value);
      totalLength += value.length;
    }
  } finally {
    reader.releaseLock();
  }
  return Buffer.concat(chunks, totalLength);
}
var JsonTransport = class {
  contentType = "application/json";
  replacer;
  reviver;
  constructor(options = {}) {
    this.replacer = options.replacer;
    this.reviver = options.reviver;
  }
  serialize(value) {
    return Buffer.from(JSON.stringify(value, this.replacer), "utf8");
  }
  async deserialize(stream) {
    const buffer = await streamToBuffer(stream);
    return JSON.parse(buffer.toString("utf8"), this.reviver);
  }
};

// src/types.ts
var MessageNotFoundError = class extends Error {
  constructor(messageId) {
    super(`Message ${messageId} not found`);
    this.name = "MessageNotFoundError";
  }
};
var MessageNotAvailableError = class extends Error {
  constructor(messageId, reason) {
    super(
      `Message ${messageId} not available for processing${reason ? `: ${reason}` : ""}`
    );
    this.name = "MessageNotAvailableError";
  }
};
var MessageCorruptedError = class extends Error {
  constructor(messageId, reason) {
    super(`Message ${messageId} is corrupted: ${reason}`);
    this.name = "MessageCorruptedError";
  }
};
var QueueEmptyError = class extends Error {
  constructor(queueName, consumerGroup) {
    super(
      `No messages available in queue "${queueName}" for consumer group "${consumerGroup}"`
    );
    this.name = "QueueEmptyError";
  }
};
var MessageLockedError = class extends Error {
  retryAfter;
  constructor(messageId, retryAfter) {
    const retryMessage = retryAfter ? ` Retry after ${retryAfter} seconds.` : " Try again later.";
    super(`Message ${messageId} is temporarily locked.${retryMessage}`);
    this.name = "MessageLockedError";
    this.retryAfter = retryAfter;
  }
};
var UnauthorizedError = class extends Error {
  constructor(message = "Missing or invalid authentication token") {
    super(message);
    this.name = "UnauthorizedError";
  }
};
var ForbiddenError = class extends Error {
  constructor(message = "Queue environment doesn't match token environment") {
    super(message);
    this.name = "ForbiddenError";
  }
};
var BadRequestError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "BadRequestError";
  }
};
var InternalServerError = class extends Error {
  constructor(message = "Unexpected server error") {
    super(message);
    this.name = "InternalServerError";
  }
};
var InvalidLimitError = class extends Error {
  constructor(limit, min = 1, max = 10) {
    super(`Invalid limit: ${limit}. Limit must be between ${min} and ${max}.`);
    this.name = "InvalidLimitError";
  }
};

// src/client.ts
async function consumeStream(stream) {
  const reader = stream.getReader();
  try {
    while (true) {
      const { done } = await reader.read();
      if (done) break;
    }
  } finally {
    reader.releaseLock();
  }
}
function parseQueueHeaders(headers) {
  const messageId = headers.get("Vqs-Message-Id");
  const deliveryCountStr = headers.get("Vqs-Delivery-Count") || "0";
  const timestamp = headers.get("Vqs-Timestamp");
  const contentType = headers.get("Content-Type") || "application/octet-stream";
  const ticket = headers.get("Vqs-Ticket");
  if (!messageId || !timestamp || !ticket) {
    return null;
  }
  const deliveryCount = parseInt(deliveryCountStr, 10);
  if (isNaN(deliveryCount)) {
    return null;
  }
  return {
    messageId,
    deliveryCount,
    createdAt: new Date(timestamp),
    contentType,
    ticket
  };
}
var QueueClient = class {
  baseUrl;
  basePath;
  customHeaders = {};
  token;
  /**
   * Create a new Vercel Queue Service client
   * @param options Client configuration options
   */
  constructor(options = {}) {
    this.baseUrl = options.baseUrl || process.env.VERCEL_QUEUE_BASE_URL || "https://vercel-queue.com";
    this.basePath = options.basePath || process.env.VERCEL_QUEUE_BASE_PATH || "/api/v2/messages";
    this.token = options.token || process.env.VERCEL_QUEUE_TOKEN;
    const VERCEL_QUEUE_HEADER_PREFIX = "VERCEL_QUEUE_HEADER_";
    this.customHeaders = Object.fromEntries(
      Object.entries(process.env).filter(([key]) => key.startsWith(VERCEL_QUEUE_HEADER_PREFIX)).map(([key, value]) => [
        // This allows headers to use dashes independent of shell used
        key.replace(VERCEL_QUEUE_HEADER_PREFIX, "").replaceAll("__", "-"),
        value || ""
      ])
    );
  }
  async getToken() {
    if (this.token) {
      return this.token;
    }
    const token = await distExports.getVercelOidcToken();
    if (!token) {
      throw new Error(
        "Failed to get OIDC token from Vercel Functions. Make sure you are running in a Vercel Function environment, or provide a token explicitly.\n\nTo set up your environment:\n1. Link your project: 'vercel link'\n2. Pull environment variables: 'vercel env pull'\n3. Run with environment: 'dotenv -e .env.local -- your-command'"
      );
    }
    return token;
  }
  /**
   * Send a message to a queue
   * @param options Send message options
   * @param transport Serializer/deserializer for the payload
   * @returns Promise with the message ID
   * @throws {BadRequestError} When request parameters are invalid
   * @throws {UnauthorizedError} When authentication fails
   * @throws {ForbiddenError} When access is denied (environment mismatch)
   * @throws {InternalServerError} When server encounters an error
   */
  async sendMessage(options, transport) {
    const { queueName, payload, idempotencyKey, retentionSeconds } = options;
    const headers = new Headers({
      Authorization: `Bearer ${await this.getToken()}`,
      "Vqs-Queue-Name": queueName,
      "Content-Type": transport.contentType,
      ...this.customHeaders
    });
    const deploymentId = options.deploymentId || process.env.VERCEL_DEPLOYMENT_ID;
    if (deploymentId) {
      headers.set("Vqs-Deployment-Id", deploymentId);
    }
    if (idempotencyKey) {
      headers.set("Vqs-Idempotency-Key", idempotencyKey);
    }
    if (retentionSeconds !== void 0) {
      headers.set("Vqs-Retention-Seconds", retentionSeconds.toString());
    }
    const body = transport.serialize(payload);
    const response = await fetch(`${this.baseUrl}${this.basePath}`, {
      method: "POST",
      body,
      headers
    });
    if (!response.ok) {
      if (response.status === 400) {
        const errorText = await response.text();
        throw new BadRequestError(errorText || "Invalid parameters");
      }
      if (response.status === 401) {
        throw new UnauthorizedError();
      }
      if (response.status === 403) {
        throw new ForbiddenError();
      }
      if (response.status === 409) {
        throw new Error("Duplicate idempotency key detected");
      }
      if (response.status >= 500) {
        throw new InternalServerError(
          `Server error: ${response.status} ${response.statusText}`
        );
      }
      throw new Error(
        `Failed to send message: ${response.status} ${response.statusText}`
      );
    }
    const responseData = await response.json();
    return responseData;
  }
  /**
   * Receive messages from a queue
   * @param options Receive messages options
   * @param transport Serializer/deserializer for the payload
   * @returns AsyncGenerator that yields messages as they arrive
   * @throws {InvalidLimitError} When limit parameter is not between 1 and 10
   * @throws {QueueEmptyError} When no messages are available (204)
   * @throws {MessageLockedError} When messages are temporarily locked (423)
   * @throws {BadRequestError} When request parameters are invalid
   * @throws {UnauthorizedError} When authentication fails
   * @throws {ForbiddenError} When access is denied (environment mismatch)
   * @throws {InternalServerError} When server encounters an error
   */
  async *receiveMessages(options, transport) {
    const { queueName, consumerGroup, visibilityTimeoutSeconds, limit } = options;
    if (limit !== void 0 && (limit < 1 || limit > 10)) {
      throw new InvalidLimitError(limit);
    }
    const headers = new Headers({
      Authorization: `Bearer ${await this.getToken()}`,
      "Vqs-Queue-Name": queueName,
      "Vqs-Consumer-Group": consumerGroup,
      Accept: "multipart/mixed",
      ...this.customHeaders
    });
    if (visibilityTimeoutSeconds !== void 0) {
      headers.set(
        "Vqs-Visibility-Timeout",
        visibilityTimeoutSeconds.toString()
      );
    }
    if (limit !== void 0) {
      headers.set("Vqs-Limit", limit.toString());
    }
    const response = await fetch(`${this.baseUrl}${this.basePath}`, {
      method: "GET",
      headers
    });
    if (response.status === 204) {
      throw new QueueEmptyError(queueName, consumerGroup);
    }
    if (!response.ok) {
      if (response.status === 400) {
        const errorText = await response.text();
        throw new BadRequestError(errorText || "Invalid parameters");
      }
      if (response.status === 401) {
        throw new UnauthorizedError();
      }
      if (response.status === 403) {
        throw new ForbiddenError();
      }
      if (response.status === 423) {
        const retryAfterHeader = response.headers.get("Retry-After");
        let retryAfter;
        if (retryAfterHeader) {
          const parsed = parseInt(retryAfterHeader, 10);
          retryAfter = isNaN(parsed) ? void 0 : parsed;
        }
        throw new MessageLockedError("next message", retryAfter);
      }
      if (response.status >= 500) {
        throw new InternalServerError(
          `Server error: ${response.status} ${response.statusText}`
        );
      }
      throw new Error(
        `Failed to receive messages: ${response.status} ${response.statusText}`
      );
    }
    for await (const multipartMessage of parseMultipartStream(response)) {
      try {
        const parsedHeaders = parseQueueHeaders(multipartMessage.headers);
        if (!parsedHeaders) {
          console.warn("Missing required queue headers in multipart part");
          await consumeStream(multipartMessage.payload);
          continue;
        }
        const deserializedPayload = await transport.deserialize(
          multipartMessage.payload
        );
        const message = {
          ...parsedHeaders,
          payload: deserializedPayload
        };
        yield message;
      } catch (error) {
        console.warn("Failed to process multipart message:", error);
        await consumeStream(multipartMessage.payload);
      }
    }
  }
  async receiveMessageById(options, transport) {
    const {
      queueName,
      consumerGroup,
      messageId,
      visibilityTimeoutSeconds,
      skipPayload
    } = options;
    const headers = new Headers({
      Authorization: `Bearer ${await this.getToken()}`,
      "Vqs-Queue-Name": queueName,
      "Vqs-Consumer-Group": consumerGroup,
      Accept: "multipart/mixed",
      ...this.customHeaders
    });
    if (visibilityTimeoutSeconds !== void 0) {
      headers.set(
        "Vqs-Visibility-Timeout",
        visibilityTimeoutSeconds.toString()
      );
    }
    if (skipPayload) {
      headers.set("Vqs-Skip-Payload", "1");
    }
    const response = await fetch(
      `${this.baseUrl}${this.basePath}/${encodeURIComponent(messageId)}`,
      {
        method: "GET",
        headers
      }
    );
    if (!response.ok) {
      if (response.status === 400) {
        const errorText = await response.text();
        throw new BadRequestError(errorText || "Invalid parameters");
      }
      if (response.status === 401) {
        throw new UnauthorizedError();
      }
      if (response.status === 403) {
        throw new ForbiddenError();
      }
      if (response.status === 404) {
        throw new MessageNotFoundError(messageId);
      }
      if (response.status === 423) {
        const retryAfterHeader = response.headers.get("Retry-After");
        let retryAfter;
        if (retryAfterHeader) {
          const parsed = parseInt(retryAfterHeader, 10);
          retryAfter = isNaN(parsed) ? void 0 : parsed;
        }
        throw new MessageLockedError(messageId, retryAfter);
      }
      if (response.status === 409) {
        throw new MessageNotAvailableError(messageId);
      }
      if (response.status >= 500) {
        throw new InternalServerError(
          `Server error: ${response.status} ${response.statusText}`
        );
      }
      throw new Error(
        `Failed to receive message by ID: ${response.status} ${response.statusText}`
      );
    }
    if (skipPayload && response.status === 204) {
      const parsedHeaders = parseQueueHeaders(response.headers);
      if (!parsedHeaders) {
        throw new MessageCorruptedError(
          messageId,
          "Missing required queue headers in 204 response"
        );
      }
      const message = {
        ...parsedHeaders,
        payload: void 0
      };
      return { message };
    }
    if (!transport) {
      throw new Error("Transport is required when skipPayload is not true");
    }
    try {
      for await (const multipartMessage of parseMultipartStream(response)) {
        try {
          const parsedHeaders = parseQueueHeaders(multipartMessage.headers);
          if (!parsedHeaders) {
            console.warn("Missing required queue headers in multipart part");
            await consumeStream(multipartMessage.payload);
            continue;
          }
          const deserializedPayload = await transport.deserialize(
            multipartMessage.payload
          );
          const message = {
            ...parsedHeaders,
            payload: deserializedPayload
          };
          return { message };
        } catch (error) {
          console.warn("Failed to deserialize message by ID:", error);
          await consumeStream(multipartMessage.payload);
          throw new MessageCorruptedError(
            messageId,
            `Failed to deserialize payload: ${error}`
          );
        }
      }
    } catch (error) {
      if (error instanceof MessageCorruptedError) {
        throw error;
      }
      throw new MessageCorruptedError(
        messageId,
        `Failed to parse multipart response: ${error}`
      );
    }
    throw new MessageNotFoundError(messageId);
  }
  /**
   * Delete a message (acknowledge processing)
   * @param options Delete message options
   * @returns Promise with delete status
   * @throws {MessageNotFoundError} When the message doesn't exist (404)
   * @throws {MessageNotAvailableError} When message can't be deleted (409)
   * @throws {BadRequestError} When ticket is missing or invalid (400)
   * @throws {UnauthorizedError} When authentication fails
   * @throws {ForbiddenError} When access is denied (environment mismatch)
   * @throws {InternalServerError} When server encounters an error
   */
  async deleteMessage(options) {
    const { queueName, consumerGroup, messageId, ticket } = options;
    const response = await fetch(
      `${this.baseUrl}${this.basePath}/${encodeURIComponent(messageId)}`,
      {
        method: "DELETE",
        headers: new Headers({
          Authorization: `Bearer ${await this.getToken()}`,
          "Vqs-Queue-Name": queueName,
          "Vqs-Consumer-Group": consumerGroup,
          "Vqs-Ticket": ticket,
          ...this.customHeaders
        })
      }
    );
    if (!response.ok) {
      if (response.status === 400) {
        throw new BadRequestError("Missing or invalid ticket");
      }
      if (response.status === 401) {
        throw new UnauthorizedError();
      }
      if (response.status === 403) {
        throw new ForbiddenError();
      }
      if (response.status === 404) {
        throw new MessageNotFoundError(messageId);
      }
      if (response.status === 409) {
        throw new MessageNotAvailableError(
          messageId,
          "Invalid ticket, message not in correct state, or already processed"
        );
      }
      if (response.status >= 500) {
        throw new InternalServerError(
          `Server error: ${response.status} ${response.statusText}`
        );
      }
      throw new Error(
        `Failed to delete message: ${response.status} ${response.statusText}`
      );
    }
    return { deleted: true };
  }
  /**
   * Change the visibility timeout of a message
   * @param options Change visibility options
   * @returns Promise with update status
   * @throws {MessageNotFoundError} When the message doesn't exist (404)
   * @throws {MessageNotAvailableError} When message can't be updated (409)
   * @throws {BadRequestError} When ticket is missing or visibility timeout invalid (400)
   * @throws {UnauthorizedError} When authentication fails
   * @throws {ForbiddenError} When access is denied (environment mismatch)
   * @throws {InternalServerError} When server encounters an error
   */
  async changeVisibility(options) {
    const {
      queueName,
      consumerGroup,
      messageId,
      ticket,
      visibilityTimeoutSeconds
    } = options;
    const response = await fetch(
      `${this.baseUrl}${this.basePath}/${encodeURIComponent(messageId)}`,
      {
        method: "PATCH",
        headers: new Headers({
          Authorization: `Bearer ${await this.getToken()}`,
          "Vqs-Queue-Name": queueName,
          "Vqs-Consumer-Group": consumerGroup,
          "Vqs-Ticket": ticket,
          "Vqs-Visibility-Timeout": visibilityTimeoutSeconds.toString(),
          ...this.customHeaders
        })
      }
    );
    if (!response.ok) {
      if (response.status === 400) {
        throw new BadRequestError(
          "Missing ticket or invalid visibility timeout"
        );
      }
      if (response.status === 401) {
        throw new UnauthorizedError();
      }
      if (response.status === 403) {
        throw new ForbiddenError();
      }
      if (response.status === 404) {
        throw new MessageNotFoundError(messageId);
      }
      if (response.status === 409) {
        throw new MessageNotAvailableError(
          messageId,
          "Invalid ticket, message not in correct state, or already processed"
        );
      }
      if (response.status >= 500) {
        throw new InternalServerError(
          `Server error: ${response.status} ${response.statusText}`
        );
      }
      throw new Error(
        `Failed to change visibility: ${response.status} ${response.statusText}`
      );
    }
    return { updated: true };
  }
};

// src/callback.ts
function validateWildcardPattern(pattern) {
  const firstIndex = pattern.indexOf("*");
  const lastIndex = pattern.lastIndexOf("*");
  if (firstIndex !== lastIndex) {
    return false;
  }
  if (firstIndex === -1) {
    return false;
  }
  if (firstIndex !== pattern.length - 1) {
    return false;
  }
  return true;
}
function matchesWildcardPattern(topicName, pattern) {
  const prefix = pattern.slice(0, -1);
  return topicName.startsWith(prefix);
}
function findTopicHandler(queueName, handlers) {
  const exactHandler = handlers[queueName];
  if (exactHandler) {
    return exactHandler;
  }
  for (const pattern in handlers) {
    if (pattern.includes("*") && matchesWildcardPattern(queueName, pattern)) {
      return handlers[pattern];
    }
  }
  return null;
}
async function parseCallback(request) {
  const contentType = request.headers.get("content-type");
  if (!contentType || !contentType.includes("application/cloudevents+json")) {
    throw new Error(
      "Invalid content type: expected 'application/cloudevents+json'"
    );
  }
  let cloudEvent;
  try {
    cloudEvent = await request.json();
  } catch (error) {
    throw new Error("Failed to parse CloudEvent from request body");
  }
  if (!cloudEvent.type || !cloudEvent.source || !cloudEvent.id || typeof cloudEvent.data !== "object" || cloudEvent.data == null) {
    throw new Error("Invalid CloudEvent: missing required fields");
  }
  if (cloudEvent.type !== "com.vercel.queue.v1beta") {
    throw new Error(
      `Invalid CloudEvent type: expected 'com.vercel.queue.v1beta', got '${cloudEvent.type}'`
    );
  }
  const missingFields = [];
  if (!("queueName" in cloudEvent.data)) missingFields.push("queueName");
  if (!("consumerGroup" in cloudEvent.data))
    missingFields.push("consumerGroup");
  if (!("messageId" in cloudEvent.data)) missingFields.push("messageId");
  if (missingFields.length > 0) {
    throw new Error(
      `Missing required CloudEvent data fields: ${missingFields.join(", ")}`
    );
  }
  const { messageId, queueName, consumerGroup } = cloudEvent.data;
  return {
    queueName,
    consumerGroup,
    messageId
  };
}
function handleCallback(handlers) {
  for (const topicPattern in handlers) {
    if (topicPattern.includes("*")) {
      if (!validateWildcardPattern(topicPattern)) {
        throw new Error(
          `Invalid wildcard pattern "${topicPattern}": * may only appear once and must be at the end of the topic name`
        );
      }
    }
  }
  const routeHandler = async (request) => {
    try {
      const { queueName, consumerGroup, messageId } = await parseCallback(request);
      const topicHandler = findTopicHandler(queueName, handlers);
      if (!topicHandler) {
        const availableTopics = Object.keys(handlers).join(", ");
        return Response.json(
          {
            error: `No handler found for topic: ${queueName}`,
            availableTopics
          },
          { status: 404 }
        );
      }
      const consumerGroupHandler = topicHandler[consumerGroup];
      if (!consumerGroupHandler) {
        const availableGroups = Object.keys(topicHandler).join(", ");
        return Response.json(
          {
            error: `No handler found for consumer group "${consumerGroup}" in topic "${queueName}".`,
            availableGroups
          },
          { status: 404 }
        );
      }
      const client = new QueueClient();
      const topic = new Topic(client, queueName);
      const cg = topic.consumerGroup(consumerGroup);
      await cg.consume(consumerGroupHandler, { messageId });
      return Response.json({ status: "success" });
    } catch (error) {
      console.error("Queue callback error:", error);
      if (error instanceof Error && (error.message.includes("Missing required CloudEvent data fields") || error.message.includes("Invalid CloudEvent") || error.message.includes("Invalid CloudEvent type") || error.message.includes("Invalid content type") || error.message.includes("Failed to parse CloudEvent"))) {
        return Response.json({ error: error.message }, { status: 400 });
      }
      return Response.json(
        { error: "Failed to process queue message" },
        { status: 500 }
      );
    }
  };
  if (isDevMode()) {
    registerDevRouteHandler(routeHandler, handlers);
  }
  return routeHandler;
}

// src/dev.ts
var devRouteHandlers = /* @__PURE__ */ new Map();
var wildcardRouteHandlers = /* @__PURE__ */ new Map();
function cleanupDeadRefs(key, refs) {
  const aliveRefs = refs.filter((ref) => ref.deref() !== void 0);
  if (aliveRefs.length === 0) {
    wildcardRouteHandlers.delete(key);
  } else if (aliveRefs.length < refs.length) {
    wildcardRouteHandlers.set(key, aliveRefs);
  }
}
function isDevMode() {
  return process.env.NODE_ENV === "development";
}
function registerDevRouteHandler(routeHandler, handlers) {
  for (const topicName in handlers) {
    for (const consumerGroup in handlers[topicName]) {
      const key = `${topicName}:${consumerGroup}`;
      if (topicName.includes("*")) {
        const existing = wildcardRouteHandlers.get(key) || [];
        cleanupDeadRefs(key, existing);
        const cleanedRefs = wildcardRouteHandlers.get(key) || [];
        const weakRef = new WeakRef(routeHandler);
        cleanedRefs.push(weakRef);
        wildcardRouteHandlers.set(key, cleanedRefs);
      } else {
        devRouteHandlers.set(key, {
          routeHandler,
          topicPattern: topicName
        });
      }
    }
  }
}
function findRouteHandlersForTopic(topicName) {
  const handlersMap = /* @__PURE__ */ new Map();
  for (const [
    key,
    { routeHandler, topicPattern }
  ] of devRouteHandlers.entries()) {
    const [_, consumerGroup] = key.split(":");
    if (topicPattern === topicName) {
      if (!handlersMap.has(routeHandler)) {
        handlersMap.set(routeHandler, /* @__PURE__ */ new Set());
      }
      handlersMap.get(routeHandler).add(consumerGroup);
    }
  }
  for (const [key, refs] of wildcardRouteHandlers.entries()) {
    const [pattern, consumerGroup] = key.split(":");
    if (matchesWildcardPattern(topicName, pattern)) {
      cleanupDeadRefs(key, refs);
      const cleanedRefs = wildcardRouteHandlers.get(key) || [];
      for (const ref of cleanedRefs) {
        const routeHandler = ref.deref();
        if (routeHandler) {
          if (!handlersMap.has(routeHandler)) {
            handlersMap.set(routeHandler, /* @__PURE__ */ new Set());
          }
          handlersMap.get(routeHandler).add(consumerGroup);
        }
      }
    }
  }
  return handlersMap;
}
function createMockCloudEventRequest(topicName, consumerGroup, messageId) {
  const cloudEvent = {
    type: "com.vercel.queue.v1beta",
    source: `/topic/${topicName}/consumer/${consumerGroup}`,
    id: messageId,
    datacontenttype: "application/json",
    data: {
      messageId,
      queueName: topicName,
      consumerGroup
    },
    time: (/* @__PURE__ */ new Date()).toISOString(),
    specversion: "1.0"
  };
  return new Request("https://localhost/api/queue/callback", {
    method: "POST",
    headers: {
      "Content-Type": "application/cloudevents+json"
    },
    body: JSON.stringify(cloudEvent)
  });
}
var DEV_CALLBACK_DELAY = 1e3;
function scheduleDevTimeout(topicName, messageId, timeoutSeconds) {
  console.log(
    `[Dev Mode] Message ${messageId} timed out for ${timeoutSeconds}s, will re-trigger`
  );
  setTimeout(
    () => {
      console.log(
        `[Dev Mode] Re-triggering callback for timed-out message ${messageId}`
      );
      triggerDevCallbacks(topicName, messageId);
    },
    timeoutSeconds * 1e3 + DEV_CALLBACK_DELAY
  );
}
function triggerDevCallbacks(topicName, messageId) {
  const handlersMap = findRouteHandlersForTopic(topicName);
  if (handlersMap.size === 0) {
    return;
  }
  const consumerGroups = Array.from(
    new Set(
      Array.from(handlersMap.values()).flatMap((groups) => Array.from(groups))
    )
  );
  console.log(
    `[Dev Mode] Triggering local callbacks for topic "${topicName}" \u2192 consumers: ${consumerGroups.join(", ")}`
  );
  setTimeout(async () => {
    for (const [routeHandler, consumerGroups2] of handlersMap.entries()) {
      for (const consumerGroup of consumerGroups2) {
        try {
          const request = createMockCloudEventRequest(
            topicName,
            consumerGroup,
            messageId
          );
          const response = await routeHandler(request);
          if (response.ok) {
            try {
              const responseData = await response.json();
              if (responseData.status === "success") {
                console.log(
                  `[Dev Mode] Message processed for ${topicName}/${consumerGroup}`
                );
              }
            } catch (jsonError) {
              console.error(
                `[Dev Mode] Failed to parse success response for ${topicName}/${consumerGroup}:`,
                jsonError
              );
            }
          } else {
            try {
              const errorData = await response.json();
              console.error(
                `[Dev Mode] Failed to process message for ${topicName}/${consumerGroup}:`,
                errorData.error || response.statusText
              );
            } catch (jsonError) {
              console.error(
                `[Dev Mode] Failed to process message for ${topicName}/${consumerGroup}:`,
                response.statusText
              );
            }
          }
        } catch (error) {
          console.error(
            `[Dev Mode] Error triggering callback for ${topicName}/${consumerGroup}:`,
            error
          );
        }
      }
    }
  }, DEV_CALLBACK_DELAY);
}
function clearDevHandlers() {
  devRouteHandlers.clear();
  wildcardRouteHandlers.clear();
}
if (process.env.NODE_ENV === "test" || process.env.VITEST) {
  globalThis.__clearDevHandlers = clearDevHandlers;
}

// src/consumer-group.ts
var ConsumerGroup = class {
  client;
  topicName;
  consumerGroupName;
  visibilityTimeout;
  refreshInterval;
  transport;
  /**
   * Create a new ConsumerGroup instance
   * @param client QueueClient instance to use for API calls
   * @param topicName Name of the topic to consume from
   * @param consumerGroupName Name of the consumer group
   * @param options Optional configuration
   */
  constructor(client, topicName, consumerGroupName, options = {}) {
    this.client = client;
    this.topicName = topicName;
    this.consumerGroupName = consumerGroupName;
    this.visibilityTimeout = options.visibilityTimeoutSeconds || 30;
    this.refreshInterval = options.refreshInterval || 10;
    this.transport = options.transport || new JsonTransport();
  }
  /**
   * Starts a background loop that periodically extends the visibility timeout for a message.
   * This prevents the message from becoming visible to other consumers while it's being processed.
   *
   * The extension loop runs every `refreshInterval` seconds and updates the message's
   * visibility timeout to `visibilityTimeout` seconds from the current time.
   *
   * @param messageId - The unique identifier of the message to extend visibility for
   * @param ticket - The receipt ticket that proves ownership of the message
   * @returns A function that when called will stop the extension loop
   *
   * @remarks
   * - The first extension attempt occurs after `refreshInterval` seconds, not immediately
   * - If an extension fails, the loop terminates with an error logged to console
   * - The returned stop function is idempotent - calling it multiple times is safe
   * - By default, the stop function returns immediately without waiting for in-flight
   * - Pass `true` to the stop function to wait for any in-flight extension to complete
   */
  startVisibilityExtension(messageId, ticket) {
    let isRunning = true;
    let resolveLifecycle;
    let timeoutId = null;
    const lifecyclePromise = new Promise((resolve) => {
      resolveLifecycle = resolve;
    });
    const extend = async () => {
      if (!isRunning) {
        resolveLifecycle();
        return;
      }
      try {
        await this.client.changeVisibility({
          queueName: this.topicName,
          consumerGroup: this.consumerGroupName,
          messageId,
          ticket,
          visibilityTimeoutSeconds: this.visibilityTimeout
        });
        if (isRunning) {
          timeoutId = setTimeout(() => extend(), this.refreshInterval * 1e3);
        } else {
          resolveLifecycle();
        }
      } catch (error) {
        console.error(
          `Failed to extend visibility for message ${messageId}:`,
          error
        );
        resolveLifecycle();
      }
    };
    timeoutId = setTimeout(() => extend(), this.refreshInterval * 1e3);
    return async (waitForCompletion = false) => {
      isRunning = false;
      if (timeoutId) {
        clearTimeout(timeoutId);
        timeoutId = null;
      }
      if (waitForCompletion) {
        await lifecyclePromise;
      } else {
        resolveLifecycle();
      }
    };
  }
  /**
   * Process a single message with the given handler
   * @param message The message to process
   * @param handler Function to process the message
   */
  async processMessage(message, handler) {
    const stopExtension = this.startVisibilityExtension(
      message.messageId,
      message.ticket
    );
    try {
      const result = await handler(message.payload, {
        messageId: message.messageId,
        deliveryCount: message.deliveryCount,
        createdAt: message.createdAt,
        topicName: this.topicName,
        consumerGroup: this.consumerGroupName
      });
      await stopExtension();
      if (result && "timeoutSeconds" in result) {
        await this.client.changeVisibility({
          queueName: this.topicName,
          consumerGroup: this.consumerGroupName,
          messageId: message.messageId,
          ticket: message.ticket,
          visibilityTimeoutSeconds: result.timeoutSeconds
        });
        if (isDevMode()) {
          scheduleDevTimeout(
            this.topicName,
            message.messageId,
            result.timeoutSeconds
          );
        }
      } else {
        await this.client.deleteMessage({
          queueName: this.topicName,
          consumerGroup: this.consumerGroupName,
          messageId: message.messageId,
          ticket: message.ticket
        });
      }
    } catch (error) {
      await stopExtension();
      if (this.transport.finalize && message.payload !== void 0 && message.payload !== null) {
        try {
          await this.transport.finalize(message.payload);
        } catch (finalizeError) {
          console.warn("Failed to finalize message payload:", finalizeError);
        }
      }
      throw error;
    }
  }
  async consume(handler, options) {
    if (options?.messageId) {
      if (options.skipPayload) {
        const response = await this.client.receiveMessageById(
          {
            queueName: this.topicName,
            consumerGroup: this.consumerGroupName,
            messageId: options.messageId,
            visibilityTimeoutSeconds: this.visibilityTimeout,
            skipPayload: true
          },
          this.transport
        );
        await this.processMessage(
          response.message,
          handler
        );
      } else {
        const response = await this.client.receiveMessageById(
          {
            queueName: this.topicName,
            consumerGroup: this.consumerGroupName,
            messageId: options.messageId,
            visibilityTimeoutSeconds: this.visibilityTimeout
          },
          this.transport
        );
        await this.processMessage(
          response.message,
          handler
        );
      }
    } else {
      let messageFound = false;
      for await (const message of this.client.receiveMessages(
        {
          queueName: this.topicName,
          consumerGroup: this.consumerGroupName,
          visibilityTimeoutSeconds: this.visibilityTimeout,
          limit: 1
        },
        this.transport
      )) {
        messageFound = true;
        await this.processMessage(message, handler);
        break;
      }
      if (!messageFound) {
        throw new Error("No messages available");
      }
    }
  }
  /**
   * Get the consumer group name
   */
  get name() {
    return this.consumerGroupName;
  }
  /**
   * Get the topic name this consumer group is subscribed to
   */
  get topic() {
    return this.topicName;
  }
};

// src/topic.ts
var Topic = class {
  client;
  topicName;
  transport;
  /**
   * Create a new Topic instance
   * @param client QueueClient instance to use for API calls
   * @param topicName Name of the topic to work with
   * @param transport Optional serializer/deserializer for the payload (defaults to JSON)
   */
  constructor(client, topicName, transport) {
    this.client = client;
    this.topicName = topicName;
    this.transport = transport || new JsonTransport();
  }
  /**
   * Publish a message to the topic
   * @param payload The data to publish
   * @param options Optional publish options
   * @returns An object containing the message ID
   * @throws {BadRequestError} When request parameters are invalid
   * @throws {UnauthorizedError} When authentication fails
   * @throws {ForbiddenError} When access is denied (environment mismatch)
   * @throws {InternalServerError} When server encounters an error
   */
  async publish(payload, options) {
    const result = await this.client.sendMessage(
      {
        queueName: this.topicName,
        payload,
        idempotencyKey: options?.idempotencyKey,
        retentionSeconds: options?.retentionSeconds,
        deploymentId: options?.deploymentId
      },
      this.transport
    );
    if (isDevMode()) {
      triggerDevCallbacks(this.topicName, result.messageId);
    }
    return { messageId: result.messageId };
  }
  /**
   * Create a consumer group for this topic
   * @param consumerGroupName Name of the consumer group
   * @param options Optional configuration for the consumer group
   * @returns A ConsumerGroup instance
   */
  consumerGroup(consumerGroupName, options) {
    const consumerOptions = {
      ...options,
      transport: options?.transport || this.transport
    };
    return new ConsumerGroup(
      this.client,
      this.topicName,
      consumerGroupName,
      consumerOptions
    );
  }
  /**
   * Get the topic name
   */
  get name() {
    return this.topicName;
  }
  /**
   * Get the transport used by this topic
   */
  get serializer() {
    return this.transport;
  }
};

// src/factory.ts
async function send(topicName, payload, options) {
  const transport = options?.transport || new JsonTransport();
  const client = new QueueClient();
  const result = await client.sendMessage(
    {
      queueName: topicName,
      payload,
      idempotencyKey: options?.idempotencyKey,
      retentionSeconds: options?.retentionSeconds,
      deploymentId: options?.deploymentId
    },
    transport
  );
  if (isDevMode()) {
    triggerDevCallbacks(topicName, result.messageId);
  }
  return { messageId: result.messageId };
}

// Generated by genversion.
const version = '4.0.1-beta.7';

const DEFAULT_RESOLVE_DATA_OPTION = 'all';
function dateToStringReplacer(_key, value) {
    if (value instanceof Date) {
        return value.toISOString();
    }
    return value;
}
/**
 * Helper to serialize error into a JSON string in the error field.
 * The error field can be either:
 * - A plain string (legacy format, just the error message)
 * - A JSON string with { message, stack, code } (new format)
 */
function serializeError(data) {
    const { error, ...rest } = data;
    // If we have an error, serialize as JSON string
    if (error !== undefined) {
        return {
            ...rest,
            error: JSON.stringify({
                message: error.message,
                stack: error.stack,
                code: error.code,
            }),
        };
    }
    return data;
}
/**
 * Helper to deserialize error field from the backend into a StructuredError object.
 * Handles backwards compatibility:
 * - If error is a JSON string with {message, stack, code} â parse into StructuredError
 * - If error is a plain string â treat as error message with no stack
 * - If no error â undefined
 *
 * This function transforms objects from wire format (where error is a JSON string)
 * to domain format (where error is a StructuredError object). The generic type
 * parameter should be the expected output type (WorkflowRun or Step).
 *
 * Note: The type assertion is necessary because the wire format types from Zod schemas
 * have `error?: string` while the domain types have complex error types (e.g., discriminated
 * unions with `error: void` or `error: StructuredError` depending on status), but the
 * transformation preserves all other fields correctly.
 */
function deserializeError(obj) {
    const { error, ...rest } = obj;
    if (!error) {
        return obj;
    }
    // Try to parse as structured error JSON
    try {
        const parsed = StructuredErrorSchema.parse(JSON.parse(error));
        return {
            ...rest,
            error: {
                message: parsed.message,
                stack: parsed.stack,
                code: parsed.code,
            },
        };
    }
    catch {
        // Backwards compatibility: error is just a plain string
        return {
            ...rest,
            error: {
                message: error,
            },
        };
    }
}
const getUserAgent = () => {
    return `@workflow/world-vercel/${version} node-${process.version} ${os.platform()} (${os.arch()})`;
};
const getHttpUrl = (config) => {
    const projectConfig = config?.projectConfig;
    const defaultUrl = 'https://vercel-workflow.com/api';
    const defaultProxyUrl = 'https://api.vercel.com/v1/workflow';
    const usingProxy = Boolean(config?.baseUrl || (projectConfig?.projectId && projectConfig?.teamId));
    const baseUrl = config?.baseUrl || (usingProxy ? defaultProxyUrl : defaultUrl);
    return { baseUrl, usingProxy };
};
const getHeaders = (config) => {
    const projectConfig = config?.projectConfig;
    const headers = new Headers(config?.headers);
    headers.set('User-Agent', getUserAgent());
    if (projectConfig) {
        headers.set('x-vercel-environment', projectConfig.environment || 'production');
        if (projectConfig.projectId) {
            headers.set('x-vercel-project-id', projectConfig.projectId);
        }
        if (projectConfig.teamId) {
            headers.set('x-vercel-team-id', projectConfig.teamId);
        }
    }
    return headers;
};
async function getHttpConfig(config) {
    const headers = getHeaders(config);
    const token = config?.token ?? (await distExports.getVercelOidcToken());
    if (token) {
        headers.set('Authorization', `Bearer ${token}`);
    }
    const { baseUrl, usingProxy } = getHttpUrl(config);
    return { baseUrl, headers, usingProxy };
}
async function makeRequest({ endpoint, options = {}, config = {}, schema, }) {
    const { baseUrl, headers } = await getHttpConfig(config);
    headers.set('Content-Type', 'application/json');
    const url = `${baseUrl}${endpoint}`;
    const response = await fetch(url, {
        ...options,
        headers,
    });
    if (!response.ok) {
        const errorData = (await response.json().catch(() => ({})));
        if (process.env.DEBUG === '1') {
            const stringifiedHeaders = Array.from(headers.entries())
                .map(([key, value]) => `-H "${key}: ${value}"`)
                .join(' ');
            console.error(`Failed to fetch, reproduce with:\ncurl -X ${options.method} ${stringifiedHeaders} "${url}"`);
        }
        throw new WorkflowAPIError(errorData.message ||
            `${options.method ?? 'GET'} ${endpoint} -> HTTP ${response.status}: ${response.statusText}`, { url, status: response.status, code: errorData.code });
    }
    try {
        const text = await response.text();
        return schema.parse(JSON.parse(text));
    }
    catch (error) {
        if (error instanceof ZodError) {
            throw new WorkflowAPIError(`Failed to parse server response for ${options.method ?? 'GET'} ${endpoint}: ${error.message}`, { url, cause: error });
        }
        throw new WorkflowAPIError(`Failed to parse server response for ${options.method ?? 'GET'} ${endpoint}`, { url, cause: error });
    }
}

const MessageWrapper = z.object({
    payload: QueuePayloadSchema,
    queueName: ValidQueueName,
});
const VERCEL_QUEUE_MAX_VISIBILITY = 82800; // 23 hours in seconds
function createQueue(config) {
    const { baseUrl, usingProxy } = getHttpUrl(config);
    const headers = getHeaders(config);
    if (usingProxy) {
        // If we're using a proxy for the Workflow API, we should also go
        // through the proxy for the queues API.
        process.env.VERCEL_QUEUE_BASE_URL = `${baseUrl}`;
        process.env.VERCEL_QUEUE_BASE_PATH = '/queues/v2/messages';
        if (config?.token) {
            process.env.VERCEL_QUEUE_TOKEN = config.token;
        }
        if (headers) {
            headers.forEach((value, key) => {
                const sanitizedKey = key.replaceAll('-', '__');
                process.env[`VERCEL_QUEUE_HEADER_${sanitizedKey}`] = value;
            });
        }
    }
    const queue = async (queueName, x, opts) => {
        const encoded = MessageWrapper.encode({
            payload: x,
            queueName,
        });
        const sanitizedQueueName = queueName.replace(/[^A-Za-z0-9-_]/g, '-');
        const { messageId } = await send(sanitizedQueueName, encoded, opts);
        return { messageId: MessageId.parse(messageId) };
    };
    const createQueueHandler = (prefix, handler) => {
        return handleCallback({
            [`${prefix}*`]: {
                default: async (body, meta) => {
                    const { payload, queueName } = MessageWrapper.parse(body);
                    const result = await handler(payload, {
                        queueName,
                        messageId: MessageId.parse(meta.messageId),
                        attempt: meta.deliveryCount,
                    });
                    if (typeof result?.timeoutSeconds === 'number') {
                        // For Vercel Queue, enforce the max visibility limit:
                        //   - When a step function throws a `RetryableError`, the retryAfter timestamp is updated and stored on the Step document
                        const adjustedTimeoutSeconds = Math.min(result.timeoutSeconds, VERCEL_QUEUE_MAX_VISIBILITY);
                        if (adjustedTimeoutSeconds !== result.timeoutSeconds) {
                            result.timeoutSeconds = adjustedTimeoutSeconds;
                        }
                    }
                    return result;
                },
            },
        });
    };
    const getDeploymentId = async () => {
        const deploymentId = process.env.VERCEL_DEPLOYMENT_ID;
        if (!deploymentId) {
            throw new Error('VERCEL_DEPLOYMENT_ID environment variable is not set');
        }
        return deploymentId;
    };
    return { queue, createQueueHandler, getDeploymentId };
}

// Helper to filter event data based on resolveData setting
function filterEventData(event, resolveData) {
    if (resolveData === 'none') {
        const { eventData: _eventData, ...rest } = event;
        return rest;
    }
    return event;
}
// Would usually "EventSchema.omit({ eventData: true })" but that doesn't work
// on zod unions. Re-creating the schema manually.
const EventWithRefsSchema = z__default.object({
    eventId: z__default.string(),
    runId: z__default.string(),
    eventType: EventTypeSchema,
    correlationId: z__default.string().optional(),
    eventDataRef: z__default.any().optional(),
    createdAt: z__default.coerce.date(),
});
// Functions
async function getWorkflowRunEvents(params, config) {
    const searchParams = new URLSearchParams();
    const { pagination, resolveData = DEFAULT_RESOLVE_DATA_OPTION } = params;
    let runId;
    let correlationId;
    if ('runId' in params) {
        runId = params.runId;
    }
    else {
        correlationId = params.correlationId;
    }
    if (!runId && !correlationId) {
        throw new Error('Either runId or correlationId must be provided');
    }
    if (pagination?.limit)
        searchParams.set('limit', pagination.limit.toString());
    if (pagination?.cursor)
        searchParams.set('cursor', pagination.cursor);
    if (pagination?.sortOrder)
        searchParams.set('sortOrder', pagination.sortOrder);
    if (correlationId)
        searchParams.set('correlationId', correlationId);
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const query = queryString ? `?${queryString}` : '';
    const endpoint = correlationId
        ? `/v1/events${query}`
        : `/v1/runs/${runId}/events${query}`;
    const response = (await makeRequest({
        endpoint,
        options: { method: 'GET' },
        config,
        schema: PaginatedResponseSchema(remoteRefBehavior === 'lazy' ? EventWithRefsSchema : EventSchema),
    }));
    return {
        ...response,
        data: response.data.map((event) => filterEventData(event, resolveData)),
    };
}
async function createWorkflowRunEvent(id, data, params, config) {
    const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION;
    const event = await makeRequest({
        endpoint: `/v1/runs/${id}/events`,
        options: {
            method: 'POST',
            body: JSON.stringify(data, dateToStringReplacer),
        },
        config,
        schema: EventSchema,
    });
    return filterEventData(event, resolveData);
}

// Helper to filter hook data based on resolveData setting
function filterHookData(hook, resolveData) {
    if (resolveData === 'none') {
        const { metadataRef: _metadataRef, ...rest } = hook;
        return rest;
    }
    return hook;
}
const HookWithRefsSchema = HookSchema.omit({
    metadata: true,
}).extend({
    metadataRef: z__default.any().optional(),
});
async function listHooks(params, config) {
    const { runId, pagination, resolveData = DEFAULT_RESOLVE_DATA_OPTION, } = params;
    const searchParams = new URLSearchParams();
    if (pagination?.limit)
        searchParams.set('limit', pagination.limit.toString());
    if (pagination?.cursor)
        searchParams.set('cursor', pagination.cursor);
    if (pagination?.sortOrder)
        searchParams.set('sortOrder', pagination.sortOrder);
    // Map resolveData to internal RemoteRefBehavior
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    if (runId)
        searchParams.set('runId', runId);
    const queryString = searchParams.toString();
    const endpoint = `/v1/hooks${queryString ? `?${queryString}` : ''}`;
    const response = (await makeRequest({
        endpoint,
        options: { method: 'GET' },
        config,
        schema: PaginatedResponseSchema(remoteRefBehavior === 'lazy' ? HookWithRefsSchema : HookSchema),
    }));
    return {
        ...response,
        data: response.data.map((hook) => filterHookData(hook, resolveData)),
    };
}
async function getHook(hookId, params, config) {
    const resolveData = params?.resolveData || 'all';
    const endpoint = `/v1/hooks/${hookId}`;
    const hook = await makeRequest({
        endpoint,
        options: { method: 'GET' },
        config,
        schema: HookSchema,
    });
    return filterHookData(hook, resolveData);
}
async function createHook(runId, data, config) {
    return makeRequest({
        endpoint: `/v1/hooks/create`,
        options: {
            method: 'POST',
            body: JSON.stringify({
                runId,
                ...data,
            }, dateToStringReplacer),
        },
        config,
        schema: HookSchema,
    });
}
async function getHookByToken(token, config) {
    return makeRequest({
        endpoint: `/v1/hooks/by-token?token=${encodeURIComponent(token)}`,
        options: {
            method: 'GET',
        },
        config,
        schema: HookSchema,
    });
}
async function disposeHook(hookId, config) {
    return makeRequest({
        endpoint: `/v1/hooks/${hookId}`,
        options: { method: 'DELETE' },
        config,
        schema: HookSchema,
    });
}

/**
 * Wire format schema for workflow runs coming from the backend.
 * The backend returns error as a JSON string, not an object, so we need
 * a schema that accepts the wire format before deserialization.
 *
 * This is used for validation in makeRequest(), then deserializeError()
 * transforms the string into the expected StructuredError object.
 */
const WorkflowRunWireBaseSchema = WorkflowRunBaseSchema.omit({
    error: true,
}).extend({
    // Backend returns error as a JSON string, not an object
    error: z$1.string().optional(),
});
// Wire schema for resolved data (full input/output)
const WorkflowRunWireSchema = WorkflowRunWireBaseSchema;
// Wire schema for lazy mode with refs instead of data
const WorkflowRunWireWithRefsSchema = WorkflowRunWireBaseSchema.omit({
    input: true,
    output: true,
}).extend({
    // We discard the results of the refs, so we don't care about the type here
    inputRef: z$1.any().optional(),
    outputRef: z$1.any().optional(),
    input: z$1.array(z$1.any()).optional(),
    output: z$1.any().optional(),
});
// Helper to filter run data based on resolveData setting
function filterRunData(run, resolveData) {
    if (resolveData === 'none') {
        const { inputRef: _inputRef, outputRef: _outputRef, ...rest } = run;
        const deserialized = deserializeError(rest);
        return {
            ...deserialized,
            input: [],
            output: undefined,
        };
    }
    return deserializeError(run);
}
// Functions
/**
 * This query technically works but should be used sparingly till the backend
 * uses CH to resolve this instead of scanning a dynamo table.
 */
async function listWorkflowRuns(params = {}, config) {
    const { workflowName, status, pagination, resolveData = DEFAULT_RESOLVE_DATA_OPTION, } = params;
    const searchParams = new URLSearchParams();
    if (workflowName)
        searchParams.set('workflowName', workflowName);
    if (status)
        searchParams.set('status', status);
    if (pagination?.limit)
        searchParams.set('limit', pagination.limit.toString());
    if (pagination?.cursor)
        searchParams.set('cursor', pagination.cursor);
    if (pagination?.sortOrder)
        searchParams.set('sortOrder', pagination.sortOrder);
    // Map resolveData to internal RemoteRefBehavior
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const endpoint = `/v1/runs${queryString ? `?${queryString}` : ''}`;
    const response = (await makeRequest({
        endpoint,
        options: { method: 'GET' },
        config,
        schema: PaginatedResponseSchema(remoteRefBehavior === 'lazy'
            ? WorkflowRunWireWithRefsSchema
            : WorkflowRunWireSchema),
    }));
    return {
        ...response,
        data: response.data.map((run) => filterRunData(run, resolveData)),
    };
}
async function createWorkflowRun(data, config) {
    const run = await makeRequest({
        endpoint: '/v1/runs/create',
        options: {
            method: 'POST',
            body: JSON.stringify(data, dateToStringReplacer),
        },
        config,
        schema: WorkflowRunWireSchema,
    });
    return deserializeError(run);
}
async function getWorkflowRun(id, params, config) {
    const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION;
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    const searchParams = new URLSearchParams();
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const endpoint = `/v1/runs/${id}${queryString ? `?${queryString}` : ''}`;
    try {
        const run = await makeRequest({
            endpoint,
            options: { method: 'GET' },
            config,
            schema: (remoteRefBehavior === 'lazy'
                ? WorkflowRunWireWithRefsSchema
                : WorkflowRunWireSchema),
        });
        return filterRunData(run, resolveData);
    }
    catch (error) {
        if (error instanceof WorkflowAPIError && error.status === 404) {
            throw new WorkflowRunNotFoundError(id);
        }
        throw error;
    }
}
async function updateWorkflowRun(id, data, config) {
    try {
        const serialized = serializeError(data);
        const run = await makeRequest({
            endpoint: `/v1/runs/${id}`,
            options: {
                method: 'PUT',
                body: JSON.stringify(serialized, dateToStringReplacer),
            },
            config,
            schema: WorkflowRunWireSchema,
        });
        return deserializeError(run);
    }
    catch (error) {
        if (error instanceof WorkflowAPIError && error.status === 404) {
            throw new WorkflowRunNotFoundError(id);
        }
        throw error;
    }
}
async function cancelWorkflowRun(id, params, config) {
    const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION;
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    const searchParams = new URLSearchParams();
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const endpoint = `/v1/runs/${id}/cancel${queryString ? `?${queryString}` : ''}`;
    try {
        const run = await makeRequest({
            endpoint,
            options: { method: 'PUT' },
            config,
            schema: (remoteRefBehavior === 'lazy'
                ? WorkflowRunWireWithRefsSchema
                : WorkflowRunWireSchema),
        });
        return filterRunData(run, resolveData);
    }
    catch (error) {
        if (error instanceof WorkflowAPIError && error.status === 404) {
            throw new WorkflowRunNotFoundError(id);
        }
        throw error;
    }
}
async function pauseWorkflowRun(id, params, config) {
    const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION;
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    const searchParams = new URLSearchParams();
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const endpoint = `/v1/runs/${id}/pause${queryString ? `?${queryString}` : ''}`;
    try {
        const run = await makeRequest({
            endpoint,
            options: { method: 'PUT' },
            config,
            schema: (remoteRefBehavior === 'lazy'
                ? WorkflowRunWireWithRefsSchema
                : WorkflowRunWireSchema),
        });
        return filterRunData(run, resolveData);
    }
    catch (error) {
        if (error instanceof WorkflowAPIError && error.status === 404) {
            throw new WorkflowRunNotFoundError(id);
        }
        throw error;
    }
}
async function resumeWorkflowRun(id, params, config) {
    const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION;
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    const searchParams = new URLSearchParams();
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const endpoint = `/v1/runs/${id}/resume${queryString ? `?${queryString}` : ''}`;
    try {
        const run = await makeRequest({
            endpoint,
            options: { method: 'PUT' },
            config,
            schema: (remoteRefBehavior === 'lazy'
                ? WorkflowRunWireWithRefsSchema
                : WorkflowRunWireSchema),
        });
        return filterRunData(run, resolveData);
    }
    catch (error) {
        if (error instanceof WorkflowAPIError && error.status === 404) {
            throw new WorkflowRunNotFoundError(id);
        }
        throw error;
    }
}

/**
 * Wire format schema for steps coming from the backend.
 * The backend returns error as a JSON string, not an object, so we need
 * a schema that accepts the wire format before deserialization.
 *
 * This is used for validation in makeRequest(), then deserializeStepError()
 * transforms the string into the expected StructuredError object.
 */
const StepWireSchema = StepSchema.omit({
    error: true,
}).extend({
    // Backend returns error as a JSON string, not an object
    error: z$1.string().optional(),
});
// Wire schema for lazy mode with refs instead of data
const StepWireWithRefsSchema = StepWireSchema.omit({
    input: true,
    output: true,
}).extend({
    // We discard the results of the refs, so we don't care about the type here
    inputRef: z$1.any().optional(),
    outputRef: z$1.any().optional(),
    input: z$1.array(z$1.any()).optional(),
    output: z$1.any().optional(),
});
// Helper to filter step data based on resolveData setting
function filterStepData(step, resolveData) {
    if (resolveData === 'none') {
        const { inputRef: _inputRef, outputRef: _outputRef, ...rest } = step;
        const deserialized = deserializeError(rest);
        return {
            ...deserialized,
            input: [],
            output: undefined,
        };
    }
    return deserializeError(step);
}
// Functions
async function listWorkflowRunSteps(params, config) {
    const { runId, pagination, resolveData = DEFAULT_RESOLVE_DATA_OPTION, } = params;
    const searchParams = new URLSearchParams();
    if (pagination?.cursor)
        searchParams.set('cursor', pagination.cursor);
    if (pagination?.limit)
        searchParams.set('limit', pagination.limit.toString());
    if (pagination?.sortOrder)
        searchParams.set('sortOrder', pagination.sortOrder);
    // Map resolveData to internal RemoteRefBehavior
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const endpoint = `/v1/runs/${runId}/steps${queryString ? `?${queryString}` : ''}`;
    const response = (await makeRequest({
        endpoint,
        options: { method: 'GET' },
        config,
        schema: PaginatedResponseSchema(remoteRefBehavior === 'lazy' ? StepWireWithRefsSchema : StepWireSchema),
    }));
    return {
        ...response,
        data: response.data.map((step) => filterStepData(step, resolveData)),
    };
}
async function createStep(runId, data, config) {
    const step = await makeRequest({
        endpoint: `/v1/runs/${runId}/steps`,
        options: {
            method: 'POST',
            body: JSON.stringify(data, dateToStringReplacer),
        },
        config,
        schema: StepWireSchema,
    });
    return deserializeError(step);
}
async function updateStep(runId, stepId, data, config) {
    const serialized = serializeError(data);
    const step = await makeRequest({
        endpoint: `/v1/runs/${runId}/steps/${stepId}`,
        options: {
            method: 'PUT',
            body: JSON.stringify(serialized, dateToStringReplacer),
        },
        config,
        schema: StepWireSchema,
    });
    return deserializeError(step);
}
async function getStep(runId, stepId, params, config) {
    const resolveData = params?.resolveData ?? DEFAULT_RESOLVE_DATA_OPTION;
    const remoteRefBehavior = resolveData === 'none' ? 'lazy' : 'resolve';
    const searchParams = new URLSearchParams();
    searchParams.set('remoteRefBehavior', remoteRefBehavior);
    const queryString = searchParams.toString();
    const endpoint = runId
        ? `/v1/runs/${runId}/steps/${stepId}${queryString ? `?${queryString}` : ''}`
        : `/v1/steps/${stepId}${queryString ? `?${queryString}` : ''}`;
    const step = await makeRequest({
        endpoint,
        options: { method: 'GET' },
        config,
        schema: (remoteRefBehavior === 'lazy'
            ? StepWireWithRefsSchema
            : StepWireSchema),
    });
    return filterStepData(step, resolveData);
}

function createStorage(config) {
    return {
        // Storage interface with namespaced methods
        runs: {
            create: (data) => createWorkflowRun(data, config),
            get: (id, params) => getWorkflowRun(id, params, config),
            update: (id, data) => updateWorkflowRun(id, data, config),
            list: (params) => listWorkflowRuns(params, config),
            cancel: (id, params) => cancelWorkflowRun(id, params, config),
            pause: (id, params) => pauseWorkflowRun(id, params, config),
            resume: (id, params) => resumeWorkflowRun(id, params, config),
        },
        steps: {
            create: (runId, data) => createStep(runId, data, config),
            get: (runId, stepId, params) => getStep(runId, stepId, params, config),
            update: (runId, stepId, data) => updateStep(runId, stepId, data, config),
            list: (params) => listWorkflowRunSteps(params, config),
        },
        events: {
            create: (runId, data, params) => createWorkflowRunEvent(runId, data, params, config),
            list: (params) => getWorkflowRunEvents(params, config),
            listByCorrelationId: (params) => getWorkflowRunEvents(params, config),
        },
        hooks: {
            create: (runId, data) => createHook(runId, data, config),
            get: (hookId, params) => getHook(hookId, params, config),
            getByToken: (token) => getHookByToken(token, config),
            list: (params) => listHooks(params, config),
            dispose: (hookId) => disposeHook(hookId, config),
        },
    };
}

function getStreamUrl(name, httpConfig) {
    return new URL(`${httpConfig.baseUrl}/v1/stream/${encodeURIComponent(name)}`);
}
function createStreamer(config) {
    return {
        async writeToStream(name, chunk) {
            const httpConfig = await getHttpConfig(config);
            await fetch(getStreamUrl(name, httpConfig), {
                method: 'PUT',
                body: chunk,
                headers: httpConfig.headers,
                duplex: 'half',
            });
        },
        async closeStream(name) {
            const httpConfig = await getHttpConfig(config);
            httpConfig.headers.set('X-Stream-Done', 'true');
            await fetch(getStreamUrl(name, httpConfig), {
                method: 'PUT',
                headers: httpConfig.headers,
            });
        },
        async readFromStream(name, startIndex) {
            const httpConfig = await getHttpConfig(config);
            const url = getStreamUrl(name, httpConfig);
            if (typeof startIndex === 'number') {
                url.searchParams.set('startIndex', String(startIndex));
            }
            const res = await fetch(url, { headers: httpConfig.headers });
            if (!res.ok)
                throw new Error(`Failed to fetch stream: ${res.status}`);
            return res.body;
        },
    };
}

function createVercelWorld(config) {
    return {
        ...createQueue(config),
        ...createStorage(config),
        ...createStreamer(config),
    };
}

const require$1 = createRequire(join(process.cwd(), 'index.js'));
let worldCache;
let stubbedWorldCache;
function defaultWorld() {
    if (process.env.VERCEL_DEPLOYMENT_ID) {
        return 'vercel';
    }
    return 'embedded';
}
/**
 * Create a new world instance based on environment variables.
 * WORKFLOW_TARGET_WORLD is used to determine the target world.
 * All other environment variables are specific to the target world
 */
const createWorld = () => {
    const targetWorld = process.env.WORKFLOW_TARGET_WORLD || defaultWorld();
    if (targetWorld === 'vercel') {
        return createVercelWorld({
            baseUrl: process.env.WORKFLOW_VERCEL_PROXY_URL,
            token: process.env.WORKFLOW_VERCEL_AUTH_TOKEN,
            projectConfig: {
                environment: process.env.WORKFLOW_VERCEL_ENV,
                projectId: process.env.WORKFLOW_VERCEL_PROJECT,
                teamId: process.env.WORKFLOW_VERCEL_TEAM,
            },
        });
    }
    if (targetWorld === 'embedded') {
        return createEmbeddedWorld({
            dataDir: process.env.WORKFLOW_EMBEDDED_DATA_DIR,
        });
    }
    const mod = require$1(targetWorld);
    if (typeof mod === 'function') {
        return mod();
    }
    else if (typeof mod.default === 'function') {
        return mod.default();
    }
    else if (typeof mod.createWorld === 'function') {
        return mod.createWorld();
    }
    throw new Error(`Invalid target world module: ${targetWorld}, must export a default function or createWorld function that returns a World instance.`);
};
/**
 * Some functions from the world are needed at build time, but we do NOT want
 * to cache the world in those instances for general use, since we don't have
 * the correct environment variables set yet. This is a safe function to
 * call at build time, that only gives access to non-environment-bound world
 * functions. The only binding value should be the target world.
 * Once we migrate to a file-based configuration (workflow.config.ts), we should
 * be able to re-combine getWorld and getWorldHandlers into one singleton.
 */
const getWorldHandlers = () => {
    if (stubbedWorldCache) {
        return stubbedWorldCache;
    }
    const _world = createWorld();
    stubbedWorldCache = _world;
    return {
        createQueueHandler: _world.createQueueHandler,
    };
};
const getWorld = () => {
    if (worldCache) {
        return worldCache;
    }
    worldCache = createWorld();
    return worldCache;
};

// OpenTelemetry trace context for distributed tracing
const TraceCarrierSchema = z$1.record(z$1.string(), z$1.string());
const WorkflowInvokePayloadSchema = z$1.object({
    runId: z$1.string(),
    traceCarrier: TraceCarrierSchema.optional(),
});
const StepInvokePayloadSchema = z$1.object({
    workflowName: z$1.string(),
    workflowRunId: z$1.string(),
    workflowStartedAt: z$1.number(),
    stepId: z$1.string(),
    traceCarrier: TraceCarrierSchema.optional(),
});

const WORKFLOW_USE_STEP = Symbol.for('WORKFLOW_USE_STEP');
const WORKFLOW_CREATE_HOOK = Symbol.for('WORKFLOW_CREATE_HOOK');
const WORKFLOW_SLEEP = Symbol.for('WORKFLOW_SLEEP');
const WORKFLOW_GET_STREAM_ID = Symbol.for('WORKFLOW_GET_STREAM_ID');
const STREAM_NAME_SYMBOL = Symbol.for('WORKFLOW_STREAM_NAME');
const STREAM_TYPE_SYMBOL = Symbol.for('WORKFLOW_STREAM_TYPE');
const BODY_INIT_SYMBOL = Symbol.for('BODY_INIT');
const WEBHOOK_RESPONSE_WRITABLE = Symbol.for('WEBHOOK_RESPONSE_WRITABLE');
const STEP_FUNCTION_NAME_SYMBOL = Symbol.for('WORKFLOW_STEP_FUNCTION_NAME');

/**
 * Detect if a readable stream is a byte stream.
 *
 * @param stream
 * @returns `"bytes"` if the stream is a byte stream, `undefined` otherwise
 */
function getStreamType(stream) {
    try {
        const reader = stream.getReader({ mode: 'byob' });
        reader.releaseLock();
        return 'bytes';
    }
    catch { }
}
function getSerializeStream(reducers) {
    const encoder = new TextEncoder();
    const stream = new TransformStream({
        transform(chunk, controller) {
            try {
                const serialized = devalue.stringify(chunk, reducers);
                controller.enqueue(encoder.encode(`${serialized}\n`));
            }
            catch (error) {
                controller.error(new WorkflowRuntimeError("Failed to serialize stream chunk. Ensure you're passing serializable types (plain objects, arrays, primitives, Date, RegExp, Map, Set).", { slug: 'serialization-failed', cause: error }));
            }
        },
    });
    return stream;
}
function getDeserializeStream(revivers) {
    const decoder = new TextDecoder();
    let buffer = '';
    const stream = new TransformStream({
        transform(chunk, controller) {
            // Append new chunk to buffer
            buffer += decoder.decode(chunk, { stream: true });
            // Process all complete lines
            while (true) {
                const newlineIndex = buffer.indexOf('\n');
                if (newlineIndex === -1)
                    break;
                const line = buffer.slice(0, newlineIndex);
                buffer = buffer.slice(newlineIndex + 1);
                if (line.length > 0) {
                    const obj = devalue.parse(line, revivers);
                    controller.enqueue(obj);
                }
            }
        },
        flush(controller) {
            // Process any remaining data in the buffer at the end of the stream
            if (buffer && buffer.length > 0) {
                const obj = devalue.parse(buffer, revivers);
                controller.enqueue(obj);
            }
        },
    });
    return stream;
}
class WorkflowServerReadableStream extends ReadableStream {
    #reader;
    constructor(name, startIndex) {
        if (typeof name !== 'string' || name.length === 0) {
            throw new Error(`"name" is required, got "${name}"`);
        }
        super({
            // @ts-expect-error Not sure why TypeScript is complaining about this
            type: 'bytes',
            pull: async (controller) => {
                let reader = this.#reader;
                if (!reader) {
                    const world = getWorld();
                    const stream = await world.readFromStream(name, startIndex);
                    reader = this.#reader = stream.getReader();
                }
                if (!reader) {
                    controller.error(new Error('Failed to get reader'));
                    return;
                }
                const result = await reader.read();
                if (result.done) {
                    this.#reader = undefined;
                    controller.close();
                }
                else {
                    controller.enqueue(result.value);
                }
            },
        });
    }
}
class WorkflowServerWritableStream extends WritableStream {
    constructor(name) {
        if (typeof name !== 'string' || name.length === 0) {
            throw new Error(`"name" is required, got "${name}"`);
        }
        const world = getWorld();
        super({
            async write(chunk) {
                await world.writeToStream(name, chunk);
            },
            async close() {
                await world.closeStream(name);
            },
        });
    }
}
function revive(str) {
    // biome-ignore lint/security/noGlobalEval: Eval is safe here - we are only passing value from `devalue.stringify()`
    // biome-ignore lint/complexity/noCommaOperator: This is how you do global scope eval
    return (0, eval)(`(${str})`);
}
function getCommonReducers(global = globalThis) {
    const abToBase64 = (value, offset, length) => {
        // Avoid returning falsy value for zero-length buffers
        if (length === 0)
            return '.';
        return Buffer.from(value, offset, length).toString('base64');
    };
    const viewToBase64 = (value) => abToBase64(value.buffer, value.byteOffset, value.byteLength);
    return {
        ArrayBuffer: (value) => value instanceof global.ArrayBuffer &&
            abToBase64(value, 0, value.byteLength),
        BigInt: (value) => typeof value === 'bigint' && value.toString(),
        BigInt64Array: (value) => value instanceof global.BigInt64Array && viewToBase64(value),
        BigUint64Array: (value) => value instanceof global.BigUint64Array && viewToBase64(value),
        Date: (value) => {
            if (!(value instanceof global.Date))
                return false;
            const valid = !Number.isNaN(value.getDate());
            // Note: "." is to avoid returning a falsy value when the date is invalid
            return valid ? value.toISOString() : '.';
        },
        Error: (value) => {
            if (!(value instanceof global.Error))
                return false;
            return {
                name: value.name,
                message: value.message,
                stack: value.stack,
            };
        },
        Float32Array: (value) => value instanceof global.Float32Array && viewToBase64(value),
        Float64Array: (value) => value instanceof global.Float64Array && viewToBase64(value),
        Headers: (value) => value instanceof global.Headers && Array.from(value),
        Int8Array: (value) => value instanceof global.Int8Array && viewToBase64(value),
        Int16Array: (value) => value instanceof global.Int16Array && viewToBase64(value),
        Int32Array: (value) => value instanceof global.Int32Array && viewToBase64(value),
        Map: (value) => value instanceof global.Map && Array.from(value),
        RegExp: (value) => value instanceof global.RegExp && {
            source: value.source,
            flags: value.flags,
        },
        Request: (value) => {
            if (!(value instanceof global.Request))
                return false;
            const data = {
                method: value.method,
                url: value.url,
                headers: value.headers,
                body: value.body,
                duplex: value.duplex,
            };
            const responseWritable = value[WEBHOOK_RESPONSE_WRITABLE];
            if (responseWritable) {
                data.responseWritable = responseWritable;
            }
            return data;
        },
        Response: (value) => {
            if (!(value instanceof global.Response))
                return false;
            return {
                type: value.type,
                url: value.url,
                status: value.status,
                statusText: value.statusText,
                headers: value.headers,
                body: value.body,
                redirected: value.redirected,
            };
        },
        Set: (value) => value instanceof global.Set && Array.from(value),
        StepFunction: (value) => {
            if (typeof value !== 'function')
                return false;
            const stepName = value[STEP_FUNCTION_NAME_SYMBOL];
            return typeof stepName === 'string' ? stepName : false;
        },
        URL: (value) => value instanceof global.URL && value.href,
        URLSearchParams: (value) => {
            if (!(value instanceof global.URLSearchParams))
                return false;
            // Avoid returning a falsy value when the URLSearchParams is empty
            if (value.size === 0)
                return '.';
            return String(value);
        },
        Uint8Array: (value) => value instanceof global.Uint8Array && viewToBase64(value),
        Uint8ClampedArray: (value) => value instanceof global.Uint8ClampedArray && viewToBase64(value),
        Uint16Array: (value) => value instanceof global.Uint16Array && viewToBase64(value),
        Uint32Array: (value) => value instanceof global.Uint32Array && viewToBase64(value),
    };
}
/**
 * Reducers for serialization boundary from the client side, passing arguments
 * to the workflow handler.
 *
 * @param global
 * @param ops
 * @returns
 */
function getExternalReducers(global = globalThis, ops) {
    return {
        ...getCommonReducers(global),
        ReadableStream: (value) => {
            if (!(value instanceof global.ReadableStream))
                return false;
            // Stream must not be locked when passing across execution boundary
            if (value.locked) {
                throw new Error('ReadableStream is locked');
            }
            const name = global.crypto.randomUUID();
            const type = getStreamType(value);
            const writable = new WorkflowServerWritableStream(name);
            if (type === 'bytes') {
                ops.push(value.pipeTo(writable));
            }
            else {
                ops.push(value
                    .pipeThrough(getSerializeStream(getExternalReducers(global, ops)))
                    .pipeTo(writable));
            }
            const s = { name };
            if (type)
                s.type = type;
            return s;
        },
        WritableStream: (value) => {
            if (!(value instanceof global.WritableStream))
                return false;
            const name = global.crypto.randomUUID();
            ops.push(new WorkflowServerReadableStream(name)
                .pipeThrough(getDeserializeStream(getExternalRevivers(global, ops)))
                .pipeTo(value));
            return { name };
        },
    };
}
/**
 * Reducers for serialization boundary from within the workflow execution
 * environment, passing return value to the client side and into step arguments.
 *
 * @param global
 * @returns
 */
function getWorkflowReducers(global = globalThis) {
    return {
        ...getCommonReducers(global),
        // Readable/Writable streams from within the workflow execution environment
        // are simply "handles" that can be passed around to other steps.
        ReadableStream: (value) => {
            if (!(value instanceof global.ReadableStream))
                return false;
            // Check if this is a fake stream storing BodyInit from Request/Response constructor
            const bodyInit = value[BODY_INIT_SYMBOL];
            if (bodyInit !== undefined) {
                // This is a fake stream - serialize the BodyInit directly
                // devalue will handle serializing strings, Uint8Array, etc.
                return { bodyInit };
            }
            const name = value[STREAM_NAME_SYMBOL];
            if (!name) {
                throw new Error('ReadableStream `name` is not set');
            }
            const s = { name };
            const type = value[STREAM_TYPE_SYMBOL];
            if (type)
                s.type = type;
            return s;
        },
        WritableStream: (value) => {
            if (!(value instanceof global.WritableStream))
                return false;
            const name = value[STREAM_NAME_SYMBOL];
            if (!name) {
                throw new Error('WritableStream `name` is not set');
            }
            return { name };
        },
    };
}
/**
 * Reducers for serialization boundary from within the step execution
 * environment, passing return value to the workflow handler.
 *
 * @param global
 * @param ops
 * @returns
 */
function getStepReducers(global = globalThis, ops) {
    return {
        ...getCommonReducers(global),
        ReadableStream: (value) => {
            if (!(value instanceof global.ReadableStream))
                return false;
            // Stream must not be locked when passing across execution boundary
            if (value.locked) {
                throw new Error('ReadableStream is locked');
            }
            // Check if the stream already has the name symbol set, in which case
            // it's already being sunk to the server and we can just return the
            // name and type.
            let name = value[STREAM_NAME_SYMBOL];
            let type = value[STREAM_TYPE_SYMBOL];
            if (!name) {
                name = global.crypto.randomUUID();
                type = getStreamType(value);
                const writable = new WorkflowServerWritableStream(name);
                if (type === 'bytes') {
                    ops.push(value.pipeTo(writable));
                }
                else {
                    ops.push(value
                        .pipeThrough(getSerializeStream(getStepReducers(global, ops)))
                        .pipeTo(writable));
                }
            }
            const s = { name };
            if (type)
                s.type = type;
            return s;
        },
        WritableStream: (value) => {
            if (!(value instanceof global.WritableStream))
                return false;
            let name = value[STREAM_NAME_SYMBOL];
            if (!name) {
                name = global.crypto.randomUUID();
                ops.push(new WorkflowServerReadableStream(name)
                    .pipeThrough(getDeserializeStream(getStepRevivers(global, ops)))
                    .pipeTo(value));
            }
            return { name };
        },
    };
}
function getCommonRevivers(global = globalThis) {
    function reviveArrayBuffer(value) {
        // Handle sentinel value for zero-length buffers
        const base64 = value === '.' ? '' : value;
        const buffer = Buffer.from(base64, 'base64');
        const arrayBuffer = new global.ArrayBuffer(buffer.length);
        const uint8Array = new global.Uint8Array(arrayBuffer);
        uint8Array.set(buffer);
        return arrayBuffer;
    }
    return {
        ArrayBuffer: reviveArrayBuffer,
        BigInt: (value) => global.BigInt(value),
        BigInt64Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.BigInt64Array(ab);
        },
        BigUint64Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.BigUint64Array(ab);
        },
        Date: (value) => new global.Date(value),
        Error: (value) => {
            const error = new global.Error(value.message);
            error.name = value.name;
            error.stack = value.stack;
            return error;
        },
        Float32Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Float32Array(ab);
        },
        Float64Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Float64Array(ab);
        },
        Headers: (value) => new global.Headers(value),
        Int8Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Int8Array(ab);
        },
        Int16Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Int16Array(ab);
        },
        Int32Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Int32Array(ab);
        },
        Map: (value) => new global.Map(value),
        RegExp: (value) => new global.RegExp(value.source, value.flags),
        Set: (value) => new global.Set(value),
        StepFunction: (value) => {
            const stepFn = getStepFunction(value);
            if (!stepFn) {
                throw new Error(`Step function "${value}" not found. Make sure the step function is registered.`);
            }
            return stepFn;
        },
        URL: (value) => new global.URL(value),
        URLSearchParams: (value) => new global.URLSearchParams(value === '.' ? '' : value),
        Uint8Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Uint8Array(ab);
        },
        Uint8ClampedArray: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Uint8ClampedArray(ab);
        },
        Uint16Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Uint16Array(ab);
        },
        Uint32Array: (value) => {
            const ab = reviveArrayBuffer(value);
            return new global.Uint32Array(ab);
        },
    };
}
/**
 * Revivers for deserialization boundary from the client side,
 * receiving the return value from the workflow handler.
 *
 * @param global
 * @param ops
 */
function getExternalRevivers(global = globalThis, ops) {
    return {
        ...getCommonRevivers(global),
        Request: (value) => {
            return new global.Request(value.url, {
                method: value.method,
                headers: new global.Headers(value.headers),
                body: value.body,
                duplex: value.duplex,
            });
        },
        Response: (value) => {
            // Note: Response constructor only accepts status, statusText, and headers
            // The type, url, and redirected properties are read-only and set by the constructor
            return new global.Response(value.body, {
                status: value.status,
                statusText: value.statusText,
                headers: new global.Headers(value.headers),
            });
        },
        ReadableStream: (value) => {
            // If this has bodyInit, it came from a Response constructor
            // Convert it to a REAL stream now that we're outside the workflow
            if ('bodyInit' in value) {
                const bodyInit = value.bodyInit;
                // Use the native Response constructor to properly convert BodyInit to ReadableStream
                const response = new global.Response(bodyInit);
                return response.body;
            }
            const readable = new WorkflowServerReadableStream(value.name, value.startIndex);
            if (value.type === 'bytes') {
                return readable;
            }
            else {
                const transform = getDeserializeStream(getExternalRevivers(global, ops));
                ops.push(readable.pipeTo(transform.writable));
                return transform.readable;
            }
        },
        WritableStream: (value) => {
            const serialize = getSerializeStream(getExternalReducers(global, ops));
            ops.push(serialize.readable.pipeTo(new WorkflowServerWritableStream(value.name)));
            return serialize.writable;
        },
    };
}
/**
 * Revivers for deserialization boundary from within the workflow execution
 * environment, receiving arguments from the client side, and return values
 * from the steps.
 *
 * @param global
 * @returns
 */
function getWorkflowRevivers(global = globalThis) {
    return {
        ...getCommonRevivers(global),
        Request: (value) => {
            Object.setPrototypeOf(value, global.Request.prototype);
            const responseWritable = value.responseWritable;
            if (responseWritable) {
                value[WEBHOOK_RESPONSE_WRITABLE] = responseWritable;
                delete value.responseWritable;
                value.respondWith = () => {
                    throw new Error('`respondWith()` must be called from within a step function');
                };
            }
            return value;
        },
        Response: (value) => {
            Object.setPrototypeOf(value, global.Response.prototype);
            return value;
        },
        ReadableStream: (value) => {
            // Check if this is a BodyInit that should be wrapped in a fake stream
            if ('bodyInit' in value) {
                // Recreate the fake stream with the BodyInit
                return Object.create(global.ReadableStream.prototype, {
                    [BODY_INIT_SYMBOL]: {
                        value: value.bodyInit,
                        writable: false,
                    },
                });
            }
            // Regular stream handling
            return Object.create(global.ReadableStream.prototype, {
                [STREAM_NAME_SYMBOL]: {
                    value: value.name,
                    writable: false,
                },
                [STREAM_TYPE_SYMBOL]: {
                    value: value.type,
                    writable: false,
                },
            });
        },
        WritableStream: (value) => {
            return Object.create(global.WritableStream.prototype, {
                [STREAM_NAME_SYMBOL]: {
                    value: value.name,
                    writable: false,
                },
            });
        },
    };
}
/**
 * Revivers for deserialization boundary from within the step execution
 * environment, receiving arguments from the workflow handler.
 *
 * @param global
 * @param ops
 * @returns
 */
function getStepRevivers(global = globalThis, ops) {
    return {
        ...getCommonRevivers(global),
        Request: (value) => {
            const responseWritable = value.responseWritable;
            const request = new global.Request(value.url, {
                method: value.method,
                headers: new global.Headers(value.headers),
                body: value.body,
                duplex: value.duplex,
            });
            if (responseWritable) {
                request.respondWith = async (response) => {
                    const writer = responseWritable.getWriter();
                    await writer.write(response);
                    await writer.close();
                };
            }
            return request;
        },
        Response: (value) => {
            // Note: Response constructor only accepts status, statusText, and headers
            // The type, url, and redirected properties are read-only and set by the constructor
            return new global.Response(value.body, {
                status: value.status,
                statusText: value.statusText,
                headers: new global.Headers(value.headers),
            });
        },
        ReadableStream: (value) => {
            // If this has bodyInit, it came from a Response constructor
            // Convert it to a REAL stream now that we're in the step environment
            if ('bodyInit' in value) {
                const bodyInit = value.bodyInit;
                // Use the native Response constructor to properly convert BodyInit to ReadableStream
                const response = new global.Response(bodyInit);
                return response.body;
            }
            const readable = new WorkflowServerReadableStream(value.name);
            if (value.type === 'bytes') {
                return readable;
            }
            else {
                const transform = getDeserializeStream(getStepRevivers(global, ops));
                ops.push(readable.pipeTo(transform.writable));
                return transform.readable;
            }
        },
        WritableStream: (value) => {
            const serialize = getSerializeStream(getStepReducers(global, ops));
            ops.push(serialize.readable.pipeTo(new WorkflowServerWritableStream(value.name)));
            return serialize.writable;
        },
    };
}
/**
 * Called from the `start()` function to serialize the workflow arguments
 * into a format that can be saved to the database and then hydrated from
 * within the workflow execution environment.
 *
 * @param value
 * @param global
 * @returns The dehydrated value, ready to be inserted into the database
 */
function dehydrateWorkflowArguments(value, ops, global = globalThis) {
    try {
        const str = devalue.stringify(value, getExternalReducers(global, ops));
        return revive(str);
    }
    catch (error) {
        throw new WorkflowRuntimeError(`Failed to serialize workflow arguments. Ensure you're passing serializable types (plain objects, arrays, primitives, Date, RegExp, Map, Set).`, { slug: 'serialization-failed', cause: error });
    }
}
/**
 * Called from workflow execution environment to hydrate the workflow
 * arguments from the database at the start of workflow execution.
 *
 * @param value
 * @param ops
 * @param global
 * @returns The hydrated value
 */
function hydrateWorkflowArguments(value, global = globalThis, extraRevivers = {}) {
    const obj = devalue.unflatten(value, {
        ...getWorkflowRevivers(global),
        ...extraRevivers,
    });
    return obj;
}
/**
 * Called at the end of a completed workflow execution to serialize the
 * return value into a format that can be saved to the database.
 *
 * @param value
 * @param global
 * @returns The dehydrated value, ready to be inserted into the database
 */
function dehydrateWorkflowReturnValue(value, global = globalThis) {
    try {
        const str = devalue.stringify(value, getWorkflowReducers(global));
        return revive(str);
    }
    catch (error) {
        throw new WorkflowRuntimeError(`Failed to serialize workflow return value. Ensure you're returning serializable types (plain objects, arrays, primitives, Date, RegExp, Map, Set).`, { slug: 'serialization-failed', cause: error });
    }
}
/**
 * Called from the client side (i.e. the execution environment where
 * the workflow run was initiated from) to hydrate the workflow
 * return value of a completed workflow run.
 *
 * @param value
 * @param global
 * @returns The hydrated return value, ready to be consumed by the client
 */
function hydrateWorkflowReturnValue(value, ops, global = globalThis, extraRevivers = {}) {
    const obj = devalue.unflatten(value, {
        ...getExternalRevivers(global, ops),
        ...extraRevivers,
    });
    return obj;
}
/**
 * Called from the workflow handler when a step is being created.
 * Dehydrates values from within the workflow execution environment
 * into a format that can be saved to the database.
 *
 * @param value
 * @param global
 * @returns The dehydrated value, ready to be inserted into the database
 */
function dehydrateStepArguments(value, global) {
    try {
        const str = devalue.stringify(value, getWorkflowReducers(global));
        return revive(str);
    }
    catch (error) {
        throw new WorkflowRuntimeError(`Failed to serialize step arguments. Ensure you're passing serializable types (plain objects, arrays, primitives, Date, RegExp, Map, Set).`, { slug: 'serialization-failed', cause: error });
    }
}
/**
 * Called from the step handler to hydrate the arguments of a step
 * from the database at the start of the step execution.
 *
 * @param value
 * @param global
 * @returns The hydrated value, ready to be consumed by the step user-code function
 */
function hydrateStepArguments(value, ops, global = globalThis, extraRevivers = {}) {
    const obj = devalue.unflatten(value, {
        ...getStepRevivers(global, ops),
        ...extraRevivers,
    });
    return obj;
}
/**
 * Called from the step handler when a step has completed.
 * Dehydrates values from within the step execution environment
 * into a format that can be saved to the database.
 *
 * @param value
 * @param global
 * @returns The dehydrated value, ready to be inserted into the database
 */
function dehydrateStepReturnValue(value, ops, global = globalThis) {
    try {
        const str = devalue.stringify(value, getStepReducers(global, ops));
        return revive(str);
    }
    catch (error) {
        throw new WorkflowRuntimeError(`Failed to serialize step return value. Ensure you're returning serializable types (plain objects, arrays, primitives, Date, RegExp, Map, Set).`, { slug: 'serialization-failed', cause: error });
    }
}
/**
 * Called from the workflow handler when replaying the event log of a `step_completed` event.
 * Hydrates the return value of a step from the database.
 *
 * @param value
 * @param global
 * @returns The hydrated return value of a step, ready to be consumed by the workflow handler
 */
function hydrateStepReturnValue(value, global = globalThis, extraRevivers = {}) {
    const obj = devalue.unflatten(value, {
        ...getWorkflowRevivers(global),
        ...extraRevivers,
    });
    return obj;
}

/**
 * OpenTelemetry semantic conventions for Vercel Workflow telemetry.
 *
 * This module provides standardized telemetry attributes following OpenTelemetry semantic conventions
 * for instrumenting workflow execution, step processing, and related operations. Each exported function
 * creates a properly formatted attribute object that can be used with OpenTelemetry spans.
 *
 * The semantic conventions are organized into several categories:
 * - **Workflow attributes**: Track workflow lifecycle, status, and metadata
 * - **Step attributes**: Monitor individual step execution, retries, and results
 * - **Queue attributes**: Instrument message queue operations
 * - **Deployment attributes**: Capture deployment environment information
 *
 * All attribute functions are type-safe and leverage existing backend types to ensure
 * consistency between telemetry data and actual system state.
 *
 * @example
 * ```typescript
 * import * as Attribute from './telemetry/semantic-conventions.js';
 *
 * // Set workflow attributes on a span
 * span.setAttributes({
 *   ...Attribute.WorkflowName('my-workflow'),
 *   ...Attribute.WorkflowOperation('start'),
 *   ...Attribute.WorkflowRunStatus('running'),
 * });
 *
 * // Set step attributes
 * span.setAttributes({
 *   ...Attribute.StepName('process-data'),
 *   ...Attribute.StepStatus('completed'),
 *   ...Attribute.StepAttempt(1),
 * });
 * ```
 *
 * @see {@link https://opentelemetry.io/docs/specs/semconv/} OpenTelemetry Semantic Conventions
 * @packageDocumentation
 */
/**
 * Creates a semantic convention function that returns an attribute object.
 * @param name - The attribute name following OpenTelemetry semantic conventions
 * @returns A function that takes a value and returns an attribute object
 */
function SemanticConvention(name) {
    return (value) => ({ [name]: value });
}
// Workflow attributes
/** The name of the workflow being executed */
const WorkflowName = SemanticConvention('workflow.name');
/** The operation being performed on the workflow */
const WorkflowOperation = SemanticConvention('workflow.operation');
/** Unique identifier for a specific workflow run instance */
const WorkflowRunId = SemanticConvention('workflow.run.id');
/** Current status of the workflow run */
const WorkflowRunStatus = SemanticConvention('workflow.run.status');
/** Timestamp when the workflow execution started (Unix timestamp) */
const WorkflowStartedAt = SemanticConvention('workflow.started_at');
/** Number of events processed during workflow execution */
const WorkflowEventsCount = SemanticConvention('workflow.events.count');
/** Number of arguments passed to the workflow */
const WorkflowArgumentsCount = SemanticConvention('workflow.arguments.count');
/** Type of the workflow result */
const WorkflowResultType = SemanticConvention('workflow.result.type');
/** Whether trace context was propagated to this workflow execution */
const WorkflowTracePropagated = SemanticConvention('workflow.trace.propagated');
/** Name of the error that caused workflow failure */
const WorkflowErrorName = SemanticConvention('workflow.error.name');
/** Error message when workflow fails */
const WorkflowErrorMessage = SemanticConvention('workflow.error.message');
/** Number of steps created during workflow execution */
const WorkflowStepsCreated = SemanticConvention('workflow.steps.created');
// Step attributes
/** Name of the step function being executed */
const StepName = SemanticConvention('step.name');
/** Unique identifier for the step instance */
const StepId = SemanticConvention('step.id');
/** Current attempt number for step execution (starts at 1) */
const StepAttempt = SemanticConvention('step.attempt');
/** Current status of the step */
const StepStatus = SemanticConvention('step.status');
/** Maximum number of retries allowed for this step */
const StepMaxRetries = SemanticConvention('step.max_retries');
/** Whether trace context was propagated to this step execution */
const StepTracePropagated = SemanticConvention('step.trace.propagated');
/** Whether the step was skipped during execution */
const StepSkipped = SemanticConvention('step.skipped');
/** Reason why the step was skipped */
const StepSkipReason = SemanticConvention('step.skip_reason');
/** Number of arguments passed to the step function */
const StepArgumentsCount = SemanticConvention('step.arguments.count');
/** Type of the step result */
const StepResultType = SemanticConvention('step.result.type');
/** Name of the error that caused step failure */
const StepErrorName = SemanticConvention('step.error.name');
/** Error message when step fails */
const StepErrorMessage = SemanticConvention('step.error.message');
/** Whether the step failed with a fatal error (no retries) */
const StepFatalError = SemanticConvention('step.fatal_error');
/** Whether all retry attempts have been exhausted */
const StepRetryExhausted = SemanticConvention('step.retry.exhausted');
/** Number of seconds to wait before next retry attempt */
const StepRetryTimeoutSeconds = SemanticConvention('step.retry.timeout_seconds');
/** Whether the step will be retried after this failure */
const StepRetryWillRetry = SemanticConvention('step.retry.will_retry');
// Queue attributes
/** Name of the queue being used for message processing */
const QueueName = SemanticConvention('queue.name');
// Deployment attributes
/** Unique identifier for the deployment environment */
const DeploymentId = SemanticConvention('deployment.id');
// Hook attributes
/** Token identifying a specific hook */
const HookToken = SemanticConvention('workflow.hook.token');
/** Unique identifier for a hook instance */
const HookId = SemanticConvention('workflow.hook.id');
/** Whether a hook was found by its token */
const HookFound = SemanticConvention('workflow.hook.found');

/**
 * Builds a workflow suspension log message based on the counts of steps, hooks, and waits.
 * @param runId - The workflow run ID
 * @param stepCount - Number of steps to be enqueued
 * @param hookCount - Number of hooks to be enqueued
 * @param waitCount - Number of waits to be enqueued
 * @returns The formatted log message or null if all counts are 0
 */
function buildWorkflowSuspensionMessage(runId, stepCount, hookCount, waitCount) {
    if (stepCount === 0 && hookCount === 0 && waitCount === 0) {
        return null;
    }
    const parts = [];
    if (stepCount > 0) {
        parts.push(`${stepCount} ${stepCount === 1 ? 'step' : 'steps'}`);
    }
    if (hookCount > 0) {
        parts.push(`${hookCount} ${hookCount === 1 ? 'hook' : 'hooks'}`);
    }
    if (waitCount > 0) {
        parts.push(`${waitCount} ${waitCount === 1 ? 'timer' : 'timers'}`);
    }
    const resumeMsgParts = [];
    if (stepCount > 0) {
        resumeMsgParts.push('steps are completed');
    }
    if (hookCount > 0) {
        resumeMsgParts.push('hooks are received');
    }
    if (waitCount > 0) {
        resumeMsgParts.push('timers have elapsed');
    }
    const resumeMsg = resumeMsgParts.join(' and ');
    return `[Workflows] "${runId}" - ${parts.join(' and ')} to be enqueued\n  Workflow will suspend and resume when ${resumeMsg}`;
}
/**
 * Generates a stream ID for a workflow run.
 * User-defined streams include a "user" segment for isolation from future system-defined streams.
 * Namespaces are base64-encoded to handle characters not allowed in Redis key names.
 *
 * @param runId - The workflow run ID
 * @param namespace - Optional namespace for the stream
 * @returns The stream ID in format: `strm_{ULID}_user_{base64(namespace)?}`
 */
function getWorkflowRunStreamId(runId, namespace) {
    const streamId = `${runId.replace('wrun_', 'strm_')}_user`;
    if (!namespace) {
        return streamId;
    }
    // Base64 encode the namespace to handle special characters that may not be allowed in Redis keys
    const encodedNamespace = Buffer.from(namespace, 'utf-8').toString('base64url');
    return `${streamId}_${encodedNamespace}`;
}
/**
 * A small wrapper around `waitUntil` that also returns
 * the result of the awaited promise.
 */
async function waitedUntil(fn) {
    const result = fn();
    functionsExports.waitUntil(result);
    return result;
}

var EventConsumerResult;
(function (EventConsumerResult) {
    /**
     * Callback consumed the event, but should not be removed from the callbacks list
     */
    EventConsumerResult[EventConsumerResult["Consumed"] = 0] = "Consumed";
    /**
     * Callback did not consume the event, so it should be passed to the next callback
     */
    EventConsumerResult[EventConsumerResult["NotConsumed"] = 1] = "NotConsumed";
    /**
     * Callback consumed the event, and should be removed from the callbacks list
     */
    EventConsumerResult[EventConsumerResult["Finished"] = 2] = "Finished";
})(EventConsumerResult || (EventConsumerResult = {}));
class EventsConsumer {
    eventIndex;
    events = [];
    callbacks = [];
    constructor(events) {
        this.events = events;
        this.eventIndex = 0;
        eventsLogger.debug('EventsConsumer initialized', { events });
    }
    /**
     * Registers a callback function to be called after an event has been consumed
     * by a different callback. The callback can return:
     *  - `EventConsumerResult.Consumed` the event is considered consumed and will not be passed to any other callback, but the callback will remain in the callbacks list
     *  - `EventConsumerResult.NotConsumed` the event is passed to the next callback
     *  - `EventConsumerResult.Finished` the event is considered consumed and the callback is removed from the callbacks list
     *
     * @param fn - The callback function to register.
     */
    subscribe(fn) {
        this.callbacks.push(fn);
        process.nextTick(this.consume);
    }
    consume = () => {
        const currentEvent = this.events[this.eventIndex] ?? null;
        for (let i = 0; i < this.callbacks.length; i++) {
            const callback = this.callbacks[i];
            let handled = EventConsumerResult.NotConsumed;
            try {
                handled = callback(currentEvent);
            }
            catch (error) {
                eventsLogger.error('EventConsumer callback threw an error', { error });
                // Hopefully shouldn't happen, but we don't want to block the workflow
                console.error('EventConsumer callback threw an error', error);
            }
            eventsLogger.debug('EventConsumer callback result', {
                handled: EventConsumerResult[handled],
                eventIndex: this.eventIndex,
                eventId: currentEvent?.eventId,
            });
            if (handled === EventConsumerResult.Consumed ||
                handled === EventConsumerResult.Finished) {
                // consumer handled this event, so increase the event index
                this.eventIndex++;
                // remove the callback if it has finished
                if (handled === EventConsumerResult.Finished) {
                    this.callbacks.splice(i, 1);
                }
                // continue to the next event
                process.nextTick(this.consume);
                return;
            }
        }
    };
}

var alea$1 = {exports: {}};

var alea = alea$1.exports;

var hasRequiredAlea;

function requireAlea () {
	if (hasRequiredAlea) return alea$1.exports;
	hasRequiredAlea = 1;
	(function (module) {
		// A port of an algorithm by Johannes BaagÃ¸e <baagoe@baagoe.com>, 2010
		// http://baagoe.com/en/RandomMusings/javascript/
		// https://github.com/nquinlan/better-random-numbers-for-javascript-mirror
		// Original work is under MIT license -

		// Copyright (C) 2010 by Johannes BaagÃ¸e <baagoe@baagoe.org>
		//
		// Permission is hereby granted, free of charge, to any person obtaining a copy
		// of this software and associated documentation files (the "Software"), to deal
		// in the Software without restriction, including without limitation the rights
		// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
		// copies of the Software, and to permit persons to whom the Software is
		// furnished to do so, subject to the following conditions:
		//
		// The above copyright notice and this permission notice shall be included in
		// all copies or substantial portions of the Software.
		//
		// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
		// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
		// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
		// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
		// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
		// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
		// THE SOFTWARE.



		(function(global, module, define) {

		function Alea(seed) {
		  var me = this, mash = Mash();

		  me.next = function() {
		    var t = 2091639 * me.s0 + me.c * 2.3283064365386963e-10; // 2^-32
		    me.s0 = me.s1;
		    me.s1 = me.s2;
		    return me.s2 = t - (me.c = t | 0);
		  };

		  // Apply the seeding algorithm from Baagoe.
		  me.c = 1;
		  me.s0 = mash(' ');
		  me.s1 = mash(' ');
		  me.s2 = mash(' ');
		  me.s0 -= mash(seed);
		  if (me.s0 < 0) { me.s0 += 1; }
		  me.s1 -= mash(seed);
		  if (me.s1 < 0) { me.s1 += 1; }
		  me.s2 -= mash(seed);
		  if (me.s2 < 0) { me.s2 += 1; }
		  mash = null;
		}

		function copy(f, t) {
		  t.c = f.c;
		  t.s0 = f.s0;
		  t.s1 = f.s1;
		  t.s2 = f.s2;
		  return t;
		}

		function impl(seed, opts) {
		  var xg = new Alea(seed),
		      state = opts && opts.state,
		      prng = xg.next;
		  prng.int32 = function() { return (xg.next() * 0x100000000) | 0; };
		  prng.double = function() {
		    return prng() + (prng() * 0x200000 | 0) * 1.1102230246251565e-16; // 2^-53
		  };
		  prng.quick = prng;
		  if (state) {
		    if (typeof(state) == 'object') copy(state, xg);
		    prng.state = function() { return copy(xg, {}); };
		  }
		  return prng;
		}

		function Mash() {
		  var n = 0xefc8249d;

		  var mash = function(data) {
		    data = String(data);
		    for (var i = 0; i < data.length; i++) {
		      n += data.charCodeAt(i);
		      var h = 0.02519603282416938 * n;
		      n = h >>> 0;
		      h -= n;
		      h *= n;
		      n = h >>> 0;
		      h -= n;
		      n += h * 0x100000000; // 2^32
		    }
		    return (n >>> 0) * 2.3283064365386963e-10; // 2^-32
		  };

		  return mash;
		}


		if (module && module.exports) {
		  module.exports = impl;
		} else {
		  this.alea = impl;
		}

		})(
		  alea,
		  module); 
	} (alea$1));
	return alea$1.exports;
}

var xor128$1 = {exports: {}};

var xor128 = xor128$1.exports;

var hasRequiredXor128;

function requireXor128 () {
	if (hasRequiredXor128) return xor128$1.exports;
	hasRequiredXor128 = 1;
	(function (module) {
		// A Javascript implementaion of the "xor128" prng algorithm by
		// George Marsaglia.  See http://www.jstatsoft.org/v08/i14/paper

		(function(global, module, define) {

		function XorGen(seed) {
		  var me = this, strseed = '';

		  me.x = 0;
		  me.y = 0;
		  me.z = 0;
		  me.w = 0;

		  // Set up generator function.
		  me.next = function() {
		    var t = me.x ^ (me.x << 11);
		    me.x = me.y;
		    me.y = me.z;
		    me.z = me.w;
		    return me.w ^= (me.w >>> 19) ^ t ^ (t >>> 8);
		  };

		  if (seed === (seed | 0)) {
		    // Integer seed.
		    me.x = seed;
		  } else {
		    // String seed.
		    strseed += seed;
		  }

		  // Mix in string seed, then discard an initial batch of 64 values.
		  for (var k = 0; k < strseed.length + 64; k++) {
		    me.x ^= strseed.charCodeAt(k) | 0;
		    me.next();
		  }
		}

		function copy(f, t) {
		  t.x = f.x;
		  t.y = f.y;
		  t.z = f.z;
		  t.w = f.w;
		  return t;
		}

		function impl(seed, opts) {
		  var xg = new XorGen(seed),
		      state = opts && opts.state,
		      prng = function() { return (xg.next() >>> 0) / 0x100000000; };
		  prng.double = function() {
		    do {
		      var top = xg.next() >>> 11,
		          bot = (xg.next() >>> 0) / 0x100000000,
		          result = (top + bot) / (1 << 21);
		    } while (result === 0);
		    return result;
		  };
		  prng.int32 = xg.next;
		  prng.quick = prng;
		  if (state) {
		    if (typeof(state) == 'object') copy(state, xg);
		    prng.state = function() { return copy(xg, {}); };
		  }
		  return prng;
		}

		if (module && module.exports) {
		  module.exports = impl;
		} else {
		  this.xor128 = impl;
		}

		})(
		  xor128,
		  module); 
	} (xor128$1));
	return xor128$1.exports;
}

var xorwow$1 = {exports: {}};

var xorwow = xorwow$1.exports;

var hasRequiredXorwow;

function requireXorwow () {
	if (hasRequiredXorwow) return xorwow$1.exports;
	hasRequiredXorwow = 1;
	(function (module) {
		// A Javascript implementaion of the "xorwow" prng algorithm by
		// George Marsaglia.  See http://www.jstatsoft.org/v08/i14/paper

		(function(global, module, define) {

		function XorGen(seed) {
		  var me = this, strseed = '';

		  // Set up generator function.
		  me.next = function() {
		    var t = (me.x ^ (me.x >>> 2));
		    me.x = me.y; me.y = me.z; me.z = me.w; me.w = me.v;
		    return (me.d = (me.d + 362437 | 0)) +
		       (me.v = (me.v ^ (me.v << 4)) ^ (t ^ (t << 1))) | 0;
		  };

		  me.x = 0;
		  me.y = 0;
		  me.z = 0;
		  me.w = 0;
		  me.v = 0;

		  if (seed === (seed | 0)) {
		    // Integer seed.
		    me.x = seed;
		  } else {
		    // String seed.
		    strseed += seed;
		  }

		  // Mix in string seed, then discard an initial batch of 64 values.
		  for (var k = 0; k < strseed.length + 64; k++) {
		    me.x ^= strseed.charCodeAt(k) | 0;
		    if (k == strseed.length) {
		      me.d = me.x << 10 ^ me.x >>> 4;
		    }
		    me.next();
		  }
		}

		function copy(f, t) {
		  t.x = f.x;
		  t.y = f.y;
		  t.z = f.z;
		  t.w = f.w;
		  t.v = f.v;
		  t.d = f.d;
		  return t;
		}

		function impl(seed, opts) {
		  var xg = new XorGen(seed),
		      state = opts && opts.state,
		      prng = function() { return (xg.next() >>> 0) / 0x100000000; };
		  prng.double = function() {
		    do {
		      var top = xg.next() >>> 11,
		          bot = (xg.next() >>> 0) / 0x100000000,
		          result = (top + bot) / (1 << 21);
		    } while (result === 0);
		    return result;
		  };
		  prng.int32 = xg.next;
		  prng.quick = prng;
		  if (state) {
		    if (typeof(state) == 'object') copy(state, xg);
		    prng.state = function() { return copy(xg, {}); };
		  }
		  return prng;
		}

		if (module && module.exports) {
		  module.exports = impl;
		} else {
		  this.xorwow = impl;
		}

		})(
		  xorwow,
		  module); 
	} (xorwow$1));
	return xorwow$1.exports;
}

var xorshift7$1 = {exports: {}};

var xorshift7 = xorshift7$1.exports;

var hasRequiredXorshift7;

function requireXorshift7 () {
	if (hasRequiredXorshift7) return xorshift7$1.exports;
	hasRequiredXorshift7 = 1;
	(function (module) {
		// A Javascript implementaion of the "xorshift7" algorithm by
		// FranÃ§ois Panneton and Pierre L'ecuyer:
		// "On the Xorgshift Random Number Generators"
		// http://saluc.engr.uconn.edu/refs/crypto/rng/panneton05onthexorshift.pdf

		(function(global, module, define) {

		function XorGen(seed) {
		  var me = this;

		  // Set up generator function.
		  me.next = function() {
		    // Update xor generator.
		    var X = me.x, i = me.i, t, v;
		    t = X[i]; t ^= (t >>> 7); v = t ^ (t << 24);
		    t = X[(i + 1) & 7]; v ^= t ^ (t >>> 10);
		    t = X[(i + 3) & 7]; v ^= t ^ (t >>> 3);
		    t = X[(i + 4) & 7]; v ^= t ^ (t << 7);
		    t = X[(i + 7) & 7]; t = t ^ (t << 13); v ^= t ^ (t << 9);
		    X[i] = v;
		    me.i = (i + 1) & 7;
		    return v;
		  };

		  function init(me, seed) {
		    var j, X = [];

		    if (seed === (seed | 0)) {
		      // Seed state array using a 32-bit integer.
		      X[0] = seed;
		    } else {
		      // Seed state using a string.
		      seed = '' + seed;
		      for (j = 0; j < seed.length; ++j) {
		        X[j & 7] = (X[j & 7] << 15) ^
		            (seed.charCodeAt(j) + X[(j + 1) & 7] << 13);
		      }
		    }
		    // Enforce an array length of 8, not all zeroes.
		    while (X.length < 8) X.push(0);
		    for (j = 0; j < 8 && X[j] === 0; ++j);
		    if (j == 8) X[7] = -1; else X[j];

		    me.x = X;
		    me.i = 0;

		    // Discard an initial 256 values.
		    for (j = 256; j > 0; --j) {
		      me.next();
		    }
		  }

		  init(me, seed);
		}

		function copy(f, t) {
		  t.x = f.x.slice();
		  t.i = f.i;
		  return t;
		}

		function impl(seed, opts) {
		  if (seed == null) seed = +(new Date);
		  var xg = new XorGen(seed),
		      state = opts && opts.state,
		      prng = function() { return (xg.next() >>> 0) / 0x100000000; };
		  prng.double = function() {
		    do {
		      var top = xg.next() >>> 11,
		          bot = (xg.next() >>> 0) / 0x100000000,
		          result = (top + bot) / (1 << 21);
		    } while (result === 0);
		    return result;
		  };
		  prng.int32 = xg.next;
		  prng.quick = prng;
		  if (state) {
		    if (state.x) copy(state, xg);
		    prng.state = function() { return copy(xg, {}); };
		  }
		  return prng;
		}

		if (module && module.exports) {
		  module.exports = impl;
		} else {
		  this.xorshift7 = impl;
		}

		})(
		  xorshift7,
		  module); 
	} (xorshift7$1));
	return xorshift7$1.exports;
}

var xor4096$1 = {exports: {}};

var xor4096 = xor4096$1.exports;

var hasRequiredXor4096;

function requireXor4096 () {
	if (hasRequiredXor4096) return xor4096$1.exports;
	hasRequiredXor4096 = 1;
	(function (module) {
		// A Javascript implementaion of Richard Brent's Xorgens xor4096 algorithm.
		//
		// This fast non-cryptographic random number generator is designed for
		// use in Monte-Carlo algorithms. It combines a long-period xorshift
		// generator with a Weyl generator, and it passes all common batteries
		// of stasticial tests for randomness while consuming only a few nanoseconds
		// for each prng generated.  For background on the generator, see Brent's
		// paper: "Some long-period random number generators using shifts and xors."
		// http://arxiv.org/pdf/1004.3115v1.pdf
		//
		// Usage:
		//
		// var xor4096 = require('xor4096');
		// random = xor4096(1);                        // Seed with int32 or string.
		// assert.equal(random(), 0.1520436450538547); // (0, 1) range, 53 bits.
		// assert.equal(random.int32(), 1806534897);   // signed int32, 32 bits.
		//
		// For nonzero numeric keys, this impelementation provides a sequence
		// identical to that by Brent's xorgens 3 implementaion in C.  This
		// implementation also provides for initalizing the generator with
		// string seeds, or for saving and restoring the state of the generator.
		//
		// On Chrome, this prng benchmarks about 2.1 times slower than
		// Javascript's built-in Math.random().

		(function(global, module, define) {

		function XorGen(seed) {
		  var me = this;

		  // Set up generator function.
		  me.next = function() {
		    var w = me.w,
		        X = me.X, i = me.i, t, v;
		    // Update Weyl generator.
		    me.w = w = (w + 0x61c88647) | 0;
		    // Update xor generator.
		    v = X[(i + 34) & 127];
		    t = X[i = ((i + 1) & 127)];
		    v ^= v << 13;
		    t ^= t << 17;
		    v ^= v >>> 15;
		    t ^= t >>> 12;
		    // Update Xor generator array state.
		    v = X[i] = v ^ t;
		    me.i = i;
		    // Result is the combination.
		    return (v + (w ^ (w >>> 16))) | 0;
		  };

		  function init(me, seed) {
		    var t, v, i, j, w, X = [], limit = 128;
		    if (seed === (seed | 0)) {
		      // Numeric seeds initialize v, which is used to generates X.
		      v = seed;
		      seed = null;
		    } else {
		      // String seeds are mixed into v and X one character at a time.
		      seed = seed + '\0';
		      v = 0;
		      limit = Math.max(limit, seed.length);
		    }
		    // Initialize circular array and weyl value.
		    for (i = 0, j = -32; j < limit; ++j) {
		      // Put the unicode characters into the array, and shuffle them.
		      if (seed) v ^= seed.charCodeAt((j + 32) % seed.length);
		      // After 32 shuffles, take v as the starting w value.
		      if (j === 0) w = v;
		      v ^= v << 10;
		      v ^= v >>> 15;
		      v ^= v << 4;
		      v ^= v >>> 13;
		      if (j >= 0) {
		        w = (w + 0x61c88647) | 0;     // Weyl.
		        t = (X[j & 127] ^= (v + w));  // Combine xor and weyl to init array.
		        i = (0 == t) ? i + 1 : 0;     // Count zeroes.
		      }
		    }
		    // We have detected all zeroes; make the key nonzero.
		    if (i >= 128) {
		      X[(seed && seed.length || 0) & 127] = -1;
		    }
		    // Run the generator 512 times to further mix the state before using it.
		    // Factoring this as a function slows the main generator, so it is just
		    // unrolled here.  The weyl generator is not advanced while warming up.
		    i = 127;
		    for (j = 4 * 128; j > 0; --j) {
		      v = X[(i + 34) & 127];
		      t = X[i = ((i + 1) & 127)];
		      v ^= v << 13;
		      t ^= t << 17;
		      v ^= v >>> 15;
		      t ^= t >>> 12;
		      X[i] = v ^ t;
		    }
		    // Storing state as object members is faster than using closure variables.
		    me.w = w;
		    me.X = X;
		    me.i = i;
		  }

		  init(me, seed);
		}

		function copy(f, t) {
		  t.i = f.i;
		  t.w = f.w;
		  t.X = f.X.slice();
		  return t;
		}
		function impl(seed, opts) {
		  if (seed == null) seed = +(new Date);
		  var xg = new XorGen(seed),
		      state = opts && opts.state,
		      prng = function() { return (xg.next() >>> 0) / 0x100000000; };
		  prng.double = function() {
		    do {
		      var top = xg.next() >>> 11,
		          bot = (xg.next() >>> 0) / 0x100000000,
		          result = (top + bot) / (1 << 21);
		    } while (result === 0);
		    return result;
		  };
		  prng.int32 = xg.next;
		  prng.quick = prng;
		  if (state) {
		    if (state.X) copy(state, xg);
		    prng.state = function() { return copy(xg, {}); };
		  }
		  return prng;
		}

		if (module && module.exports) {
		  module.exports = impl;
		} else {
		  this.xor4096 = impl;
		}

		})(
		  xor4096,                                     // window object or global
		  module); 
	} (xor4096$1));
	return xor4096$1.exports;
}

var tychei$1 = {exports: {}};

var tychei = tychei$1.exports;

var hasRequiredTychei;

function requireTychei () {
	if (hasRequiredTychei) return tychei$1.exports;
	hasRequiredTychei = 1;
	(function (module) {
		// A Javascript implementaion of the "Tyche-i" prng algorithm by
		// Samuel Neves and Filipe Araujo.
		// See https://eden.dei.uc.pt/~sneves/pubs/2011-snfa2.pdf

		(function(global, module, define) {

		function XorGen(seed) {
		  var me = this, strseed = '';

		  // Set up generator function.
		  me.next = function() {
		    var b = me.b, c = me.c, d = me.d, a = me.a;
		    b = (b << 25) ^ (b >>> 7) ^ c;
		    c = (c - d) | 0;
		    d = (d << 24) ^ (d >>> 8) ^ a;
		    a = (a - b) | 0;
		    me.b = b = (b << 20) ^ (b >>> 12) ^ c;
		    me.c = c = (c - d) | 0;
		    me.d = (d << 16) ^ (c >>> 16) ^ a;
		    return me.a = (a - b) | 0;
		  };

		  /* The following is non-inverted tyche, which has better internal
		   * bit diffusion, but which is about 25% slower than tyche-i in JS.
		  me.next = function() {
		    var a = me.a, b = me.b, c = me.c, d = me.d;
		    a = (me.a + me.b | 0) >>> 0;
		    d = me.d ^ a; d = d << 16 ^ d >>> 16;
		    c = me.c + d | 0;
		    b = me.b ^ c; b = b << 12 ^ d >>> 20;
		    me.a = a = a + b | 0;
		    d = d ^ a; me.d = d = d << 8 ^ d >>> 24;
		    me.c = c = c + d | 0;
		    b = b ^ c;
		    return me.b = (b << 7 ^ b >>> 25);
		  }
		  */

		  me.a = 0;
		  me.b = 0;
		  me.c = 2654435769 | 0;
		  me.d = 1367130551;

		  if (seed === Math.floor(seed)) {
		    // Integer seed.
		    me.a = (seed / 0x100000000) | 0;
		    me.b = seed | 0;
		  } else {
		    // String seed.
		    strseed += seed;
		  }

		  // Mix in string seed, then discard an initial batch of 64 values.
		  for (var k = 0; k < strseed.length + 20; k++) {
		    me.b ^= strseed.charCodeAt(k) | 0;
		    me.next();
		  }
		}

		function copy(f, t) {
		  t.a = f.a;
		  t.b = f.b;
		  t.c = f.c;
		  t.d = f.d;
		  return t;
		}
		function impl(seed, opts) {
		  var xg = new XorGen(seed),
		      state = opts && opts.state,
		      prng = function() { return (xg.next() >>> 0) / 0x100000000; };
		  prng.double = function() {
		    do {
		      var top = xg.next() >>> 11,
		          bot = (xg.next() >>> 0) / 0x100000000,
		          result = (top + bot) / (1 << 21);
		    } while (result === 0);
		    return result;
		  };
		  prng.int32 = xg.next;
		  prng.quick = prng;
		  if (state) {
		    if (typeof(state) == 'object') copy(state, xg);
		    prng.state = function() { return copy(xg, {}); };
		  }
		  return prng;
		}

		if (module && module.exports) {
		  module.exports = impl;
		} else {
		  this.tychei = impl;
		}

		})(
		  tychei,
		  module); 
	} (tychei$1));
	return tychei$1.exports;
}

var seedrandom$3 = {exports: {}};

/*
Copyright 2019 David Bau.

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

*/
var seedrandom$2 = seedrandom$3.exports;

var hasRequiredSeedrandom$1;

function requireSeedrandom$1 () {
	if (hasRequiredSeedrandom$1) return seedrandom$3.exports;
	hasRequiredSeedrandom$1 = 1;
	(function (module) {
		(function (global, pool, math) {
		//
		// The following constants are related to IEEE 754 limits.
		//

		var width = 256,        // each RC4 output is 0 <= x < 256
		    chunks = 6,         // at least six RC4 outputs for each double
		    digits = 52,        // there are 52 significant digits in a double
		    rngname = 'random', // rngname: name for Math.random and Math.seedrandom
		    startdenom = math.pow(width, chunks),
		    significance = math.pow(2, digits),
		    overflow = significance * 2,
		    mask = width - 1,
		    nodecrypto;         // node.js crypto module, initialized at the bottom.

		//
		// seedrandom()
		// This is the seedrandom function described above.
		//
		function seedrandom(seed, options, callback) {
		  var key = [];
		  options = (options == true) ? { entropy: true } : (options || {});

		  // Flatten the seed string or build one from local entropy if needed.
		  var shortseed = mixkey(flatten(
		    options.entropy ? [seed, tostring(pool)] :
		    (seed == null) ? autoseed() : seed, 3), key);

		  // Use the seed to initialize an ARC4 generator.
		  var arc4 = new ARC4(key);

		  // This function returns a random double in [0, 1) that contains
		  // randomness in every bit of the mantissa of the IEEE 754 value.
		  var prng = function() {
		    var n = arc4.g(chunks),             // Start with a numerator n < 2 ^ 48
		        d = startdenom,                 //   and denominator d = 2 ^ 48.
		        x = 0;                          //   and no 'extra last byte'.
		    while (n < significance) {          // Fill up all significant digits by
		      n = (n + x) * width;              //   shifting numerator and
		      d *= width;                       //   denominator and generating a
		      x = arc4.g(1);                    //   new least-significant-byte.
		    }
		    while (n >= overflow) {             // To avoid rounding up, before adding
		      n /= 2;                           //   last byte, shift everything
		      d /= 2;                           //   right using integer math until
		      x >>>= 1;                         //   we have exactly the desired bits.
		    }
		    return (n + x) / d;                 // Form the number within [0, 1).
		  };

		  prng.int32 = function() { return arc4.g(4) | 0; };
		  prng.quick = function() { return arc4.g(4) / 0x100000000; };
		  prng.double = prng;

		  // Mix the randomness into accumulated entropy.
		  mixkey(tostring(arc4.S), pool);

		  // Calling convention: what to return as a function of prng, seed, is_math.
		  return (options.pass || callback ||
		      function(prng, seed, is_math_call, state) {
		        if (state) {
		          // Load the arc4 state from the given state if it has an S array.
		          if (state.S) { copy(state, arc4); }
		          // Only provide the .state method if requested via options.state.
		          prng.state = function() { return copy(arc4, {}); };
		        }

		        // If called as a method of Math (Math.seedrandom()), mutate
		        // Math.random because that is how seedrandom.js has worked since v1.0.
		        if (is_math_call) { math[rngname] = prng; return seed; }

		        // Otherwise, it is a newer calling convention, so return the
		        // prng directly.
		        else return prng;
		      })(
		  prng,
		  shortseed,
		  'global' in options ? options.global : (this == math),
		  options.state);
		}

		//
		// ARC4
		//
		// An ARC4 implementation.  The constructor takes a key in the form of
		// an array of at most (width) integers that should be 0 <= x < (width).
		//
		// The g(count) method returns a pseudorandom integer that concatenates
		// the next (count) outputs from ARC4.  Its return value is a number x
		// that is in the range 0 <= x < (width ^ count).
		//
		function ARC4(key) {
		  var t, keylen = key.length,
		      me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];

		  // The empty key [] is treated as [0].
		  if (!keylen) { key = [keylen++]; }

		  // Set up S using the standard key scheduling algorithm.
		  while (i < width) {
		    s[i] = i++;
		  }
		  for (i = 0; i < width; i++) {
		    s[i] = s[j = mask & (j + key[i % keylen] + (t = s[i]))];
		    s[j] = t;
		  }

		  // The "g" method returns the next (count) outputs as one number.
		  (me.g = function(count) {
		    // Using instance members instead of closure state nearly doubles speed.
		    var t, r = 0,
		        i = me.i, j = me.j, s = me.S;
		    while (count--) {
		      t = s[i = mask & (i + 1)];
		      r = r * width + s[mask & ((s[i] = s[j = mask & (j + t)]) + (s[j] = t))];
		    }
		    me.i = i; me.j = j;
		    return r;
		    // For robust unpredictability, the function call below automatically
		    // discards an initial batch of values.  This is called RC4-drop[256].
		    // See http://google.com/search?q=rsa+fluhrer+response&btnI
		  })(width);
		}

		//
		// copy()
		// Copies internal state of ARC4 to or from a plain object.
		//
		function copy(f, t) {
		  t.i = f.i;
		  t.j = f.j;
		  t.S = f.S.slice();
		  return t;
		}
		//
		// flatten()
		// Converts an object tree to nested arrays of strings.
		//
		function flatten(obj, depth) {
		  var result = [], typ = (typeof obj), prop;
		  if (depth && typ == 'object') {
		    for (prop in obj) {
		      try { result.push(flatten(obj[prop], depth - 1)); } catch (e) {}
		    }
		  }
		  return (result.length ? result : typ == 'string' ? obj : obj + '\0');
		}

		//
		// mixkey()
		// Mixes a string seed into a key that is an array of integers, and
		// returns a shortened string seed that is equivalent to the result key.
		//
		function mixkey(seed, key) {
		  var stringseed = seed + '', smear, j = 0;
		  while (j < stringseed.length) {
		    key[mask & j] =
		      mask & ((smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++));
		  }
		  return tostring(key);
		}

		//
		// autoseed()
		// Returns an object for autoseeding, using window.crypto and Node crypto
		// module if available.
		//
		function autoseed() {
		  try {
		    var out;
		    if (nodecrypto && (out = nodecrypto.randomBytes)) {
		      // The use of 'out' to remember randomBytes makes tight minified code.
		      out = out(width);
		    } else {
		      out = new Uint8Array(width);
		      (global.crypto || global.msCrypto).getRandomValues(out);
		    }
		    return tostring(out);
		  } catch (e) {
		    var browser = global.navigator,
		        plugins = browser && browser.plugins;
		    return [+new Date, global, plugins, global.screen, tostring(pool)];
		  }
		}

		//
		// tostring()
		// Converts an array of charcodes to a string
		//
		function tostring(a) {
		  return String.fromCharCode.apply(0, a);
		}

		//
		// When seedrandom.js is loaded, we immediately mix a few bits
		// from the built-in RNG into the entropy pool.  Because we do
		// not want to interfere with deterministic PRNG state later,
		// seedrandom will not call math.random on its own again after
		// initialization.
		//
		mixkey(math.random(), pool);

		//
		// Nodejs and AMD support: export the implementation as a module using
		// either convention.
		//
		if (module.exports) {
		  module.exports = seedrandom;
		  // When in node.js, try using crypto package for autoseeding.
		  try {
		    nodecrypto = require('crypto');
		  } catch (ex) {}
		} else {
		  // When included as a plain script, set up Math.seedrandom global.
		  math['seed' + rngname] = seedrandom;
		}


		// End anonymous scope, and pass initial values.
		})(
		  // global: `self` in browsers (including strict mode and web workers),
		  // otherwise `this` in Node and other environments
		  (typeof self !== 'undefined') ? self : seedrandom$2,
		  [],     // pool: entropy pool starts empty
		  Math    // math: package containing random, pow, and seedrandom
		); 
	} (seedrandom$3));
	return seedrandom$3.exports;
}

var seedrandom$1;
var hasRequiredSeedrandom;

function requireSeedrandom () {
	if (hasRequiredSeedrandom) return seedrandom$1;
	hasRequiredSeedrandom = 1;
	// A library of seedable RNGs implemented in Javascript.
	//
	// Usage:
	//
	// var seedrandom = require('seedrandom');
	// var random = seedrandom(1); // or any seed.
	// var x = random();       // 0 <= x < 1.  Every bit is random.
	// var x = random.quick(); // 0 <= x < 1.  32 bits of randomness.

	// alea, a 53-bit multiply-with-carry generator by Johannes BaagÃ¸e.
	// Period: ~2^116
	// Reported to pass all BigCrush tests.
	var alea = requireAlea();

	// xor128, a pure xor-shift generator by George Marsaglia.
	// Period: 2^128-1.
	// Reported to fail: MatrixRank and LinearComp.
	var xor128 = requireXor128();

	// xorwow, George Marsaglia's 160-bit xor-shift combined plus weyl.
	// Period: 2^192-2^32
	// Reported to fail: CollisionOver, SimpPoker, and LinearComp.
	var xorwow = requireXorwow();

	// xorshift7, by FranÃ§ois Panneton and Pierre L'ecuyer, takes
	// a different approach: it adds robustness by allowing more shifts
	// than Marsaglia's original three.  It is a 7-shift generator
	// with 256 bits, that passes BigCrush with no systmatic failures.
	// Period 2^256-1.
	// No systematic BigCrush failures reported.
	var xorshift7 = requireXorshift7();

	// xor4096, by Richard Brent, is a 4096-bit xor-shift with a
	// very long period that also adds a Weyl generator. It also passes
	// BigCrush with no systematic failures.  Its long period may
	// be useful if you have many generators and need to avoid
	// collisions.
	// Period: 2^4128-2^32.
	// No systematic BigCrush failures reported.
	var xor4096 = requireXor4096();

	// Tyche-i, by Samuel Neves and Filipe Araujo, is a bit-shifting random
	// number generator derived from ChaCha, a modern stream cipher.
	// https://eden.dei.uc.pt/~sneves/pubs/2011-snfa2.pdf
	// Period: ~2^127
	// No systematic BigCrush failures reported.
	var tychei = requireTychei();

	// The original ARC4-based prng included in this library.
	// Period: ~2^1600
	var sr = requireSeedrandom$1();

	sr.alea = alea;
	sr.xor128 = xor128;
	sr.xorwow = xorwow;
	sr.xorshift7 = xorshift7;
	sr.xor4096 = xor4096;
	sr.tychei = tychei;

	seedrandom$1 = sr;
	return seedrandom$1;
}

var seedrandomExports = requireSeedrandom();
const seedrandom = /*@__PURE__*/getDefaultExportFromCjs(seedrandomExports);

export { hydrateWorkflowReturnValue as $, stepLogger as A, EventConsumerResult as B, hydrateStepReturnValue as C, DeploymentId as D, ERROR_SLUGS as E, FatalError as F, seedrandom as G, HookId as H, webhookLogger as I, parseDurationToDate as J, WorkflowEventsCount as K, getPort as L, monotonicFactory as M, EventsConsumer as N, WORKFLOW_USE_STEP as O, WORKFLOW_CREATE_HOOK as P, WORKFLOW_SLEEP as Q, WORKFLOW_GET_STREAM_ID as R, dehydrateWorkflowReturnValue as S, WorkflowResultType as T, BODY_INIT_SYMBOL as U, getWorldHandlers as V, WorkflowServerWritableStream as W, WorkflowInvokePayloadSchema as X, withTraceContext as Y, StepInvokePayloadSchema as Z, getExternalRevivers as _, getSerializeStream as a, WorkflowRunCancelledError as a0, QueueName as a1, WorkflowTracePropagated as a2, WorkflowStartedAt as a3, buildWorkflowSuspensionMessage as a4, dehydrateStepArguments as a5, WorkflowAPIError as a6, WorkflowStepsCreated as a7, WorkflowErrorMessage as a8, WorkflowErrorName as a9, StepAttempt as aa, StepName as ab, getStepFunction as ac, StepTracePropagated as ad, StepMaxRetries as ae, StepId as af, runtimeLogger as ag, StepStatus as ah, StepRetryTimeoutSeconds as ai, StepSkipReason as aj, StepSkipped as ak, StepArgumentsCount as al, StepResultType as am, StepErrorMessage as an, StepErrorName as ao, StepFatalError as ap, StepRetryExhausted as aq, RetryableError as ar, StepRetryWillRetry as as, requireTokenError as at, getExternalReducers as b, getWorld as c, WEBHOOK_RESPONSE_WRITABLE as d, WorkflowRuntimeError as e, WorkflowRunId as f, getWorkflowRunStreamId as g, hydrateStepArguments as h, HookToken as i, dehydrateStepReturnValue as j, functionsExports as k, WorkflowName as l, getSpanContextForTraceCarrier as m, HookFound as n, WorkflowOperation as o, WorkflowArgumentsCount as p, dehydrateWorkflowArguments as q, registerStepFunction as r, serializeTraceCarrier as s, trace as t, WorkflowRunStatus as u, hydrateWorkflowArguments as v, waitedUntil as w, WorkflowRunNotCompletedError as x, WorkflowRunFailedError as y, withResolvers as z };
